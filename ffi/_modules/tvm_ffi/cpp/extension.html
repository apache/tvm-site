
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>tvm_ffi.cpp.extension &#8212; tvm-ffi</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/collapsible-lists/css/tree_view.css?v=a885cde7" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=38aa6179" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=3a1e5d7d"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../_static/collapsible-lists/js/CollapsibleLists.compressed.js?v=73120307"></script>
    <script src="../../../_static/collapsible-lists/js/apply-collapsible-lists.js?v=660e4f45"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="../../../_static/downloads/require.min.js"></script>
    <script src="../../../_static/downloads/d3.min.js"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.12.1/dist/mermaid.esm.min.mjs";





const initStyles = () => {
    const defaultStyle = document.createElement('style');
    defaultStyle.textContent = `pre.mermaid {
    /* Same as .mermaid-container > pre */
    display: block;
    width: 100%;
}

pre.mermaid > svg {
    /* Same as .mermaid-container > pre > svg */
    height: 500px;
    width: 100%;
    max-width: 100% !important;
}`;
    document.head.appendChild(defaultStyle);

    const fullscreenStyle = document.createElement('style');
    fullscreenStyle.textContent = `.mermaid-container {
    display: flex;
    flex-direction: row;
    width: 100%;
}

.mermaid-container > pre {
    display: block;
    width: 100%;
}

.mermaid-container > pre > svg {
    height: 500px;
    width: 100%;
    max-width: 100% !important;
}

.mermaid-fullscreen-btn {
    width: 28px;
    height: 28px;
    background: rgba(255, 255, 255, 0.95);
    border: 1px solid rgba(0, 0, 0, 0.3);
    border-radius: 4px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.2s;
    box-shadow: 0 2px 6px rgba(0, 0, 0, 0.2);
    font-size: 14px;
    line-height: 1;
    padding: 0;
    color: #333;
}

.mermaid-fullscreen-btn:hover {
    opacity: 100% !important;
    background: rgba(255, 255, 255, 1);
    box-shadow: 0 3px 10px rgba(0, 0, 0, 0.3);
    transform: scale(1.1);
}

.mermaid-fullscreen-btn.dark-theme {
    background: rgba(50, 50, 50, 0.95);
    border: 1px solid rgba(255, 255, 255, 0.3);
    color: #e0e0e0;
}

.mermaid-fullscreen-btn.dark-theme:hover {
    background: rgba(60, 60, 60, 1);
    box-shadow: 0 3px 10px rgba(255, 255, 255, 0.2);
}

.mermaid-fullscreen-modal {
    display: none;
    position: fixed !important;
    top: 0 !important;
    left: 0 !important;
    width: 95vw;
    height: 100vh;
    background: rgba(255, 255, 255, 0.98);
    z-index: 9999;
    padding: 20px;
    overflow: auto;
}

.mermaid-fullscreen-modal.dark-theme {
    background: rgba(0, 0, 0, 0.98);
}

.mermaid-fullscreen-modal.active {
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen {
    position: relative;
    width: 95vw;
    height: 90vh;
    max-width: 95vw;
    max-height: 90vh;
    background: white;
    border-radius: 8px;
    padding: 20px;
    box-shadow: 0 10px 40px rgba(0, 0, 0, 0.3);
    overflow: auto;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen.dark-theme {
    background: #1a1a1a;
    box-shadow: 0 10px 40px rgba(0, 0, 0, 0.8);
}

.mermaid-container-fullscreen pre.mermaid {
    width: 100%;
    height: 100%;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen .mermaid svg {
    height: 100% !important;
    width: 100% !important;
    cursor: grab;
}

.mermaid-fullscreen-close {
    position: fixed !important;
    top: 20px !important;
    right: 20px !important;
    width: 40px;
    height: 40px;
    background: rgba(255, 255, 255, 0.95);
    border: 1px solid rgba(0, 0, 0, 0.2);
    border-radius: 50%;
    cursor: pointer;
    z-index: 10000;
    display: flex;
    align-items: center;
    justify-content: center;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
    transition: all 0.2s;
    font-size: 24px;
    line-height: 1;
    color: #333;
}

.mermaid-fullscreen-close:hover {
    background: white;
    box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4);
    transform: scale(1.1);
}

.mermaid-fullscreen-close.dark-theme {
    background: rgba(50, 50, 50, 0.95);
    border: 1px solid rgba(255, 255, 255, 0.2);
    color: #e0e0e0;
}

.mermaid-fullscreen-close.dark-theme:hover {
    background: rgba(60, 60, 60, 1);
    box-shadow: 0 6px 16px rgba(255, 255, 255, 0.2);
}

.mermaid-fullscreen-modal .mermaid-fullscreen-btn {
    display: none !important;
}`;
    document.head.appendChild(fullscreenStyle);
}

// Detect if page has dark background
const isDarkTheme = () => {
    // We use a set of heuristics:
    // 1. Check for common dark mode classes or attributes
    // 2. Check computed background color brightness
    if (document.documentElement.classList.contains('dark') ||
        document.documentElement.getAttribute('data-theme') === 'dark' ||
        document.body.classList.contains('dark') ||
        document.body.getAttribute('data-theme') === 'dark') {
        // console.log("Dark theme detected via class/attribute");
        return true;
    }
    if (document.documentElement.classList.contains('light') ||
        document.documentElement.getAttribute('data-theme') === 'light' ||
        document.body.classList.contains('light') ||
        document.body.getAttribute('data-theme') === 'light') {
        // console.log("Light theme detected via class/attribute");
        return false;
    }
    if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
        // console.log("Dark theme detected via prefers-color-scheme");
        return true;
    }
    const bgColor = window.getComputedStyle(document.body).backgroundColor;
    const match = bgColor.match(/rgb\((\d+),\s*(\d+),\s*(\d+)/);
    if (match) {
        const r = parseInt(match[1]);
        const g = parseInt(match[2]);
        const b = parseInt(match[3]);
        const brightness = (r * 299 + g * 587 + b * 114) / 1000;
        // console.log("Background color brightness:", brightness);
        return brightness < 128;
    }
    // console.log("No dark or light theme detected, defaulting to light theme");
    return false;
};

let darkTheme = isDarkTheme();
let modal = null;
let modalContent = null;
let previousScrollOffset = [window.scrollX, window.scrollY];

const runMermaid = async (rerun) => {
    console.log("Running mermaid diagrams, rerun =", rerun);
    // clear all existing mermaid charts
    let all_mermaids = document.querySelectorAll(".mermaid");

    if (rerun) {
        all_mermaids.forEach((el) => {
            if(!el.hasAttribute("data-original-code")) {
                // store original code
                // console.log(`Storing original code for first run: `, el.innerHTML);
                el.setAttribute('data-original-code', el.innerHTML);
            }
            if(el.getAttribute("data-processed") === "true") {
                // remove and restore original
                el.removeAttribute("data-processed");
                // console.log(`Restoring original code for re-run: `, el.getAttribute('data-original-code'));
                el.innerHTML = el.getAttribute('data-original-code');
            } else {
                // store original code
                // console.log(`Storing original code for re-run: `, el.innerHTML);
                el.setAttribute('data-original-code', el.innerHTML);
            }
        });
        await mermaid.run();
    }

    all_mermaids = document.querySelectorAll(".mermaid");
    const mermaids_processed = document.querySelectorAll(".mermaid[data-processed='true']");

    if ("False" === "True") {
        const mermaids_to_add_zoom = -1 === -1 ? all_mermaids.length : -1;
        if(mermaids_to_add_zoom > 0) {
            var svgs = d3.selectAll("");
            if(all_mermaids.length !== mermaids_processed.length) {
                setTimeout(() => runMermaid(false), 200);
                return;
            } else if(svgs.size() !== mermaids_to_add_zoom) {
                setTimeout(() => runMermaid(false), 200);
                return;
            } else {
                svgs.each(function() {
                    var svg = d3.select(this);
                    svg.html("<g class='wrapper'>" + svg.html() + "</g>");
                    var inner = svg.select("g");
                    var zoom = d3.zoom().on("zoom", function(event) {
                        inner.attr("transform", event.transform);
                    });
                    svg.call(zoom);
                });
            }
        }
    } else if(all_mermaids.length !== mermaids_processed.length) {
        // Wait for mermaid to process all diagrams
        setTimeout(() => runMermaid(false), 200);
        return;
    }

    // Stop here if not adding fullscreen capability
    if ("True" !== "True") return;

    if (modal !== null ) {
        // Destroy existing modal
        modal.remove();
        modal = null;
        modalContent = null;
    }

    modal = document.createElement('div');
    modal.className = 'mermaid-fullscreen-modal' + (darkTheme ? ' dark-theme' : '');
    modal.setAttribute('role', 'dialog');
    modal.setAttribute('aria-modal', 'true');
    modal.setAttribute('aria-label', 'Fullscreen diagram viewer');
    modal.innerHTML = `
        <button class="mermaid-fullscreen-close${darkTheme ? ' dark-theme' : ''}" aria-label="Close fullscreen">✕</button>
        <div class="mermaid-container-fullscreen${darkTheme ? ' dark-theme' : ''}"></div>
    `;
    document.body.appendChild(modal);

    modalContent = modal.querySelector('.mermaid-container-fullscreen');
    const closeBtn = modal.querySelector('.mermaid-fullscreen-close');

    const closeModal = () => {
        modal.classList.remove('active');
        modalContent.innerHTML = '';
        document.body.style.overflow = ''
        window.scrollTo({left: previousScrollOffset[0], top: previousScrollOffset[1], behavior: 'instant'});
    };

    closeBtn.addEventListener('click', closeModal);
    modal.addEventListener('click', (e) => {
        if (e.target === modal) closeModal();
    });
    document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape' && modal.classList.contains('active')) {
            closeModal();
        }
    });

    document.querySelectorAll('.mermaid').forEach((mermaidDiv) => {
        if (mermaidDiv.parentNode.classList.contains('mermaid-container') ||
            mermaidDiv.closest('.mermaid-fullscreen-modal')) {
            // Already processed, adjust button class if needed
            const existingBtn = mermaidDiv.parentNode.querySelector('.mermaid-fullscreen-btn');
            if (existingBtn) {
                existingBtn.className = 'mermaid-fullscreen-btn' + (darkTheme ? ' dark-theme' : '');
            }
            return;
        }

        const container = document.createElement('div');
        container.className = 'mermaid-container';
        mermaidDiv.parentNode.insertBefore(container, mermaidDiv);
        container.appendChild(mermaidDiv);

        const fullscreenBtn = document.createElement('button');
        fullscreenBtn.className = 'mermaid-fullscreen-btn' + (darkTheme ? ' dark-theme' : '');
        fullscreenBtn.setAttribute('aria-label', 'View diagram in fullscreen');
        fullscreenBtn.textContent = '⛶';
        fullscreenBtn.style.opacity = '50%';

        // Calculate dynamic position based on diagram's margin and padding
        const diagramStyle = window.getComputedStyle(mermaidDiv);
        const marginTop = parseFloat(diagramStyle.marginTop) || 0;
        const marginRight = parseFloat(diagramStyle.marginRight) || 0;
        const paddingTop = parseFloat(diagramStyle.paddingTop) || 0;
        const paddingRight = parseFloat(diagramStyle.paddingRight) || 0;
        fullscreenBtn.style.top = `${marginTop + paddingTop + 4}px`;
        fullscreenBtn.style.right = `${marginRight + paddingRight + 4}px`;

        fullscreenBtn.addEventListener('click', () => {
            previousScrollOffset = [window.scroll, window.scrollY];
            const clone = mermaidDiv.cloneNode(true);
            modalContent.innerHTML = '';
            modalContent.appendChild(clone);

            const svg = clone.querySelector('svg');
            if (svg) {
                svg.removeAttribute('width');
                svg.removeAttribute('height');
                svg.style.width = '100%';
                svg.style.height = 'auto';
                svg.style.maxWidth = '100%';
                svg.style.sdisplay = 'block';

                if ("False" === "True") {
                    setTimeout(() => {
                        const g = svg.querySelector('g');
                        if (g) {
                            var svgD3 = d3.select(svg);
                            svgD3.html("<g class='wrapper'>" + svgD3.html() + "</g>");
                            var inner = svgD3.select("g");
                            var zoom = d3.zoom().on("zoom", function(event) {
                                inner.attr("transform", event.transform);
                            });
                            svgD3.call(zoom);
                        }
                    }, 100);
                }
            }

            modal.classList.add('active');
            document.body.style.overflow = 'hidden';
        });
        container.appendChild(fullscreenBtn);
    });
};

const load = async () => {
    initStyles();

    await runMermaid(true);

    const reRunIfThemeChanges = async () => {
        const newDarkTheme = isDarkTheme();
        if (newDarkTheme !== darkTheme) {
            darkTheme = newDarkTheme;
            console.log("Theme change detected, re-running mermaid with", darkTheme ? "dark" : "default", "theme");
            await mermaid.initialize(
                {...JSON.parse(
                    `{"startOnLoad": false}`
                ),
                ...{ darkMode: darkTheme, theme: darkTheme ? 'dark' : 'default' },
                }
            );
            await runMermaid(true);
        }
    };

    // Update theme classes when theme changes
    const themeObserver = new MutationObserver(reRunIfThemeChanges);
    themeObserver.observe(document.documentElement, {
        attributes: true,
        attributeFilter: ['class', 'style', 'data-theme']
    });
    themeObserver.observe(document.body, {
        attributes: true,
        attributeFilter: ['class', 'style', 'data-theme']
    });
};





console.log("Initializing mermaid with", darkTheme ? "dark" : "default", "theme");
mermaid.initialize(
    {...JSON.parse(
        `{"startOnLoad": false}`
    ),
    ...{ darkMode: darkTheme, theme: darkTheme ? 'dark' : 'default' },
    }
);

window.addEventListener("load", load);</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/tvm_ffi/cpp/extension';</script>
    <link rel="icon" href="https://tvm.apache.org/images/logo/tvm-logo-square.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Feb 08, 2026"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">tvm-ffi</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../get_started/quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../get_started/stable_c_abi.html">Stable C ABI</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../guides/export_func_cls.html">Export Functions and Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guides/kernel_library_guide.html">Kernel Library Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guides/compiler_integration.html">Compiler Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guides/cubin_launcher.html">CUBIN Launcher Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guides/python_lang_guide.html">Python Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guides/cpp_lang_guide.html">C++ Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guides/rust_lang_guide.html">Rust Guide</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Concepts</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../concepts/abi_overview.html">ABI Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../concepts/any.html">Any and AnyView</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../concepts/object_and_class.html">Object and Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../concepts/tensor.html">Tensor and DLPack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../concepts/func_module.html">Function and Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../concepts/exception_handling.html">Exception Handling</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Packaging</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../packaging/python_packaging.html">Python Packaging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../packaging/stubgen.html">Stub Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../packaging/cpp_tooling.html">C++ Tooling</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../reference/python/index.html">Python API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.Object.html">tvm_ffi.Object</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.Tensor.html">tvm_ffi.Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.from_dlpack.html">tvm_ffi.from_dlpack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.Shape.html">tvm_ffi.Shape</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.dtype.html">tvm_ffi.dtype</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.Device_class.html">tvm_ffi.Device</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.DLDeviceType.html">tvm_ffi.DLDeviceType</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.device_function.html">tvm_ffi.device</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.Function.html">tvm_ffi.Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.Module.html">tvm_ffi.Module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.system_lib.html">tvm_ffi.system_lib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.load_module.html">tvm_ffi.load_module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.Array.html">tvm_ffi.Array</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.Map.html">tvm_ffi.Map</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.register_error.html">tvm_ffi.register_error</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.register_object.html">tvm_ffi.register_object</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.register_global_func.html">tvm_ffi.register_global_func</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.get_global_func.html">tvm_ffi.get_global_func</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.get_global_func_metadata.html">tvm_ffi.get_global_func_metadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.init_ffi_api.html">tvm_ffi.init_ffi_api</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.remove_global_func.html">tvm_ffi.remove_global_func</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.StreamContext.html">tvm_ffi.StreamContext</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.use_torch_stream.html">tvm_ffi.use_torch_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.use_raw_stream.html">tvm_ffi.use_raw_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.get_raw_stream.html">tvm_ffi.get_raw_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/cpp/generated/tvm_ffi.cpp.load_inline.html">tvm_ffi.cpp.load_inline</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/cpp/generated/tvm_ffi.cpp.build_inline.html">tvm_ffi.cpp.build_inline</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/cpp/generated/tvm_ffi.cpp.load.html">tvm_ffi.cpp.load</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/cpp/generated/tvm_ffi.cpp.build.html">tvm_ffi.cpp.build</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/cpp/generated/tvm_ffi.libinfo.load_lib_module.html">tvm_ffi.libinfo.load_lib_module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/cpp/generated/tvm_ffi.cpp.nvrtc.nvrtc_compile.html">tvm_ffi.cpp.nvrtc.nvrtc_compile</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.serialization.from_json_graph_str.html">tvm_ffi.serialization.from_json_graph_str</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.serialization.to_json_graph_str.html">tvm_ffi.serialization.to_json_graph_str</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.access_path.AccessKind.html">tvm_ffi.access_path.AccessKind</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.access_path.AccessPath.html">tvm_ffi.access_path.AccessPath</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.access_path.AccessStep.html">tvm_ffi.access_path.AccessStep</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.convert.html">tvm_ffi.convert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/python/generated/tvm_ffi.ObjectConvertible.html">tvm_ffi.ObjectConvertible</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/cpp/index.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/rust/index.html">Rust API</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Manual</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../dev/source_build.html">Build from Source</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dev/doc_build.html">Build This Doc Site</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dev/ci_cd.html">Reproduce CI/CD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dev/release_process.html">Release Process</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/apache/tvm-ffi" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for tvm_ffi.cpp.extension</h1><div class="highlight"><pre>
<span></span><span class="c1"># Licensed to the Apache Software Foundation (ASF) under one</span>
<span class="c1"># or more contributor license agreements.  See the NOTICE file</span>
<span class="c1"># distributed with this work for additional information</span>
<span class="c1"># regarding copyright ownership.  The ASF licenses this file</span>
<span class="c1"># to you under the Apache License, Version 2.0 (the</span>
<span class="c1"># &quot;License&quot;); you may not use this file except in compliance</span>
<span class="c1"># with the License.  You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#   http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing,</span>
<span class="c1"># software distributed under the License is distributed on an</span>
<span class="c1"># &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</span>
<span class="c1"># KIND, either express or implied.  See the License for the</span>
<span class="c1"># specific language governing permissions and limitations</span>
<span class="c1"># under the License.</span>
<span class="sd">&quot;&quot;&quot;Build and load C++/CUDA sources into a tvm_ffi Module using Ninja.&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">functools</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">hashlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">shutil</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Sequence</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">contextlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">nullcontext</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">tvm_ffi.libinfo</span><span class="w"> </span><span class="kn">import</span> <span class="n">find_dlpack_include_path</span><span class="p">,</span> <span class="n">find_include_path</span><span class="p">,</span> <span class="n">find_libtvm_ffi</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tvm_ffi.module</span><span class="w"> </span><span class="kn">import</span> <span class="n">Module</span><span class="p">,</span> <span class="n">load_module</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tvm_ffi.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">FileLock</span>

<span class="n">IS_WINDOWS</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">&quot;win32&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_hash_sources</span><span class="p">(</span>
    <span class="n">cpp_source</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cuda_source</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cpp_files</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cuda_files</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">functions</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
    <span class="n">extra_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">extra_cuda_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">extra_ldflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">extra_include_paths</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">embed_cubin</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate a unique hash for the given sources and functions.&quot;&quot;&quot;</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">sha256</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_hash</span><span class="p">(</span><span class="n">obj</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">obj</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">m</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;None&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">m</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;str&quot;</span><span class="p">)</span>
            <span class="n">m</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">))</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">):</span>
            <span class="n">m</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;bytes&quot;</span><span class="p">)</span>
            <span class="n">m</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
            <span class="n">m</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Mapping&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                <span class="n">item</span> <span class="o">=</span> <span class="n">obj</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                <span class="n">_hash</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                <span class="n">_hash</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="n">m</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Sequence&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">:</span>
                <span class="n">_hash</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">_hash</span><span class="p">(</span>
        <span class="p">(</span>
            <span class="n">cpp_source</span><span class="p">,</span>
            <span class="n">cuda_source</span><span class="p">,</span>
            <span class="nb">sorted</span><span class="p">(</span><span class="n">cpp_files</span><span class="p">)</span> <span class="k">if</span> <span class="n">cpp_files</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="nb">sorted</span><span class="p">(</span><span class="n">cuda_files</span><span class="p">)</span> <span class="k">if</span> <span class="n">cuda_files</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">functions</span><span class="p">,</span>
            <span class="n">extra_cflags</span><span class="p">,</span>
            <span class="n">extra_cuda_cflags</span><span class="p">,</span>
            <span class="n">extra_ldflags</span><span class="p">,</span>
            <span class="n">extra_include_paths</span><span class="p">,</span>
            <span class="n">embed_cubin</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">m</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()[:</span><span class="mi">16</span><span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_maybe_write</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">content</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Write content to path if it does not already exist with the same content.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
        <span class="k">with</span> <span class="n">p</span><span class="o">.</span><span class="n">open</span><span class="p">()</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">existing_content</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">existing_content</span> <span class="o">==</span> <span class="n">content</span><span class="p">:</span>
            <span class="k">return</span>
    <span class="k">with</span> <span class="n">p</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>


<span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_find_cuda_home</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Find the CUDA install path.&quot;&quot;&quot;</span>
    <span class="c1"># Guess #1</span>
    <span class="n">cuda_home</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;CUDA_HOME&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;CUDA_PATH&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cuda_home</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Guess #2</span>
        <span class="n">nvcc_path</span> <span class="o">=</span> <span class="n">shutil</span><span class="o">.</span><span class="n">which</span><span class="p">(</span><span class="s2">&quot;nvcc&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nvcc_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cuda_home</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">nvcc_path</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Guess #3</span>
            <span class="k">if</span> <span class="n">IS_WINDOWS</span><span class="p">:</span>
                <span class="n">cuda_root</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA&quot;</span><span class="p">)</span>
                <span class="n">cuda_homes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cuda_root</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;v*.*&quot;</span><span class="p">))</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cuda_homes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;Could not find CUDA installation. Please set CUDA_HOME environment variable.&quot;</span>
                    <span class="p">)</span>
                <span class="n">cuda_home</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">cuda_homes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cuda_home</span> <span class="o">=</span> <span class="s2">&quot;/usr/local/cuda&quot;</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">Path</span><span class="p">(</span><span class="n">cuda_home</span><span class="p">)</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Could not find CUDA installation. Please set CUDA_HOME environment variable.&quot;</span>
                <span class="p">)</span>
    <span class="k">return</span> <span class="n">cuda_home</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_get_cuda_target</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the CUDA target architecture flag.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s2">&quot;TVM_FFI_CUDA_ARCH_LIST&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
        <span class="n">arch_list</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TVM_FFI_CUDA_ARCH_LIST&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>  <span class="c1"># e.g., &quot;8.9 9.0a&quot;</span>
        <span class="n">flags</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">arch</span> <span class="ow">in</span> <span class="n">arch_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">arch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">))</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid CUDA architecture: </span><span class="si">{</span><span class="n">arch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">major</span><span class="p">,</span> <span class="n">minor</span> <span class="o">=</span> <span class="n">arch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
            <span class="n">flags</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;-gencode=arch=compute_</span><span class="si">{</span><span class="n">major</span><span class="si">}{</span><span class="n">minor</span><span class="si">}</span><span class="s2">,code=sm_</span><span class="si">{</span><span class="n">major</span><span class="si">}{</span><span class="n">minor</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">flags</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">status</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nvidia-smi&quot;</span><span class="p">,</span> <span class="s2">&quot;--query-gpu=compute_cap&quot;</span><span class="p">,</span> <span class="s2">&quot;--format=csv,noheader&quot;</span><span class="p">],</span>
                <span class="n">capture_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">check</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">compute_cap</span> <span class="o">=</span> <span class="n">status</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">major</span><span class="p">,</span> <span class="n">minor</span> <span class="o">=</span> <span class="n">compute_cap</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;-gencode=arch=compute_</span><span class="si">{</span><span class="n">major</span><span class="si">}{</span><span class="n">minor</span><span class="si">}</span><span class="s2">,code=sm_</span><span class="si">{</span><span class="n">major</span><span class="si">}{</span><span class="n">minor</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># fallback to a reasonable default</span>
            <span class="k">return</span> <span class="s2">&quot;-gencode=arch=compute_70,code=sm_70&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_run_command_in_dev_prompt</span><span class="p">(</span>
    <span class="n">args</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">cwd</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">capture_output</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CompletedProcess</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Locates the Developer Command Prompt and runs a command within its environment.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Path to vswhere.exe</span>
        <span class="n">vswhere_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span>
            <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ProgramFiles(x86)&quot;</span><span class="p">,</span> <span class="s2">&quot;C:</span><span class="se">\\</span><span class="s2">Program Files (x86)&quot;</span><span class="p">))</span>
            <span class="o">/</span> <span class="s2">&quot;Microsoft Visual Studio&quot;</span>
            <span class="o">/</span> <span class="s2">&quot;Installer&quot;</span>
            <span class="o">/</span> <span class="s2">&quot;vswhere.exe&quot;</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">Path</span><span class="p">(</span><span class="n">vswhere_path</span><span class="p">)</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="s2">&quot;vswhere.exe not found.&quot;</span><span class="p">)</span>

        <span class="c1"># Find the Visual Studio installation path</span>
        <span class="n">vs_install_path</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">vswhere_path</span><span class="p">,</span>
                <span class="s2">&quot;-latest&quot;</span><span class="p">,</span>
                <span class="s2">&quot;-prerelease&quot;</span><span class="p">,</span>
                <span class="s2">&quot;-products&quot;</span><span class="p">,</span>
                <span class="s2">&quot;*&quot;</span><span class="p">,</span>
                <span class="s2">&quot;-property&quot;</span><span class="p">,</span>
                <span class="s2">&quot;installationPath&quot;</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="n">capture_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">text</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">check</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">vs_install_path</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="s2">&quot;No Visual Studio installation found.&quot;</span><span class="p">)</span>

        <span class="c1"># Construct the path to the VsDevCmd.bat file</span>
        <span class="n">vsdevcmd_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">vs_install_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;Common7&quot;</span> <span class="o">/</span> <span class="s2">&quot;Tools&quot;</span> <span class="o">/</span> <span class="s2">&quot;VsDevCmd.bat&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">Path</span><span class="p">(</span><span class="n">vsdevcmd_path</span><span class="p">)</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;VsDevCmd.bat not found at: </span><span class="si">{</span><span class="n">vsdevcmd_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Use cmd.exe to run the batch file and then your command.</span>
        <span class="c1"># The /k flag keeps the command prompt open after the batch file runs.</span>
        <span class="c1"># The &quot;&amp;&quot; symbol chains the commands.</span>
        <span class="n">cmd_command</span> <span class="o">=</span> <span class="s1">&#39;&quot;</span><span class="si">{vsdevcmd_path}</span><span class="s1">&quot; -arch=x64 &amp; </span><span class="si">{command}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">vsdevcmd_path</span><span class="o">=</span><span class="n">vsdevcmd_path</span><span class="p">,</span> <span class="n">command</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Execute the command in a new shell</span>
        <span class="k">return</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="n">cmd_command</span><span class="p">,</span> <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cwd</span><span class="o">=</span><span class="n">cwd</span><span class="p">,</span> <span class="n">capture_output</span><span class="o">=</span><span class="n">capture_output</span><span class="p">,</span> <span class="n">shell</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="k">except</span> <span class="p">(</span><span class="ne">FileNotFoundError</span><span class="p">,</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;Failed to run the following command in MSVC developer environment: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_generate_ninja_build</span><span class="p">(</span>  <span class="c1"># noqa: PLR0915, PLR0912</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">with_cuda</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">extra_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">extra_cuda_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">extra_ldflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">extra_include_paths</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">cpp_files</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">cuda_files</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">embed_cubin</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate the content of build.ninja for building the module.&quot;&quot;&quot;</span>
    <span class="n">default_include_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">find_include_path</span><span class="p">(),</span> <span class="n">find_dlpack_include_path</span><span class="p">()]</span>
    <span class="n">tvm_ffi_lib</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">find_libtvm_ffi</span><span class="p">())</span>
    <span class="n">tvm_ffi_lib_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">tvm_ffi_lib</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span>
    <span class="n">tvm_ffi_lib_name</span> <span class="o">=</span> <span class="n">tvm_ffi_lib</span><span class="o">.</span><span class="n">stem</span>
    <span class="k">if</span> <span class="n">IS_WINDOWS</span><span class="p">:</span>
        <span class="n">default_cflags</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;/std:c++17&quot;</span><span class="p">,</span>
            <span class="s2">&quot;/MD&quot;</span><span class="p">,</span>
            <span class="s2">&quot;/wd4819&quot;</span><span class="p">,</span>
            <span class="s2">&quot;/wd4251&quot;</span><span class="p">,</span>
            <span class="s2">&quot;/wd4244&quot;</span><span class="p">,</span>
            <span class="s2">&quot;/wd4267&quot;</span><span class="p">,</span>
            <span class="s2">&quot;/wd4275&quot;</span><span class="p">,</span>
            <span class="s2">&quot;/wd4018&quot;</span><span class="p">,</span>
            <span class="s2">&quot;/wd4190&quot;</span><span class="p">,</span>
            <span class="s2">&quot;/wd4624&quot;</span><span class="p">,</span>
            <span class="s2">&quot;/wd4067&quot;</span><span class="p">,</span>
            <span class="s2">&quot;/wd4068&quot;</span><span class="p">,</span>
            <span class="s2">&quot;/EHsc&quot;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">default_cuda_cflags</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;-Xcompiler&quot;</span><span class="p">,</span> <span class="s2">&quot;/std:c++17&quot;</span><span class="p">,</span> <span class="s2">&quot;/O2&quot;</span><span class="p">]</span>
        <span class="n">default_ldflags</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;/DLL&quot;</span><span class="p">,</span>
            <span class="sa">f</span><span class="s2">&quot;/LIBPATH:</span><span class="si">{</span><span class="n">tvm_ffi_lib_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tvm_ffi_lib_name</span><span class="si">}</span><span class="s2">.lib&quot;</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">default_cflags</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;-std=c++17&quot;</span><span class="p">,</span> <span class="s2">&quot;-fPIC&quot;</span><span class="p">,</span> <span class="s2">&quot;-O2&quot;</span><span class="p">]</span>
        <span class="n">default_cuda_cflags</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;-Xcompiler&quot;</span><span class="p">,</span> <span class="s2">&quot;-fPIC&quot;</span><span class="p">,</span> <span class="s2">&quot;-std=c++17&quot;</span><span class="p">,</span> <span class="s2">&quot;-O2&quot;</span><span class="p">]</span>
        <span class="n">default_ldflags</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;-shared&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;-L</span><span class="si">{</span><span class="n">tvm_ffi_lib_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;-ltvm_ffi&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">with_cuda</span><span class="p">:</span>
            <span class="c1"># determine the compute capability of the current GPU</span>
            <span class="n">default_cuda_cflags</span> <span class="o">+=</span> <span class="p">[</span><span class="n">_get_cuda_target</span><span class="p">()]</span>
            <span class="n">default_ldflags</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="s2">&quot;-L</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">_find_cuda_home</span><span class="p">())</span> <span class="o">/</span> <span class="s2">&quot;lib64&quot;</span><span class="p">)),</span>
                <span class="s2">&quot;-lcudart&quot;</span><span class="p">,</span>  <span class="c1"># cuda runtime library</span>
            <span class="p">]</span>

    <span class="n">cflags</span> <span class="o">=</span> <span class="n">default_cflags</span> <span class="o">+</span> <span class="p">[</span><span class="n">flag</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">flag</span> <span class="ow">in</span> <span class="n">extra_cflags</span><span class="p">]</span>
    <span class="n">cuda_cflags</span> <span class="o">=</span> <span class="n">default_cuda_cflags</span> <span class="o">+</span> <span class="p">[</span><span class="n">flag</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">flag</span> <span class="ow">in</span> <span class="n">extra_cuda_cflags</span><span class="p">]</span>
    <span class="n">ldflags</span> <span class="o">=</span> <span class="n">default_ldflags</span> <span class="o">+</span> <span class="p">[</span><span class="n">flag</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">flag</span> <span class="ow">in</span> <span class="n">extra_ldflags</span><span class="p">]</span>
    <span class="n">include_paths</span> <span class="o">=</span> <span class="n">default_include_paths</span> <span class="o">+</span> <span class="p">[</span>
        <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">())</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">extra_include_paths</span>
    <span class="p">]</span>

    <span class="c1"># append include paths</span>
    <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">include_paths</span><span class="p">:</span>
        <span class="n">cflags</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-I</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;$:&quot;</span><span class="p">)))</span>
        <span class="n">cuda_cflags</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-I</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;$:&quot;</span><span class="p">)))</span>

    <span class="c1"># flags</span>
    <span class="n">ninja</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;ninja_required_version = 1.3&quot;</span><span class="p">)</span>
    <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;cxx = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;CXX&quot;</span><span class="p">,</span> <span class="s2">&quot;cl&quot;</span> <span class="k">if</span> <span class="n">IS_WINDOWS</span> <span class="k">else</span> <span class="s2">&quot;c++&quot;</span><span class="p">)))</span>
    <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;cflags = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cflags</span><span class="p">)))</span>
    <span class="k">if</span> <span class="n">with_cuda</span><span class="p">:</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;nvcc = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">_find_cuda_home</span><span class="p">())</span> <span class="o">/</span> <span class="s2">&quot;bin&quot;</span> <span class="o">/</span> <span class="s2">&quot;nvcc&quot;</span><span class="p">)))</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;cuda_cflags = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cuda_cflags</span><span class="p">)))</span>
    <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;ldflags = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ldflags</span><span class="p">)))</span>

    <span class="c1"># rules</span>
    <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;rule compile&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">IS_WINDOWS</span><span class="p">:</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;  command = $cxx /showIncludes $cflags -c $in /Fo$out&quot;</span><span class="p">)</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;  deps = msvc&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;  depfile = $out.d&quot;</span><span class="p">)</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;  deps = gcc&quot;</span><span class="p">)</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;  command = $cxx -MMD -MF $out.d $cflags -c $in -o $out&quot;</span><span class="p">)</span>
    <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">with_cuda</span><span class="p">:</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;rule compile_cuda&quot;</span><span class="p">)</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;  depfile = $out.d&quot;</span><span class="p">)</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;  deps = gcc&quot;</span><span class="p">)</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="s2">&quot;  command = $nvcc --generate-dependencies-with-compile --dependency-output $out.d $cuda_cflags -c $in -o $out&quot;</span>
        <span class="p">)</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="c1"># Add rules for object merging and cubin embedding (Unix only)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">IS_WINDOWS</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">embed_cubin</span><span class="p">:</span>
            <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;rule merge_objects&quot;</span><span class="p">)</span>
            <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;  command = ld -r -o $out $in&quot;</span><span class="p">)</span>
            <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

            <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;rule embed_cubin&quot;</span><span class="p">)</span>
            <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;  command = </span><span class="si">{</span><span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="si">}</span><span class="s2"> -m tvm_ffi.utils.embed_cubin --output-obj $out --input-obj $in --cubin $cubin --name $name&quot;</span>
            <span class="p">)</span>
            <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;rule link&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">IS_WINDOWS</span><span class="p">:</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;  command = $cxx $in /link $ldflags /out:$out&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;  command = $cxx $in $ldflags -o $out&quot;</span><span class="p">)</span>
    <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="c1"># build targets</span>
    <span class="n">obj_files</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cpp_path</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">cpp_files</span><span class="p">)):</span>
        <span class="n">obj_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;cpp_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">.o&quot;</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;build </span><span class="si">{}</span><span class="s2">: compile </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">obj_name</span><span class="p">,</span> <span class="n">cpp_path</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;$:&quot;</span><span class="p">)))</span>
        <span class="n">obj_files</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obj_name</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cuda_path</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">cuda_files</span><span class="p">)):</span>
        <span class="n">obj_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;cuda_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">.o&quot;</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;build </span><span class="si">{}</span><span class="s2">: compile_cuda </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">obj_name</span><span class="p">,</span> <span class="n">cuda_path</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;$:&quot;</span><span class="p">)))</span>
        <span class="n">obj_files</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obj_name</span><span class="p">)</span>

    <span class="c1"># Use appropriate extension based on platform</span>
    <span class="n">ext</span> <span class="o">=</span> <span class="s2">&quot;.dll&quot;</span> <span class="k">if</span> <span class="n">IS_WINDOWS</span> <span class="k">else</span> <span class="s2">&quot;.so&quot;</span>

    <span class="c1"># For Unix systems with embed_cubin, use a 3-step process:</span>
    <span class="c1"># 1. Merge all object files into a unified object file</span>
    <span class="c1"># 2. Embed each cubin into the unified object file (chain them)</span>
    <span class="c1"># 3. Link the final object file into a shared library</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">IS_WINDOWS</span> <span class="ow">and</span> <span class="n">embed_cubin</span><span class="p">:</span>
        <span class="c1"># Step 1: Merge object files into unified.o</span>
        <span class="n">unified_obj</span> <span class="o">=</span> <span class="s2">&quot;unified.o&quot;</span>
        <span class="n">obj_files_str</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">obj_files</span><span class="p">)</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;build </span><span class="si">{</span><span class="n">unified_obj</span><span class="si">}</span><span class="s2">: merge_objects </span><span class="si">{</span><span class="n">obj_files_str</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="c1"># Step 2: Chain embed_cubin operations for each cubin</span>
        <span class="n">current_obj</span> <span class="o">=</span> <span class="n">unified_obj</span>
        <span class="k">for</span> <span class="n">cubin_name</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">embed_cubin</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="c1"># Create next object file name</span>
            <span class="n">next_obj</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;unified_with_</span><span class="si">{</span><span class="n">cubin_name</span><span class="si">}</span><span class="s2">.o&quot;</span>
            <span class="n">cubin_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cubin_name</span><span class="si">}</span><span class="s2">.cubin&quot;</span>

            <span class="c1"># Add ninja build rule</span>
            <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;build </span><span class="si">{</span><span class="n">next_obj</span><span class="si">}</span><span class="s2">: embed_cubin </span><span class="si">{</span><span class="n">current_obj</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  cubin = </span><span class="si">{</span><span class="n">cubin_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  name = </span><span class="si">{</span><span class="n">cubin_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

            <span class="n">current_obj</span> <span class="o">=</span> <span class="n">next_obj</span>

        <span class="c1"># Step 3: Link the final object file</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;build </span><span class="si">{</span><span class="n">name</span><span class="si">}{</span><span class="n">ext</span><span class="si">}</span><span class="s2">: link </span><span class="si">{</span><span class="n">current_obj</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Original behavior: directly link object files (for Windows or no cubin embedding)</span>
        <span class="n">link_files_str</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">obj_files</span><span class="p">)</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;build </span><span class="si">{</span><span class="n">name</span><span class="si">}{</span><span class="n">ext</span><span class="si">}</span><span class="s2">: link </span><span class="si">{</span><span class="n">link_files_str</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="c1"># default target</span>
    <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;default </span><span class="si">{</span><span class="n">name</span><span class="si">}{</span><span class="n">ext</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ninja</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ninja</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">build_ninja</span><span class="p">(</span><span class="n">build_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Build the module in the given build directory using ninja.&quot;&quot;&quot;</span>
    <span class="n">command</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ninja&quot;</span><span class="p">,</span> <span class="s2">&quot;-v&quot;</span><span class="p">]</span>
    <span class="n">num_workers</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;MAX_JOBS&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">num_workers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">command</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;-j&quot;</span><span class="p">,</span> <span class="n">num_workers</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">IS_WINDOWS</span><span class="p">:</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">_run_command_in_dev_prompt</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="n">command</span><span class="p">,</span> <span class="n">cwd</span><span class="o">=</span><span class="n">build_dir</span><span class="p">,</span> <span class="n">capture_output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">command</span><span class="p">,</span> <span class="n">cwd</span><span class="o">=</span><span class="n">build_dir</span><span class="p">,</span> <span class="n">capture_output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">status</span><span class="o">.</span><span class="n">returncode</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;ninja exited with status </span><span class="si">{</span><span class="n">status</span><span class="o">.</span><span class="n">returncode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="s2">&quot;oem&quot;</span> <span class="k">if</span> <span class="n">IS_WINDOWS</span> <span class="k">else</span> <span class="s2">&quot;utf-8&quot;</span>
        <span class="k">if</span> <span class="n">status</span><span class="o">.</span><span class="n">stdout</span><span class="p">:</span>
            <span class="n">msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;stdout:</span><span class="se">\n</span><span class="si">{</span><span class="n">status</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">status</span><span class="o">.</span><span class="n">stderr</span><span class="p">:</span>
            <span class="n">msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;stderr:</span><span class="se">\n</span><span class="si">{</span><span class="n">status</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">msg</span><span class="p">))</span>


<span class="c1"># Translation table for escaping C++ string literals</span>
<span class="n">_CPP_ESCAPE_TABLE</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">maketrans</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="se">\\\\</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="s1">&#39;&quot;&#39;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="se">\\</span><span class="s1">&quot;&#39;</span><span class="p">,</span>
        <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">n&quot;</span><span class="p">,</span>
        <span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">r&quot;</span><span class="p">,</span>
        <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">t&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_escape_cpp_string_literal</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Escape special characters for C++ string literals.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">s</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="n">_CPP_ESCAPE_TABLE</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_decorate_with_tvm_ffi</span><span class="p">(</span><span class="n">source</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">functions</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Decorate the given source code with TVM FFI export macros.&quot;&quot;&quot;</span>
    <span class="n">sources</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;#include &lt;tvm/ffi/container/tensor.h&gt;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;#include &lt;tvm/ffi/dtype.h&gt;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;#include &lt;tvm/ffi/error.h&gt;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;#include &lt;tvm/ffi/extra/c_env_api.h&gt;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;#include &lt;tvm/ffi/function.h&gt;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">source</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">for</span> <span class="n">func_name</span><span class="p">,</span> <span class="n">func_doc</span> <span class="ow">in</span> <span class="n">functions</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">sources</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TVM_FFI_DLL_EXPORT_TYPED_FUNC(</span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s2">);&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">func_doc</span><span class="p">:</span>
            <span class="c1"># Escape the docstring for C++ string literal</span>
            <span class="n">escaped_doc</span> <span class="o">=</span> <span class="n">_escape_cpp_string_literal</span><span class="p">(</span><span class="n">func_doc</span><span class="p">)</span>
            <span class="n">sources</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;TVM_FFI_DLL_EXPORT_TYPED_FUNC_DOC(</span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s1">, &quot;</span><span class="si">{</span><span class="n">escaped_doc</span><span class="si">}</span><span class="s1">&quot;);&#39;</span><span class="p">)</span>

    <span class="n">sources</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sources</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_str_seq2list</span><span class="p">(</span><span class="n">seq</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">seq</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">seq</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_build_impl</span><span class="p">(</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">cpp_files</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cuda_files</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_cuda_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_ldflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_include_paths</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">build_directory</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">need_lock</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">embed_cubin</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Real implementation of build function.&quot;&quot;&quot;</span>
    <span class="c1"># need to resolve the path to make it unique</span>
    <span class="n">cpp_path_list</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">())</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">_str_seq2list</span><span class="p">(</span><span class="n">cpp_files</span><span class="p">)]</span>
    <span class="n">cuda_path_list</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">())</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">_str_seq2list</span><span class="p">(</span><span class="n">cuda_files</span><span class="p">)]</span>
    <span class="n">with_cpp</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">cpp_path_list</span><span class="p">)</span>
    <span class="n">with_cuda</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">cuda_path_list</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">with_cpp</span> <span class="ow">or</span> <span class="n">with_cuda</span><span class="p">,</span> <span class="s2">&quot;Either cpp_files or cuda_files must be provided.&quot;</span>

    <span class="n">extra_ldflags_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">extra_ldflags</span><span class="p">)</span> <span class="k">if</span> <span class="n">extra_ldflags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="n">extra_cflags_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">extra_cflags</span><span class="p">)</span> <span class="k">if</span> <span class="n">extra_cflags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="n">extra_cuda_cflags_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">extra_cuda_cflags</span><span class="p">)</span> <span class="k">if</span> <span class="n">extra_cuda_cflags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="n">extra_include_paths_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">extra_include_paths</span><span class="p">)</span> <span class="k">if</span> <span class="n">extra_include_paths</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>

    <span class="n">build_dir</span><span class="p">:</span> <span class="n">Path</span>
    <span class="k">if</span> <span class="n">build_directory</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;TVM_FFI_CACHE_DIR&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="s2">&quot;~/.cache/tvm-ffi&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()))</span>
        <span class="n">source_hash</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">_hash_sources</span><span class="p">(</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="n">cpp_path_list</span><span class="p">,</span>
            <span class="n">cuda_path_list</span><span class="p">,</span>
            <span class="p">{},</span>
            <span class="n">extra_cflags_list</span><span class="p">,</span>
            <span class="n">extra_cuda_cflags_list</span><span class="p">,</span>
            <span class="n">extra_ldflags_list</span><span class="p">,</span>
            <span class="n">extra_include_paths_list</span><span class="p">,</span>
            <span class="n">embed_cubin</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">build_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">source_hash</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">build_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">build_directory</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span>
    <span class="n">build_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># CUBIN embedding is only supported on Unix systems</span>
    <span class="k">if</span> <span class="n">embed_cubin</span> <span class="ow">and</span> <span class="n">IS_WINDOWS</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;CUBIN embedding is not yet supported on Windows&quot;</span><span class="p">)</span>

    <span class="c1"># Write CUBIN files to build directory if needed (for Unix systems)</span>
    <span class="c1"># These will be embedded using the embed_cubin utility during ninja build</span>
    <span class="k">if</span> <span class="n">embed_cubin</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">cubin_name</span><span class="p">,</span> <span class="n">cubin_bytes</span> <span class="ow">in</span> <span class="n">embed_cubin</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">cubin_path</span> <span class="o">=</span> <span class="n">build_dir</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cubin_name</span><span class="si">}</span><span class="s2">.cubin&quot;</span>
            <span class="n">cubin_path</span><span class="o">.</span><span class="n">write_bytes</span><span class="p">(</span><span class="n">cubin_bytes</span><span class="p">)</span>

    <span class="c1"># generate build.ninja</span>
    <span class="n">ninja_source</span> <span class="o">=</span> <span class="n">_generate_ninja_build</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">with_cuda</span><span class="o">=</span><span class="n">with_cuda</span><span class="p">,</span>
        <span class="n">extra_cflags</span><span class="o">=</span><span class="n">extra_cflags_list</span><span class="p">,</span>
        <span class="n">extra_cuda_cflags</span><span class="o">=</span><span class="n">extra_cuda_cflags_list</span><span class="p">,</span>
        <span class="n">extra_ldflags</span><span class="o">=</span><span class="n">extra_ldflags_list</span><span class="p">,</span>
        <span class="n">extra_include_paths</span><span class="o">=</span><span class="n">extra_include_paths_list</span><span class="p">,</span>
        <span class="n">cpp_files</span><span class="o">=</span><span class="n">cpp_path_list</span><span class="p">,</span>
        <span class="n">cuda_files</span><span class="o">=</span><span class="n">cuda_path_list</span><span class="p">,</span>
        <span class="n">embed_cubin</span><span class="o">=</span><span class="n">embed_cubin</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># may not hold lock when build_directory is specified, prevent deadlock</span>
    <span class="k">with</span> <span class="n">FileLock</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">build_dir</span> <span class="o">/</span> <span class="s2">&quot;lock&quot;</span><span class="p">))</span> <span class="k">if</span> <span class="n">need_lock</span> <span class="k">else</span> <span class="n">nullcontext</span><span class="p">():</span>
        <span class="c1"># write build.ninja if it does not already exist</span>
        <span class="n">_maybe_write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">build_dir</span> <span class="o">/</span> <span class="s2">&quot;build.ninja&quot;</span><span class="p">),</span> <span class="n">ninja_source</span><span class="p">)</span>
        <span class="c1"># build the module</span>
        <span class="n">build_ninja</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">build_dir</span><span class="p">))</span>
        <span class="c1"># Use appropriate extension based on platform</span>
        <span class="n">ext</span> <span class="o">=</span> <span class="s2">&quot;.dll&quot;</span> <span class="k">if</span> <span class="n">IS_WINDOWS</span> <span class="k">else</span> <span class="s2">&quot;.so&quot;</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">((</span><span class="n">build_dir</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}{</span><span class="n">ext</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">())</span>


<div class="viewcode-block" id="build_inline">
<a class="viewcode-back" href="../../../reference/python/cpp/generated/tvm_ffi.cpp.build_inline.html#tvm_ffi.cpp.build_inline">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">build_inline</span><span class="p">(</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">cpp_sources</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cuda_sources</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">functions</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_cuda_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_ldflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_include_paths</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">build_directory</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">embed_cubin</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compile and build a C++/CUDA module from inline source code.</span>

<span class="sd">    This function compiles the given C++ and/or CUDA source code into a shared library. Both ``cpp_sources`` and</span>
<span class="sd">    ``cuda_sources`` are compiled to an object file, and then linked together into a shared library. It&#39;s possible to only</span>
<span class="sd">    provide cpp_sources or cuda_sources. The path to the compiled shared library is returned.</span>

<span class="sd">    The ``functions`` parameter is used to specify which functions in the source code should be exported to the tvm ffi</span>
<span class="sd">    module. It can be a mapping, a sequence, or a single string. When a mapping is given, the keys are the names of the</span>
<span class="sd">    exported functions, and the values are docstrings for the functions. When a sequence of string is given, they are</span>
<span class="sd">    the function names needed to be exported, and the docstrings are set to empty strings. A single function name can</span>
<span class="sd">    also be given as a string, indicating that only one function is to be exported.</span>

<span class="sd">    Extra compiler and linker flags can be provided via the ``extra_cflags``, ``extra_cuda_cflags``, and ``extra_ldflags``</span>
<span class="sd">    parameters. The default flags are generally sufficient for most use cases, but you may need to provide additional</span>
<span class="sd">    flags for your specific use case.</span>

<span class="sd">    The include dir of tvm ffi and dlpack are used by default for the compiler to find the headers. Thus, you can</span>
<span class="sd">    include any header from tvm ffi in your source code. You can also provide additional include paths via the</span>
<span class="sd">    ``extra_include_paths`` parameter and include custom headers in your source code.</span>

<span class="sd">    The compiled shared library is cached in a cache directory to avoid recompilation. The `build_directory` parameter</span>
<span class="sd">    is provided to specify the build directory. If not specified, a default tvm ffi cache directory will be used.</span>
<span class="sd">    The default cache directory can be specified via the `TVM_FFI_CACHE_DIR` environment variable. If not specified,</span>
<span class="sd">    the default cache directory is ``~/.cache/tvm-ffi``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name</span>
<span class="sd">        The name of the tvm ffi module.</span>
<span class="sd">    cpp_sources</span>
<span class="sd">        The C++ source code. It can be a list of sources or a single source.</span>
<span class="sd">    cuda_sources</span>
<span class="sd">        The CUDA source code. It can be a list of sources or a single source.</span>
<span class="sd">    functions</span>
<span class="sd">        The functions in cpp_sources or cuda_source that will be exported to the tvm ffi module. When a mapping is</span>
<span class="sd">        given, the keys are the names of the exported functions, and the values are docstrings for the functions</span>
<span class="sd">        (use an empty string to skip documentation for specific functions). When a sequence or a single string is given, they are</span>
<span class="sd">        the functions needed to be exported, and the docstrings are set to empty strings. A single function name can</span>
<span class="sd">        also be given as a string. When cpp_sources is given, the functions must be declared (not necessarily defined)</span>
<span class="sd">        in the cpp_sources. When cpp_sources is not given, the functions must be defined in the cuda_sources. If not</span>
<span class="sd">        specified, no function will be exported.</span>
<span class="sd">    extra_cflags</span>
<span class="sd">        The extra compiler flags for C++ compilation.</span>
<span class="sd">        The default flags are:</span>

<span class="sd">        - On Linux/macOS: [&#39;-std=c++17&#39;, &#39;-fPIC&#39;, &#39;-O2&#39;]</span>
<span class="sd">        - On Windows: [&#39;/std:c++17&#39;, &#39;/O2&#39;]</span>

<span class="sd">    extra_cuda_cflags</span>
<span class="sd">        The extra compiler flags for CUDA compilation.</span>

<span class="sd">    extra_ldflags</span>
<span class="sd">        The extra linker flags.</span>
<span class="sd">        The default flags are:</span>

<span class="sd">        - On Linux/macOS: [&#39;-shared&#39;]</span>
<span class="sd">        - On Windows: [&#39;/DLL&#39;]</span>

<span class="sd">    extra_include_paths</span>
<span class="sd">        The extra include paths.</span>

<span class="sd">    build_directory</span>
<span class="sd">        The build directory. If not specified, a default tvm ffi cache directory will be used. By default, the</span>
<span class="sd">        cache directory is ``~/.cache/tvm-ffi``. You can also set the ``TVM_FFI_CACHE_DIR`` environment variable to</span>
<span class="sd">        specify the cache directory.</span>

<span class="sd">    embed_cubin: Mapping[str, bytes], optional</span>
<span class="sd">        A mapping from CUBIN module names to CUBIN binary data. TVM-FFI provides a macro `TVM_FFI_EMBED_CUBIN(name)` to embed</span>
<span class="sd">        CUBIN data into the compiled shared library. The keys should match the names used in `TVM_FFI_EMBED_CUBIN(name)` calls</span>
<span class="sd">        in the C++ source code. The values are the CUBIN binary data bytes. The embedded CUBIN kernels can be accessed by</span>
<span class="sd">        the macro `TVM_FFI_EMBED_CUBIN_GET_KERNEL(name, kernel_name)` defined in the `tvm/ffi/extra/cuda/cubin_launcher.h` header.</span>
<span class="sd">        See the `examples/cubin_launcher` directory for examples how to use cubin launcher to launch CUBIN kernels in TVM-FFI.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    lib_path: str</span>
<span class="sd">        The path to the built shared library.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import torch</span>
<span class="sd">        from tvm_ffi import Module</span>
<span class="sd">        import tvm_ffi.cpp</span>

<span class="sd">        # define the cpp source code</span>
<span class="sd">        cpp_source = &#39;&#39;&#39;</span>
<span class="sd">             void add_one_cpu(tvm::ffi::TensorView x, tvm::ffi::TensorView y) {</span>
<span class="sd">               // implementation of a library function</span>
<span class="sd">               TVM_FFI_ICHECK(x.ndim() == 1) &lt;&lt; &quot;x must be a 1D tensor&quot;;</span>
<span class="sd">               DLDataType f32_dtype{kDLFloat, 32, 1};</span>
<span class="sd">               TVM_FFI_ICHECK(x.dtype() == f32_dtype) &lt;&lt; &quot;x must be a float tensor&quot;;</span>
<span class="sd">               TVM_FFI_ICHECK(y.ndim() == 1) &lt;&lt; &quot;y must be a 1D tensor&quot;;</span>
<span class="sd">               TVM_FFI_ICHECK(y.dtype() == f32_dtype) &lt;&lt; &quot;y must be a float tensor&quot;;</span>
<span class="sd">               TVM_FFI_ICHECK(x.size(0) == y.size(0)) &lt;&lt; &quot;x and y must have the same shape&quot;;</span>
<span class="sd">               for (int i = 0; i &lt; x.size(0); ++i) {</span>
<span class="sd">                 static_cast&lt;float*&gt;(y.data_ptr())[i] = static_cast&lt;float*&gt;(x.data_ptr())[i] + 1;</span>
<span class="sd">               }</span>
<span class="sd">             }</span>
<span class="sd">        &#39;&#39;&#39;</span>

<span class="sd">        # compile the cpp source code and load the module</span>
<span class="sd">        lib_path: str = tvm_ffi.cpp.build_inline(</span>
<span class="sd">            name=&quot;hello&quot;,</span>
<span class="sd">            cpp_sources=cpp_source,</span>
<span class="sd">            functions=&quot;add_one_cpu&quot;,</span>
<span class="sd">        )</span>

<span class="sd">        # load the module</span>
<span class="sd">        mod: Module = tvm_ffi.load_module(lib_path)</span>

<span class="sd">        # use the function from the loaded module to perform</span>
<span class="sd">        x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)</span>
<span class="sd">        y = torch.empty_like(x)</span>
<span class="sd">        mod.add_one_cpu(x, y)</span>
<span class="sd">        torch.testing.assert_close(x + 1, y)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cpp_source_list</span> <span class="o">=</span> <span class="n">_str_seq2list</span><span class="p">(</span><span class="n">cpp_sources</span><span class="p">)</span>
    <span class="n">cpp_source</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cpp_source_list</span><span class="p">)</span>
    <span class="n">with_cpp</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">cpp_source_list</span><span class="p">)</span>
    <span class="k">del</span> <span class="n">cpp_source_list</span>

    <span class="n">cuda_source_list</span> <span class="o">=</span> <span class="n">_str_seq2list</span><span class="p">(</span><span class="n">cuda_sources</span><span class="p">)</span>
    <span class="n">cuda_source</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cuda_source_list</span><span class="p">)</span>
    <span class="n">with_cuda</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">cuda_source_list</span><span class="p">)</span>
    <span class="k">del</span> <span class="n">cuda_source_list</span>

    <span class="n">extra_ldflags_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">extra_ldflags</span><span class="p">)</span> <span class="k">if</span> <span class="n">extra_ldflags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="n">extra_cflags_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">extra_cflags</span><span class="p">)</span> <span class="k">if</span> <span class="n">extra_cflags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="n">extra_cuda_cflags_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">extra_cuda_cflags</span><span class="p">)</span> <span class="k">if</span> <span class="n">extra_cuda_cflags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="n">extra_include_paths_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">extra_include_paths</span><span class="p">)</span> <span class="k">if</span> <span class="n">extra_include_paths</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>

    <span class="c1"># add function registration code to sources</span>
    <span class="k">if</span> <span class="n">functions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">function_map</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">functions</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">function_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">functions</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">}</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">functions</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
        <span class="n">function_map</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">functions</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">function_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="s2">&quot;&quot;</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">functions</span><span class="p">}</span>

    <span class="k">if</span> <span class="n">with_cpp</span><span class="p">:</span>
        <span class="n">cpp_source</span> <span class="o">=</span> <span class="n">_decorate_with_tvm_ffi</span><span class="p">(</span><span class="n">cpp_source</span><span class="p">,</span> <span class="n">function_map</span><span class="p">)</span>
        <span class="n">cuda_source</span> <span class="o">=</span> <span class="n">_decorate_with_tvm_ffi</span><span class="p">(</span><span class="n">cuda_source</span><span class="p">,</span> <span class="p">{})</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cpp_source</span> <span class="o">=</span> <span class="n">_decorate_with_tvm_ffi</span><span class="p">(</span><span class="n">cpp_source</span><span class="p">,</span> <span class="p">{})</span>
        <span class="n">cuda_source</span> <span class="o">=</span> <span class="n">_decorate_with_tvm_ffi</span><span class="p">(</span><span class="n">cuda_source</span><span class="p">,</span> <span class="n">function_map</span><span class="p">)</span>
    <span class="c1"># determine the cache dir for the built module</span>
    <span class="n">build_dir</span><span class="p">:</span> <span class="n">Path</span>
    <span class="k">if</span> <span class="n">build_directory</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;TVM_FFI_CACHE_DIR&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="s2">&quot;~/.cache/tvm-ffi&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()))</span>
        <span class="n">source_hash</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">_hash_sources</span><span class="p">(</span>
            <span class="n">cpp_source</span><span class="p">,</span>
            <span class="n">cuda_source</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="n">function_map</span><span class="p">,</span>
            <span class="n">extra_cflags_list</span><span class="p">,</span>
            <span class="n">extra_cuda_cflags_list</span><span class="p">,</span>
            <span class="n">extra_ldflags_list</span><span class="p">,</span>
            <span class="n">extra_include_paths_list</span><span class="p">,</span>
            <span class="n">embed_cubin</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">build_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">source_hash</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">build_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">build_directory</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span>
    <span class="n">build_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">cpp_file</span> <span class="o">=</span> <span class="nb">str</span><span class="p">((</span><span class="n">build_dir</span> <span class="o">/</span> <span class="s2">&quot;main.cpp&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">())</span>
    <span class="n">cuda_file</span> <span class="o">=</span> <span class="nb">str</span><span class="p">((</span><span class="n">build_dir</span> <span class="o">/</span> <span class="s2">&quot;cuda.cu&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">())</span>

    <span class="k">with</span> <span class="n">FileLock</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">build_dir</span> <span class="o">/</span> <span class="s2">&quot;lock&quot;</span><span class="p">)):</span>
        <span class="c1"># write source files if they do not already exist</span>
        <span class="n">_maybe_write</span><span class="p">(</span><span class="n">cpp_file</span><span class="p">,</span> <span class="n">cpp_source</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">with_cuda</span><span class="p">:</span>
            <span class="n">_maybe_write</span><span class="p">(</span><span class="n">cuda_file</span><span class="p">,</span> <span class="n">cuda_source</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">_build_impl</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">cpp_files</span><span class="o">=</span><span class="p">[</span><span class="n">cpp_file</span><span class="p">]</span> <span class="k">if</span> <span class="n">with_cpp</span> <span class="k">else</span> <span class="p">[],</span>
            <span class="n">cuda_files</span><span class="o">=</span><span class="p">[</span><span class="n">cuda_file</span><span class="p">]</span> <span class="k">if</span> <span class="n">with_cuda</span> <span class="k">else</span> <span class="p">[],</span>
            <span class="n">extra_cflags</span><span class="o">=</span><span class="n">extra_cflags_list</span><span class="p">,</span>
            <span class="n">extra_cuda_cflags</span><span class="o">=</span><span class="n">extra_cuda_cflags_list</span><span class="p">,</span>
            <span class="n">extra_ldflags</span><span class="o">=</span><span class="n">extra_ldflags_list</span><span class="p">,</span>
            <span class="n">extra_include_paths</span><span class="o">=</span><span class="n">extra_include_paths_list</span><span class="p">,</span>
            <span class="n">build_directory</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">build_dir</span><span class="p">),</span>
            <span class="n">need_lock</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># already hold the lock</span>
            <span class="n">embed_cubin</span><span class="o">=</span><span class="n">embed_cubin</span><span class="p">,</span>
        <span class="p">)</span></div>



<div class="viewcode-block" id="load_inline">
<a class="viewcode-back" href="../../../reference/python/cpp/generated/tvm_ffi.cpp.load_inline.html#tvm_ffi.cpp.load_inline">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">load_inline</span><span class="p">(</span>  <span class="c1"># noqa: PLR0913</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">cpp_sources</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cuda_sources</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">functions</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_cuda_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_ldflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_include_paths</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">build_directory</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">embed_cubin</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keep_module_alive</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Module</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compile, build and load a C++/CUDA module from inline source code.</span>

<span class="sd">    This function compiles the given C++ and/or CUDA source code into a shared library. Both ``cpp_sources`` and</span>
<span class="sd">    ``cuda_sources`` are compiled to an object file, and then linked together into a shared library. It&#39;s possible to only</span>
<span class="sd">    provide cpp_sources or cuda_sources.</span>

<span class="sd">    The ``functions`` parameter is used to specify which functions in the source code should be exported to the tvm ffi</span>
<span class="sd">    module. It can be a mapping, a sequence, or a single string. When a mapping is given, the keys are the names of the</span>
<span class="sd">    exported functions, and the values are docstrings for the functions. When a sequence of string is given, they are</span>
<span class="sd">    the function names needed to be exported, and the docstrings are set to empty strings. A single function name can</span>
<span class="sd">    also be given as a string, indicating that only one function is to be exported.</span>

<span class="sd">    Extra compiler and linker flags can be provided via the ``extra_cflags``, ``extra_cuda_cflags``, and ``extra_ldflags``</span>
<span class="sd">    parameters. The default flags are generally sufficient for most use cases, but you may need to provide additional</span>
<span class="sd">    flags for your specific use case.</span>

<span class="sd">    The include dir of tvm ffi and dlpack are used by default for the compiler to find the headers. Thus, you can</span>
<span class="sd">    include any header from tvm ffi in your source code. You can also provide additional include paths via the</span>
<span class="sd">    ``extra_include_paths`` parameter and include custom headers in your source code.</span>

<span class="sd">    The compiled shared library is cached in a cache directory to avoid recompilation. The `build_directory` parameter</span>
<span class="sd">    is provided to specify the build directory. If not specified, a default tvm ffi cache directory will be used.</span>
<span class="sd">    The default cache directory can be specified via the `TVM_FFI_CACHE_DIR` environment variable. If not specified,</span>
<span class="sd">    the default cache directory is ``~/.cache/tvm-ffi``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name</span>
<span class="sd">        The name of the tvm ffi module.</span>
<span class="sd">    cpp_sources</span>
<span class="sd">        The C++ source code. It can be a list of sources or a single source.</span>
<span class="sd">    cuda_sources</span>
<span class="sd">        The CUDA source code. It can be a list of sources or a single source.</span>
<span class="sd">    functions</span>
<span class="sd">        The functions in cpp_sources or cuda_source that will be exported to the tvm ffi module. When a mapping is</span>
<span class="sd">        given, the keys are the names of the exported functions, and the values are docstrings for the functions</span>
<span class="sd">        (use an empty string to skip documentation for specific functions). When a sequence or a single string is given, they are</span>
<span class="sd">        the functions needed to be exported, and the docstrings are set to empty strings. A single function name can</span>
<span class="sd">        also be given as a string. When cpp_sources is given, the functions must be declared (not necessarily defined)</span>
<span class="sd">        in the cpp_sources. When cpp_sources is not given, the functions must be defined in the cuda_sources. If not</span>
<span class="sd">        specified, no function will be exported.</span>
<span class="sd">    extra_cflags</span>
<span class="sd">        The extra compiler flags for C++ compilation.</span>
<span class="sd">        The default flags are:</span>

<span class="sd">        - On Linux/macOS: [&#39;-std=c++17&#39;, &#39;-fPIC&#39;, &#39;-O2&#39;]</span>
<span class="sd">        - On Windows: [&#39;/std:c++17&#39;, &#39;/O2&#39;]</span>

<span class="sd">    extra_cuda_cflags</span>
<span class="sd">        The extra compiler flags for CUDA compilation.</span>

<span class="sd">    extra_ldflags</span>
<span class="sd">        The extra linker flags.</span>
<span class="sd">        The default flags are:</span>

<span class="sd">        - On Linux/macOS: [&#39;-shared&#39;]</span>
<span class="sd">        - On Windows: [&#39;/DLL&#39;]</span>

<span class="sd">    extra_include_paths</span>
<span class="sd">        The extra include paths.</span>

<span class="sd">    build_directory</span>
<span class="sd">        The build directory. If not specified, a default tvm ffi cache directory will be used. By default, the</span>
<span class="sd">        cache directory is ``~/.cache/tvm-ffi``. You can also set the ``TVM_FFI_CACHE_DIR`` environment variable to</span>
<span class="sd">        specify the cache directory.</span>

<span class="sd">    embed_cubin</span>
<span class="sd">        A mapping from CUBIN module names to CUBIN binary data. When provided, the CUBIN data will be embedded</span>
<span class="sd">        into the compiled shared library using objcopy, making it accessible via the TVM_FFI_EMBED_CUBIN macro.</span>
<span class="sd">        The keys should match the names used in TVM_FFI_EMBED_CUBIN calls in the C++ source code.</span>

<span class="sd">    keep_module_alive</span>
<span class="sd">        Whether to keep the module alive. If True, the module will be kept alive</span>
<span class="sd">        for the duration of the program until libtvm_ffi.so is unloaded.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mod: Module</span>
<span class="sd">        The loaded tvm ffi module.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    :py:func:`tvm_ffi.load_module`</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import torch</span>
<span class="sd">        from tvm_ffi import Module</span>
<span class="sd">        import tvm_ffi.cpp</span>

<span class="sd">        # define the cpp source code</span>
<span class="sd">        cpp_source = &#39;&#39;&#39;</span>
<span class="sd">             void add_one_cpu(tvm::ffi::TensorView x, tvm::ffi::TensorView y) {</span>
<span class="sd">               // implementation of a library function</span>
<span class="sd">               TVM_FFI_ICHECK(x.ndim() == 1) &lt;&lt; &quot;x must be a 1D tensor&quot;;</span>
<span class="sd">               DLDataType f32_dtype{kDLFloat, 32, 1};</span>
<span class="sd">               TVM_FFI_ICHECK(x.dtype() == f32_dtype) &lt;&lt; &quot;x must be a float tensor&quot;;</span>
<span class="sd">               TVM_FFI_ICHECK(y.ndim() == 1) &lt;&lt; &quot;y must be a 1D tensor&quot;;</span>
<span class="sd">               TVM_FFI_ICHECK(y.dtype() == f32_dtype) &lt;&lt; &quot;y must be a float tensor&quot;;</span>
<span class="sd">               TVM_FFI_ICHECK(x.size(0) == y.size(0)) &lt;&lt; &quot;x and y must have the same shape&quot;;</span>
<span class="sd">               for (int i = 0; i &lt; x.size(0); ++i) {</span>
<span class="sd">                 static_cast&lt;float*&gt;(y.data_ptr())[i] = static_cast&lt;float*&gt;(x.data_ptr())[i] + 1;</span>
<span class="sd">               }</span>
<span class="sd">             }</span>
<span class="sd">        &#39;&#39;&#39;</span>

<span class="sd">        # compile the cpp source code and load the module</span>
<span class="sd">        mod: Module = tvm_ffi.cpp.load_inline(</span>
<span class="sd">            name=&quot;hello&quot;,</span>
<span class="sd">            cpp_sources=cpp_source,</span>
<span class="sd">            functions=&quot;add_one_cpu&quot;,</span>
<span class="sd">        )</span>

<span class="sd">        # use the function from the loaded module to perform</span>
<span class="sd">        x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)</span>
<span class="sd">        y = torch.empty_like(x)</span>
<span class="sd">        mod.add_one_cpu(x, y)</span>
<span class="sd">        torch.testing.assert_close(x + 1, y)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">load_module</span><span class="p">(</span>
        <span class="n">build_inline</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">cpp_sources</span><span class="o">=</span><span class="n">cpp_sources</span><span class="p">,</span>
            <span class="n">cuda_sources</span><span class="o">=</span><span class="n">cuda_sources</span><span class="p">,</span>
            <span class="n">functions</span><span class="o">=</span><span class="n">functions</span><span class="p">,</span>
            <span class="n">extra_cflags</span><span class="o">=</span><span class="n">extra_cflags</span><span class="p">,</span>
            <span class="n">extra_cuda_cflags</span><span class="o">=</span><span class="n">extra_cuda_cflags</span><span class="p">,</span>
            <span class="n">extra_ldflags</span><span class="o">=</span><span class="n">extra_ldflags</span><span class="p">,</span>
            <span class="n">extra_include_paths</span><span class="o">=</span><span class="n">extra_include_paths</span><span class="p">,</span>
            <span class="n">build_directory</span><span class="o">=</span><span class="n">build_directory</span><span class="p">,</span>
            <span class="n">embed_cubin</span><span class="o">=</span><span class="n">embed_cubin</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">keep_module_alive</span><span class="o">=</span><span class="n">keep_module_alive</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="build">
<a class="viewcode-back" href="../../../reference/python/cpp/generated/tvm_ffi.cpp.build.html#tvm_ffi.cpp.build">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">build</span><span class="p">(</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">cpp_files</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cuda_files</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_cuda_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_ldflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_include_paths</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">build_directory</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compile and build a C++/CUDA module from source files.</span>

<span class="sd">    This function compiles the given C++ and/or CUDA source files into a shared library. Both ``cpp_files`` and</span>
<span class="sd">    ``cuda_files`` are compiled to object files, and then linked together into a shared library. It&#39;s possible to only</span>
<span class="sd">    provide cpp_files or cuda_files. The path to the compiled shared library is returned.</span>

<span class="sd">    Note that this function does not automatically export functions to the tvm ffi module. You need to</span>
<span class="sd">    manually use the TVM FFI export macros (e.g., ``TVM_FFI_DLL_EXPORT_TYPED_FUNC``) in your source files to export</span>
<span class="sd">    functions. This gives you more control over which functions are exported and how they are exported.</span>

<span class="sd">    Extra compiler and linker flags can be provided via the ``extra_cflags``, ``extra_cuda_cflags``, and ``extra_ldflags``</span>
<span class="sd">    parameters. The default flags are generally sufficient for most use cases, but you may need to provide additional</span>
<span class="sd">    flags for your specific use case.</span>

<span class="sd">    The include dir of tvm ffi and dlpack are used by default for the compiler to find the headers. Thus, you can</span>
<span class="sd">    include any header from tvm ffi in your source files. You can also provide additional include paths via the</span>
<span class="sd">    ``extra_include_paths`` parameter and include custom headers in your source code.</span>

<span class="sd">    The compiled shared library is cached in a cache directory to avoid recompilation. The `build_directory` parameter</span>
<span class="sd">    is provided to specify the build directory. If not specified, a default tvm ffi cache directory will be used.</span>
<span class="sd">    The default cache directory can be specified via the `TVM_FFI_CACHE_DIR` environment variable. If not specified,</span>
<span class="sd">    the default cache directory is ``~/.cache/tvm-ffi``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name</span>
<span class="sd">        The name of the tvm ffi module.</span>
<span class="sd">    cpp_files</span>
<span class="sd">        The C++ source files to compile. It can be a list of file paths or a single file path. Both absolute and</span>
<span class="sd">        relative paths are supported.</span>
<span class="sd">    cuda_files</span>
<span class="sd">        The CUDA source files to compile. It can be a list of file paths or a single file path. Both absolute and</span>
<span class="sd">        relative paths are supported.</span>
<span class="sd">    extra_cflags</span>
<span class="sd">        The extra compiler flags for C++ compilation.</span>
<span class="sd">        The default flags are:</span>

<span class="sd">        - On Linux/macOS: [&#39;-std=c++17&#39;, &#39;-fPIC&#39;, &#39;-O2&#39;]</span>
<span class="sd">        - On Windows: [&#39;/std:c++17&#39;, &#39;/MD&#39;, &#39;/O2&#39;]</span>

<span class="sd">    extra_cuda_cflags</span>
<span class="sd">        The extra compiler flags for CUDA compilation.</span>
<span class="sd">        The default flags are:</span>

<span class="sd">        - [&#39;-Xcompiler&#39;, &#39;-fPIC&#39;, &#39;-std=c++17&#39;, &#39;-O2&#39;] (Linux/macOS)</span>
<span class="sd">        - [&#39;-Xcompiler&#39;, &#39;/std:c++17&#39;, &#39;/O2&#39;] (Windows)</span>

<span class="sd">    extra_ldflags</span>
<span class="sd">        The extra linker flags.</span>
<span class="sd">        The default flags are:</span>

<span class="sd">        - On Linux/macOS: [&#39;-shared&#39;, &#39;-L&lt;tvm_ffi_lib_path&gt;&#39;, &#39;-ltvm_ffi&#39;]</span>
<span class="sd">        - On Windows: [&#39;/DLL&#39;, &#39;/LIBPATH:&lt;tvm_ffi_lib_path&gt;&#39;, &#39;&lt;tvm_ffi_lib_name&gt;.lib&#39;]</span>

<span class="sd">    extra_include_paths</span>
<span class="sd">        The extra include paths for header files. Both absolute and relative paths are supported.</span>

<span class="sd">    build_directory</span>
<span class="sd">        The build directory. If not specified, a default tvm ffi cache directory will be used. By default, the</span>
<span class="sd">        cache directory is ``~/.cache/tvm-ffi``. You can also set the ``TVM_FFI_CACHE_DIR`` environment variable to</span>
<span class="sd">        specify the cache directory.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    lib_path: str</span>
<span class="sd">        The path to the built shared library.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import torch</span>
<span class="sd">        from tvm_ffi import Module</span>
<span class="sd">        import tvm_ffi.cpp</span>

<span class="sd">        # Assume we have a C++ source file &quot;my_ops.cpp&quot; with the following content:</span>
<span class="sd">        # ```cpp</span>
<span class="sd">        # #include &lt;tvm/ffi/container/tensor.h&gt;</span>
<span class="sd">        # #include &lt;tvm/ffi/dtype.h&gt;</span>
<span class="sd">        # #include &lt;tvm/ffi/error.h&gt;</span>
<span class="sd">        # #include &lt;tvm/ffi/extra/c_env_api.h&gt;</span>
<span class="sd">        # #include &lt;tvm/ffi/function.h&gt;</span>
<span class="sd">        #</span>
<span class="sd">        # void add_one_cpu(tvm::ffi::TensorView x, tvm::ffi::TensorView y) {</span>
<span class="sd">        #   TVM_FFI_ICHECK(x.ndim() == 1) &lt;&lt; &quot;x must be a 1D tensor&quot;;</span>
<span class="sd">        #   DLDataType f32_dtype{kDLFloat, 32, 1};</span>
<span class="sd">        #   TVM_FFI_ICHECK(x.dtype() == f32_dtype) &lt;&lt; &quot;x must be a float tensor&quot;;</span>
<span class="sd">        #   TVM_FFI_ICHECK(y.ndim() == 1) &lt;&lt; &quot;y must be a 1D tensor&quot;;</span>
<span class="sd">        #   TVM_FFI_ICHECK(y.dtype() == f32_dtype) &lt;&lt; &quot;y must be a float tensor&quot;;</span>
<span class="sd">        #   TVM_FFI_ICHECK(x.size(0) == y.size(0)) &lt;&lt; &quot;x and y must have the same shape&quot;;</span>
<span class="sd">        #   for (int i = 0; i &lt; x.size(0); ++i) {</span>
<span class="sd">        #     static_cast&lt;float*&gt;(y.data_ptr())[i] = static_cast&lt;float*&gt;(x.data_ptr())[i] + 1;</span>
<span class="sd">        #   }</span>
<span class="sd">        # }</span>
<span class="sd">        #</span>
<span class="sd">        # TVM_FFI_DLL_EXPORT_TYPED_FUNC(add_one_cpu, add_one_cpu);</span>
<span class="sd">        # ```</span>

<span class="sd">        # compile the cpp source file and get the library path</span>
<span class="sd">        lib_path: str = tvm_ffi.cpp.build(</span>
<span class="sd">            name=&quot;my_ops&quot;,</span>
<span class="sd">            cpp_files=&quot;my_ops.cpp&quot;,</span>
<span class="sd">        )</span>

<span class="sd">        # load the module</span>
<span class="sd">        mod: Module = tvm_ffi.load_module(lib_path)</span>

<span class="sd">        # use the function from the loaded module</span>
<span class="sd">        x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)</span>
<span class="sd">        y = torch.empty_like(x)</span>
<span class="sd">        mod.add_one_cpu(x, y)</span>
<span class="sd">        torch.testing.assert_close(x + 1, y)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_build_impl</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">cpp_files</span><span class="o">=</span><span class="n">cpp_files</span><span class="p">,</span>
        <span class="n">cuda_files</span><span class="o">=</span><span class="n">cuda_files</span><span class="p">,</span>
        <span class="n">extra_cflags</span><span class="o">=</span><span class="n">extra_cflags</span><span class="p">,</span>
        <span class="n">extra_cuda_cflags</span><span class="o">=</span><span class="n">extra_cuda_cflags</span><span class="p">,</span>
        <span class="n">extra_ldflags</span><span class="o">=</span><span class="n">extra_ldflags</span><span class="p">,</span>
        <span class="n">extra_include_paths</span><span class="o">=</span><span class="n">extra_include_paths</span><span class="p">,</span>
        <span class="n">build_directory</span><span class="o">=</span><span class="n">build_directory</span><span class="p">,</span>
        <span class="n">need_lock</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="load">
<a class="viewcode-back" href="../../../reference/python/cpp/generated/tvm_ffi.cpp.load.html#tvm_ffi.cpp.load">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">cpp_files</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cuda_files</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_cuda_cflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_ldflags</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_include_paths</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">build_directory</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keep_module_alive</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Module</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compile, build and load a C++/CUDA module from source files.</span>

<span class="sd">    This function compiles the given C++ and/or CUDA source files into a shared library and loads it as a tvm ffi</span>
<span class="sd">    module. Both ``cpp_files`` and ``cuda_files`` are compiled to object files, and then linked together into a shared</span>
<span class="sd">    library. It&#39;s possible to only provide cpp_files or cuda_files.</span>

<span class="sd">    Note that this function does not automatically export functions to the tvm ffi module. You need to</span>
<span class="sd">    manually use the TVM FFI export macros (e.g., :c:macro:`TVM_FFI_DLL_EXPORT_TYPED_FUNC`) in your source files to export</span>
<span class="sd">    functions. This gives you more control over which functions are exported and how they are exported.</span>

<span class="sd">    Extra compiler and linker flags can be provided via the ``extra_cflags``, ``extra_cuda_cflags``, and ``extra_ldflags``</span>
<span class="sd">    parameters. The default flags are generally sufficient for most use cases, but you may need to provide additional</span>
<span class="sd">    flags for your specific use case.</span>

<span class="sd">    The include dir of tvm ffi and dlpack are used by default for the compiler to find the headers. Thus, you can</span>
<span class="sd">    include any header from tvm ffi in your source files. You can also provide additional include paths via the</span>
<span class="sd">    ``extra_include_paths`` parameter and include custom headers in your source code.</span>

<span class="sd">    The compiled shared library is cached in a cache directory to avoid recompilation. The `build_directory` parameter</span>
<span class="sd">    is provided to specify the build directory. If not specified, a default tvm ffi cache directory will be used.</span>
<span class="sd">    The default cache directory can be specified via the `TVM_FFI_CACHE_DIR` environment variable. If not specified,</span>
<span class="sd">    the default cache directory is ``~/.cache/tvm-ffi``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name</span>
<span class="sd">        The name of the tvm ffi module.</span>
<span class="sd">    cpp_files</span>
<span class="sd">        The C++ source files to compile. It can be a list of file paths or a single file path. Both absolute and</span>
<span class="sd">        relative paths are supported.</span>
<span class="sd">    cuda_files</span>
<span class="sd">        The CUDA source files to compile. It can be a list of file paths or a single file path. Both absolute and</span>
<span class="sd">        relative paths are supported.</span>
<span class="sd">    extra_cflags</span>
<span class="sd">        The extra compiler flags for C++ compilation.</span>
<span class="sd">        The default flags are:</span>

<span class="sd">        - On Linux/macOS: [&#39;-std=c++17&#39;, &#39;-fPIC&#39;, &#39;-O2&#39;]</span>
<span class="sd">        - On Windows: [&#39;/std:c++17&#39;, &#39;/MD&#39;, &#39;/O2&#39;]</span>

<span class="sd">    extra_cuda_cflags</span>
<span class="sd">        The extra compiler flags for CUDA compilation.</span>
<span class="sd">        The default flags are:</span>

<span class="sd">        - [&#39;-Xcompiler&#39;, &#39;-fPIC&#39;, &#39;-std=c++17&#39;, &#39;-O2&#39;] (Linux/macOS)</span>
<span class="sd">        - [&#39;-Xcompiler&#39;, &#39;/std:c++17&#39;, &#39;/O2&#39;] (Windows)</span>

<span class="sd">    extra_ldflags</span>
<span class="sd">        The extra linker flags.</span>
<span class="sd">        The default flags are:</span>

<span class="sd">        - On Linux/macOS: [&#39;-shared&#39;, &#39;-L&lt;tvm_ffi_lib_path&gt;&#39;, &#39;-ltvm_ffi&#39;]</span>
<span class="sd">        - On Windows: [&#39;/DLL&#39;, &#39;/LIBPATH:&lt;tvm_ffi_lib_path&gt;&#39;, &#39;&lt;tvm_ffi_lib_name&gt;.lib&#39;]</span>

<span class="sd">    extra_include_paths</span>
<span class="sd">        The extra include paths for header files. Both absolute and relative paths are supported.</span>

<span class="sd">    build_directory</span>
<span class="sd">        The build directory. If not specified, a default tvm ffi cache directory will be used. By default, the</span>
<span class="sd">        cache directory is ``~/.cache/tvm-ffi``. You can also set the ``TVM_FFI_CACHE_DIR`` environment variable to</span>
<span class="sd">        specify the cache directory.</span>

<span class="sd">    keep_module_alive</span>
<span class="sd">        Whether to keep the module alive. If True, the module will be kept alive</span>
<span class="sd">        for the duration of the program until libtvm_ffi.so is unloaded.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mod: Module</span>
<span class="sd">        The loaded tvm ffi module.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    :py:func:`tvm_ffi.load_module`</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import torch</span>
<span class="sd">        from tvm_ffi import Module</span>
<span class="sd">        import tvm_ffi.cpp</span>

<span class="sd">        # Assume we have a C++ source file &quot;my_ops.cpp&quot; with the following content:</span>
<span class="sd">        # ```cpp</span>
<span class="sd">        # #include &lt;tvm/ffi/container/tensor.h&gt;</span>
<span class="sd">        # #include &lt;tvm/ffi/dtype.h&gt;</span>
<span class="sd">        # #include &lt;tvm/ffi/error.h&gt;</span>
<span class="sd">        # #include &lt;tvm/ffi/extra/c_env_api.h&gt;</span>
<span class="sd">        # #include &lt;tvm/ffi/function.h&gt;</span>
<span class="sd">        #</span>
<span class="sd">        # void add_one_cpu(tvm::ffi::TensorView x, tvm::ffi::TensorView y) {</span>
<span class="sd">        #   TVM_FFI_ICHECK(x.ndim() == 1) &lt;&lt; &quot;x must be a 1D tensor&quot;;</span>
<span class="sd">        #   DLDataType f32_dtype{kDLFloat, 32, 1};</span>
<span class="sd">        #   TVM_FFI_ICHECK(x.dtype() == f32_dtype) &lt;&lt; &quot;x must be a float tensor&quot;;</span>
<span class="sd">        #   TVM_FFI_ICHECK(y.ndim() == 1) &lt;&lt; &quot;y must be a 1D tensor&quot;;</span>
<span class="sd">        #   TVM_FFI_ICHECK(y.dtype() == f32_dtype) &lt;&lt; &quot;y must be a float tensor&quot;;</span>
<span class="sd">        #   TVM_FFI_ICHECK(x.size(0) == y.size(0)) &lt;&lt; &quot;x and y must have the same shape&quot;;</span>
<span class="sd">        #   for (int i = 0; i &lt; x.size(0); ++i) {</span>
<span class="sd">        #     static_cast&lt;float*&gt;(y.data_ptr())[i] = static_cast&lt;float*&gt;(x.data_ptr())[i] + 1;</span>
<span class="sd">        #   }</span>
<span class="sd">        # }</span>
<span class="sd">        #</span>
<span class="sd">        # TVM_FFI_DLL_EXPORT_TYPED_FUNC(add_one_cpu, add_one_cpu);</span>
<span class="sd">        # ```</span>

<span class="sd">        # compile the cpp source file and load the module</span>
<span class="sd">        mod: Module = tvm_ffi.cpp.load(</span>
<span class="sd">            name=&quot;my_ops&quot;,</span>
<span class="sd">            cpp_files=&quot;my_ops.cpp&quot;,</span>
<span class="sd">        )</span>

<span class="sd">        # use the function from the loaded module</span>
<span class="sd">        x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)</span>
<span class="sd">        y = torch.empty_like(x)</span>
<span class="sd">        mod.add_one_cpu(x, y)</span>
<span class="sd">        torch.testing.assert_close(x + 1, y)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">load_module</span><span class="p">(</span>
        <span class="n">build</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">cpp_files</span><span class="o">=</span><span class="n">cpp_files</span><span class="p">,</span>
            <span class="n">cuda_files</span><span class="o">=</span><span class="n">cuda_files</span><span class="p">,</span>
            <span class="n">extra_cflags</span><span class="o">=</span><span class="n">extra_cflags</span><span class="p">,</span>
            <span class="n">extra_cuda_cflags</span><span class="o">=</span><span class="n">extra_cuda_cflags</span><span class="p">,</span>
            <span class="n">extra_ldflags</span><span class="o">=</span><span class="n">extra_ldflags</span><span class="p">,</span>
            <span class="n">extra_include_paths</span><span class="o">=</span><span class="n">extra_include_paths</span><span class="p">,</span>
            <span class="n">build_directory</span><span class="o">=</span><span class="n">build_directory</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">keep_module_alive</span><span class="o">=</span><span class="n">keep_module_alive</span><span class="p">,</span>
    <span class="p">)</span></div>

</pre></div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Apache TVM FFI contributors
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Feb 08, 2026.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  
  <div class="footer-container" style="margin: 5px 0; font-size: 0.9em; color: #6c757d;">
      <div class="footer-line1" style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 3px;">
          <div class="footer-copyright-short">
              Copyright © 2025, Apache Software Foundation
          </div>
          <div class="footer-dropdown">
              <div class="dropdown">
                  <button class="btn btn-link dropdown-toggle" type="button" id="footerDropdown" data-bs-toggle="dropdown"
                  aria-expanded="false" style="font-size: 0.9em; color: #6c757d; text-decoration: none; padding: 0; border: none; background: none;">
                      ASF
                  </button>
                  <ul class="dropdown-menu" aria-labelledby="footerDropdown" style="font-size: 0.9em;">
<li><a class="dropdown-item" href="https://apache.org/" target="_blank" style="font-size: 0.9em;">ASF Homepage</a></li>
<li><a class="dropdown-item" href="https://www.apache.org/licenses/" target="_blank" style="font-size: 0.9em;">License</a></li>
<li><a class="dropdown-item" href="https://www.apache.org/foundation/sponsorship.html" target="_blank" style="font-size: 0.9em;">Sponsorship</a></li>
<li><a class="dropdown-item" href="https://tvm.apache.org/docs/reference/security.html" target="_blank" style="font-size: 0.9em;">Security</a></li>
<li><a class="dropdown-item" href="https://www.apache.org/foundation/thanks.html" target="_blank" style="font-size: 0.9em;">Thanks</a></li>
<li><a class="dropdown-item" href="https://www.apache.org/events/current-event" target="_blank" style="font-size: 0.9em;">Events</a></li>
                  </ul>
              </div>
          </div>
      </div>
      <div class="footer-line2" style="font-size: 0.9em; color: #6c757d;">
          Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.
      </div>
  </div>
  
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>