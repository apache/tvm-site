<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Integrating TVM into PyTorch</title>
    <link rel="shortcut icon" href="/assets/images/favicon.ico">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    <link rel="stylesheet" href="/css/slick.css">
    <link rel="stylesheet" href="/css/slick-theme.css">
    <link rel="stylesheet" href="/css/custom.css">
    
</head>
<body>

    
<div class="bannerPage">
      <header class="header">
      <div class="container">
        <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
            <a href="/"><img src="/assets/images/logo.svg" alt="Logo"></a>
          </div>
          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="/assets/images/close-icon.svg"
                alt="Close"></button>
                <ul class="nav">
    
    <li class="nav-item">
        <a class="nav-link" href="/community">Community</a>
    </li>
    
    <li class="nav-item">
        <a class="nav-link" href="/download">Download</a>
    </li>
    
    <li class="nav-item">
        <a class="nav-link" href="/blog">Blog</a>
    </li>
    
    <li class="nav-item">
        <a class="nav-link" href="https://tvm.apache.org/docs/">Docs</a>
    </li>
    
    <li class="nav-item">
        <a class="nav-link" href="https://tvmcon.org/">Conference</a>
    </li>
    
    <li class="nav-item">
        <a class="nav-link" href="https://github.com/apache/tvm/">Github</a>
    </li>
    
</ul>
            <div class="responsiveasfdropdown">
              <button type="button" class="btn-link">
                ASF
              </button>
              <ul>
    
    <li>
        <a href="https://www.apache.org/">Apache Homepage</a>
    </li>
    
    <li>
        <a href="https://www.apache.org/licenses/">License</a>
    </li>
    
    <li>
        <a href="https://www.apache.org/foundation/sponsorship.html">Sponsorship</a>
    </li>
    
    <li>
        <a href="https://www.apache.org/security/">Security</a>
    </li>
    
    <li>
        <a href="https://www.apache.org/foundation/thanks.html">Thanks</a>
    </li>
    
    <li>
        <a href="https://www.apache.org/events/current-event">Events</a>
    </li>
    
</ul>
            </div>
          </div>
          <div class="responsiveMenuIcon">
            <button type="button" id="menuBtn" class="btn-menu"><img src="/assets/images/menu-icon.svg"
                alt="Menu Icon" /></button>
          </div>
          <div class="asfDropdown">
            <div class="dropdown">
              <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"
                aria-expanded="false">
                ASF
              </button>
              <div class="dropdown-menu dropdown-menu-right">
                <ul>
    
    <li>
        <a href="https://www.apache.org/">Apache Homepage</a>
    </li>
    
    <li>
        <a href="https://www.apache.org/licenses/">License</a>
    </li>
    
    <li>
        <a href="https://www.apache.org/foundation/sponsorship.html">Sponsorship</a>
    </li>
    
    <li>
        <a href="https://www.apache.org/security/">Security</a>
    </li>
    
    <li>
        <a href="https://www.apache.org/foundation/thanks.html">Thanks</a>
    </li>
    
    <li>
        <a href="https://www.apache.org/events/current-event">Events</a>
    </li>
    
</ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </header>

</div>


<div class="container">
<div class="content">
  <div class="row">
    <div class="span14 w-100">
      <h1>Integrating TVM into PyTorch </h1>
      <p class="post-meta">
        <time datetime="2019-05-30T00:00:00+00:00" itemprop="datePublished">
          May 30, 2019
        </time>
        
        • <span itemprop="author" itemscope itemtype="http://schema.org/Person">
          <span itemprop="name">Bram Wasti</span>
        </span>
        
      </p>
      <p class="post-meta">
        </p>
    </br>
    <p>As TVM continuously demonstrates improvements to the efficiency of deep learning execution,
it has become clear that PyTorch stands to benefit from directly leveraging the compiler stack.
A major tenet of PyTorch is providing seamless and robust integrations that don’t get in the user’s way.
To that end, PyTorch now has an official TVM-based backend, <a href="https://github.com/pytorch/tvm">torch_tvm</a>.</p>

<p>Usage is simple:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import torch_tvm
torch_tvm.enable()
</code></pre></div></div>

<p>That’s it!  PyTorch will then attempt to convert all operators it can to known Relay operators during its JIT compilation process.</p>

<h3 id="background">Background</h3>

<p>Unlike many other ML frameworks, PyTorch exposes an eager-execution programming interface.  This style of programming avoids graph-based meta-programming and focuses on the direct manipulation of n-dimensional arrays (tensors) in a Pythonic way.  As such, the framework was initially well suited for the experimentation and development of models, but not for automatic performance optimization or deployment.  To leverage optimizing compiler techniques, some large changes were recently introduced to PyTorch to solve this problem.</p>

<p><img src="https://i.imgur.com/4XVHbJE.png" alt="TVM Integration" /></p>

<p>PyTorch 1.0 introduced PyTorch IR, a PyTorch-specific intermediate representation for models similar to Relay.  PyTorch programs can be converted into the IR via model tracing, which records the execution of a model or TorchScript, a subset of Python.  The new TVM backend lowers PyTorch IR to Relay, and is able to transparently improve PyTorch performance with little user involvement.</p>

<h3 id="integration-and-results">Integration and Results</h3>

<p>To support Relay, two features were added to the PyTorch JIT: custom transformation passes and custom subgraph interpreters.</p>

<p>When <code class="language-plaintext highlighter-rouge">torch_tvm</code> is enabled, subgraphs of PyTorch IR that can be converted to Relay <code class="language-plaintext highlighter-rouge">Expr</code>s will be marked as Relay-compatible.  Since PyTorch IR does not always contain shape information, none of the subgraphs can be compiled in a useful way before invocation.</p>

<p>During user invocation, the PyTorch JIT runtime will determine input shape information and compile the previously marked subgraphs with the new Relay C++ <a href="https://github.com/pytorch/tvm/blob/main/torch_tvm/compiler.cpp#L226-L246">build system</a>.  The compilation is cached based on input shapes for subsequent runs.  More details can be found in the <a href="https://github.com/pytorch/tvm/blob/main/README.md">README</a>.</p>

<p><code class="language-plaintext highlighter-rouge">torch_tvm</code> has a continuous benchmark system set up, which is monitoring the performance of ResNet18 on CPU.
Out of the box TVM provides over two times the performance of the default PyTorch JIT backend for various ResNet models.
Below is a graph that details the iterations per second achieved with 16 threads on an AWS c5n.4xlarge instance (larger is better):</p>

<p style="text-align: center"><img src="https://i.imgur.com/KfJ7oas.png" alt="bench" width="90%" /></p>

<p>These results are quite encouraging, and the project will continue to focus on improving CPU inference speed across more models.</p>

<h3 id="future-work">Future work</h3>

<p>Right now the PyTorch JIT does a lot of work to find pure functional subsets of its IR to feed to Relay.  This avoids the need to map aliasing and control flow information to Relay, but is not necessary.  Mapping more of the PyTorch IR to Relay may yield performance wins and is a goal of the project.  PyTorch IR is rapidly changing as it is being developed, so this must be done carefully.</p>

<p>More work will be done to ensure the hand off between PyTorch and TVM code is efficient.  This includes unifying the threading model, allocators and reducing the overhead associated with copying inputs into TVM.</p>

<h3 id="tutorial">Tutorial</h3>

<p>If you have an already written PyTorch model, the easiest way to get started comes from using <code class="language-plaintext highlighter-rouge">torch.jit.trace</code> as follows</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import torch_tvm
from your_model import model, inputs

torch_tvm.enable(opt_level=3)

iters = 100
warmup = 10

# Ensure your model is in eval mode and also turn off gradients.
with torch.no_grad():
  # Use tuned parameters for better performance.
  with autotvm.apply_history_best("test/autotvm_tuning.log"):
    # This is where all the compilation happens.
    trace_tvm = torch.jit.trace(model, inputs)
    
    # Warmup
    for _ in range(warmup):
      _ = trace_tvm(*inputs)

    # Benchmark
    start = time.time()
    for _ in range(iters):
      _ = trace_tvm(*inputs)
    tvm_time = time.time() - start
    
    print("Took {}s to run {} iters".format(tvm_time, iters))
</code></pre></div></div>

<p>Much of this code comes from <a href="https://github.com/pytorch/tvm/blob/main/test/benchmarks.py">benchmarks.py</a>.  Note that tuned parameters for AVX2 LLVM compilation is in the <code class="language-plaintext highlighter-rouge">test/</code> folder of the repo.</p>

<p>If you are more comfortable using Relay directly, it is possible to simply extract the expression directly from a
PyTorch function either via (implicit) tracing or TorchScript:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def add(a, b, c):
    return a + b + c

# via tracing
relay_graph = torch_tvm.to_relay(add, inputs)

@torch.jit.script
def mul(a, b, c):
    return a * b * c

# via script
relay_graph = torch_tvm.to_relay(mul, inputs)
</code></pre></div></div>


    </div>
  </div>
</div>
</div>

    




  <script src="https://code.jquery.com/jquery-2.2.0.min.js" type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
  <!-- <script src="./assets/js/slick.js"></script> -->
  <script src="/assets/js/custome.js"></script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-75982049-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-75982049-2');
  </script>
</body>
<section class="footerSec">
  <div class="footerHeader">
    <ul class="container d-flex align-md-items-center justify-content-between flex-column flex-md-row">
      <li class="logo">

        <p><a href="/"><img src="/assets/images/logo.svg" alt="logo" title="logo" /></a></p>
      </li>
      <li class="copywrite d-flex align-items-center">
        <h5 id="apache-software-foundation--all-right-reserved">© 2024 Apache Software Foundation | All right reserved</h5>
      </li>
    </ul>

  </div>

  <ul class="container">
    <li class="footernote">
      Copyright © 2024 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</li>
  </ul>

</section>
</html>
