
.. DO NOT EDIT. THIS FILE WAS AUTOMATICALLY GENERATED BY
.. TVM'S MONKEY-PATCHED VERSION OF SPHINX-GALLERY. TO MAKE
.. CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "how_to/compile_models/from_pytorch.py"

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        This tutorial can be used interactively with Google Colab! You can also click
        :ref:`here <sphx_glr_download_how_to_compile_models_from_pytorch.py>` to run the Jupyter notebook locally.

        .. image:: https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg
            :align: center
            :target: https://colab.research.google.com/github/apache/tvm-site/blob/asf-site/docs/_downloads/1f4943aed1aa607b2775c18b1d71db10/from_pytorch.ipynb
            :width: 300px

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_how_to_compile_models_from_pytorch.py:


Compile PyTorch Models
======================
**Author**: `Alex Wong <https://github.com/alexwong/>`_

This article is an introductory tutorial to deploy PyTorch models with Relay.

For us to begin, PyTorch should be installed.
TorchVision is also required so we can use the model zoo.
A quick solution is to install via pip:

.. code-block:: bash

    %%shell
    pip install torch
    pip install torchvision

or please refer to official site
https://pytorch.org/get-started/locally/

PyTorch versions should be backwards compatible but should be used
with the proper TorchVision version.

Currently, TVM supports PyTorch 1.7 and 1.4. Other versions may
be unstable.

.. GENERATED FROM PYTHON SOURCE LINES 43-55

.. code-block:: default


    import tvm
    from tvm import relay

    import numpy as np

    from tvm.contrib.download import download_testdata

    # PyTorch imports
    import torch
    import torchvision








.. GENERATED FROM PYTHON SOURCE LINES 56-58

Load a pretrained PyTorch model
-------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 58-67

.. code-block:: default

    model_name = "resnet18"
    model = getattr(torchvision.models, model_name)(pretrained=True)
    model = model.eval()

    # We grab the TorchScripted model via tracing
    input_shape = [1, 3, 224, 224]
    input_data = torch.randn(input_shape)
    scripted_model = torch.jit.trace(model, input_data).eval()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /venv/apache-tvm-py3.7/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
      f"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, "
    /venv/apache-tvm-py3.7/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
      warnings.warn(msg)
    Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /workspace/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth
      0%|          | 0.00/44.7M [00:00<?, ?B/s]     18%|#7        | 7.99M/44.7M [00:00<00:00, 59.1MB/s]     36%|###5      | 16.0M/44.7M [00:00<00:00, 48.4MB/s]     54%|#####3    | 24.0M/44.7M [00:00<00:00, 59.5MB/s]     72%|#######1  | 32.0M/44.7M [00:00<00:00, 60.7MB/s]     90%|########9 | 40.0M/44.7M [00:00<00:00, 58.3MB/s]    100%|##########| 44.7M/44.7M [00:00<00:00, 62.7MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 68-71

Load a test image
-----------------
Classic cat example!

.. GENERATED FROM PYTHON SOURCE LINES 71-91

.. code-block:: default

    from PIL import Image

    img_url = "https://github.com/dmlc/mxnet.js/blob/main/data/cat.png?raw=true"
    img_path = download_testdata(img_url, "cat.png", module="data")
    img = Image.open(img_path).resize((224, 224))

    # Preprocess the image and convert to tensor
    from torchvision import transforms

    my_preprocess = transforms.Compose(
        [
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )
    img = my_preprocess(img)
    img = np.expand_dims(img, 0)








.. GENERATED FROM PYTHON SOURCE LINES 92-95

Import the graph to Relay
-------------------------
Convert PyTorch graph to Relay graph. The input name can be arbitrary.

.. GENERATED FROM PYTHON SOURCE LINES 95-99

.. code-block:: default

    input_name = "input0"
    shape_list = [(input_name, img.shape)]
    mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)








.. GENERATED FROM PYTHON SOURCE LINES 100-103

Relay Build
-----------
Compile the graph to llvm target with given input specification.

.. GENERATED FROM PYTHON SOURCE LINES 103-108

.. code-block:: default

    target = tvm.target.Target("llvm", host="llvm")
    dev = tvm.cpu(0)
    with tvm.transform.PassContext(opt_level=3):
        lib = relay.build(mod, target=target, params=params)








.. GENERATED FROM PYTHON SOURCE LINES 109-112

Execute the portable graph on TVM
---------------------------------
Now we can try deploying the compiled model on target.

.. GENERATED FROM PYTHON SOURCE LINES 112-123

.. code-block:: default

    from tvm.contrib import graph_executor

    dtype = "float32"
    m = graph_executor.GraphModule(lib["default"](dev))
    # Set inputs
    m.set_input(input_name, tvm.nd.array(img.astype(dtype)))
    # Execute
    m.run()
    # Get outputs
    tvm_output = m.get_output(0)








.. GENERATED FROM PYTHON SOURCE LINES 124-127

Look up synset name
-------------------
Look up prediction top 1 index in 1000 class synset.

.. GENERATED FROM PYTHON SOURCE LINES 127-172

.. code-block:: default

    synset_url = "".join(
        [
            "https://raw.githubusercontent.com/Cadene/",
            "pretrained-models.pytorch/master/data/",
            "imagenet_synsets.txt",
        ]
    )
    synset_name = "imagenet_synsets.txt"
    synset_path = download_testdata(synset_url, synset_name, module="data")
    with open(synset_path) as f:
        synsets = f.readlines()

    synsets = [x.strip() for x in synsets]
    splits = [line.split(" ") for line in synsets]
    key_to_classname = {spl[0]: " ".join(spl[1:]) for spl in splits}

    class_url = "".join(
        [
            "https://raw.githubusercontent.com/Cadene/",
            "pretrained-models.pytorch/master/data/",
            "imagenet_classes.txt",
        ]
    )
    class_name = "imagenet_classes.txt"
    class_path = download_testdata(class_url, class_name, module="data")
    with open(class_path) as f:
        class_id_to_key = f.readlines()

    class_id_to_key = [x.strip() for x in class_id_to_key]

    # Get top-1 result for TVM
    top1_tvm = np.argmax(tvm_output.numpy()[0])
    tvm_class_key = class_id_to_key[top1_tvm]

    # Convert input to PyTorch variable and get PyTorch result for comparison
    with torch.no_grad():
        torch_img = torch.from_numpy(img)
        output = model(torch_img)

        # Get top-1 result for PyTorch
        top1_torch = np.argmax(output.numpy())
        torch_class_key = class_id_to_key[top1_torch]

    print("Relay top-1 id: {}, class name: {}".format(top1_tvm, key_to_classname[tvm_class_key]))
    print("Torch top-1 id: {}, class name: {}".format(top1_torch, key_to_classname[torch_class_key]))




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Relay top-1 id: 281, class name: tabby, tabby cat
    Torch top-1 id: 281, class name: tabby, tabby cat





.. _sphx_glr_download_how_to_compile_models_from_pytorch.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: from_pytorch.py <from_pytorch.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: from_pytorch.ipynb <from_pytorch.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
