
.. DO NOT EDIT. THIS FILE WAS AUTOMATICALLY GENERATED BY
.. TVM'S MONKEY-PATCHED VERSION OF SPHINX-GALLERY. TO MAKE
.. CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "how_to/compile_models/from_darknet.py"

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        This tutorial can be used interactively with Google Colab! You can also click
        :ref:`here <sphx_glr_download_how_to_compile_models_from_darknet.py>` to run the Jupyter notebook locally.

        .. image:: https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg
            :align: center
            :target: https://colab.research.google.com/github/apache/tvm-site/blob/asf-site/docs/_downloads/f97d815b408ef3f4d6bcb3e073c2d4dd/from_darknet.ipynb
            :width: 300px

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_how_to_compile_models_from_darknet.py:


Compile YOLO-V2 and YOLO-V3 in DarkNet Models
=============================================
**Author**: `Siju Samuel <https://siju-samuel.github.io/>`_

This article is an introductory tutorial to deploy darknet models with TVM.
All the required models and libraries will be downloaded from the internet by the script.
This script runs the YOLO-V2 and YOLO-V3 Model with the bounding boxes
Darknet parsing have dependancy with CFFI and CV2 library
Please install CFFI and CV2 before executing this script

.. code-block:: bash

  %%shell
  pip install cffi opencv-python

.. GENERATED FROM PYTHON SOURCE LINES 34-50

.. code-block:: default


    # numpy and matplotlib
    import numpy as np
    import matplotlib.pyplot as plt
    import sys

    # tvm, relay
    import tvm
    from tvm import te
    from tvm import relay
    from ctypes import *
    from tvm.contrib.download import download_testdata
    from tvm.relay.testing.darknet import __darknetffi__
    import tvm.relay.testing.yolo_detection
    import tvm.relay.testing.darknet








.. GENERATED FROM PYTHON SOURCE LINES 51-54

Choose the model
-----------------------
Models are: 'yolov2', 'yolov3' or 'yolov3-tiny'

.. GENERATED FROM PYTHON SOURCE LINES 54-58

.. code-block:: default


    # Model name
    MODEL_NAME = "yolov3"








.. GENERATED FROM PYTHON SOURCE LINES 59-62

Download required files
-----------------------
Download cfg and weights file if first time.

.. GENERATED FROM PYTHON SOURCE LINES 62-94

.. code-block:: default

    CFG_NAME = MODEL_NAME + ".cfg"
    WEIGHTS_NAME = MODEL_NAME + ".weights"
    REPO_URL = "https://github.com/dmlc/web-data/blob/main/darknet/"
    CFG_URL = REPO_URL + "cfg/" + CFG_NAME + "?raw=true"
    WEIGHTS_URL = "https://pjreddie.com/media/files/" + WEIGHTS_NAME

    cfg_path = download_testdata(CFG_URL, CFG_NAME, module="darknet")
    weights_path = download_testdata(WEIGHTS_URL, WEIGHTS_NAME, module="darknet")

    # Download and Load darknet library
    if sys.platform in ["linux", "linux2"]:
        DARKNET_LIB = "libdarknet2.0.so"
        DARKNET_URL = REPO_URL + "lib/" + DARKNET_LIB + "?raw=true"
    elif sys.platform == "darwin":
        DARKNET_LIB = "libdarknet_mac2.0.so"
        DARKNET_URL = REPO_URL + "lib_osx/" + DARKNET_LIB + "?raw=true"
    else:
        err = "Darknet lib is not supported on {} platform".format(sys.platform)
        raise NotImplementedError(err)

    lib_path = download_testdata(DARKNET_URL, DARKNET_LIB, module="darknet")

    DARKNET_LIB = __darknetffi__.dlopen(lib_path)
    net = DARKNET_LIB.load_network(cfg_path.encode("utf-8"), weights_path.encode("utf-8"), 0)
    dtype = "float32"
    batch_size = 1

    data = np.empty([batch_size, net.c, net.h, net.w], dtype)
    shape_dict = {"data": data.shape}
    print("Converting darknet to relay functions...")
    mod, params = relay.frontend.from_darknet(net, dtype=dtype, shape=data.shape)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Converting darknet to relay functions...




.. GENERATED FROM PYTHON SOURCE LINES 95-98

Import the graph to Relay
-------------------------
compile the model

.. GENERATED FROM PYTHON SOURCE LINES 98-107

.. code-block:: default

    target = tvm.target.Target("llvm", host="llvm")
    dev = tvm.cpu(0)
    data = np.empty([batch_size, net.c, net.h, net.w], dtype)
    shape = {"data": data.shape}
    print("Compiling the model...")
    with tvm.transform.PassContext(opt_level=3):
        lib = relay.build(mod, target=target, params=params)

    [neth, netw] = shape["data"][2:]  # Current image shape is 608x608




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Compiling the model...




.. GENERATED FROM PYTHON SOURCE LINES 108-110

Load a test image
-----------------

.. GENERATED FROM PYTHON SOURCE LINES 110-116

.. code-block:: default

    test_image = "dog.jpg"
    print("Loading the test image...")
    img_url = REPO_URL + "data/" + test_image + "?raw=true"
    img_path = download_testdata(img_url, test_image, "data")

    data = tvm.relay.testing.darknet.load_image(img_path, netw, neth)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Loading the test image...




.. GENERATED FROM PYTHON SOURCE LINES 117-120

Execute on TVM Runtime
----------------------
The process is no different from other examples.

.. GENERATED FROM PYTHON SOURCE LINES 120-204

.. code-block:: default

    from tvm.contrib import graph_executor

    m = graph_executor.GraphModule(lib["default"](dev))

    # set inputs
    m.set_input("data", tvm.nd.array(data.astype(dtype)))
    # execute
    print("Running the test image...")

    # detection
    # thresholds
    thresh = 0.5
    nms_thresh = 0.45

    m.run()
    # get outputs
    tvm_out = []
    if MODEL_NAME == "yolov2":
        layer_out = {}
        layer_out["type"] = "Region"
        # Get the region layer attributes (n, out_c, out_h, out_w, classes, coords, background)
        layer_attr = m.get_output(2).numpy()
        layer_out["biases"] = m.get_output(1).numpy()
        out_shape = (layer_attr[0], layer_attr[1] // layer_attr[0], layer_attr[2], layer_attr[3])
        layer_out["output"] = m.get_output(0).numpy().reshape(out_shape)
        layer_out["classes"] = layer_attr[4]
        layer_out["coords"] = layer_attr[5]
        layer_out["background"] = layer_attr[6]
        tvm_out.append(layer_out)

    elif MODEL_NAME == "yolov3":
        for i in range(3):
            layer_out = {}
            layer_out["type"] = "Yolo"
            # Get the yolo layer attributes (n, out_c, out_h, out_w, classes, total)
            layer_attr = m.get_output(i * 4 + 3).numpy()
            layer_out["biases"] = m.get_output(i * 4 + 2).numpy()
            layer_out["mask"] = m.get_output(i * 4 + 1).numpy()
            out_shape = (layer_attr[0], layer_attr[1] // layer_attr[0], layer_attr[2], layer_attr[3])
            layer_out["output"] = m.get_output(i * 4).numpy().reshape(out_shape)
            layer_out["classes"] = layer_attr[4]
            tvm_out.append(layer_out)

    elif MODEL_NAME == "yolov3-tiny":
        for i in range(2):
            layer_out = {}
            layer_out["type"] = "Yolo"
            # Get the yolo layer attributes (n, out_c, out_h, out_w, classes, total)
            layer_attr = m.get_output(i * 4 + 3).numpy()
            layer_out["biases"] = m.get_output(i * 4 + 2).numpy()
            layer_out["mask"] = m.get_output(i * 4 + 1).numpy()
            out_shape = (layer_attr[0], layer_attr[1] // layer_attr[0], layer_attr[2], layer_attr[3])
            layer_out["output"] = m.get_output(i * 4).numpy().reshape(out_shape)
            layer_out["classes"] = layer_attr[4]
            tvm_out.append(layer_out)
            thresh = 0.560

    # do the detection and bring up the bounding boxes
    img = tvm.relay.testing.darknet.load_image_color(img_path)
    _, im_h, im_w = img.shape
    dets = tvm.relay.testing.yolo_detection.fill_network_boxes(
        (netw, neth), (im_w, im_h), thresh, 1, tvm_out
    )
    last_layer = net.layers[net.n - 1]
    tvm.relay.testing.yolo_detection.do_nms_sort(dets, last_layer.classes, nms_thresh)

    coco_name = "coco.names"
    coco_url = REPO_URL + "data/" + coco_name + "?raw=true"
    font_name = "arial.ttf"
    font_url = REPO_URL + "data/" + font_name + "?raw=true"
    coco_path = download_testdata(coco_url, coco_name, module="data")
    font_path = download_testdata(font_url, font_name, module="data")

    with open(coco_path) as f:
        content = f.readlines()

    names = [x.strip() for x in content]

    tvm.relay.testing.yolo_detection.show_detections(img, dets, thresh, names, last_layer.classes)
    tvm.relay.testing.yolo_detection.draw_detections(
        font_path, img, dets, thresh, names, last_layer.classes
    )
    plt.imshow(img.transpose(1, 2, 0))
    plt.show()



.. image-sg:: /how_to/compile_models/images/sphx_glr_from_darknet_001.png
   :alt: from darknet
   :srcset: /how_to/compile_models/images/sphx_glr_from_darknet_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Running the test image...
    class:['dog 0.994'] left:127 top:227 right:316 bottom:533
    class:['truck 0.9266'] left:471 top:83 right:689 bottom:169
    class:['bicycle 0.9984'] left:111 top:113 right:577 bottom:447





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  21.271 seconds)


.. _sphx_glr_download_how_to_compile_models_from_darknet.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: from_darknet.py <from_darknet.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: from_darknet.ipynb <from_darknet.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
