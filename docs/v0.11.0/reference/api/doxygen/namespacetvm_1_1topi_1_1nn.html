<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>tvm: tvm::topi::nn Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">tvm
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacetvm.html">tvm</a></li><li class="navelem"><a class="el" href="namespacetvm_1_1topi.html">topi</a></li><li class="navelem"><a class="el" href="namespacetvm_1_1topi_1_1nn.html">nn</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#enum-members">Enumerations</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">tvm::topi::nn Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:a3ffa0974d8cdcd5b8ca7afb3cfbaf53c"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a> : int { <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53ca9780bd19bf6706355258ca09ddeab335">kAvgPool</a>, 
<a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53cae5769af06e46579729c6b5e2d0c70563">kMaxPool</a>
 }<tr class="memdesc:a3ffa0974d8cdcd5b8ca7afb3cfbaf53c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pooling type.  <a href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:a3ffa0974d8cdcd5b8ca7afb3cfbaf53c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a258f660698c476e2ac7e7f78b32ad6ba"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a258f660698c476e2ac7e7f78b32ad6ba">bias_add</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;data, const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;bias, int axis)</td></tr>
<tr class="memdesc:a258f660698c476e2ac7e7f78b32ad6ba"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates an operation that calculates data + bias.  <a href="#a258f660698c476e2ac7e7f78b32ad6ba">More...</a><br /></td></tr>
<tr class="separator:a258f660698c476e2ac7e7f78b32ad6ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abaa4e2bba6a3d3db3eaca614fdf5bbea"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#abaa4e2bba6a3d3db3eaca614fdf5bbea">binarize_pack</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;data, int axis, std::string name=&quot;PackedInput&quot;, std::string tag=&quot;binarize_pack&quot;)</td></tr>
<tr class="memdesc:abaa4e2bba6a3d3db3eaca614fdf5bbea"><td class="mdescLeft">&#160;</td><td class="mdescRight">Binarization and bit-packing along a certain axis.  <a href="#abaa4e2bba6a3d3db3eaca614fdf5bbea">More...</a><br /></td></tr>
<tr class="separator:abaa4e2bba6a3d3db3eaca614fdf5bbea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08aaeadaa767fa996d2f2e0a7d12c7cd"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a08aaeadaa767fa996d2f2e0a7d12c7cd">binary_dense</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;data, const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;weight)</td></tr>
<tr class="memdesc:a08aaeadaa767fa996d2f2e0a7d12c7cd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Binary matrix multiplication using xor and bit-count.  <a href="#a08aaeadaa767fa996d2f2e0a7d12c7cd">More...</a><br /></td></tr>
<tr class="separator:a08aaeadaa767fa996d2f2e0a7d12c7cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34e1a8305acf89ef2f745c8d99bf8e89"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a34e1a8305acf89ef2f745c8d99bf8e89">dense</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;data, const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;weight, const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;bias, const <a class="el" href="classtvm_1_1runtime_1_1DataType.html">DataType</a> &amp;out_dtype)</td></tr>
<tr class="memdesc:a34e1a8305acf89ef2f745c8d99bf8e89"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates an operation that calculates data * weight^T + bias.  <a href="#a34e1a8305acf89ef2f745c8d99bf8e89">More...</a><br /></td></tr>
<tr class="separator:a34e1a8305acf89ef2f745c8d99bf8e89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a93ec4d667dc49c109a0ccb16f6c6d05b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a93ec4d667dc49c109a0ccb16f6c6d05b">all</a> (<a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; args)</td></tr>
<tr class="memdesc:a93ec4d667dc49c109a0ccb16f6c6d05b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a new expression of the logical and of all conditions in the arguments.  <a href="#a93ec4d667dc49c109a0ccb16f6c6d05b">More...</a><br /></td></tr>
<tr class="separator:a93ec4d667dc49c109a0ccb16f6c6d05b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af210f30ef7afb28cd369dacc8f05be68"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#af210f30ef7afb28cd369dacc8f05be68">dilate</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; strides, double dilation_value, std::string name=&quot;tensor&quot;, std::string tag=<a class="el" href="namespacetvm_1_1topi.html#a29e22aa45900dad3b6f9f705bb1dc688">kInjective</a>)</td></tr>
<tr class="memdesc:af210f30ef7afb28cd369dacc8f05be68"><td class="mdescLeft">&#160;</td><td class="mdescRight">Dilate data with given dilation value (0 by default).  <a href="#af210f30ef7afb28cd369dacc8f05be68">More...</a><br /></td></tr>
<tr class="separator:af210f30ef7afb28cd369dacc8f05be68"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a553de73860c1a295d6ee566a3916b4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a6a553de73860c1a295d6ee566a3916b4">flatten</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, std::string name=&quot;tensor&quot;, std::string tag=<a class="el" href="namespacetvm_1_1topi.html#a29e22aa45900dad3b6f9f705bb1dc688">kInjective</a>)</td></tr>
<tr class="memdesc:a6a553de73860c1a295d6ee566a3916b4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Flattens the input tensor into a 2-D tensor by collapsing higher dimensions. This requires the input tensor to have constant sized dimensions.  <a href="#a6a553de73860c1a295d6ee566a3916b4">More...</a><br /></td></tr>
<tr class="separator:a6a553de73860c1a295d6ee566a3916b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:accc17ec14bd2ccc2c0e8055165ba69bd"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#accc17ec14bd2ccc2c0e8055165ba69bd">layer_norm</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;data, const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;gamma, const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;beta, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1Integer.html">Integer</a> &gt; &amp;axis, double epsilon, std::string name=&quot;T_layer_norm&quot;, std::string tag=<a class="el" href="namespacetvm_1_1topi.html#a29e22aa45900dad3b6f9f705bb1dc688">kInjective</a>)</td></tr>
<tr class="memdesc:accc17ec14bd2ccc2c0e8055165ba69bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Layer normalization.  <a href="#accc17ec14bd2ccc2c0e8055165ba69bd">More...</a><br /></td></tr>
<tr class="separator:accc17ec14bd2ccc2c0e8055165ba69bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac3d8de9144f915a5dd27dcb70c0abdd4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#ac3d8de9144f915a5dd27dcb70c0abdd4">lrn</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;data, int size, int axis=1, float alpha=0.0001, float beta=0.75, float bias=2, std::string name=&quot;tensor&quot;, std::string tag=<a class="el" href="namespacetvm_1_1topi.html#a13aaf23f0ab77f1ed4a7d4b7816bf210">kBroadcast</a>)</td></tr>
<tr class="memdesc:ac3d8de9144f915a5dd27dcb70c0abdd4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Local response normalization inference operator.  <a href="#ac3d8de9144f915a5dd27dcb70c0abdd4">More...</a><br /></td></tr>
<tr class="separator:ac3d8de9144f915a5dd27dcb70c0abdd4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07b8a04f27f17af58dd9f18218cfe081"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a07b8a04f27f17af58dd9f18218cfe081">scale_shift_nchw</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;scale, const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;shift, std::string name=&quot;ScaleShift&quot;, std::string tag=<a class="el" href="namespacetvm_1_1topi.html#a13aaf23f0ab77f1ed4a7d4b7816bf210">kBroadcast</a>)</td></tr>
<tr class="memdesc:a07b8a04f27f17af58dd9f18218cfe081"><td class="mdescLeft">&#160;</td><td class="mdescRight">Scale and shift with NCHW order.  <a href="#a07b8a04f27f17af58dd9f18218cfe081">More...</a><br /></td></tr>
<tr class="separator:a07b8a04f27f17af58dd9f18218cfe081"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acaf3bc4e89fc55b8444d2550d25f4f22"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#acaf3bc4e89fc55b8444d2550d25f4f22">scale_shift_nhwc</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;scale, const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;shift, std::string name=&quot;ScaleShift&quot;, std::string tag=<a class="el" href="namespacetvm_1_1topi.html#a13aaf23f0ab77f1ed4a7d4b7816bf210">kBroadcast</a>)</td></tr>
<tr class="memdesc:acaf3bc4e89fc55b8444d2550d25f4f22"><td class="mdescLeft">&#160;</td><td class="mdescRight">Scale and shift with NHWC order.  <a href="#acaf3bc4e89fc55b8444d2550d25f4f22">More...</a><br /></td></tr>
<tr class="separator:acaf3bc4e89fc55b8444d2550d25f4f22"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2806be7f95eec10be2b3555a9094cee2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a2806be7f95eec10be2b3555a9094cee2">pool_grad_impl</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;out_grad, const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;kernel_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;stride_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;padding_size, <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a> pool_type, bool ceil_mode, const size_t height_axis, const size_t width_axis, bool count_include_pad)</td></tr>
<tr class="separator:a2806be7f95eec10be2b3555a9094cee2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab03974ee6b2d02a4619de1a4d0b42891"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#ab03974ee6b2d02a4619de1a4d0b42891">find_depth_height_width</a> (const std::string &amp;layout, int *depth_axis, int *height_axis, int *width_axis)</td></tr>
<tr class="separator:ab03974ee6b2d02a4619de1a4d0b42891"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec3b2a3e902d0d9c1f89d04ee8b3bcac"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#aec3b2a3e902d0d9c1f89d04ee8b3bcac">find_height_width</a> (const std::string &amp;layout, int *height_axis, int *width_axis)</td></tr>
<tr class="separator:aec3b2a3e902d0d9c1f89d04ee8b3bcac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab678a94b9369834c1b5d24d5a4595dbf"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#ab678a94b9369834c1b5d24d5a4595dbf">find_width</a> (const std::string &amp;layout, int *width_axis)</td></tr>
<tr class="separator:ab678a94b9369834c1b5d24d5a4595dbf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7bb635a3241be1593258b374e651e344"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a7bb635a3241be1593258b374e651e344">pool_grad</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;out_grad, const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;kernel_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;stride_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;padding_size, <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a> pool_type, bool ceil_mode, const std::string &amp;layout=&quot;NCHW&quot;, bool count_include_pad=true)</td></tr>
<tr class="memdesc:a7bb635a3241be1593258b374e651e344"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculate gradient of pooling on height and width dimension of data. It decides the height and width dimension according to the layout string, in which 'W' and 'H' means width and height respectively. Width and height dimension cannot be split. For example, NCHW, NCHW16c, etc. are valid for pool, while NCHW16w, NCHW16h are not. See <em>layout</em> for more information of the layout string convention.  <a href="#a7bb635a3241be1593258b374e651e344">More...</a><br /></td></tr>
<tr class="separator:a7bb635a3241be1593258b374e651e344"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a752c4130dac73fd2de0390c5f6b24b15"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a752c4130dac73fd2de0390c5f6b24b15">start_index</a> (const <a class="el" href="classtvm_1_1tir_1_1Var.html">Var</a> &amp;out_index, const <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &amp;odim, const <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &amp;idim)</td></tr>
<tr class="separator:a752c4130dac73fd2de0390c5f6b24b15"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d244c196a5a481640cfc610fad3c7db"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a8d244c196a5a481640cfc610fad3c7db">end_index</a> (const <a class="el" href="classtvm_1_1tir_1_1Var.html">Var</a> &amp;out_index, const <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &amp;odim, const <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &amp;idim)</td></tr>
<tr class="separator:a8d244c196a5a481640cfc610fad3c7db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3fb74f1c3df6edf17c9a3f1e122f84fe"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3fb74f1c3df6edf17c9a3f1e122f84fe">adaptive_pool_impl</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;output_size, <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a> pool_type, const std::vector&lt; int &gt; &amp;axes)</td></tr>
<tr class="memdesc:a3fb74f1c3df6edf17c9a3f1e122f84fe"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform adaptive pooling on N dimensional data.  <a href="#a3fb74f1c3df6edf17c9a3f1e122f84fe">More...</a><br /></td></tr>
<tr class="separator:a3fb74f1c3df6edf17c9a3f1e122f84fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a150f883cae332ed85d56522da218ad73"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a150f883cae332ed85d56522da218ad73">adaptive_pool</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;output_size, <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a> pool_type, const std::string &amp;layout=&quot;NCHW&quot;)</td></tr>
<tr class="memdesc:a150f883cae332ed85d56522da218ad73"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adaptively perform pooling on height and width dimension of data. The pooling kernel and stride sizes are automatically chosen for desired output sizes. It decides the height and width dimension according to the layout string, in which 'W' and 'H' means width and height respectively. Width and height dimension cannot be split. For example, NCHW, NCHW16c, etc. are valid for pool, while NCHW16w, NCHW16h are not. See <em>layout</em> for more information of the layout string convention.  <a href="#a150f883cae332ed85d56522da218ad73">More...</a><br /></td></tr>
<tr class="separator:a150f883cae332ed85d56522da218ad73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a66fdbc05d6f8f5fade4e14ca1dbc686a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a66fdbc05d6f8f5fade4e14ca1dbc686a">adaptive_pool3d</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;output_size, <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a> pool_type, const std::string &amp;layout=&quot;NCDHW&quot;)</td></tr>
<tr class="memdesc:a66fdbc05d6f8f5fade4e14ca1dbc686a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adaptively perform pooling on three dimensional data. See the two dimensional version above for details.  <a href="#a66fdbc05d6f8f5fade4e14ca1dbc686a">More...</a><br /></td></tr>
<tr class="separator:a66fdbc05d6f8f5fade4e14ca1dbc686a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac4178bea4e2910c3ddefb2ef1ebe8575"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#ac4178bea4e2910c3ddefb2ef1ebe8575">adaptive_pool1d</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;output_size, <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a> pool_type, const std::string &amp;layout=&quot;NCW&quot;)</td></tr>
<tr class="memdesc:ac4178bea4e2910c3ddefb2ef1ebe8575"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adaptively perform pooling on one dimensional data. See the two dimensional version above for details.  <a href="#ac4178bea4e2910c3ddefb2ef1ebe8575">More...</a><br /></td></tr>
<tr class="separator:ac4178bea4e2910c3ddefb2ef1ebe8575"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2bcf6bad18e028ce14ef854974629c0"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#af2bcf6bad18e028ce14ef854974629c0">global_pool</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a> pool_type, const std::string &amp;layout=&quot;NCHW&quot;)</td></tr>
<tr class="memdesc:af2bcf6bad18e028ce14ef854974629c0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform global pooling on height and width dimension of data. It decides the height and width dimension according to the layout string, in which 'W' and 'H' means width and height respectively. Width and height dimension cannot be split. For example, NCHW, NCHW16c, ... are valid for global_pool, while NCHW16w, NCHW16h are not. See <em>layout</em> for more information of the layout string convention.  <a href="#af2bcf6bad18e028ce14ef854974629c0">More...</a><br /></td></tr>
<tr class="separator:af2bcf6bad18e028ce14ef854974629c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27571804c2096b32ab05e7b3e32c5af6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a27571804c2096b32ab05e7b3e32c5af6">pool_impl_nd</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;kernel_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;stride_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;dilation_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;padding_size, <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a> pool_type, bool ceil_mode, const std::vector&lt; int &gt; &amp;axis, bool count_include_pad)</td></tr>
<tr class="memdesc:a27571804c2096b32ab05e7b3e32c5af6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform pooling on N-dimension of data.  <a href="#a27571804c2096b32ab05e7b3e32c5af6">More...</a><br /></td></tr>
<tr class="separator:a27571804c2096b32ab05e7b3e32c5af6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca7c280684bfa7f8eb16a4a2ae0891f4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#aca7c280684bfa7f8eb16a4a2ae0891f4">pool1d</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;kernel_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;stride_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;dilation_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;padding_size, <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a> pool_type, bool ceil_mode, const std::string &amp;layout=&quot;NCW&quot;, bool count_include_pad=true)</td></tr>
<tr class="memdesc:aca7c280684bfa7f8eb16a4a2ae0891f4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform pooling on the width dimension of data. Width axis is determined by the layout string in which 'W' means width. Width dimension cannot be split. For example, NCW, NCW16c, etc. are valid for pool, while NCW16w is not. See <em>layout</em> for more information of the layout string convention.  <a href="#aca7c280684bfa7f8eb16a4a2ae0891f4">More...</a><br /></td></tr>
<tr class="separator:aca7c280684bfa7f8eb16a4a2ae0891f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9db26746e71db4065a913ff8046fd2fa"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a9db26746e71db4065a913ff8046fd2fa">pool2d</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;kernel_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;stride_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;dilation_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;padding_size, <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a> pool_type, bool ceil_mode, const std::string &amp;layout=&quot;NCHW&quot;, bool count_include_pad=true)</td></tr>
<tr class="memdesc:a9db26746e71db4065a913ff8046fd2fa"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform pooling on height and width dimension of data. It decides the height and width dimension according to the layout string, in which 'W' and 'H' means width and height respectively. Width and height dimension cannot be split. For example, NCHW, NCHW16c, etc. are valid for pool, while NCHW16w, NCHW16h are not. See <em>layout</em> for more information of the layout string convention.  <a href="#a9db26746e71db4065a913ff8046fd2fa">More...</a><br /></td></tr>
<tr class="separator:a9db26746e71db4065a913ff8046fd2fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5bacf7e4d7aa499e4c8420d39d7ad7e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#ae5bacf7e4d7aa499e4c8420d39d7ad7e">pool3d</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;kernel_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;stride_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;dilation_size, const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;padding_size, <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a> pool_type, bool ceil_mode, const std::string &amp;layout=&quot;NCDHW&quot;, bool count_include_pad=true)</td></tr>
<tr class="memdesc:ae5bacf7e4d7aa499e4c8420d39d7ad7e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform pooling on depth, height and width dimension of data. It decides the depth, height and width dimension according to the layout string, in which 'D', 'W' and 'H' means depth, width and height respectively. Depth, Width and height dimension cannot be split. For example, NCDHW, NCDHW16c, etc. are valid for pool, while NCDHW16d, NCDHW16w or NCDHW16h are not. See <em>layout</em> for more information of the layout string convention.  <a href="#ae5bacf7e4d7aa499e4c8420d39d7ad7e">More...</a><br /></td></tr>
<tr class="separator:ae5bacf7e4d7aa499e4c8420d39d7ad7e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2cb22c64412c3eacb351c12b883333b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#aa2cb22c64412c3eacb351c12b883333b">softmax</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, int axis=-1, std::string name=&quot;tensor&quot;, std::string tag=&quot;softmax_output&quot;)</td></tr>
<tr class="memdesc:aa2cb22c64412c3eacb351c12b883333b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Softmax activation.  <a href="#aa2cb22c64412c3eacb351c12b883333b">More...</a><br /></td></tr>
<tr class="separator:aa2cb22c64412c3eacb351c12b883333b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0e20b6b30ec8296c1f037866d3bf772"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#ac0e20b6b30ec8296c1f037866d3bf772">log_softmax</a> (const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;x, std::string name=&quot;tensor&quot;, std::string tag=&quot;log_softmax_output&quot;)</td></tr>
<tr class="memdesc:ac0e20b6b30ec8296c1f037866d3bf772"><td class="mdescLeft">&#160;</td><td class="mdescRight">Log softmax activation.  <a href="#ac0e20b6b30ec8296c1f037866d3bf772">More...</a><br /></td></tr>
<tr class="separator:ac0e20b6b30ec8296c1f037866d3bf772"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Enumeration Type Documentation</h2>
<a id="a3ffa0974d8cdcd5b8ca7afb3cfbaf53c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">&#9670;&nbsp;</a></span>PoolType</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">tvm::topi::nn::PoolType</a> : int</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Pooling type. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a3ffa0974d8cdcd5b8ca7afb3cfbaf53ca9780bd19bf6706355258ca09ddeab335"></a>kAvgPool&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a3ffa0974d8cdcd5b8ca7afb3cfbaf53cae5769af06e46579729c6b5e2d0c70563"></a>kMaxPool&#160;</td><td class="fielddoc"></td></tr>
</table>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="a150f883cae332ed85d56522da218ad73"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a150f883cae332ed85d56522da218ad73">&#9670;&nbsp;</a></span>adaptive_pool()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::adaptive_pool </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>output_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a>&#160;</td>
          <td class="paramname"><em>pool_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layout</em> = <code>&quot;NCHW&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Adaptively perform pooling on height and width dimension of data. The pooling kernel and stride sizes are automatically chosen for desired output sizes. It decides the height and width dimension according to the layout string, in which 'W' and 'H' means width and height respectively. Width and height dimension cannot be split. For example, NCHW, NCHW16c, etc. are valid for pool, while NCHW16w, NCHW16h are not. See <em>layout</em> for more information of the layout string convention. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor </td></tr>
    <tr><td class="paramname">output_size</td><td>Vector of two ints: {output_height, output_width} </td></tr>
    <tr><td class="paramname">pool_type</td><td>The type of pooling operator </td></tr>
    <tr><td class="paramname">layout</td><td>The input layout. Pooling supports any layout as long as 'H' and 'W' appear. The layout is supposed to be composed of upper cases, lower cases and (optional) numbers, where upper case indicates a dimension and the corresponding lower case (with factor size) indicates the split dimension. For example, NCHW16c can describe a 5-D tensor of [batch_size, channel, height, width, channel_block]. (in which factor size <code>16</code> will not be used in pooling but for other operators, it can be used to decide the output shape). Since pooling does not care about the factor size of dimensions other than <code>H</code> and <code>W</code>, one can pass <code>NCHWc</code> as well.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output tensor in same layout order </dd></dl>

</div>
</div>
<a id="ac4178bea4e2910c3ddefb2ef1ebe8575"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac4178bea4e2910c3ddefb2ef1ebe8575">&#9670;&nbsp;</a></span>adaptive_pool1d()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::adaptive_pool1d </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>output_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a>&#160;</td>
          <td class="paramname"><em>pool_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layout</em> = <code>&quot;NCW&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Adaptively perform pooling on one dimensional data. See the two dimensional version above for details. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor </td></tr>
    <tr><td class="paramname">output_size</td><td>Vector of one int: {output_width} </td></tr>
    <tr><td class="paramname">pool_type</td><td>The type of pooling operator </td></tr>
    <tr><td class="paramname">layout</td><td>The input layout. The default is "NCW". </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a66fdbc05d6f8f5fade4e14ca1dbc686a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a66fdbc05d6f8f5fade4e14ca1dbc686a">&#9670;&nbsp;</a></span>adaptive_pool3d()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::adaptive_pool3d </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>output_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a>&#160;</td>
          <td class="paramname"><em>pool_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layout</em> = <code>&quot;NCDHW&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Adaptively perform pooling on three dimensional data. See the two dimensional version above for details. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor </td></tr>
    <tr><td class="paramname">output_size</td><td>Vector of three ints: {output_depth, output_height, output_width} </td></tr>
    <tr><td class="paramname">pool_type</td><td>The type of pooling operator </td></tr>
    <tr><td class="paramname">layout</td><td>The input layout. The default is "NCDHW". </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a3fb74f1c3df6edf17c9a3f1e122f84fe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3fb74f1c3df6edf17c9a3f1e122f84fe">&#9670;&nbsp;</a></span>adaptive_pool_impl()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::adaptive_pool_impl </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>output_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a>&#160;</td>
          <td class="paramname"><em>pool_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>axes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Perform adaptive pooling on N dimensional data. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor </td></tr>
    <tr><td class="paramname">output_size</td><td>int vector of size in each dimension </td></tr>
    <tr><td class="paramname">pool_type</td><td>The type of pooling operator </td></tr>
    <tr><td class="paramname">axes</td><td>indices of each dimension</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output tensor in same layout order </dd></dl>

</div>
</div>
<a id="a93ec4d667dc49c109a0ccb16f6c6d05b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a93ec4d667dc49c109a0ccb16f6c6d05b">&#9670;&nbsp;</a></span>all()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> tvm::topi::nn::all </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt;&#160;</td>
          <td class="paramname"><em>args</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a new expression of the logical and of all conditions in the arguments. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">args</td><td>The arguments to find the logical conjunction of</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The logical conjunction expression </dd></dl>

</div>
</div>
<a id="a258f660698c476e2ac7e7f78b32ad6ba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a258f660698c476e2ac7e7f78b32ad6ba">&#9670;&nbsp;</a></span>bias_add()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> tvm::topi::nn::bias_add </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>axis</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Creates an operation that calculates data + bias. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>Tensor with shape [batch, in_dim] </td></tr>
    <tr><td class="paramname">bias</td><td>Tensor with shape [batch]. </td></tr>
    <tr><td class="paramname">axis</td><td>The axis to add the bias to. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Tensor with shape [batch, in_dim] </dd></dl>

</div>
</div>
<a id="abaa4e2bba6a3d3db3eaca614fdf5bbea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abaa4e2bba6a3d3db3eaca614fdf5bbea">&#9670;&nbsp;</a></span>binarize_pack()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> tvm::topi::nn::binarize_pack </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name</em> = <code>&quot;PackedInput&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>tag</em> = <code>&quot;binarize_pack&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Binarization and bit-packing along a certain axis. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>N-D tensor, can be any layout </td></tr>
    <tr><td class="paramname">axis</td><td>The axis along which to do binarization and bit-packing. This axis must have a size equal to an integer multiple of 32. </td></tr>
    <tr><td class="paramname">name</td><td>The name of the operation </td></tr>
    <tr><td class="paramname">tag</td><td>The tag to mark the operation</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Output tensor with dtype uint32 </dd></dl>

</div>
</div>
<a id="a08aaeadaa767fa996d2f2e0a7d12c7cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a08aaeadaa767fa996d2f2e0a7d12c7cd">&#9670;&nbsp;</a></span>binary_dense()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> tvm::topi::nn::binary_dense </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>weight</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Binary matrix multiplication using xor and bit-count. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>Tensor with shape [batch, in_dim], dtype is uint32 </td></tr>
    <tr><td class="paramname">weight</td><td>Tensor with shape [out_dim, in_dim], dtype is uint32</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Tensor with shape [batch, out_dim], dtype is float32 </dd></dl>

</div>
</div>
<a id="a34e1a8305acf89ef2f745c8d99bf8e89"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34e1a8305acf89ef2f745c8d99bf8e89">&#9670;&nbsp;</a></span>dense()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> tvm::topi::nn::dense </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1DataType.html">DataType</a> &amp;&#160;</td>
          <td class="paramname"><em>out_dtype</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Creates an operation that calculates data * weight^T + bias. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>Tensor with shape [batch, in_dim] </td></tr>
    <tr><td class="paramname">weight</td><td>Tensor with shape [out_dim, in_dim] </td></tr>
    <tr><td class="paramname">bias</td><td>Tensor with shape [out_dim]. Optional; to omit bias, pass Tensor() </td></tr>
    <tr><td class="paramname">out_dtype</td><td>Output data type. Used for mixed precision.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Tensor with shape [batch, out_dim] </dd></dl>

</div>
</div>
<a id="af210f30ef7afb28cd369dacc8f05be68"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af210f30ef7afb28cd369dacc8f05be68">&#9670;&nbsp;</a></span>dilate()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::dilate </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt;&#160;</td>
          <td class="paramname"><em>strides</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>dilation_value</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name</em> = <code>&quot;tensor&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>tag</em> = <code><a class="el" href="namespacetvm_1_1topi.html#a29e22aa45900dad3b6f9f705bb1dc688">kInjective</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Dilate data with given dilation value (0 by default). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor, this can have any number of dimensions and any layout. </td></tr>
    <tr><td class="paramname">strides</td><td>Dilation stride for each dimension. Stride 1 means no dilation. </td></tr>
    <tr><td class="paramname">dilation_value</td><td>Value used to dilate the input. </td></tr>
    <tr><td class="paramname">name</td><td>The name of the operation </td></tr>
    <tr><td class="paramname">tag</td><td>The tag to mark the operation</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output tensor. </dd></dl>

</div>
</div>
<a id="a8d244c196a5a481640cfc610fad3c7db"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d244c196a5a481640cfc610fad3c7db">&#9670;&nbsp;</a></span>end_index()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> tvm::topi::nn::end_index </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1tir_1_1Var.html">Var</a> &amp;&#160;</td>
          <td class="paramname"><em>out_index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &amp;&#160;</td>
          <td class="paramname"><em>odim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &amp;&#160;</td>
          <td class="paramname"><em>idim</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ab03974ee6b2d02a4619de1a4d0b42891"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab03974ee6b2d02a4619de1a4d0b42891">&#9670;&nbsp;</a></span>find_depth_height_width()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool tvm::topi::nn::find_depth_height_width </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>depth_axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>height_axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>width_axis</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="aec3b2a3e902d0d9c1f89d04ee8b3bcac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec3b2a3e902d0d9c1f89d04ee8b3bcac">&#9670;&nbsp;</a></span>find_height_width()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool tvm::topi::nn::find_height_width </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>height_axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>width_axis</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ab678a94b9369834c1b5d24d5a4595dbf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab678a94b9369834c1b5d24d5a4595dbf">&#9670;&nbsp;</a></span>find_width()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool tvm::topi::nn::find_width </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>width_axis</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a6a553de73860c1a295d6ee566a3916b4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6a553de73860c1a295d6ee566a3916b4">&#9670;&nbsp;</a></span>flatten()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::flatten </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name</em> = <code>&quot;tensor&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>tag</em> = <code><a class="el" href="namespacetvm_1_1topi.html#a29e22aa45900dad3b6f9f705bb1dc688">kInjective</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Flattens the input tensor into a 2-D tensor by collapsing higher dimensions. This requires the input tensor to have constant sized dimensions. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">name</td><td>The name of the operation </td></tr>
    <tr><td class="paramname">tag</td><td>The tag to mark the operation</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A 2-D tensor. </dd></dl>

</div>
</div>
<a id="af2bcf6bad18e028ce14ef854974629c0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af2bcf6bad18e028ce14ef854974629c0">&#9670;&nbsp;</a></span>global_pool()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::global_pool </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a>&#160;</td>
          <td class="paramname"><em>pool_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layout</em> = <code>&quot;NCHW&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Perform global pooling on height and width dimension of data. It decides the height and width dimension according to the layout string, in which 'W' and 'H' means width and height respectively. Width and height dimension cannot be split. For example, NCHW, NCHW16c, ... are valid for global_pool, while NCHW16w, NCHW16h are not. See <em>layout</em> for more information of the layout string convention. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor represent as layout </td></tr>
    <tr><td class="paramname">pool_type</td><td>The type of pooling operator </td></tr>
    <tr><td class="paramname">layout</td><td>The input layout. global-pooling supports any layout as long as 'H' and 'W' appear. The layout is supposed to be composed of upper cases, lower cases and (optional) numbers, where upper case indicates a dimension and the corresponding lower case (with factor size) indicates the sub-dimension. For example, <code>NCHW16c</code> can describe a 5-D tensor of [batch_size, channel, height, width, channel_block]. (in which factor size <code>16</code> will not be used in pooling but for other operators, it can be used to decide the output shape). Since pooling does not care about the factor size of dimensions other than <code>H</code> and <code>W</code>, one can pass <code>NCHWc</code> as well.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output tensor in same layout with height and width dimension size of 1. e.g., for NCHW, the output shape will be [batch, channel, 1, 1] </dd></dl>

</div>
</div>
<a id="accc17ec14bd2ccc2c0e8055165ba69bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#accc17ec14bd2ccc2c0e8055165ba69bd">&#9670;&nbsp;</a></span>layer_norm()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::layer_norm </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1Integer.html">Integer</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name</em> = <code>&quot;T_layer_norm&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>tag</em> = <code><a class="el" href="namespacetvm_1_1topi.html#a29e22aa45900dad3b6f9f705bb1dc688">kInjective</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Layer normalization. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>N-D tensor with shape [d_0, d_1, ..., d_{N-1}] </td></tr>
    <tr><td class="paramname">gamma</td><td>K-D tensor with shape [r_0, r_1, ..., r_{K-1}] where K == len(axis) and d_{axis_k} == r_k </td></tr>
    <tr><td class="paramname">beta</td><td>Optional, K-D tensor with shape [r_0, r_1, ..., r_{K-1}] where d_{axis_k} == r_k </td></tr>
    <tr><td class="paramname">axis</td><td>The axis to normalize over. </td></tr>
    <tr><td class="paramname">epsilon</td><td>The epsilon value to avoid division by zero. </td></tr>
    <tr><td class="paramname">name</td><td>The name of the operation. </td></tr>
    <tr><td class="paramname">tag</td><td>The tag to mark the operation. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The normalized tensor, with the same shape as data. </dd></dl>

</div>
</div>
<a id="ac0e20b6b30ec8296c1f037866d3bf772"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac0e20b6b30ec8296c1f037866d3bf772">&#9670;&nbsp;</a></span>log_softmax()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::log_softmax </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name</em> = <code>&quot;tensor&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>tag</em> = <code>&quot;log_softmax_output&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Log softmax activation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor. 2-D where log softmax is performed along the second dimension </td></tr>
    <tr><td class="paramname">name</td><td>The name of the operation </td></tr>
    <tr><td class="paramname">tag</td><td>The tag to mark the operation</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A Tensor whose op member is the log softmax operation </dd></dl>

</div>
</div>
<a id="ac3d8de9144f915a5dd27dcb70c0abdd4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac3d8de9144f915a5dd27dcb70c0abdd4">&#9670;&nbsp;</a></span>lrn()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::lrn </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>axis</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.0001</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em> = <code>0.75</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>bias</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name</em> = <code>&quot;tensor&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>tag</em> = <code><a class="el" href="namespacetvm_1_1topi.html#a13aaf23f0ab77f1ed4a7d4b7816bf210">kBroadcast</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Local response normalization inference operator. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>The input tensor. 4-D shape NCHW or NHWC </td></tr>
    <tr><td class="paramname">size</td><td><a class="el" href="classtvm_1_1Integer.html" title="Container of constant int that adds more constructors. ">Integer</a> to define normalisation window size </td></tr>
    <tr><td class="paramname">axis</td><td>Input data layout channel axis </td></tr>
    <tr><td class="paramname">alpha</td><td>Float scaling factor </td></tr>
    <tr><td class="paramname">beta</td><td>Exponent value </td></tr>
    <tr><td class="paramname">bias</td><td>Offset to avoid dividing by zero </td></tr>
    <tr><td class="paramname">name</td><td>The name of the operation </td></tr>
    <tr><td class="paramname">tag</td><td>The tag to mark the operation</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A Tensor whose op member is the Local response normalization operation </dd></dl>

</div>
</div>
<a id="aca7c280684bfa7f8eb16a4a2ae0891f4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca7c280684bfa7f8eb16a4a2ae0891f4">&#9670;&nbsp;</a></span>pool1d()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::pool1d </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>kernel_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>stride_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>dilation_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>padding_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a>&#160;</td>
          <td class="paramname"><em>pool_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>ceil_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layout</em> = <code>&quot;NCW&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>count_include_pad</em> = <code>true</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Perform pooling on the width dimension of data. Width axis is determined by the layout string in which 'W' means width. Width dimension cannot be split. For example, NCW, NCW16c, etc. are valid for pool, while NCW16w is not. See <em>layout</em> for more information of the layout string convention. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">kernel_size</td><td>Vector of one int: {kernel_width} </td></tr>
    <tr><td class="paramname">stride_size</td><td>Vector of one int: {stride_width} </td></tr>
    <tr><td class="paramname">dilation_size</td><td>Vector of one int: {dilation_width} </td></tr>
    <tr><td class="paramname">padding_size</td><td>Vector of two ints: {head_pad_width, tail_pad_width} </td></tr>
    <tr><td class="paramname">pool_type</td><td>The type of pooling operator </td></tr>
    <tr><td class="paramname">ceil_mode</td><td>Whether to use ceil when calculating the output size </td></tr>
    <tr><td class="paramname">layout</td><td>The input layout. Pooling supports any layout as long as 'W' appears. The layout is supposed to be composed of upper cases, lower cases and (optional) numbers, where upper case indicates a dimension and the corresponding lower case (with factor size) indicates the split dimension. For example, NCW16c can describe a 4-D tensor of [batch_size, channel, width, channel_block]. (in which factor size <code>16</code> will not be used in pooling but for other operators, it can be used to decide the output shape). Since pooling does not care about the factor size of dimensions other than <code>W</code>, one can pass <code>NCWc</code> as well. </td></tr>
    <tr><td class="paramname">count_include_pad</td><td>Whether include padding in the calculation when pool_type is 'avg'</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output tensor in the same layout </dd></dl>

</div>
</div>
<a id="a9db26746e71db4065a913ff8046fd2fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9db26746e71db4065a913ff8046fd2fa">&#9670;&nbsp;</a></span>pool2d()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::pool2d </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>kernel_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>stride_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>dilation_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>padding_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a>&#160;</td>
          <td class="paramname"><em>pool_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>ceil_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layout</em> = <code>&quot;NCHW&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>count_include_pad</em> = <code>true</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Perform pooling on height and width dimension of data. It decides the height and width dimension according to the layout string, in which 'W' and 'H' means width and height respectively. Width and height dimension cannot be split. For example, NCHW, NCHW16c, etc. are valid for pool, while NCHW16w, NCHW16h are not. See <em>layout</em> for more information of the layout string convention. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">kernel_size</td><td>Vector of two ints: {kernel_height, kernel_width} </td></tr>
    <tr><td class="paramname">stride_size</td><td>Vector of two ints: {stride_height, stride_width} </td></tr>
    <tr><td class="paramname">dilation_size</td><td>Vector of two ints: {dilation_height, dilation_width} </td></tr>
    <tr><td class="paramname">padding_size</td><td>Vector of two ints: {padding_height, padding_width} </td></tr>
    <tr><td class="paramname">pool_type</td><td>The type of pooling operator </td></tr>
    <tr><td class="paramname">ceil_mode</td><td>Whether to use ceil when calculating the output size </td></tr>
    <tr><td class="paramname">layout</td><td>The input layout. Pooling supports any layout as long as 'H' and 'W' appear. The layout is supposed to be composed of upper cases, lower cases and (optional) numbers, where upper case indicates a dimension and the corresponding lower case (with factor size) indicates the split dimension. For example, NCHW16c can describe a 5-D tensor of [batch_size, channel, height, width, channel_block]. (in which factor size <code>16</code> will not be used in pooling but for other operators, it can be used to decide the output shape). Since pooling does not care about the factor size of dimensions other than <code>H</code> and <code>W</code>, one can pass <code>NCHWc</code> as well. </td></tr>
    <tr><td class="paramname">count_include_pad</td><td>Whether include padding in the calculation when pool_type is 'avg'</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output tensor in the same layout </dd></dl>

</div>
</div>
<a id="ae5bacf7e4d7aa499e4c8420d39d7ad7e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5bacf7e4d7aa499e4c8420d39d7ad7e">&#9670;&nbsp;</a></span>pool3d()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::pool3d </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>kernel_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>stride_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>dilation_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>padding_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a>&#160;</td>
          <td class="paramname"><em>pool_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>ceil_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layout</em> = <code>&quot;NCDHW&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>count_include_pad</em> = <code>true</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Perform pooling on depth, height and width dimension of data. It decides the depth, height and width dimension according to the layout string, in which 'D', 'W' and 'H' means depth, width and height respectively. Depth, Width and height dimension cannot be split. For example, NCDHW, NCDHW16c, etc. are valid for pool, while NCDHW16d, NCDHW16w or NCDHW16h are not. See <em>layout</em> for more information of the layout string convention. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">kernel_size</td><td>Vector of three ints: {kernel_depth, kernel_height, kernel_width} </td></tr>
    <tr><td class="paramname">stride_size</td><td>Vector of three ints: {stride_depth, stride_height, stride_width} </td></tr>
    <tr><td class="paramname">dilation_size</td><td>Vector of three ints: {dilation_depth, dilation_height, dilation_width} </td></tr>
    <tr><td class="paramname">padding_size</td><td>Vector of six ints: {head_pad_depth, head_pad_height, head_pad_width, tail_pad_depth, tail_pad_height, tail_pad_width} </td></tr>
    <tr><td class="paramname">pool_type</td><td>The type of pooling operator </td></tr>
    <tr><td class="paramname">ceil_mode</td><td>Whether to use ceil when calculating the output size </td></tr>
    <tr><td class="paramname">layout</td><td>The input layout. Pooling supports any layout as long as 'D', 'H' and 'W' appear. The layout is supposed to be composed of upper cases, lower cases and (optional) numbers, where upper case indicates a dimension and the corresponding lower case (with factor size) indicates the split dimension. For example, NCDHW16c can describe a 6-D tensor of [batch_size, channel, depth, height, width, channel_block]. (in which factor size <code>16</code> will not be used in pooling but for other operators, it can be used to decide the output shape). Since pooling does not care about the factor size of dimensions other than <code>D</code>, <code>H</code> and <code>W</code>, one can pass <code>NCDHWc</code> as well. </td></tr>
    <tr><td class="paramname">count_include_pad</td><td>Whether include padding in the calculation when pool_type is 'avg'</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output tensor in the same layout </dd></dl>

</div>
</div>
<a id="a7bb635a3241be1593258b374e651e344"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7bb635a3241be1593258b374e651e344">&#9670;&nbsp;</a></span>pool_grad()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::pool_grad </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>kernel_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>stride_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>padding_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a>&#160;</td>
          <td class="paramname"><em>pool_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>ceil_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layout</em> = <code>&quot;NCHW&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>count_include_pad</em> = <code>true</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Calculate gradient of pooling on height and width dimension of data. It decides the height and width dimension according to the layout string, in which 'W' and 'H' means width and height respectively. Width and height dimension cannot be split. For example, NCHW, NCHW16c, etc. are valid for pool, while NCHW16w, NCHW16h are not. See <em>layout</em> for more information of the layout string convention. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">out_grad</td><td>The output gradient tensor. </td></tr>
    <tr><td class="paramname">x</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">kernel_size</td><td>Vector of two ints: {kernel_height, kernel_width} </td></tr>
    <tr><td class="paramname">stride_size</td><td>Vector of two ints: {stride_height, stride_width} </td></tr>
    <tr><td class="paramname">padding_size</td><td>Vector of two ints: {padding_height, padding_width} </td></tr>
    <tr><td class="paramname">pool_type</td><td>The type of pooling operator </td></tr>
    <tr><td class="paramname">ceil_mode</td><td>Whether to use ceil when calculating the output size </td></tr>
    <tr><td class="paramname">layout</td><td>The input layout. Pooling supports any layout as long as 'H' and 'W' appear. The layout is supposed to be composed of upper cases, lower cases and (optional) numbers, where upper case indicates a dimension and the corresponding lower case (with factor size) indicates the split dimension. For example, NCHW16c can describe a 5-D tensor of [batch_size, channel, height, width, channel_block]. (in which factor size <code>16</code> will not be used in pooling but for other operators, it can be used to decide the output shape). Since pooling does not care about the factor size of dimensions other than <code>H</code> and <code>W</code>, one can pass <code>NCHWc</code> as well. </td></tr>
    <tr><td class="paramname">count_include_pad</td><td>Whether include padding in the calculation when pool_type is 'avg'</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output tensor in the same layout </dd></dl>

</div>
</div>
<a id="a2806be7f95eec10be2b3555a9094cee2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2806be7f95eec10be2b3555a9094cee2">&#9670;&nbsp;</a></span>pool_grad_impl()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::pool_grad_impl </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>kernel_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>stride_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>padding_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a>&#160;</td>
          <td class="paramname"><em>pool_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>ceil_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const size_t&#160;</td>
          <td class="paramname"><em>height_axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const size_t&#160;</td>
          <td class="paramname"><em>width_axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>count_include_pad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a27571804c2096b32ab05e7b3e32c5af6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a27571804c2096b32ab05e7b3e32c5af6">&#9670;&nbsp;</a></span>pool_impl_nd()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::pool_impl_nd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>kernel_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>stride_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>dilation_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1runtime_1_1Array.html">Array</a>&lt; <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>padding_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetvm_1_1topi_1_1nn.html#a3ffa0974d8cdcd5b8ca7afb3cfbaf53c">PoolType</a>&#160;</td>
          <td class="paramname"><em>pool_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>ceil_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>count_include_pad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Perform pooling on N-dimension of data. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor </td></tr>
    <tr><td class="paramname">kernel_size</td><td>Vector of N ints </td></tr>
    <tr><td class="paramname">stride_size</td><td>Vector of N ints </td></tr>
    <tr><td class="paramname">dilation_size</td><td>Vector of N ints </td></tr>
    <tr><td class="paramname">padding_size</td><td>Vector of N*2 ints [head_pad_d1, head_pad_d2, ..., head_pad_dN, tail_pad_d1, tail_pad_d2, ..., tail_pad_dN] </td></tr>
    <tr><td class="paramname">pool_type</td><td>The type of pooling operator </td></tr>
    <tr><td class="paramname">ceil_mode</td><td>Whether to use ceil when calculating the output size </td></tr>
    <tr><td class="paramname">axis</td><td>Vector of indices for the N dimensions </td></tr>
    <tr><td class="paramname">count_include_pad</td><td>Whether include padding in the calculation</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output tensor in same layout order </dd></dl>

</div>
</div>
<a id="a07b8a04f27f17af58dd9f18218cfe081"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a07b8a04f27f17af58dd9f18218cfe081">&#9670;&nbsp;</a></span>scale_shift_nchw()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::scale_shift_nchw </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name</em> = <code>&quot;ScaleShift&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>tag</em> = <code><a class="el" href="namespacetvm_1_1topi.html#a13aaf23f0ab77f1ed4a7d4b7816bf210">kBroadcast</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Scale and shift with NCHW order. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">scale</td><td>Scale tensor, 1-D of size channel </td></tr>
    <tr><td class="paramname">shift</td><td>Shift tensor, 1-D of size channel </td></tr>
    <tr><td class="paramname">name</td><td>The name of the operation </td></tr>
    <tr><td class="paramname">tag</td><td>The tag to mark the operation</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A Tensor whose op member is the scale shift operation </dd></dl>

</div>
</div>
<a id="acaf3bc4e89fc55b8444d2550d25f4f22"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acaf3bc4e89fc55b8444d2550d25f4f22">&#9670;&nbsp;</a></span>scale_shift_nhwc()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::scale_shift_nhwc </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name</em> = <code>&quot;ScaleShift&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>tag</em> = <code><a class="el" href="namespacetvm_1_1topi.html#a13aaf23f0ab77f1ed4a7d4b7816bf210">kBroadcast</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Scale and shift with NHWC order. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">scale</td><td>Scale tensor, 1-D of size channel </td></tr>
    <tr><td class="paramname">shift</td><td>Shift tensor, 1-D of size channel </td></tr>
    <tr><td class="paramname">name</td><td>The name of the operation </td></tr>
    <tr><td class="paramname">tag</td><td>The tag to mark the operation</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A Tensor whose op member is the scale shift operation </dd></dl>

</div>
</div>
<a id="aa2cb22c64412c3eacb351c12b883333b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa2cb22c64412c3eacb351c12b883333b">&#9670;&nbsp;</a></span>softmax()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> tvm::topi::nn::softmax </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>axis</em> = <code>-1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name</em> = <code>&quot;tensor&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>tag</em> = <code>&quot;softmax_output&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Softmax activation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The input tensor. Can be any dimension </td></tr>
    <tr><td class="paramname">axis</td><td>The channel axis along which softmax is performed </td></tr>
    <tr><td class="paramname">name</td><td>The name of the operation </td></tr>
    <tr><td class="paramname">tag</td><td>The tag to mark the operation</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A Tensor whose op member is the softmax operation </dd></dl>

</div>
</div>
<a id="a752c4130dac73fd2de0390c5f6b24b15"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a752c4130dac73fd2de0390c5f6b24b15">&#9670;&nbsp;</a></span>start_index()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> tvm::topi::nn::start_index </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1tir_1_1Var.html">Var</a> &amp;&#160;</td>
          <td class="paramname"><em>out_index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &amp;&#160;</td>
          <td class="paramname"><em>odim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classtvm_1_1PrimExpr.html">PrimExpr</a> &amp;&#160;</td>
          <td class="paramname"><em>idim</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
