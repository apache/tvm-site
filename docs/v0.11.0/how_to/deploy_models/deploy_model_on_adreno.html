





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Deploy the Pretrained Model on Adreno &mdash; tvm 0.11.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tlcpack_theme.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Deploy the Pretrained Model on Android" href="deploy_model_on_android.html" />
    <link rel="prev" title="Deploy Deep Learning Models" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/vta>VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <input type="checkbox" class="version-toggle-box" hidden id="version-toggle">
              <label for="version-toggle" class="version-toggle-label">
                  <div tabindex="0" class="version version-selector version-selector-show">
                    0.11.dev0 <span class="chevron versions-hidden"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m8 4 8 8-8 8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span><span class="chevron versions-shown"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m4 8 8 8 8-8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span>
                  </div>
                </label>
                <div class="version-details wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                  <p class="caption" role="heading"><span class="caption-text">Versions</span></p>
                  <ol style="text-align: left">
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="/">0.11.dev0 (main)</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.8.0/">v0.8.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.9.0/">v0.9.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.10.0/">v0.10.0</a></div></li>
                    
                  </ol>
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installing TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contributor Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/index.html">User Tutorial</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">How To Guides</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../compile_models/index.html">Compile Deep Learning Models</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../deploy/index.html">Deploy Models and Integrate TVM</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../deploy/index.html#build-the-tvm-runtime-library">Build the TVM runtime library</a></li>
<li class="toctree-l3"><a class="reference internal" href="../deploy/index.html#cross-compile-the-tvm-runtime-for-other-architectures">Cross compile the TVM runtime for other architectures</a></li>
<li class="toctree-l3"><a class="reference internal" href="../deploy/index.html#optimize-and-tune-models-for-target-devices">Optimize and tune models for target devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../deploy/index.html#deploy-optimized-model-on-target-devices">Deploy optimized model on target devices</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../deploy/index.html#additional-deployment-how-tos">Additional Deployment How-Tos</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="index.html">Deploy Deep Learning Models</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_relay/index.html">Work With Relay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_schedules/index.html">Work With Tensor Expression and Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../optimize_operators/index.html">Optimize Tensor Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autotvm/index.html">Auto-Tune with Templates and AutoTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autoscheduler/index.html">Use AutoScheduler for Template-Free Scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_microtvm/index.html">Work With microTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../extend_tvm/index.html">Extend TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../profile/index.html">Profile Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../errors.html">Handle TVM Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/tutorial/index.html">Developer Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to/how_to.html">Developer How-To Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Architecture  Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../arch/index.html">Design and Architecture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Topic Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../topic/microtvm/index.html">microTVM: TVM on bare-metal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../topic/vta/index.html">VTA: Versatile Tensor Accelerator</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/links.html">Other APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="../index.html">How To Guides</a> <span class="br-arrow">></span></li>
        
          <li><a href="../deploy/index.html">Deploy Models and Integrate TVM</a> <span class="br-arrow">></span></li>
        
          <li><a href="index.html">Deploy Deep Learning Models</a> <span class="br-arrow">></span></li>
        
      <li>Deploy the Pretrained Model on Adreno</li>
    
    
      
      
        
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/tvm/edit/main/docs/how_to/deploy_models/deploy_model_on_adreno.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-how-to-deploy-models-deploy-model-on-adreno-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="deploy-the-pretrained-model-on-adreno">
<span id="tutorial-deploy-model-on-adreno"></span><span id="sphx-glr-how-to-deploy-models-deploy-model-on-adreno-py"></span><h1>Deploy the Pretrained Model on Adreno<a class="headerlink" href="#deploy-the-pretrained-model-on-adreno" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: Daniil Barinov</p>
<p>This article is a step-by-step tutorial to deploy pretrained Pytorch ResNet-18 model on Adreno (on different precisions).</p>
<p>For us to begin with, PyTorch must be installed.
TorchVision is also required since we will be using it as our model zoo.</p>
<p>A quick solution is to install it via pip:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install torch
pip install torchvision
</pre></div>
</div>
<p>Besides that, you should have TVM builded for Android.
See the following instructions on how to build it.</p>
<p><a class="reference external" href="https://tvm.apache.org/docs/how_to/deploy/adreno.html">Deploy to Adreno GPU</a></p>
<p>After the build section there should be two files in <em>build</em> directory «libtvm_runtime.so» and «tvm_rpc».
Let’s push them to the device and run TVM RPC Server.</p>
<div class="section" id="tvm-rpc-server">
<h2>TVM RPC Server<a class="headerlink" href="#tvm-rpc-server" title="Permalink to this headline">¶</a></h2>
<p>To get the hash of the device use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>adb devices
</pre></div>
</div>
<p>Then to upload these two files to the device you should use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>adb -s &lt;device_hash&gt; push <span class="o">{</span>libtvm_runtime.so,tvm_rpc<span class="o">}</span> /data/local/tmp
</pre></div>
</div>
<p>At this moment you will have «libtvm_runtime.so» and «tvm_rpc» on path /data/local/tmp on your device.
Sometimes cmake can’t find «libc++_shared.so». Use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>find <span class="si">${</span><span class="nv">ANDROID_NDK_HOME</span><span class="si">}</span> -name libc++_shared.so
</pre></div>
</div>
<p>to find it and also push it with adb on the desired device:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>adb -s &lt;device_hash&gt; push libc++_shared.so /data/local/tmp
</pre></div>
</div>
<p>We are now ready to run the TVM RPC Server.
Launch rpc_tracker with following line in 1st console:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3 -m tvm.exec.rpc_tracker --port <span class="m">9190</span>
</pre></div>
</div>
<p>Then we need to run tvm_rpc server from under the desired device in 2nd console:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>adb -s &lt;device_hash&gt; reverse tcp:9190 tcp:9190
adb -s &lt;device_hash&gt; forward tcp:9090 tcp:9090
adb -s &lt;device_hash&gt; forward tcp:9091 tcp:9091
adb -s &lt;device_hash&gt; forward tcp:9092 tcp:9092
adb -s &lt;device_hash&gt; forward tcp:9093 tcp:9093
adb -s &lt;device_hash&gt; shell <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span>/data/local/tmp /data/local/tmp/tvm_rpc server --host<span class="o">=</span><span class="m">0</span>.0.0.0 --port<span class="o">=</span><span class="m">9090</span> --tracker<span class="o">=</span><span class="m">127</span>.0.0.1:9190 --key<span class="o">=</span>android --port-end<span class="o">=</span><span class="m">9190</span>
</pre></div>
</div>
<p>Before proceeding to compile and infer model, specify TVM_TRACKER_HOST and TVM_TRACKER_PORT</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">TVM_TRACKER_HOST</span><span class="o">=</span><span class="m">0</span>.0.0.0
<span class="nb">export</span> <span class="nv">TVM_TRACKER_PORT</span><span class="o">=</span><span class="m">9190</span>
</pre></div>
</div>
<p>check that the tracker is running and the device is available</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -m tvm.exec.query_rpc_tracker --port <span class="m">9190</span>
</pre></div>
</div>
<p>For example, if we have 1 Android device,
the output can be:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Queue Status
----------------------------------
key          total  free  pending
----------------------------------
android      <span class="m">1</span>      <span class="m">1</span>     <span class="m">0</span>
----------------------------------
</pre></div>
</div>
</div>
<div class="section" id="load-a-test-image">
<h2>Load a test image<a class="headerlink" href="#load-a-test-image" title="Permalink to this headline">¶</a></h2>
<p>As an example we would use classical cat image from ImageNet</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="kn">import</span> <span class="n">download_testdata</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_url</span></a> <span class="o">=</span> <span class="s2">&quot;https://github.com/dmlc/mxnet.js/blob/main/data/cat.png?raw=true&quot;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_path</span></a> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_url</span></a><span class="p">,</span> <span class="s2">&quot;cat.png&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_path</span></a><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Preprocess the image and convert to tensor</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="n">my_preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">my_preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_deploy_model_on_adreno_001.png" srcset="../../_images/sphx_glr_deploy_model_on_adreno_001.png" alt="deploy model on adreno" class = "sphx-glr-single-img"/></div>
<div class="section" id="load-pretrained-pytorch-model">
<h2>Load pretrained Pytorch model<a class="headerlink" href="#load-pretrained-pytorch-model" title="Permalink to this headline">¶</a></h2>
<p>Create a Relay graph from a Pytorch ResNet-18 model</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">te</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">relay</span><span class="p">,</span> <span class="n">rpc</span>
<span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="kn">import</span> <span class="n">utils</span><span class="p">,</span> <span class="n">ndk</span>
<span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="kn">import</span> <span class="n">graph_executor</span>

<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_name</span></a> <span class="o">=</span> <span class="s2">&quot;resnet18&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_name</span></a><span class="p">)(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># We grab the TorchScripted model via tracing</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_shape</span></a> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">]</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_shape</span></a><span class="p">)</span>
<span class="n">scripted_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Input name can be arbitrary</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_name</span></a> <span class="o">=</span> <span class="s2">&quot;input0&quot;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">shape_list</span></a> <span class="o">=</span> <span class="p">[(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_name</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img</span><span class="o">.</span><span class="n">shape</span></a><span class="p">)]</span>
<span class="n">mod</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a> <span class="o">=</span> <a href="../../reference/api/python/relay/frontend.html#tvm.relay.frontend.from_pytorch" title="tvm.relay.frontend.from_pytorch" class="sphx-glr-backref-module-tvm-relay-frontend sphx-glr-backref-type-py-function"><span class="n">relay</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">from_pytorch</span></a><span class="p">(</span><span class="n">scripted_model</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">shape_list</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/venv/apache-tvm-py3.7/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter &#39;pretrained&#39; is deprecated since 0.13 and will be removed in 0.15, please use &#39;weights&#39; instead.
  f&quot;The parameter &#39;{pretrained_param}&#39; is deprecated since 0.13 and will be removed in 0.15, &quot;
/venv/apache-tvm-py3.7/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for &#39;weights&#39; are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/workspace/python/tvm/relay/frontend/pytorch_utils.py:47: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  return LooseVersion(torch_ver) &gt; ver
/venv/apache-tvm-py3.7/lib/python3.7/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
</pre></div>
</div>
</div>
<div class="section" id="precisions">
<h2>Precisions<a class="headerlink" href="#precisions" title="Permalink to this headline">¶</a></h2>
<p>Since TVM support Mixed Precision, we need to register mixed_precision_conversion:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tvm.relay.op</span> <span class="kn">import</span> <span class="n">register_mixed_precision_conversion</span>

<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conv2d_acc</span></a> <span class="o">=</span> <span class="s2">&quot;float32&quot;</span>


<span class="nd">@register_mixed_precision_conversion</span><span class="p">(</span><span class="s2">&quot;nn.conv2d&quot;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">conv2d_mixed_precision_rule</span><span class="p">(</span><span class="n">call_node</span><span class="p">:</span> <span class="s2">&quot;relay.Call&quot;</span><span class="p">,</span> <span class="n">mixed_precision_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">global</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conv2d_acc</span></a>
    <span class="k">return</span> <span class="p">[</span>
        <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">mixed_precision</span><span class="o">.</span><span class="n">MIXED_PRECISION_ALWAYS</span></a><span class="p">,</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conv2d_acc</span></a><span class="p">,</span>
        <span class="n">mixed_precision_type</span><span class="p">,</span>
    <span class="p">]</span>


<span class="nd">@register_mixed_precision_conversion</span><span class="p">(</span><span class="s2">&quot;nn.dense&quot;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">conv2d_mixed_precision_rule</span><span class="p">(</span><span class="n">call_node</span><span class="p">:</span> <span class="s2">&quot;relay.Call&quot;</span><span class="p">,</span> <span class="n">mixed_precision_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">global</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conv2d_acc</span></a>
    <span class="k">return</span> <span class="p">[</span>
        <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">mixed_precision</span><span class="o">.</span><span class="n">MIXED_PRECISION_ALWAYS</span></a><span class="p">,</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conv2d_acc</span></a><span class="p">,</span>
        <span class="n">mixed_precision_type</span><span class="p">,</span>
    <span class="p">]</span>
</pre></div>
</div>
<p>and also define the conversion function itself</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">convert_to_dtype</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dtype</span></a><span class="p">):</span>
    <span class="c1"># downcast to float16</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dtype</span></a> <span class="o">==</span> <span class="s2">&quot;float16&quot;</span> <span class="ow">or</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dtype</span></a> <span class="o">==</span> <span class="s2">&quot;float16_acc32&quot;</span><span class="p">:</span>
        <span class="k">global</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conv2d_acc</span></a>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conv2d_acc</span></a> <span class="o">=</span> <span class="s2">&quot;float16&quot;</span> <span class="k">if</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dtype</span></a> <span class="o">==</span> <span class="s2">&quot;float16&quot;</span> <span class="k">else</span> <span class="s2">&quot;float32&quot;</span>
        <span class="kn">from</span> <span class="nn">tvm.ir</span> <span class="kn">import</span> <span class="n">IRModule</span>

        <span class="n">mod</span> <span class="o">=</span> <a href="../../reference/api/python/ir.html#tvm.ir.IRModule.from_expr" title="tvm.ir.IRModule.from_expr" class="sphx-glr-backref-module-tvm-ir-IRModule sphx-glr-backref-type-py-method"><span class="n">IRModule</span><span class="o">.</span><span class="n">from_expr</span></a><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
        <span class="n">seq</span> <span class="o">=</span> <a href="../../reference/api/python/ir.html#tvm.transform.Sequential" title="tvm.transform.Sequential" class="sphx-glr-backref-module-tvm-transform sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <span class="p">[</span><a href="../../reference/api/python/relay/transform.html#tvm.relay.transform.InferType" title="tvm.relay.transform.InferType" class="sphx-glr-backref-module-tvm-relay-transform sphx-glr-backref-type-py-function"><span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">InferType</span></a><span class="p">(),</span> <a href="../../reference/api/python/relay/transform.html#tvm.relay.transform.ToMixedPrecision" title="tvm.relay.transform.ToMixedPrecision" class="sphx-glr-backref-module-tvm-relay-transform sphx-glr-backref-type-py-function"><span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">ToMixedPrecision</span></a><span class="p">()]</span>
        <span class="p">)</span>
        <span class="k">with</span> <a href="../../reference/api/python/ir.html#tvm.transform.PassContext" title="tvm.transform.PassContext" class="sphx-glr-backref-module-tvm-transform sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span></a><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">mod</span> <span class="o">=</span> <span class="n">seq</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mod</span>
</pre></div>
</div>
<p>Let’s choose “float16_acc32” for example.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dtype</span></a> <span class="o">=</span> <span class="s2">&quot;float16_acc32&quot;</span>
<span class="n">mod</span> <span class="o">=</span> <span class="n">convert_to_dtype</span><span class="p">(</span><span class="n">mod</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">],</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dtype</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dtype</span></a> <span class="o">=</span> <span class="s2">&quot;float32&quot;</span> <span class="k">if</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dtype</span></a> <span class="o">==</span> <span class="s2">&quot;float32&quot;</span> <span class="k">else</span> <span class="s2">&quot;float16&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>def @main(%input0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %conv1.weight: Tensor[(64, 3, 7, 7), float32] /* ty=Tensor[(64, 3, 7, 7), float32] */, %bn1.weight: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %bn1.bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %bn1.running_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %bn1.running_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.0.conv1.weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %layer1.0.bn1.weight: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.0.bn1.bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.0.bn1.running_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.0.bn1.running_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.0.conv2.weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %layer1.0.bn2.weight: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.0.bn2.bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.0.bn2.running_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.0.bn2.running_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.1.conv1.weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %layer1.1.bn1.weight: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.1.bn1.bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.1.bn1.running_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.1.bn1.running_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.1.conv2.weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %layer1.1.bn2.weight: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.1.bn2.bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.1.bn2.running_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer1.1.bn2.running_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %layer2.0.conv1.weight: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %layer2.0.bn1.weight: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.0.bn1.bias: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.0.bn1.running_mean: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.0.bn1.running_var: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.0.conv2.weight: Tensor[(128, 128, 3, 3), float32] /* ty=Tensor[(128, 128, 3, 3), float32] */, %layer2.0.bn2.weight: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.0.bn2.bias: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.0.bn2.running_mean: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.0.bn2.running_var: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.0.downsample.0.weight: Tensor[(128, 64, 1, 1), float32] /* ty=Tensor[(128, 64, 1, 1), float32] */, %layer2.0.downsample.1.weight: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.0.downsample.1.bias: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.0.downsample.1.running_mean: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.0.downsample.1.running_var: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.1.conv1.weight: Tensor[(128, 128, 3, 3), float32] /* ty=Tensor[(128, 128, 3, 3), float32] */, %layer2.1.bn1.weight: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.1.bn1.bias: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.1.bn1.running_mean: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.1.bn1.running_var: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.1.conv2.weight: Tensor[(128, 128, 3, 3), float32] /* ty=Tensor[(128, 128, 3, 3), float32] */, %layer2.1.bn2.weight: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.1.bn2.bias: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.1.bn2.running_mean: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer2.1.bn2.running_var: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %layer3.0.conv1.weight: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %layer3.0.bn1.weight: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.0.bn1.bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.0.bn1.running_mean: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.0.bn1.running_var: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.0.conv2.weight: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %layer3.0.bn2.weight: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.0.bn2.bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.0.bn2.running_mean: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.0.bn2.running_var: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.0.downsample.0.weight: Tensor[(256, 128, 1, 1), float32] /* ty=Tensor[(256, 128, 1, 1), float32] */, %layer3.0.downsample.1.weight: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.0.downsample.1.bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.0.downsample.1.running_mean: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.0.downsample.1.running_var: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.1.conv1.weight: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %layer3.1.bn1.weight: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.1.bn1.bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.1.bn1.running_mean: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.1.bn1.running_var: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.1.conv2.weight: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %layer3.1.bn2.weight: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.1.bn2.bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.1.bn2.running_mean: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer3.1.bn2.running_var: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %layer4.0.conv1.weight: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %layer4.0.bn1.weight: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.0.bn1.bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.0.bn1.running_mean: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.0.bn1.running_var: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.0.conv2.weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %layer4.0.bn2.weight: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.0.bn2.bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.0.bn2.running_mean: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.0.bn2.running_var: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.0.downsample.0.weight: Tensor[(512, 256, 1, 1), float32] /* ty=Tensor[(512, 256, 1, 1), float32] */, %layer4.0.downsample.1.weight: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.0.downsample.1.bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.0.downsample.1.running_mean: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.0.downsample.1.running_var: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.1.conv1.weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %layer4.1.bn1.weight: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.1.bn1.bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.1.bn1.running_mean: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.1.bn1.running_var: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.1.conv2.weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %layer4.1.bn2.weight: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.1.bn2.bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.1.bn2.running_mean: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %layer4.1.bn2.running_var: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %fc.weight: Tensor[(1000, 512), float32] /* ty=Tensor[(1000, 512), float32] */, %fc.bias: Tensor[(1000), float32] /* ty=Tensor[(1000), float32] */) -&gt; Tensor[(1, 1000), float16] {
  %0 = cast(%input0, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 3, 224, 224), float16] */;
  %1 = cast(%conv1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(64, 3, 7, 7), float16] */;
  %2 = nn.conv2d(%0, %1, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 64, 112, 112), float32] */;
  %3 = cast(%2, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 64, 112, 112), float16] */;
  %4 = cast(%bn1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %5 = cast(%bn1.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %6 = cast(%bn1.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %7 = cast(%bn1.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %8 = nn.batch_norm(%3, %4, %5, %6, %7) /* ty=(Tensor[(1, 64, 112, 112), float16], Tensor[(64), float16], Tensor[(64), float16]) */;
  %9 = %8.0 /* ty=Tensor[(1, 64, 112, 112), float16] */;
  %10 = nn.relu(%9) /* ty=Tensor[(1, 64, 112, 112), float16] */;
  %11 = nn.max_pool2d(%10, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %12 = cast(%layer1.0.conv1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(64, 64, 3, 3), float16] */;
  %13 = nn.conv2d(%11, %12, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 64, 56, 56), float32] */;
  %14 = cast(%13, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %15 = cast(%layer1.0.bn1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %16 = cast(%layer1.0.bn1.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %17 = cast(%layer1.0.bn1.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %18 = cast(%layer1.0.bn1.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %19 = nn.batch_norm(%14, %15, %16, %17, %18) /* ty=(Tensor[(1, 64, 56, 56), float16], Tensor[(64), float16], Tensor[(64), float16]) */;
  %20 = %19.0 /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %21 = nn.relu(%20) /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %22 = cast(%layer1.0.conv2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(64, 64, 3, 3), float16] */;
  %23 = nn.conv2d(%21, %22, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 64, 56, 56), float32] */;
  %24 = cast(%23, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %25 = cast(%layer1.0.bn2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %26 = cast(%layer1.0.bn2.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %27 = cast(%layer1.0.bn2.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %28 = cast(%layer1.0.bn2.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %29 = nn.batch_norm(%24, %25, %26, %27, %28) /* ty=(Tensor[(1, 64, 56, 56), float16], Tensor[(64), float16], Tensor[(64), float16]) */;
  %30 = %29.0 /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %31 = add(%30, %11) /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %32 = nn.relu(%31) /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %33 = cast(%layer1.1.conv1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(64, 64, 3, 3), float16] */;
  %34 = nn.conv2d(%32, %33, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 64, 56, 56), float32] */;
  %35 = cast(%34, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %36 = cast(%layer1.1.bn1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %37 = cast(%layer1.1.bn1.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %38 = cast(%layer1.1.bn1.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %39 = cast(%layer1.1.bn1.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %40 = nn.batch_norm(%35, %36, %37, %38, %39) /* ty=(Tensor[(1, 64, 56, 56), float16], Tensor[(64), float16], Tensor[(64), float16]) */;
  %41 = %40.0 /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %42 = nn.relu(%41) /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %43 = cast(%layer1.1.conv2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(64, 64, 3, 3), float16] */;
  %44 = nn.conv2d(%42, %43, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 64, 56, 56), float32] */;
  %45 = cast(%44, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %46 = cast(%layer1.1.bn2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %47 = cast(%layer1.1.bn2.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %48 = cast(%layer1.1.bn2.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %49 = cast(%layer1.1.bn2.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(64), float16] */;
  %50 = nn.batch_norm(%45, %46, %47, %48, %49) /* ty=(Tensor[(1, 64, 56, 56), float16], Tensor[(64), float16], Tensor[(64), float16]) */;
  %51 = %50.0 /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %52 = add(%51, %32) /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %53 = nn.relu(%52) /* ty=Tensor[(1, 64, 56, 56), float16] */;
  %54 = cast(%layer2.0.conv1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(128, 64, 3, 3), float16] */;
  %55 = nn.conv2d(%53, %54, strides=[2, 2], padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 128, 28, 28), float32] */;
  %56 = cast(%55, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %57 = cast(%layer2.0.bn1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %58 = cast(%layer2.0.bn1.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %59 = cast(%layer2.0.bn1.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %60 = cast(%layer2.0.bn1.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %61 = nn.batch_norm(%56, %57, %58, %59, %60) /* ty=(Tensor[(1, 128, 28, 28), float16], Tensor[(128), float16], Tensor[(128), float16]) */;
  %62 = %61.0 /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %63 = nn.relu(%62) /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %64 = cast(%layer2.0.conv2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(128, 128, 3, 3), float16] */;
  %65 = nn.conv2d(%63, %64, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 128, 28, 28), float32] */;
  %66 = cast(%65, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %67 = cast(%layer2.0.bn2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %68 = cast(%layer2.0.bn2.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %69 = cast(%layer2.0.bn2.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %70 = cast(%layer2.0.bn2.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %71 = nn.batch_norm(%66, %67, %68, %69, %70) /* ty=(Tensor[(1, 128, 28, 28), float16], Tensor[(128), float16], Tensor[(128), float16]) */;
  %72 = cast(%layer2.0.downsample.0.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(128, 64, 1, 1), float16] */;
  %73 = nn.conv2d(%53, %72, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 128, 28, 28), float32] */;
  %74 = cast(%73, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %75 = cast(%layer2.0.downsample.1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %76 = cast(%layer2.0.downsample.1.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %77 = cast(%layer2.0.downsample.1.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %78 = cast(%layer2.0.downsample.1.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %79 = nn.batch_norm(%74, %75, %76, %77, %78) /* ty=(Tensor[(1, 128, 28, 28), float16], Tensor[(128), float16], Tensor[(128), float16]) */;
  %80 = %71.0 /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %81 = %79.0 /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %82 = add(%80, %81) /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %83 = nn.relu(%82) /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %84 = cast(%layer2.1.conv1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(128, 128, 3, 3), float16] */;
  %85 = nn.conv2d(%83, %84, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 128, 28, 28), float32] */;
  %86 = cast(%85, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %87 = cast(%layer2.1.bn1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %88 = cast(%layer2.1.bn1.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %89 = cast(%layer2.1.bn1.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %90 = cast(%layer2.1.bn1.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %91 = nn.batch_norm(%86, %87, %88, %89, %90) /* ty=(Tensor[(1, 128, 28, 28), float16], Tensor[(128), float16], Tensor[(128), float16]) */;
  %92 = %91.0 /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %93 = nn.relu(%92) /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %94 = cast(%layer2.1.conv2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(128, 128, 3, 3), float16] */;
  %95 = nn.conv2d(%93, %94, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 128, 28, 28), float32] */;
  %96 = cast(%95, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %97 = cast(%layer2.1.bn2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %98 = cast(%layer2.1.bn2.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %99 = cast(%layer2.1.bn2.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %100 = cast(%layer2.1.bn2.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(128), float16] */;
  %101 = nn.batch_norm(%96, %97, %98, %99, %100) /* ty=(Tensor[(1, 128, 28, 28), float16], Tensor[(128), float16], Tensor[(128), float16]) */;
  %102 = %101.0 /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %103 = add(%102, %83) /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %104 = nn.relu(%103) /* ty=Tensor[(1, 128, 28, 28), float16] */;
  %105 = cast(%layer3.0.conv1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(256, 128, 3, 3), float16] */;
  %106 = nn.conv2d(%104, %105, strides=[2, 2], padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 256, 14, 14), float32] */;
  %107 = cast(%106, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %108 = cast(%layer3.0.bn1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %109 = cast(%layer3.0.bn1.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %110 = cast(%layer3.0.bn1.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %111 = cast(%layer3.0.bn1.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %112 = nn.batch_norm(%107, %108, %109, %110, %111) /* ty=(Tensor[(1, 256, 14, 14), float16], Tensor[(256), float16], Tensor[(256), float16]) */;
  %113 = %112.0 /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %114 = nn.relu(%113) /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %115 = cast(%layer3.0.conv2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(256, 256, 3, 3), float16] */;
  %116 = nn.conv2d(%114, %115, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 256, 14, 14), float32] */;
  %117 = cast(%116, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %118 = cast(%layer3.0.bn2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %119 = cast(%layer3.0.bn2.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %120 = cast(%layer3.0.bn2.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %121 = cast(%layer3.0.bn2.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %122 = nn.batch_norm(%117, %118, %119, %120, %121) /* ty=(Tensor[(1, 256, 14, 14), float16], Tensor[(256), float16], Tensor[(256), float16]) */;
  %123 = cast(%layer3.0.downsample.0.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(256, 128, 1, 1), float16] */;
  %124 = nn.conv2d(%104, %123, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 256, 14, 14), float32] */;
  %125 = cast(%124, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %126 = cast(%layer3.0.downsample.1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %127 = cast(%layer3.0.downsample.1.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %128 = cast(%layer3.0.downsample.1.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %129 = cast(%layer3.0.downsample.1.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %130 = nn.batch_norm(%125, %126, %127, %128, %129) /* ty=(Tensor[(1, 256, 14, 14), float16], Tensor[(256), float16], Tensor[(256), float16]) */;
  %131 = %122.0 /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %132 = %130.0 /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %133 = add(%131, %132) /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %134 = nn.relu(%133) /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %135 = cast(%layer3.1.conv1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(256, 256, 3, 3), float16] */;
  %136 = nn.conv2d(%134, %135, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 256, 14, 14), float32] */;
  %137 = cast(%136, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %138 = cast(%layer3.1.bn1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %139 = cast(%layer3.1.bn1.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %140 = cast(%layer3.1.bn1.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %141 = cast(%layer3.1.bn1.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %142 = nn.batch_norm(%137, %138, %139, %140, %141) /* ty=(Tensor[(1, 256, 14, 14), float16], Tensor[(256), float16], Tensor[(256), float16]) */;
  %143 = %142.0 /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %144 = nn.relu(%143) /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %145 = cast(%layer3.1.conv2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(256, 256, 3, 3), float16] */;
  %146 = nn.conv2d(%144, %145, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 256, 14, 14), float32] */;
  %147 = cast(%146, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %148 = cast(%layer3.1.bn2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %149 = cast(%layer3.1.bn2.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %150 = cast(%layer3.1.bn2.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %151 = cast(%layer3.1.bn2.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(256), float16] */;
  %152 = nn.batch_norm(%147, %148, %149, %150, %151) /* ty=(Tensor[(1, 256, 14, 14), float16], Tensor[(256), float16], Tensor[(256), float16]) */;
  %153 = %152.0 /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %154 = add(%153, %134) /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %155 = nn.relu(%154) /* ty=Tensor[(1, 256, 14, 14), float16] */;
  %156 = cast(%layer4.0.conv1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(512, 256, 3, 3), float16] */;
  %157 = nn.conv2d(%155, %156, strides=[2, 2], padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 512, 7, 7), float32] */;
  %158 = cast(%157, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %159 = cast(%layer4.0.bn1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %160 = cast(%layer4.0.bn1.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %161 = cast(%layer4.0.bn1.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %162 = cast(%layer4.0.bn1.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %163 = nn.batch_norm(%158, %159, %160, %161, %162) /* ty=(Tensor[(1, 512, 7, 7), float16], Tensor[(512), float16], Tensor[(512), float16]) */;
  %164 = %163.0 /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %165 = nn.relu(%164) /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %166 = cast(%layer4.0.conv2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(512, 512, 3, 3), float16] */;
  %167 = nn.conv2d(%165, %166, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 512, 7, 7), float32] */;
  %168 = cast(%167, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %169 = cast(%layer4.0.bn2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %170 = cast(%layer4.0.bn2.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %171 = cast(%layer4.0.bn2.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %172 = cast(%layer4.0.bn2.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %173 = nn.batch_norm(%168, %169, %170, %171, %172) /* ty=(Tensor[(1, 512, 7, 7), float16], Tensor[(512), float16], Tensor[(512), float16]) */;
  %174 = cast(%layer4.0.downsample.0.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(512, 256, 1, 1), float16] */;
  %175 = nn.conv2d(%155, %174, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 512, 7, 7), float32] */;
  %176 = cast(%175, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %177 = cast(%layer4.0.downsample.1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %178 = cast(%layer4.0.downsample.1.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %179 = cast(%layer4.0.downsample.1.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %180 = cast(%layer4.0.downsample.1.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %181 = nn.batch_norm(%176, %177, %178, %179, %180) /* ty=(Tensor[(1, 512, 7, 7), float16], Tensor[(512), float16], Tensor[(512), float16]) */;
  %182 = %173.0 /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %183 = %181.0 /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %184 = add(%182, %183) /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %185 = nn.relu(%184) /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %186 = cast(%layer4.1.conv1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(512, 512, 3, 3), float16] */;
  %187 = nn.conv2d(%185, %186, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 512, 7, 7), float32] */;
  %188 = cast(%187, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %189 = cast(%layer4.1.bn1.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %190 = cast(%layer4.1.bn1.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %191 = cast(%layer4.1.bn1.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %192 = cast(%layer4.1.bn1.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %193 = nn.batch_norm(%188, %189, %190, %191, %192) /* ty=(Tensor[(1, 512, 7, 7), float16], Tensor[(512), float16], Tensor[(512), float16]) */;
  %194 = %193.0 /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %195 = nn.relu(%194) /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %196 = cast(%layer4.1.conv2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(512, 512, 3, 3), float16] */;
  %197 = nn.conv2d(%195, %196, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 512, 7, 7), float32] */;
  %198 = cast(%197, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %199 = cast(%layer4.1.bn2.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %200 = cast(%layer4.1.bn2.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %201 = cast(%layer4.1.bn2.running_mean, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %202 = cast(%layer4.1.bn2.running_var, dtype=&quot;float16&quot;) /* ty=Tensor[(512), float16] */;
  %203 = nn.batch_norm(%198, %199, %200, %201, %202) /* ty=(Tensor[(1, 512, 7, 7), float16], Tensor[(512), float16], Tensor[(512), float16]) */;
  %204 = %203.0 /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %205 = add(%204, %185) /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %206 = nn.relu(%205) /* ty=Tensor[(1, 512, 7, 7), float16] */;
  %207 = cast(%206, dtype=&quot;float32&quot;) /* ty=Tensor[(1, 512, 7, 7), float32] */;
  %208 = nn.adaptive_avg_pool2d(%207, output_size=[1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %209 = reshape(%208, newshape=[0, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %210 = squeeze(%209, axis=[2, 3]) /* ty=Tensor[(1, 512), float32] */;
  %211 = cast(%210, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 512), float16] */;
  %212 = cast(%fc.weight, dtype=&quot;float16&quot;) /* ty=Tensor[(1000, 512), float16] */;
  %213 = nn.dense(%211, %212, units=None, out_dtype=&quot;float32&quot;) /* ty=Tensor[(1, 1000), float32] */;
  %214 = cast(%213, dtype=&quot;float16&quot;) /* ty=Tensor[(1, 1000), float16] */;
  %215 = cast(%fc.bias, dtype=&quot;float16&quot;) /* ty=Tensor[(1000), float16] */;
  nn.bias_add(%214, %215, axis=-1) /* ty=Tensor[(1, 1000), float16] */
}
</pre></div>
</div>
<p>As you can see in the IR, the architecture now contains cast operations, which are
needed to convert to FP16 precision.
You can also use “float16” or “float32” precisions as other dtype options.</p>
</div>
<div class="section" id="compile-the-model-with-relay">
<h2>Compile the model with relay<a class="headerlink" href="#compile-the-model-with-relay" title="Permalink to this headline">¶</a></h2>
<p>Specify Adreno target before compiling to generate texture
leveraging kernels and get all the benefits of textures
Note: This generated example running on our x86 server for demonstration.
If running it on the Android device, we need to
specify its instruction set. Set <code class="code docutils literal notranslate"><span class="pre">local_demo</span></code> to False if you want
to run this tutorial with a real device.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">local_demo</span></a> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># by default on CPU target will execute.</span>
<span class="c1"># select &#39;cpu&#39;, &#39;opencl&#39; and &#39;vulkan&#39;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_target</span></a> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>

<span class="c1"># Change target configuration.</span>
<span class="c1"># Run `adb shell cat /proc/cpuinfo` to find the arch.</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">arch</span></a> <span class="o">=</span> <span class="s2">&quot;arm64&quot;</span>
<a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a> <span class="o">=</span> <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class"><span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">Target</span></a><span class="p">(</span><span class="s2">&quot;llvm -mtriple=</span><span class="si">%s</span><span class="s2">-linux-android&quot;</span> <span class="o">%</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">arch</span></a><span class="p">)</span>

<span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">local_demo</span></a><span class="p">:</span>
    <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a> <span class="o">=</span> <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class"><span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">Target</span></a><span class="p">(</span><span class="s2">&quot;llvm&quot;</span><span class="p">)</span>
<span class="k">elif</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_target</span></a> <span class="o">==</span> <span class="s2">&quot;opencl&quot;</span><span class="p">:</span>
    <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a> <span class="o">=</span> <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class"><span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">Target</span></a><span class="p">(</span><span class="s2">&quot;opencl&quot;</span><span class="p">,</span> <span class="n">host</span><span class="o">=</span><a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">)</span>
<span class="k">elif</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_target</span></a> <span class="o">==</span> <span class="s2">&quot;vulkan&quot;</span><span class="p">:</span>
    <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a> <span class="o">=</span> <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class"><span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">Target</span></a><span class="p">(</span><span class="s2">&quot;vulkan&quot;</span><span class="p">,</span> <span class="n">host</span><span class="o">=</span><a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">)</span>

<span class="k">with</span> <a href="../../reference/api/python/ir.html#tvm.transform.PassContext" title="tvm.transform.PassContext" class="sphx-glr-backref-module-tvm-transform sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span></a><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">lib</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="o">=</span><a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="deploy-the-model-remotely-by-rpc">
<h2>Deploy the Model Remotely by RPC<a class="headerlink" href="#deploy-the-model-remotely-by-rpc" title="Permalink to this headline">¶</a></h2>
<p>Using RPC you can deploy the model from host
machine to the remote Adreno device</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker_host</span></a> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;TVM_TRACKER_HOST&quot;</span><span class="p">,</span> <span class="s2">&quot;127.0.0.1&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker_port</span></a> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;TVM_TRACKER_PORT&quot;</span><span class="p">,</span> <span class="mi">9190</span><span class="p">))</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">key</span></a> <span class="o">=</span> <span class="s2">&quot;android&quot;</span>

<span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">local_demo</span></a><span class="p">:</span>
    <a href="../../reference/api/python/rpc.html#tvm.rpc.LocalSession" title="tvm.rpc.LocalSession" class="sphx-glr-backref-module-tvm-rpc sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">remote</span></a> <span class="o">=</span> <a href="../../reference/api/python/rpc.html#tvm.rpc.LocalSession" title="tvm.rpc.LocalSession" class="sphx-glr-backref-module-tvm-rpc sphx-glr-backref-type-py-class"><span class="n">rpc</span><span class="o">.</span><span class="n">LocalSession</span></a><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">tracker</span> <span class="o">=</span> <a href="../../reference/api/python/rpc.html#tvm.rpc.connect_tracker" title="tvm.rpc.connect_tracker" class="sphx-glr-backref-module-tvm-rpc sphx-glr-backref-type-py-function"><span class="n">rpc</span><span class="o">.</span><span class="n">connect_tracker</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker_host</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker_port</span></a><span class="p">)</span>
    <span class="c1"># When running a heavy model, we should increase the `session_timeout`</span>
    <a href="../../reference/api/python/rpc.html#tvm.rpc.LocalSession" title="tvm.rpc.LocalSession" class="sphx-glr-backref-module-tvm-rpc sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">remote</span></a> <span class="o">=</span> <span class="n">tracker</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">key</span></a><span class="p">,</span> <span class="n">priority</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">session_timeout</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">local_demo</span></a><span class="p">:</span>
    <span class="n">dev</span> <span class="o">=</span> <a href="../../reference/api/python/rpc.html#tvm.rpc.RPCSession.cpu" title="tvm.rpc.RPCSession.cpu" class="sphx-glr-backref-module-tvm-rpc sphx-glr-backref-type-py-method"><span class="n">remote</span><span class="o">.</span><span class="n">cpu</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">elif</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_target</span></a> <span class="o">==</span> <span class="s2">&quot;opencl&quot;</span><span class="p">:</span>
    <span class="n">dev</span> <span class="o">=</span> <a href="../../reference/api/python/rpc.html#tvm.rpc.RPCSession.cl" title="tvm.rpc.RPCSession.cl" class="sphx-glr-backref-module-tvm-rpc sphx-glr-backref-type-py-method"><span class="n">remote</span><span class="o">.</span><span class="n">cl</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">elif</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_target</span></a> <span class="o">==</span> <span class="s2">&quot;vulkan&quot;</span><span class="p">:</span>
    <span class="n">dev</span> <span class="o">=</span> <a href="../../reference/api/python/rpc.html#tvm.rpc.RPCSession.vulkan" title="tvm.rpc.RPCSession.vulkan" class="sphx-glr-backref-module-tvm-rpc sphx-glr-backref-type-py-method"><span class="n">remote</span><span class="o">.</span><span class="n">vulkan</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">dev</span> <span class="o">=</span> <a href="../../reference/api/python/rpc.html#tvm.rpc.RPCSession.cpu" title="tvm.rpc.RPCSession.cpu" class="sphx-glr-backref-module-tvm-rpc sphx-glr-backref-type-py-method"><span class="n">remote</span><span class="o">.</span><span class="n">cpu</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<a href="../../reference/api/python/contrib.html#tvm.contrib.utils.TempDirectory" title="tvm.contrib.utils.TempDirectory" class="sphx-glr-backref-module-tvm-contrib-utils sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">temp</span></a> <span class="o">=</span> <a href="../../reference/api/python/contrib.html#tvm.contrib.utils.tempdir" title="tvm.contrib.utils.tempdir" class="sphx-glr-backref-module-tvm-contrib-utils sphx-glr-backref-type-py-function"><span class="n">utils</span><span class="o">.</span><span class="n">tempdir</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dso_binary</span></a> <span class="o">=</span> <span class="s2">&quot;dev_lib_cl.so&quot;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dso_binary_path</span></a> <span class="o">=</span> <a href="../../reference/api/python/contrib.html#tvm.contrib.utils.TempDirectory.relpath" title="tvm.contrib.utils.TempDirectory.relpath" class="sphx-glr-backref-module-tvm-contrib-utils sphx-glr-backref-type-py-method"><span class="n">temp</span><span class="o">.</span><span class="n">relpath</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dso_binary</span></a><span class="p">)</span>
<span class="n">fcompile</span> <span class="o">=</span> <a href="../../reference/api/python/contrib.html#tvm.contrib.ndk.create_shared" title="tvm.contrib.ndk.create_shared" class="sphx-glr-backref-module-tvm-contrib-ndk sphx-glr-backref-type-py-function"><span class="n">ndk</span><span class="o">.</span><span class="n">create_shared</span></a> <span class="k">if</span> <span class="ow">not</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">local_demo</span></a> <span class="k">else</span> <span class="kc">None</span>
<span class="n">lib</span><span class="o">.</span><span class="n">export_library</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dso_binary_path</span></a><span class="p">,</span> <span class="n">fcompile</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">remote_path</span></a> <span class="o">=</span> <span class="s2">&quot;/data/local/tmp/&quot;</span> <span class="o">+</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dso_binary</span></a>
<a href="../../reference/api/python/rpc.html#tvm.rpc.RPCSession.upload" title="tvm.rpc.RPCSession.upload" class="sphx-glr-backref-module-tvm-rpc sphx-glr-backref-type-py-method"><span class="n">remote</span><span class="o">.</span><span class="n">upload</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dso_binary_path</span></a><span class="p">)</span>
<a href="../../reference/api/python/runtime.html#tvm.runtime.Module" title="tvm.runtime.Module" class="sphx-glr-backref-module-tvm-runtime sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rlib</span></a> <span class="o">=</span> <a href="../../reference/api/python/rpc.html#tvm.rpc.RPCSession.load_module" title="tvm.rpc.RPCSession.load_module" class="sphx-glr-backref-module-tvm-rpc sphx-glr-backref-type-py-method"><span class="n">remote</span><span class="o">.</span><span class="n">load_module</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dso_binary</span></a><span class="p">)</span>
<a href="../../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule" title="tvm.contrib.graph_executor.GraphModule" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">m</span></a> <span class="o">=</span> <a href="../../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule" title="tvm.contrib.graph_executor.GraphModule" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-class"><span class="n">graph_executor</span><span class="o">.</span><span class="n">GraphModule</span></a><span class="p">(</span><a href="../../reference/api/python/runtime.html#tvm.runtime.Module" title="tvm.runtime.Module" class="sphx-glr-backref-module-tvm-runtime sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rlib</span></a><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">](</span><span class="n">dev</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="run-inference">
<h2>Run inference<a class="headerlink" href="#run-inference" title="Permalink to this headline">¶</a></h2>
<p>We now can set inputs, infer our model and get predictions as output</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule.set_input" title="tvm.contrib.graph_executor.GraphModule.set_input" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-method"><span class="n">m</span><span class="o">.</span><span class="n">set_input</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_name</span></a><span class="p">,</span> <a href="../../reference/api/python/ndarray.html#tvm.nd.array" title="tvm.nd.array" class="sphx-glr-backref-module-tvm-nd sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)))</span>
<a href="../../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule.run" title="tvm.contrib.graph_executor.GraphModule.run" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-method"><span class="n">m</span><span class="o">.</span><span class="n">run</span></a><span class="p">()</span>
<span class="n">tvm_output</span> <span class="o">=</span> <a href="../../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule.get_output" title="tvm.contrib.graph_executor.GraphModule.get_output" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-method"><span class="n">m</span><span class="o">.</span><span class="n">get_output</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="get-predictions-and-performance-statistic">
<h2>Get predictions and performance statistic<a class="headerlink" href="#get-predictions-and-performance-statistic" title="Permalink to this headline">¶</a></h2>
<p>This piece of code displays the top-1 and top-5 predictions, as
well as provides information about the model’s performance</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">join</span></a><span class="p">,</span> <span class="n">isfile</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="kn">import</span> <span class="n">download</span>

<span class="c1"># Download ImageNet categories</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">categ_url</span></a> <span class="o">=</span> <span class="s2">&quot;https://github.com/uwsampl/web-data/raw/main/vta/models/&quot;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">categ_fn</span></a> <span class="o">=</span> <span class="s2">&quot;synset.txt&quot;</span>
<span class="n">download</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">categ_url</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">categ_fn</span></a><span class="p">),</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">categ_fn</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">synset</span></a> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">categ_fn</span></a><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>

<span class="n">top_categories</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">tvm_output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">top5</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">top_categories</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[:</span><span class="mi">5</span><span class="p">]</span>

<span class="c1"># Report top-1 classification result</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Top-1 id: </span><span class="si">{}</span><span class="s2">, class name: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">top5</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">synset</span></a><span class="p">[</span><span class="n">top5</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]))</span>

<span class="c1"># Report top-5 classification results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Top5 predictions: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">#1:&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">synset</span></a><span class="p">[</span><span class="n">top5</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">#2:&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">synset</span></a><span class="p">[</span><span class="n">top5</span><span class="p">[</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">#3:&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">synset</span></a><span class="p">[</span><span class="n">top5</span><span class="p">[</span><span class="mi">3</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">#4:&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">synset</span></a><span class="p">[</span><span class="n">top5</span><span class="p">[</span><span class="mi">4</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">#5:&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">synset</span></a><span class="p">[</span><span class="n">top5</span><span class="p">[</span><span class="mi">5</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">top5</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ImageNetClassifier</span></a> <span class="o">=</span> <span class="kc">False</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">top_categories</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]:</span>
    <span class="k">if</span> <span class="s2">&quot;cat&quot;</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">synset</span></a><span class="p">[</span><span class="n">k</span><span class="p">]:</span>
        <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ImageNetClassifier</span></a> <span class="o">=</span> <span class="kc">True</span>
<span class="k">assert</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ImageNetClassifier</span></a><span class="p">,</span> <span class="s2">&quot;Failed ImageNet classifier validation check&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluate inference time cost...&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule.benchmark" title="tvm.contrib.graph_executor.GraphModule.benchmark" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-method"><span class="n">m</span><span class="o">.</span><span class="n">benchmark</span></a><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/workspace/python/tvm/runtime/ndarray.py:200: DeprecationWarning: NDArray.asnumpy() will be deprecated in TVM v0.8 release. Please use NDArray.numpy() instead.
  DeprecationWarning,
Top-1 id: 281, class name: tabby, tabby cat

Top5 predictions:

        #1: tabby, tabby cat
        #2: tiger cat
        #3: lynx, catamount
        #4: red fox, Vulpes vulpes
        #5: Egyptian cat
         [281 282 287 277 285]
Evaluate inference time cost...
Execution time summary:
 mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)
 2523.3301    2520.1300    2548.5365    2519.0336      8.5041
</pre></div>
</div>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-how-to-deploy-models-deploy-model-on-adreno-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/2387d8448da213eb625e6b3d916327d4/deploy_model_on_adreno.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">deploy_model_on_adreno.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/b9e7311d8c56eb6e6aca08f0be35ff03/deploy_model_on_adreno.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">deploy_model_on_adreno.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="deploy_model_on_android.html" class="btn btn-neutral float-right" title="Deploy the Pretrained Model on Android" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Deploy Deep Learning Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2022 Apache Software Foundation | All rights reserved</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote">Copyright © 2022 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>