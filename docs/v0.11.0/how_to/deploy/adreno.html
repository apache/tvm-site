





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Deploy to Adreno GPU &mdash; tvm 0.11.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tlcpack_theme.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Integrate TVM into Your Project" href="integrate.html" />
    <link rel="prev" title="Deploy to Android" href="android.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/vta>VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <input type="checkbox" class="version-toggle-box" hidden id="version-toggle">
              <label for="version-toggle" class="version-toggle-label">
                  <div tabindex="0" class="version version-selector version-selector-show">
                    0.11.dev0 <span class="chevron versions-hidden"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m8 4 8 8-8 8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span><span class="chevron versions-shown"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m4 8 8 8 8-8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span>
                  </div>
                </label>
                <div class="version-details wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                  <p class="caption" role="heading"><span class="caption-text">Versions</span></p>
                  <ol style="text-align: left">
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="/">0.11.dev0 (main)</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.8.0/">v0.8.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.9.0/">v0.9.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.10.0/">v0.10.0</a></div></li>
                    
                  </ol>
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installing TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contributor Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/index.html">User Tutorial</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">How To Guides</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../compile_models/index.html">Compile Deep Learning Models</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Deploy Models and Integrate TVM</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="index.html#build-the-tvm-runtime-library">Build the TVM runtime library</a></li>
<li class="toctree-l3"><a class="reference internal" href="index.html#cross-compile-the-tvm-runtime-for-other-architectures">Cross compile the TVM runtime for other architectures</a></li>
<li class="toctree-l3"><a class="reference internal" href="index.html#optimize-and-tune-models-for-target-devices">Optimize and tune models for target devices</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="index.html#deploy-optimized-model-on-target-devices">Deploy optimized model on target devices</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="cpp_deploy.html">Deploy TVM Module using C++ API</a></li>
<li class="toctree-l4"><a class="reference internal" href="android.html">Deploy to Android</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">Deploy to Adreno GPU</a></li>
<li class="toctree-l4"><a class="reference internal" href="integrate.html">Integrate TVM into Your Project</a></li>
<li class="toctree-l4"><a class="reference internal" href="hls.html">HLS Backend Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="arm_compute_lib.html">Relay Arm<sup>®</sup> Compute Library Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensorrt.html">Relay TensorRT Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="vitis_ai.html">Vitis AI Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="bnns.html">Relay BNNS Integration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="index.html#additional-deployment-how-tos">Additional Deployment How-Tos</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_relay/index.html">Work With Relay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_schedules/index.html">Work With Tensor Expression and Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../optimize_operators/index.html">Optimize Tensor Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autotvm/index.html">Auto-Tune with Templates and AutoTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autoscheduler/index.html">Use AutoScheduler for Template-Free Scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_microtvm/index.html">Work With microTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../extend_tvm/index.html">Extend TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../profile/index.html">Profile Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../errors.html">Handle TVM Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/tutorial/index.html">Developer Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to/how_to.html">Developer How-To Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Architecture  Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../arch/index.html">Design and Architecture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Topic Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../topic/microtvm/index.html">microTVM: TVM on bare-metal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../topic/vta/index.html">VTA: Versatile Tensor Accelerator</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/links.html">Other APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="../index.html">How To Guides</a> <span class="br-arrow">></span></li>
        
          <li><a href="index.html">Deploy Models and Integrate TVM</a> <span class="br-arrow">></span></li>
        
      <li>Deploy to Adreno GPU</li>
    
    
      
      
        
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/tvm/edit/main/docs/how_to/deploy/adreno.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="deploy-to-adreno-gpu">
<h1>Deploy to Adreno GPU<a class="headerlink" href="#deploy-to-adreno-gpu" title="Permalink to this headline">¶</a></h1>
<p><strong>Authors</strong>: Daniil Barinov, Egor Churaev, Andrey Malyshev</p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Adreno is a series of graphics processing unit (GPU) semiconductor
intellectual property cores developed by Qualcomm and used in many of
their SoCs.</p>
<p>The Adreno GPU accelerates the rendering of complex geometries to
deliver high-performance graphics and a rich user experience with low
power consumption.</p>
<p>This guide will demonstrate <a class="reference internal" href="#advantages-of-the-textures"><span class="std std-ref">the benefits of using textures with Adreno</span></a>,
how to <a class="reference internal" href="#building-tvm-for-adreno"><span class="std std-ref">build TVM with OpenCL</span></a> (needed by Adreno devices) and TVM RPC
enabled. It will also provide <a class="reference internal" href="#build-and-deploy-model-for-adreno"><span class="std std-ref">example code</span></a> to better understand the differences in compiling and deploying models
for Adreno devices.</p>
</div>
<div class="section" id="advantages-of-the-textures">
<span id="id1"></span><h2>Advantages of the Textures<a class="headerlink" href="#advantages-of-the-textures" title="Permalink to this headline">¶</a></h2>
<p>One of the Adreno’s advantages is the clever handling of textures. At
the moment, TVM is able to benefit from this by having texture support
for Adreno. The graph below shows the Adreno A5x architecture.</p>
<p><img alt="High-level overview of the Adreno A5x architecture for OpenCL" src="https://raw.githubusercontent.com/tlc-pack/web-data/main/images/how-to/adreno_architecture.png" /></p>
<p><em>Fig. 1 High-level overview of the Adreno A5x architecture for OpenCL</em></p>
<p><em>source:</em> <a class="reference external" href="https://dl.acm.org/doi/10.1145/3204919.3204935">OpenCL Optimization and Best Practices for Qualcomm Adreno GPUs</a></p>
<p>Reasons of using textures:</p>
<ul class="simple">
<li><p>Texture processor (TP) has a dedicated L1 cache, which is read-only cache and stores data
fetched from level-2 (L2) cache for texture operations (primary
reason)</p></li>
<li><p>The handling of image boundaries is built-in.</p></li>
<li><p>Supports numerous image format and data type combinations with
support for automatic format conversions</p></li>
</ul>
<p>Overall, with textures, it is possible to achieve a significant performance boost
compared to OpenCL buffer based solutions.</p>
</div>
<div class="section" id="building-tvm-for-adreno">
<span id="id2"></span><h2>Building TVM for Adreno<a class="headerlink" href="#building-tvm-for-adreno" title="Permalink to this headline">¶</a></h2>
<p>This section gives instructions on how to build the Android part of TVM
with OpenCL and TVM RPC Server in order to deploy models on Adreno.</p>
<p>Since the process of building TVM for Adreno is exactly the same as the
process of building TVM for Android, please refer to these instructions:
<a class="reference external" href="https://github.com/apache/tvm/tree/main/apps/cpp_rpc">TVM RPC
Server</a>.</p>
<p>Since there are many required packages for Android, you can use the official Docker Image to build TVM.
For more information refer to this guide: <a class="reference external" href="https://tvm.apache.org/docs/how_to/deploy_models/deploy_model_on_android.html">Deploy the Pretrained Model on Android</a>.</p>
<p><strong>Prerequisites</strong>: Android NDK and Android Debug Bridge must
be installed, the desired device must have OpenCL support and Android part of TVM must be built:</p>
<ul class="simple">
<li><p>Read documentation about <em>Android NDK installation</em> here: <a class="reference external" href="https://developer.android.com/ndk">https://developer.android.com/ndk</a></p></li>
<li><p>To get access to adb tools you can see <em>Android Debug Bridge installation</em> here: <a class="reference external" href="https://developer.android.com/studio/command-line/adb">https://developer.android.com/studio/command-line/adb</a></p></li>
</ul>
<p>You can also build the android part of TVM locally. From the root
folder of TVM:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>mkdir build_android
cd build_android
cmake .. -DUSE_OPENCL=ON -DCMAKE_TOOLCHAIN_FILE=${ANDROID_NDK_HOME}/build/cmake/android.toolchain.cmake -DANDROID_ABI=arm64-v8a -DANDROID_NATIVE_API_LEVEL=android-28 -DCMAKE_FIND_ROOT_PATH_MODE_PACKAGE=ON -DANDROID_STL=c++_static -DUSE_CPP_RPC=ON
make -jN tvm_runtime tvm_rpc
</pre></div>
</div>
<p>where <strong>N</strong> is the number of cores available on your <em>CPU</em>.</p>
<p>At this stage you have built TVM for Adreno.</p>
</div>
<div class="section" id="build-and-deploy-model-for-adreno">
<span id="id3"></span><h2>Build and deploy model for Adreno<a class="headerlink" href="#build-and-deploy-model-for-adreno" title="Permalink to this headline">¶</a></h2>
<p>In this section we will focus on target, needed to compile and deploy models for Adreno, demonstrate
the differences in generated kernels with and without textures and, in addition, the
possibility of choosing a different precision for model compilation will
be considered.</p>
<p>For the complete step-py-step process of compiling and deploying models on
Adreno, including selection of precision, running the inference of the
model, getting the predictions, and measuring the performance please refer to this tutorial: <a class="reference external" href="https://tvm.apache.org/docs/how_to/deploy_models/deploy_model_on_adreno.html">How To Deploy model on Adreno</a></p>
<p><img alt="Android deployment pipeline" src="https://raw.githubusercontent.com/tlc-pack/web-data/main/images/how-to/android_deployment_pipeline.jpg" /></p>
<p><em>Fig.2 Deployment pipeline on Adreno devices</em></p>
<p>The figure above demonstrates a generalized pipeline for deploying and running neural network models on android devices.
As can be seen from the figure, the compiled model has a set_input() and a run() methods,
which <em>prepare the inputs</em> for inference and <em>execute the inference</em> on the remote device using the Graph Executor runtime module.</p>
<div class="section" id="adreno-target">
<h3>Adreno target<a class="headerlink" href="#adreno-target" title="Permalink to this headline">¶</a></h3>
<p>Normally, when compiling models for Android using OpenCL, the
corresponding target is used</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">target</span><span class="o">=</span><span class="s2">&quot;opencl&quot;</span>
</pre></div>
</div>
<p>Using Adreno, we want to get all the benefits of textures, so we have to
use the following target to generate texture leveraging kernels</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">target</span><span class="o">=</span><span class="s2">&quot;opencl -device=adreno&quot;</span>
</pre></div>
</div>
<p>Let’s write a simple model with one convolutional (conv2d) layer and take a look at generated kernels for these
two targets</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">relay</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="n">filter_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="nb">filter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">filter_shape</span><span class="p">)</span>

<span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">filter_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">data_layout</span><span class="o">=</span><span class="s2">&quot;NHWC&quot;</span><span class="p">,</span> <span class="n">kernel_layout</span><span class="o">=</span><span class="s2">&quot;HWIO&quot;</span><span class="p">,</span> <span class="n">out_dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

<span class="n">mod</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">Function</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">D</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
   <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">filter</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Now compile our model with the classic OpenCL target and print its modules:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">target</span><span class="o">=</span><span class="s2">&quot;opencl&quot;</span>

<span class="k">with</span> <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
   <span class="n">graph</span><span class="p">,</span> <span class="n">lib</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build_module</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lib</span><span class="o">.</span><span class="n">imported_modules</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_source</span><span class="p">())</span>
</pre></div>
</div>
<p>Notice that the generated convolution kernel has pointers in
the initialization of the function. The kernels generated with the above target are buffer-based.</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">__kernel</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">tvmgen_default_fused_nn_conv2d_kernel0</span><span class="p">(</span><span class="n">__global</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="kr">restrict</span><span class="w"> </span><span class="n">p0</span><span class="p">,</span><span class="w"> </span><span class="n">__global</span><span class="w"> </span><span class="kt">double</span><span class="o">*</span><span class="w"> </span><span class="kr">restrict</span><span class="w"> </span><span class="n">p1</span><span class="p">,</span><span class="w"> </span><span class="n">__global</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="kr">restrict</span><span class="w"> </span><span class="n">conv2d_nhwc</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="c1">// body..</span>
</pre></div>
</div>
<p>Now take a look at “opencl -device=adreno” target:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">target</span><span class="o">=</span><span class="s2">&quot;opencl -device=adreno&quot;</span>

<span class="k">with</span> <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
   <span class="n">graph</span><span class="p">,</span> <span class="n">lib</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build_module</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lib</span><span class="o">.</span><span class="n">imported_modules</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_source</span><span class="p">())</span>
</pre></div>
</div>
<p>The kernels generated this way is actually working with 2d arrays, leveraging textures</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">__kernel</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">tvmgen_default_fused_nn_conv2d_kernel0</span><span class="p">(</span><span class="n">__write_only</span><span class="w"> </span><span class="n">image2d_t</span><span class="w"> </span><span class="n">pad_temp_global_texture</span><span class="p">,</span><span class="w"> </span><span class="n">__read_only</span><span class="w"> </span><span class="n">image2d_t</span><span class="w"> </span><span class="n">p0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="c1">// body..</span>
</pre></div>
</div>
<p><em>image2d_t</em> is a built-in OpenCL types that represents two-dimensional image object and provides several additional functions.
When we use <em>image2d_t</em> we read <em>4 elements at one time</em>, and it helps to utilize hardware in a more efficient way.</p>
</div>
<div class="section" id="precisions">
<h3>Precisions<a class="headerlink" href="#precisions" title="Permalink to this headline">¶</a></h3>
<p>The right choice of precision for a specific workload can greatly increase the efficiency of the solution,
shifting the initial balance of precision and speed to the side that is a priority for the problem.</p>
<p>We can choose from <em>float16</em>, <em>float16_acc32</em> (Mixed Precision), <em>float32</em> (standard).</p>
<p><strong>Float16</strong></p>
<p>To leverage the GPU hardware capabilities and utilize the benefits of half precision computation and memory management,
we can convert an original model having floating points operation to a model operating with half precision.
Choosing lower precision will positively affect the performance of the model, but it may also have a decrease in the accuracy of the model.
To do the conversion you need to write a simple conversion function and specify the <em>dtype</em> value of “float16” before calling the function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span>  <span class="nf">convert_to_dtype</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
   <span class="c1"># downcast to float16</span>
   <span class="k">if</span>  <span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;float16&quot;</span><span class="p">:</span>
      <span class="k">global</span>  <span class="n">conv2d_acc</span> <span class="o">=</span> <span class="s2">&quot;float16&quot;</span>
      <span class="kn">from</span>  <span class="nn">tvm.ir</span>  <span class="kn">import</span>  <span class="n">IRModule</span>
      <span class="n">mod</span> <span class="o">=</span> <span class="n">IRModule</span><span class="o">.</span><span class="n">from_expr</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
      <span class="n">seq</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
         <span class="p">[</span>
               <span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">InferType</span><span class="p">(),</span>
               <span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">ToMixedPrecision</span><span class="p">()</span>
         <span class="p">]</span>
      <span class="p">)</span>
      <span class="k">with</span>  <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
         <span class="n">mod</span> <span class="o">=</span> <span class="n">seq</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
   <span class="k">return</span>  <span class="n">mod</span>

<span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float16&quot;</span>
<span class="n">mod</span> <span class="o">=</span> <span class="n">convert_to_dtype</span><span class="p">(</span><span class="n">mod</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
<p>We then can compile our model in any convinient way</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span>  <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">lib</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
        <span class="n">mod</span><span class="p">,</span> <span class="n">target_host</span><span class="o">=</span><span class="n">target_host</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span>
    <span class="p">)</span>
</pre></div>
</div>
<p><strong>float16_acc32 (Mixed Precision)</strong></p>
<p>ToMixedPrecision pass traverse over the network and split network to clusters of ops dealing with float or float16 data types.
The clusters are defined by three types of operations:
- Operations always be converted into float16 data type
- Operations which can be converted if they follow by converted cluster
- Operations never be converted to the float16 data type
This list is defined in the ToMixedPrecision implementation here
<a class="reference external" href="https://github.com/apache/tvm/blob/main/python/tvm/relay/transform/mixed_precision.py#L34">relay/transform/mixed_precision.py</a>
and can be overridden by user</p>
<p>In some cases, we want higher precision in accumulation than the input data.
This is supported, for example, for conv2d and dense operations. To override accumulation type you need to register
function with <code class="docutils literal notranslate"><span class="pre">&#64;register_mixed_precision_conversion</span></code> decorator to modify parameters of <code class="docutils literal notranslate"><span class="pre">ToMixedPrecision</span></code> conversion</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span>  <span class="nn">tvm.relay.op</span>  <span class="kn">import</span>  <span class="n">register_mixed_precision_conversion</span>

<span class="n">conv2d_acc</span> <span class="o">=</span> <span class="s2">&quot;float32&quot;</span>

<span class="c1"># Pick a priority &gt; 10 to overwrite defaults, higher priorities take precedence</span>
<span class="nd">@register_mixed_precision_conversion</span><span class="p">(</span><span class="s2">&quot;nn.conv2d&quot;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="k">def</span>  <span class="nf">conv2d_mixed_precision_rule</span><span class="p">(</span><span class="n">call_node</span><span class="p">:</span> <span class="s2">&quot;relay.Call&quot;</span><span class="p">,</span> <span class="n">mixed_precision_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">global</span>  <span class="n">conv2d_acc</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="c1"># always do main calculation in mixed_precision_type</span>
        <span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">mixed_precision</span><span class="o">.</span><span class="n">MIXED_PRECISION_ALWAYS</span><span class="p">,</span>
        <span class="c1"># the dtype for the accumulator</span>
        <span class="n">conv2d_acc</span><span class="p">,</span>
        <span class="c1"># the output dtype for the operation (usually fp16)</span>
        <span class="n">mixed_precision_type</span><span class="p">,</span>
    <span class="p">]</span>

<span class="c1"># Same for dense</span>
<span class="nd">@register_mixed_precision_conversion</span><span class="p">(</span><span class="s2">&quot;nn.dense&quot;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="k">def</span>  <span class="nf">conv2d_mixed_precision_rule</span><span class="p">(</span><span class="n">call_node</span><span class="p">:</span> <span class="s2">&quot;relay.Call&quot;</span><span class="p">,</span> <span class="n">mixed_precision_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">global</span>  <span class="n">conv2d_acc</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">mixed_precision</span><span class="o">.</span><span class="n">MIXED_PRECISION_ALWAYS</span><span class="p">,</span>
        <span class="n">conv2d_acc</span><span class="p">,</span>
        <span class="n">mixed_precision_type</span><span class="p">,</span>
    <span class="p">]</span>
</pre></div>
</div>
<p>Now we need to modify the conversion function by adding some logical “forks” and ToMixedPrecision() call,
then create a Relay graph from desired model in any convinient way and obtain <strong>mod</strong> (which is IR representation of the model),
after which we can convert it to the required <strong>dtype</strong> and then assemble our model sequentialy</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span>  <span class="nf">convert_to_dtype</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
    <span class="c1"># downcast to float16</span>
    <span class="k">if</span>  <span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;float16&quot;</span>  <span class="ow">or</span>  <span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;float16_acc32&quot;</span><span class="p">:</span>
        <span class="k">global</span>  <span class="n">conv2d_acc</span>
        <span class="n">conv2d_acc</span> <span class="o">=</span> <span class="s2">&quot;float16&quot;</span>  <span class="k">if</span>  <span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;float16&quot;</span>  <span class="k">else</span>  <span class="s2">&quot;float32&quot;</span>
        <span class="kn">from</span>  <span class="nn">tvm.ir</span>  <span class="kn">import</span>  <span class="n">IRModule</span>
        <span class="n">mod</span> <span class="o">=</span> <span class="n">IRModule</span><span class="o">.</span><span class="n">from_expr</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
        <span class="n">seq</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">InferType</span><span class="p">(),</span>
                <span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">ToMixedPrecision</span><span class="p">()</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span><span class="p">(</span>
             <span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;relay.ToMixedPrecision.keep_orig_output_dtype&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span>
             <span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
         <span class="n">mod</span> <span class="o">=</span> <span class="n">seq</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
    <span class="k">return</span>  <span class="n">mod</span>

<span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float16_acc32&quot;</span>
<span class="n">mod</span> <span class="o">=</span> <span class="n">convert_to_dtype</span><span class="p">(</span><span class="n">mod</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="p">)</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="s2">&quot;float32&quot;</span>  <span class="k">if</span>  <span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;float32&quot;</span>  <span class="k">else</span>  <span class="s2">&quot;float16&quot;</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">ToMixedPrecision</span></code> method is a pass to convert an FP32 relay graph into an FP16 version (with
FP16 or FP32 accumulation dtypes). Doing this transformation is useful for reducing model size
as it halves the expected size of the weights (FP16_acc16 case).</p>
<p>From this point onwards, we can compile our model as normal</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span>  <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">lib</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
        <span class="n">mod</span><span class="p">,</span> <span class="n">target_host</span><span class="o">=</span><span class="n">target_host</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="integrate.html" class="btn btn-neutral float-right" title="Integrate TVM into Your Project" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="android.html" class="btn btn-neutral float-left" title="Deploy to Android" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2022 Apache Software Foundation | All rights reserved</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote">Copyright © 2022 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>