
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "how_to/work_with_relay/using_pipeline_executor.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_how_to_work_with_relay_using_pipeline_executor.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_how_to_work_with_relay_using_pipeline_executor.py:


Using Pipeline Executor in Relay
=================================
**Author**: `Hua Jiang <https://github.com/huajsj>`_

This is a short tutorial on how to use "Pipeline Executor" with Relay.

.. GENERATED FROM PYTHON SOURCE LINES 24-40

.. code-block:: default

    import tvm
    from tvm import te
    import numpy as np
    from tvm.contrib import graph_executor as runtime
    from tvm.relay.op.contrib.cutlass import partition_for_cutlass
    from tvm import relay
    from tvm.relay import testing
    import tvm.testing
    from tvm.contrib.cutlass import (
        has_cutlass,
        num_cutlass_partitions,
        finalize_modules,
        finalize_modules_vm,
    )

    img_size = 8







.. GENERATED FROM PYTHON SOURCE LINES 41-45

Create a simple network, this network can be a pre-trained model too.
---------------------------------------------------------------------
Let's create a very simple network for demonstration.
It consists of convolution, batch normalization, dense, and ReLU activation.

.. GENERATED FROM PYTHON SOURCE LINES 45-72

.. code-block:: default

    def get_network():
        out_channels = 16
        batch_size = 1
        data = relay.var("data", relay.TensorType((batch_size, 3, img_size, img_size), "float16"))
        dense_weight = relay.var(
            "dweight", relay.TensorType((batch_size, 16 * img_size * img_size), "float16")
        )
        weight = relay.var("weight")
        second_weight = relay.var("second_weight")
        bn_gamma = relay.var("bn_gamma")
        bn_beta = relay.var("bn_beta")
        bn_mmean = relay.var("bn_mean")
        bn_mvar = relay.var("bn_var")
        simple_net = relay.nn.conv2d(
            data=data, weight=weight, kernel_size=(3, 3), channels=out_channels, padding=(1, 1)
        )
        simple_net = relay.nn.batch_norm(simple_net, bn_gamma, bn_beta, bn_mmean, bn_mvar)[0]
        simple_net = relay.nn.relu(simple_net)
        simple_net = relay.nn.batch_flatten(simple_net)
        simple_net = relay.nn.dense(simple_net, dense_weight)
        simple_net = relay.Function(relay.analysis.free_vars(simple_net), simple_net)
        data_shape = (batch_size, 3, img_size, img_size)
        net, params = testing.create_workload(simple_net)
        return net, params, data_shape


    net, params, data_shape = get_network()







.. GENERATED FROM PYTHON SOURCE LINES 73-77

Splitting the network into two subgraphs.
-----------------------------------------
This function called 'graph_split' from a unit test is just an example. User can create a customized logic
to split the graph.

.. GENERATED FROM PYTHON SOURCE LINES 77-84

.. code-block:: default

    import inspect
    import os

    tutorial_dir = os.path.dirname(inspect.getfile(lambda: None))
    os.sys.path.append(os.path.join(tutorial_dir, "../../../tests/python/relay"))
    from test_pipeline_executor import graph_split








.. GENERATED FROM PYTHON SOURCE LINES 85-86

Splitting the network into two subgraphs.

.. GENERATED FROM PYTHON SOURCE LINES 86-88

.. code-block:: default

    split_config = [{"op_name": "nn.relu", "op_index": 0}]
    subgraphs = graph_split(net["main"], split_config, params)







.. GENERATED FROM PYTHON SOURCE LINES 89-90

The generated subgraphs should look something like below.

.. GENERATED FROM PYTHON SOURCE LINES 90-111

.. code-block:: default


    """
    #subgraphs[0])

     def @main(%data: Tensor[(1, 3, img_size, img_size), float16]) {
      %0 = nn.conv2d(%data, meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float16] */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, img_size, img_size), float16] */;
      %1 = nn.batch_norm(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float16] */, meta[relay.Constant][2] /* ty=Tensor[(16), float16]*/, meta[relay.Constant][3] /* ty=Tensor[(16), float16] */, meta[relay.Constant][4] /* ty=Tensor[(16), float16] */) /* ty=(Tensor[(1,16, img_size, img_size), float16], Tensor[(16), float16], Tensor[(16), float16]) */;
      %2 = %1.0;
      nn.relu(%2) /* ty=Tensor[(1, 16, img_size, img_size), float16] */
     }

    #subgraphs[1]

     def @main(%data_n_0: Tensor[(1, 16, 8, 8), float16] /* ty=Tensor[(1, 16, 8, 8), float16] */) {
      %0 = nn.batch_flatten(%data_n_0) /* ty=Tensor[(1, 1024), float16] */;
      nn.dense(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 1024), float16] */, units=None) /* ty=Tensor[(1, 1), float16] */
     }

    """









.. GENERATED FROM PYTHON SOURCE LINES 117-119

Build the subgraph with cutlass target.
---------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 119-144

.. code-block:: default


    cutlass = tvm.target.Target(
        {
            "kind": "cutlass",
            "sm": int(tvm.target.Target("cuda").arch.split("_")[1]),
            "use_3xtf32": True,
            "split_k_slices": [1],
            "profile_all_alignments": False,
            "find_first_valid": True,
            "use_multiprocessing": True,
            "use_fast_math": False,
            "tmp_dir": "./tmp",
        },
        host=tvm.target.Target("llvm"),
    )


    def cutlass_build(mod, target, params=None, target_host=None, mod_name="default"):
        target = [target, cutlass]
        lib = relay.build_module.build(
            mod, target=target, params=params, target_host=target_host, mod_name=mod_name
        )
        return lib









.. GENERATED FROM PYTHON SOURCE LINES 145-148

Run the two subgraphs in pipeline with pipeline executor.
---------------------------------------------------------
Set 'USE_PIPELINE_EXECUTOR' as ON, and set USE_CUTLASS' as ON  in cmake.

.. GENERATED FROM PYTHON SOURCE LINES 148-150

.. code-block:: default

    from tvm.contrib import graph_executor, pipeline_executor, pipeline_executor_build








.. GENERATED FROM PYTHON SOURCE LINES 151-154

Create subgraph pipeline configuration.
Associate a subgraph module with a target.
Use CUTLASS BYOC to build the second subgraph module.

.. GENERATED FROM PYTHON SOURCE LINES 154-157

.. code-block:: default

    mod0, mod1 = subgraphs[0], subgraphs[1]
    # Use cutlass as the codegen.
    mod1 = partition_for_cutlass(mod1)







.. GENERATED FROM PYTHON SOURCE LINES 158-159

Get the pipeline executor configuration object.

.. GENERATED FROM PYTHON SOURCE LINES 159-160

.. code-block:: default

    pipe_config = pipeline_executor_build.PipelineConfig()







.. GENERATED FROM PYTHON SOURCE LINES 161-162

Set the compile target of the subgraph module.

.. GENERATED FROM PYTHON SOURCE LINES 162-164

.. code-block:: default

    pipe_config[mod0].target = "llvm"
    pipe_config[mod0].dev = tvm.cpu(0)







.. GENERATED FROM PYTHON SOURCE LINES 165-166

Set the compile target of the second subgraph module as cuda.

.. GENERATED FROM PYTHON SOURCE LINES 166-177

.. code-block:: default

    pipe_config[mod1].target = "cuda"
    pipe_config[mod1].dev = tvm.device("cuda", 0)
    pipe_config[mod1].build_func = cutlass_build
    pipe_config[mod1].export_cc = "nvcc"
    # Create the pipeline by connecting the subgraph modules.
    # The global input will be forwarded to the input interface of the first module named mod0
    pipe_config["input"]["data"].connect(pipe_config[mod0]["input"]["data"])
    # The first output of mod0 will be forwarded to the input interface of mod1
    pipe_config[mod0]["output"][0].connect(pipe_config[mod1]["input"]["data_n_0"])
    # The first output of mod1 will be the first global output.
    pipe_config[mod1]["output"][0].connect(pipe_config["output"][0])







.. GENERATED FROM PYTHON SOURCE LINES 178-179

The pipeline configuration as below.

.. GENERATED FROM PYTHON SOURCE LINES 179-191

.. code-block:: default

    """
    print(pipe_config)
     Inputs
      |data: mod0:data

     output
      |output(0) : mod1.output(0)

     connections
      |mod0.output(0)-> mod1.data_n_0
    """








.. GENERATED FROM PYTHON SOURCE LINES 197-199

Build the pipeline executor.
----------------------------

.. GENERATED FROM PYTHON SOURCE LINES 199-201

.. code-block:: default

    with tvm.transform.PassContext(opt_level=3):
        pipeline_mod_factory = pipeline_executor_build.build(pipe_config)







.. GENERATED FROM PYTHON SOURCE LINES 202-203

Export the parameter configuration to a file.

.. GENERATED FROM PYTHON SOURCE LINES 203-206

.. code-block:: default

    directory_path = tvm.contrib.utils.tempdir().temp_dir
    os.makedirs(directory_path, exist_ok=True)
    config_file_name = pipeline_mod_factory.export_library(directory_path)







.. GENERATED FROM PYTHON SOURCE LINES 207-209

Use the load function to create and initialize PipelineModule.
--------------------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 209-211

.. code-block:: default

    pipeline_module = pipeline_executor.PipelineModule.load_library(config_file_name)








.. GENERATED FROM PYTHON SOURCE LINES 212-215

Run the pipeline executor.
--------------------------
Allocate input data.

.. GENERATED FROM PYTHON SOURCE LINES 215-217

.. code-block:: default

    data = np.random.uniform(-1, 1, size=data_shape).astype("float16")
    pipeline_module.set_input("data", tvm.nd.array(data))







.. GENERATED FROM PYTHON SOURCE LINES 218-220

Run the two subgraph in the pipeline mode to get the output asynchronously
or synchronously. In the following example, it is synchronous.

.. GENERATED FROM PYTHON SOURCE LINES 220-222

.. code-block:: default

    pipeline_module.run()
    outputs = pipeline_module.get_output()







.. GENERATED FROM PYTHON SOURCE LINES 223-226

Use graph_executor for verification.
------------------------------------
Run these two subgraphs in sequence with graph_executor to get the output.

.. GENERATED FROM PYTHON SOURCE LINES 226-246

.. code-block:: default

    target = "llvm"
    dev0 = tvm.device(target, 0)
    lib0 = relay.build_module.build(mod0, target, params=params)
    module0 = runtime.GraphModule(lib0["default"](dev0))
    cuda = tvm.target.Target("cuda", host=tvm.target.Target("llvm"))
    lib1 = relay.build_module.build(mod1, [cuda, cutlass], params=params)
    lib1 = finalize_modules(lib1, "compile.so", "./tmp")

    dev1 = tvm.device("cuda", 0)

    module1 = runtime.GraphModule(lib1["default"](dev1))

    module0.set_input("data", data)
    module0.run()
    out_shape = (1, 16, img_size, img_size)
    out = module0.get_output(0, tvm.nd.empty(out_shape, "float16"))
    module1.set_input("data_n_0", out)
    module1.run()
    out_shape = (1, 1)
    out = module1.get_output(0, tvm.nd.empty(out_shape, "float16"))







.. GENERATED FROM PYTHON SOURCE LINES 247-248

Verify the result.

.. GENERATED FROM PYTHON SOURCE LINES 248-249

.. code-block:: default

    tvm.testing.assert_allclose(outputs[0].numpy(), out.numpy())








.. _sphx_glr_download_how_to_work_with_relay_using_pipeline_executor.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: using_pipeline_executor.py <using_pipeline_executor.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: using_pipeline_executor.ipynb <using_pipeline_executor.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
