

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Deploy the Pretrained Model on Android &mdash; tvm 0.7.dev1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tvm_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Compile Tensorflow Models" href="from_tensorflow.html" />
    <link rel="prev" title="Deploy a Framework-prequantized Model with TVM - Part 3 (TFLite)" href="deploy_prequantized_tflite.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.7.dev1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../relay_quick_start.html">Quick Start Tutorial for Compiling Deep Learning Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_expr_get_started.html">Get Started with Tensor Expression</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#compile-deep-learning-models">Compile Deep Learning Models</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="from_onnx.html">Compile ONNX Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_ssd_gluoncv.html">Deploy Single Shot Multibox Detector(SSD) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="using_external_lib.html">Using External Libraries in Relay</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_coreml.html">Compile CoreML Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_keras.html">Compile Keras Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_quantized.html">Deploy a Quantized Model on Cuda</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_caffe2.html">Compile Caffe2 Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_mxnet.html">Compile MXNet Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_model_on_rasp.html">Deploy the Pretrained Model on Raspberry Pi</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_pytorch.html">Compile PyTorch Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_prequantized.html">Deploy a Framework-prequantized Model with TVM</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_tflite.html">Compile TFLite Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_prequantized_tflite.html">Deploy a Framework-prequantized Model with TVM - Part 3 (TFLite)</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Deploy the Pretrained Model on Android</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#setup-environment">Setup Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="#start-rpc-tracker">Start RPC Tracker</a></li>
<li class="toctree-l4"><a class="reference internal" href="#register-android-device-to-rpc-tracker">Register Android device to RPC Tracker</a></li>
<li class="toctree-l4"><a class="reference internal" href="#load-pretrained-keras-model">Load pretrained keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#compile-the-model-with-relay">Compile the model with relay</a></li>
<li class="toctree-l4"><a class="reference internal" href="#deploy-the-model-remotely-by-rpc">Deploy the Model Remotely by RPC</a></li>
<li class="toctree-l4"><a class="reference internal" href="#execute-on-tvm">Execute on TVM</a></li>
<li class="toctree-l4"><a class="reference internal" href="#sample-output">Sample Output</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="from_tensorflow.html">Compile Tensorflow Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_darknet.html">Compile YOLO-V2 and YOLO-V3 in DarkNet Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="build_gcn.html">Building a Graph Convolutional Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_sparse.html">Deploy a Hugging Face Pruned Model on CPU</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#tensor-expression-and-schedules">Tensor Expression and Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#optimize-tensor-operators">Optimize Tensor Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#auto-tuning">Auto tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#developer-tutorials">Developer Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#topi-tvm-operator-inventory">TOPI: TVM Operator Inventory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#micro-tvm">Micro TVM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../vta/index.html">VTA: Deep Learning Accelerator Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy/index.html">Deploy and Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contribute to TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/links.html">Links to API References</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/index.html">Design and Developer Guide</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../frontend/tensorflow.html">TensorFlow Frontend</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">tvm</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Tutorials</a> &raquo;</li>
        
      <li>Deploy the Pretrained Model on Android</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/tutorials/frontend/deploy_model_on_android.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorials-frontend-deploy-model-on-android-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="deploy-the-pretrained-model-on-android">
<span id="tutorial-deploy-model-on-android"></span><span id="sphx-glr-tutorials-frontend-deploy-model-on-android-py"></span><h1>Deploy the Pretrained Model on Android<a class="headerlink" href="#deploy-the-pretrained-model-on-android" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://tkat0.github.io/">Tomohiro Kato</a></p>
<p>This is an example of using Relay to compile a keras model and deploy it on Android device.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="k">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras.applications.mobilenet_v2</span> <span class="k">import</span> <span class="n">MobileNetV2</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">te</span>
<span class="kn">import</span> <span class="nn">tvm.relay</span> <span class="k">as</span> <span class="nn">relay</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">rpc</span>
<span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="k">import</span> <span class="n">util</span><span class="p">,</span> <span class="n">ndk</span><span class="p">,</span> <span class="n">graph_runtime</span> <span class="k">as</span> <span class="n">runtime</span>
<span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="k">import</span> <span class="n">download_testdata</span>
</pre></div>
</div>
<div class="section" id="setup-environment">
<h2>Setup Environment<a class="headerlink" href="#setup-environment" title="Permalink to this headline">¶</a></h2>
<p>Since there are many required packages for Android, it is recommended to use the official Docker Image.</p>
<p>First, to build and run Docker Image, we can run the following command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre>git clone --recursive https://github.com/apache/incubator-tvm tvm
<span class="nb">cd</span> tvm
docker build -t tvm.demo_android -f docker/Dockerfile.demo_android ./docker
docker run --pid<span class="o">=</span>host -h tvm -v $PWD:/workspace <span class="se">\</span>
       -w /workspace -p 9190:9190 --name tvm -it tvm.demo_android bash
</pre></div>
</div>
<p>You are now inside the container. The cloned TVM directory is mounted on /workspace.
At this time, mount the 9190 port used by RPC described later.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please execute the following steps in the container.
We can execute <code class="code docutils literal notranslate"><span class="pre">docker</span> <span class="pre">exec</span> <span class="pre">-it</span> <span class="pre">tvm</span> <span class="pre">bash</span></code> to open a new terminal in the container.</p>
</div>
<p>Next we build the TVM.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre>mkdir build
<span class="nb">cd</span> build
cmake -DUSE_LLVM<span class="o">=</span>llvm-config-8 <span class="se">\</span>
      -DUSE_RPC<span class="o">=</span>ON <span class="se">\</span>
      -DUSE_SORT<span class="o">=</span>ON <span class="se">\</span>
      -DUSE_VULKAN<span class="o">=</span>ON <span class="se">\</span>
      -DUSE_GRAPH_RUNTIME<span class="o">=</span>ON <span class="se">\</span>
      ..
make -j10
</pre></div>
</div>
<p>After building TVM successfully, Please set PYTHONPATH.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span class="nb">echo</span> <span class="s1">&#39;export PYTHONPATH=/workspace/python:/workspace/topi/python:/workspace/vta/python:${PYTHONPATH}&#39;</span> &gt;&gt; ~/.bashrc
<span class="nb">source</span> ~/.bashrc
</pre></div>
</div>
</div>
<div class="section" id="start-rpc-tracker">
<h2>Start RPC Tracker<a class="headerlink" href="#start-rpc-tracker" title="Permalink to this headline">¶</a></h2>
<p>TVM uses RPC session to communicate with Android device.</p>
<p>To start an RPC tracker, run this command in the container. The tracker is
required during the whole tuning process, so we need to open a new terminal for
this command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre>python3 -m tvm.exec.rpc_tracker --host<span class="o">=</span>0.0.0.0 --port<span class="o">=</span>9190
</pre></div>
</div>
<p>The expected output is</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre>INFO:RPCTracker:bind to 0.0.0.0:9190
</pre></div>
</div>
</div>
<div class="section" id="register-android-device-to-rpc-tracker">
<h2>Register Android device to RPC Tracker<a class="headerlink" href="#register-android-device-to-rpc-tracker" title="Permalink to this headline">¶</a></h2>
<p>Now we can register our Android device to the tracker.</p>
<p>Follow this <a class="reference external" href="https://github.com/apache/incubator-tvm/tree/master/apps/android_rpc">readme page</a> to
install TVM RPC APK on the android device.</p>
<p>Here is an example of config.mk. I enabled OpenCL and Vulkan.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span class="nv">APP_ABI</span> <span class="o">=</span> arm64-v8a

<span class="nv">APP_PLATFORM</span> <span class="o">=</span> android-24

<span class="c1"># whether enable OpenCL during compile</span>
<span class="nv">USE_OPENCL</span> <span class="o">=</span> 1

<span class="c1"># whether to enable Vulkan during compile</span>
<span class="nv">USE_VULKAN</span> <span class="o">=</span> 1

ifeq <span class="o">(</span><span class="k">$(</span>USE_VULKAN<span class="k">)</span>, 1<span class="o">)</span>
  <span class="c1"># Statically linking vulkan requires API Level 24 or higher</span>
  <span class="nv">APP_PLATFORM</span> <span class="o">=</span> android-24
endif

<span class="c1"># the additional include headers you want to add, e.g., SDK_PATH/adrenosdk/Development/Inc</span>
ADD_C_INCLUDES +<span class="o">=</span> /work/adrenosdk-linux-5_0/Development/Inc
<span class="c1"># downloaded from https://github.com/KhronosGroup/OpenCL-Headers</span>
ADD_C_INCLUDES +<span class="o">=</span> /usr/local/OpenCL-Headers/

<span class="c1"># the additional link libs you want to add, e.g., ANDROID_LIB_PATH/libOpenCL.so</span>
<span class="nv">ADD_LDLIBS</span> <span class="o">=</span> /workspace/pull-from-android-device/libOpenCL.so
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>At this time, don’t forget to <a class="reference external" href="https://github.com/apache/incubator-tvm/tree/master/apps/android_rpc#architecture-and-android-standalone-toolchain">create a standalone toolchain</a> .</p>
<p>for example</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre>/opt/android-sdk-linux/ndk-bundle/build/tools/make-standalone-toolchain.sh <span class="se">\</span>
   --platform<span class="o">=</span>android-24 --use-llvm --arch<span class="o">=</span>arm64 --install-dir<span class="o">=</span>/opt/android-toolchain-arm64
<span class="nb">export</span> <span class="nv">TVM_NDK_CC</span><span class="o">=</span>/opt/android-toolchain-arm64/bin/aarch64-linux-android-g++
</pre></div>
</div>
</div>
<p>Next, start the Android application and enter the IP address and port of RPC Tracker.
Then you have already registered your device.</p>
<p>After registering devices, we can confirm it by querying rpc_tracker</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre>python3 -m tvm.exec.query_rpc_tracker --host<span class="o">=</span>0.0.0.0 --port<span class="o">=</span>9190
</pre></div>
</div>
<p>For example, if we have 1 Android device.
the output can be</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre>Queue Status
----------------------------------
key          total  free  pending
----------------------------------
android      <span class="m">1</span>      <span class="m">1</span>     0
----------------------------------
</pre></div>
</div>
<p>To confirm that you can communicate with Android, we can run following test script.
If you use OpenCL and Vulkan, please set <code class="code docutils literal notranslate"><span class="pre">test_opencl</span></code> and <code class="code docutils literal notranslate"><span class="pre">test_vulkan</span></code> in the script.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span class="nb">export</span> <span class="nv">TVM_TRACKER_HOST</span><span class="o">=</span>0.0.0.0
<span class="nb">export</span> <span class="nv">TVM_TRACKER_PORT</span><span class="o">=</span>9190
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span class="nb">cd</span> /workspace/apps/android_rpc
python3 tests/android_rpc_test.py
</pre></div>
</div>
</div>
<div class="section" id="load-pretrained-keras-model">
<h2>Load pretrained keras model<a class="headerlink" href="#load-pretrained-keras-model" title="Permalink to this headline">¶</a></h2>
<p>We load a pretrained MobileNetV2(alpha=0.5) classification model provided by keras.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>  <span class="c1"># Destroys the current TF graph and creates a new one.</span>
<span class="n">weights_url</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;https://github.com/JonathanCMitchell/&#39;</span><span class="p">,</span>
                       <span class="s1">&#39;mobilenet_v2_keras/releases/download/v1.1/&#39;</span><span class="p">,</span>
                       <span class="s1">&#39;mobilenet_v2_weights_tf_dim_ordering_tf_kernels_0.5_224.h5&#39;</span><span class="p">])</span>
<span class="n">weights_file</span> <span class="o">=</span> <span class="s1">&#39;mobilenet_v2_weights.h5&#39;</span>
<span class="n">weights_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">weights_url</span><span class="p">,</span> <span class="n">weights_file</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s1">&#39;keras&#39;</span><span class="p">)</span>
<span class="n">keras_mobilenet_v2</span> <span class="o">=</span> <span class="n">MobileNetV2</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">keras_mobilenet_v2</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">weights_path</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre>File /workspace/.tvm_test_data/keras/mobilenet_v2_weights.h5 exists, skip.
</pre></div>
</div>
<p>In order to test our model, here we download an image of cat and
transform its format.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">img_url</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/dmlc/mxnet.js/blob/master/data/cat.png?raw=true&#39;</span>
<span class="n">img_name</span> <span class="o">=</span> <span class="s1">&#39;cat.png&#39;</span>
<span class="n">img_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">img_url</span><span class="p">,</span> <span class="n">img_name</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="s1">&#39;float32&#39;</span>

<span class="k">def</span> <span class="nf">transform_image</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="View documentation for numpy.array"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="o">-</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="View documentation for numpy.array"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="mf">123.</span><span class="p">,</span> <span class="mf">117.</span><span class="p">,</span> <span class="mf">104.</span><span class="p">])</span>
    <span class="n">image</span> <span class="o">/=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="View documentation for numpy.array"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="mf">58.395</span><span class="p">,</span> <span class="mf">57.12</span><span class="p">,</span> <span class="mf">57.375</span><span class="p">])</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis" title="View documentation for numpy.newaxis"><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span></a><span class="p">,</span> <span class="p">:]</span>
    <span class="k">return</span> <span class="n">image</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">transform_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre>File /workspace/.tvm_test_data/data/cat.png exists, skip.
</pre></div>
</div>
<p>synset is used to transform the label from number of ImageNet class to
the word human can understand.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">synset_url</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;https://gist.githubusercontent.com/zhreshold/&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;4d0b62f3d01426887599d4f7ede23ee5/raw/&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;596b27d23537e5a1b5751d2b0481ef172f58b539/&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;imagenet1000_clsid_to_human.txt&#39;</span><span class="p">])</span>
<span class="n">synset_name</span> <span class="o">=</span> <span class="s1">&#39;imagenet1000_clsid_to_human.txt&#39;</span>
<span class="n">synset_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">synset_url</span><span class="p">,</span> <span class="n">synset_name</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">synset_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">synset</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre>File /workspace/.tvm_test_data/data/imagenet1000_clsid_to_human.txt exists, skip.
</pre></div>
</div>
</div>
<div class="section" id="compile-the-model-with-relay">
<h2>Compile the model with relay<a class="headerlink" href="#compile-the-model-with-relay" title="Permalink to this headline">¶</a></h2>
<p>If we run the example on our x86 server for demonstration, we can simply
set it as <code class="code docutils literal notranslate"><span class="pre">llvm</span></code>. If running it on the Android device, we need to
specify its instruction set. Set <code class="code docutils literal notranslate"><span class="pre">local_demo</span></code> to False if you want
to run this tutorial with a real device.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">local_demo</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># by default on CPU target will execute.</span>
<span class="c1"># select &#39;cpu&#39;, &#39;opencl&#39; and &#39;vulkan&#39;</span>
<span class="n">test_target</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span>

<span class="c1"># Change target configuration.</span>
<span class="c1"># Run `adb shell cat /proc/cpuinfo` to find the arch.</span>
<span class="n">arch</span> <span class="o">=</span> <span class="s1">&#39;arm64&#39;</span>
<span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;llvm -target=</span><span class="si">%s</span><span class="s1">-linux-android&#39;</span> <span class="o">%</span> <span class="n">arch</span>
<span class="n">target_host</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">if</span> <span class="n">local_demo</span><span class="p">:</span>
    <span class="n">target_host</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;llvm&#39;</span>
<span class="k">elif</span> <span class="n">test_target</span> <span class="o">==</span> <span class="s1">&#39;opencl&#39;</span><span class="p">:</span>
    <span class="n">target_host</span> <span class="o">=</span> <span class="n">target</span>
    <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;opencl&#39;</span>
<span class="k">elif</span> <span class="n">test_target</span> <span class="o">==</span> <span class="s1">&#39;vulkan&#39;</span><span class="p">:</span>
    <span class="n">target_host</span> <span class="o">=</span> <span class="n">target</span>
    <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;vulkan&#39;</span>

<span class="n">input_name</span> <span class="o">=</span> <span class="s1">&#39;input_1&#39;</span>
<span class="n">shape_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">}</span>
<span class="n">mod</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <a href="../../api/python/relay/frontend.html#tvm.relay.frontend.from_keras" title="View documentation for tvm.relay.frontend.from_keras"><span class="n">relay</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">from_keras</span></a><span class="p">(</span><span class="n">keras_mobilenet_v2</span><span class="p">,</span> <span class="n">shape_dict</span><span class="p">)</span>

<span class="k">with</span> <a href="../../api/python/ir.html#tvm.transform.PassContext" title="View documentation for tvm.transform.PassContext"><span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span></a><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">graph</span><span class="p">,</span> <span class="n">lib</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.build" title="View documentation for tvm.relay.build"><span class="n">relay</span><span class="o">.</span><span class="n">build</span></a><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
                                     <span class="n">target_host</span><span class="o">=</span><span class="n">target_host</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="c1"># After `relay.build`, you will get three return values: graph,</span>
<span class="c1"># library and the new parameter, since we do some optimization that will</span>
<span class="c1"># change the parameters but keep the result of model as the same.</span>

<span class="c1"># Save the library at local temporary directory.</span>
<span class="n">tmp</span> <span class="o">=</span> <a href="../../api/python/contrib.html#tvm.contrib.util.tempdir" title="View documentation for tvm.contrib.util.tempdir"><span class="n">util</span><span class="o">.</span><span class="n">tempdir</span></a><span class="p">()</span>
<span class="n">lib_fname</span> <span class="o">=</span> <span class="n">tmp</span><span class="o">.</span><span class="n">relpath</span><span class="p">(</span><span class="s1">&#39;net.so&#39;</span><span class="p">)</span>
<span class="n">fcompile</span> <span class="o">=</span> <a href="../../api/python/contrib.html#tvm.contrib.ndk.create_shared" title="View documentation for tvm.contrib.ndk.create_shared"><span class="n">ndk</span><span class="o">.</span><span class="n">create_shared</span></a> <span class="k">if</span> <span class="ow">not</span> <span class="n">local_demo</span> <span class="k">else</span> <span class="kc">None</span>
<span class="n">lib</span><span class="o">.</span><span class="n">export_library</span><span class="p">(</span><span class="n">lib_fname</span><span class="p">,</span> <span class="n">fcompile</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="deploy-the-model-remotely-by-rpc">
<h2>Deploy the Model Remotely by RPC<a class="headerlink" href="#deploy-the-model-remotely-by-rpc" title="Permalink to this headline">¶</a></h2>
<p>With RPC, you can deploy the model remotely from your host machine
to the remote android device.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">tracker_host</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;TVM_TRACKER_HOST&#39;</span><span class="p">,</span> <span class="s1">&#39;0.0.0.0&#39;</span><span class="p">)</span>
<span class="n">tracker_port</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;TVM_TRACKER_PORT&#39;</span><span class="p">,</span> <span class="mi">9190</span><span class="p">))</span>
<span class="n">key</span> <span class="o">=</span> <span class="s1">&#39;android&#39;</span>

<span class="k">if</span> <span class="n">local_demo</span><span class="p">:</span>
    <span class="n">remote</span> <span class="o">=</span> <a href="../../api/python/rpc.html#tvm.rpc.LocalSession" title="View documentation for tvm.rpc.LocalSession"><span class="n">rpc</span><span class="o">.</span><span class="n">LocalSession</span></a><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">tracker</span> <span class="o">=</span> <a href="../../api/python/rpc.html#tvm.rpc.connect_tracker" title="View documentation for tvm.rpc.connect_tracker"><span class="n">rpc</span><span class="o">.</span><span class="n">connect_tracker</span></a><span class="p">(</span><span class="n">tracker_host</span><span class="p">,</span> <span class="n">tracker_port</span><span class="p">)</span>
    <span class="c1"># When running a heavy model, we should increase the `session_timeout`</span>
    <span class="n">remote</span> <span class="o">=</span> <span class="n">tracker</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">priority</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                             <span class="n">session_timeout</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="k">if</span> <span class="n">local_demo</span><span class="p">:</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">remote</span><span class="o">.</span><span class="n">cpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">test_target</span> <span class="o">==</span> <span class="s1">&#39;opencl&#39;</span><span class="p">:</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">remote</span><span class="o">.</span><span class="n">cl</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">test_target</span> <span class="o">==</span> <span class="s1">&#39;vulkan&#39;</span><span class="p">:</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">remote</span><span class="o">.</span><span class="n">vulkan</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">remote</span><span class="o">.</span><span class="n">cpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># upload the library to remote device and load it</span>
<span class="n">remote</span><span class="o">.</span><span class="n">upload</span><span class="p">(</span><span class="n">lib_fname</span><span class="p">)</span>
<span class="n">rlib</span> <span class="o">=</span> <span class="n">remote</span><span class="o">.</span><span class="n">load_module</span><span class="p">(</span><span class="s1">&#39;net.so&#39;</span><span class="p">)</span>

<span class="c1"># create the remote runtime module</span>
<span class="n">module</span> <span class="o">=</span> <a href="../../api/python/graph_runtime.html#tvm.contrib.graph_runtime.create" title="View documentation for tvm.contrib.graph_runtime.create"><span class="n">runtime</span><span class="o">.</span><span class="n">create</span></a><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">rlib</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="execute-on-tvm">
<h2>Execute on TVM<a class="headerlink" href="#execute-on-tvm" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="c1"># set parameter (upload params to the remote device. This may take a while)</span>
<span class="n">module</span><span class="o">.</span><span class="n">set_input</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
<span class="c1"># set input data</span>
<span class="n">module</span><span class="o">.</span><span class="n">set_input</span><span class="p">(</span><span class="n">input_name</span><span class="p">,</span> <a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)))</span>
<span class="c1"># run</span>
<span class="n">module</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="c1"># get output</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">get_output</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># get top1 result</span>
<span class="n">top1</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.argmax.html#numpy.argmax" title="View documentation for numpy.argmax"><span class="n">np</span><span class="o">.</span><span class="n">argmax</span></a><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TVM prediction top-1: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">synset</span><span class="p">[</span><span class="n">top1</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Evaluate inference time cost...&#39;</span><span class="p">)</span>
<span class="n">ftimer</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">time_evaluator</span><span class="p">(</span><span class="s1">&#39;run&#39;</span><span class="p">,</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">prof_res</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="View documentation for numpy.array"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">ftimer</span><span class="p">()</span><span class="o">.</span><span class="n">results</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>  <span class="c1"># convert to millisecond</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean inference time (std dev): </span><span class="si">%.2f</span><span class="s1"> ms (</span><span class="si">%.2f</span><span class="s1"> ms)&#39;</span> <span class="o">%</span> <span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.mean.html#numpy.mean" title="View documentation for numpy.mean"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a><span class="p">(</span><span class="n">prof_res</span><span class="p">),</span>
                                                            <a href="https://numpy.org/doc/stable/reference/generated/numpy.std.html#numpy.std" title="View documentation for numpy.std"><span class="n">np</span><span class="o">.</span><span class="n">std</span></a><span class="p">(</span><span class="n">prof_res</span><span class="p">)))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre>TVM prediction top-1: tiger cat
Evaluate inference time cost...
Mean inference time (std dev): 4.31 ms (0.46 ms)
</pre></div>
</div>
</div>
<div class="section" id="sample-output">
<h2>Sample Output<a class="headerlink" href="#sample-output" title="Permalink to this headline">¶</a></h2>
<p>The following is the result of ‘cpu’, ‘opencl’ and ‘vulkan’ using Adreno 530 on Snapdragon 820</p>
<p>Although we can run on a GPU, it is slower than CPU.
To speed up, we need to write and optimize the schedule according to the GPU architecture.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span class="c1"># cpu</span>
TVM prediction top-1: tiger cat
Evaluate inference <span class="nb">time</span> cost...
Mean inference <span class="nb">time</span> <span class="o">(</span>std dev<span class="o">)</span>: 37.92 ms <span class="o">(</span>19.67 ms<span class="o">)</span>

<span class="c1"># opencl</span>
TVM prediction top-1: tiger cat
Evaluate inference <span class="nb">time</span> cost...
Mean inference <span class="nb">time</span> <span class="o">(</span>std dev<span class="o">)</span>: 419.83 ms <span class="o">(</span>7.49 ms<span class="o">)</span>

<span class="c1"># vulkan</span>
TVM prediction top-1: tiger cat
Evaluate inference <span class="nb">time</span> cost...
Mean inference <span class="nb">time</span> <span class="o">(</span>std dev<span class="o">)</span>: 465.80 ms <span class="o">(</span>4.52 ms<span class="o">)</span>
</pre></div>
</div>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-frontend-deploy-model-on-android-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/3961fdfa7abff1b6dc996faa43b4c40f/deploy_model_on_android.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">deploy_model_on_android.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/38606228ff7130fbd6473b7c0625ddcd/deploy_model_on_android.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">deploy_model_on_android.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="from_tensorflow.html" class="btn btn-neutral float-right" title="Compile Tensorflow Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="deploy_prequantized_tflite.html" class="btn btn-neutral float-left" title="Deploy a Framework-prequantized Model with TVM - Part 3 (TFLite)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Apache Software Foundation

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>