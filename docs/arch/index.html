



<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Design and Architecture &mdash; tvm 0.22.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/downloads/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/tlcpack_theme.css" type="text/css" />

  
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=feaa0556"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="TVM Runtime System" href="runtime.html" />
    <link rel="prev" title="Handle TVM Errors" href="../errors.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://tvm.apache.org/docs/reference/security.html>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://tvm.apache.org/docs/reference/security.html>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="sidetitle" alt="Documentation Home"> tvm
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../get_started/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Installing TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/tutorials/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/tutorials/ir_module.html">IRModule</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">How To</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../how_to/tutorials/e2e_opt_model.html">End-to-End Optimize Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how_to/tutorials/customize_opt.html">Customize Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how_to/tutorials/optimize_llm.html">Optimize Large Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how_to/tutorials/cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how_to/dev/index.html">Development Guides</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Dive</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Design and Architecture</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overall-flow">Overall Flow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#key-data-structures">Key data structures</a></li>
<li class="toctree-l3"><a class="reference internal" href="#transformations">Transformations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#relax-transformations">relax transformations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tir-transformations">tir transformations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cross-level-transformations">cross-level transformations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#target-translation">Target Translation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#runtime-execution">Runtime Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="#summary-and-discussions">Summary and Discussions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tvm-support">tvm/support</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tvm-runtime">tvm/runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="runtime.html">TVM Runtime System</a></li>
<li class="toctree-l3"><a class="reference internal" href="runtime.html#runtime-specific-information">Runtime-Specific Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="introduction_to_module_serialization.html">Introduction to Module Serialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="device_target_interactions.html">Device/Target Interactions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tvm-node">tvm/node</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tvm-ir">tvm/ir</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pass_infra.html">Pass Infrastructure</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tvm-target">tvm/target</a><ul>
<li class="toctree-l3"><a class="reference internal" href="device_target_interactions.html">Device/Target Interactions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tvm-relax">tvm/relax</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tvm-tir">tvm/tir</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tvm-arith">tvm/arith</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tvm-te-and-tvm-topi">tvm/te and tvm/topi</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tvm-meta-schedule">tvm/meta_schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tvm-dlight">tvm/dlight</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../deep_dive/tensor_ir/index.html">TensorIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_dive/relax/index.html">Relax</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/api/links.html">Other APIs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contribute/index.html">Contributor Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/security.html">Security Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Index</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> <span class="br-arrow">></span></li>
        
      <li>Design and Architecture</li>
    
    
      
      
        
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/tvm/edit/main/docs/arch/index.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="design-and-architecture">
<h1>Design and Architecture<a class="headerlink" href="#design-and-architecture" title="Link to this heading"></a></h1>
<p>This document is intended for developers who want to understand the architecture of Apache TVM and/or actively develop on the project.
This page is organized as follows:</p>
<ul class="simple">
<li><p>The <a class="reference internal" href="#overall-flow">Overall Flow</a> gives an overview of the steps that TVM takes to turn a high level description of a model into a deployable module.
To get started, please read this section first.</p></li>
<li><p>Brief introduction to the key components of the TVM stack. Feel free to also check out the <a class="reference internal" href="../deep_dive/tensor_ir/index.html#tensor-ir-deep-dive"><span class="std std-ref">TensorIR Deep Dive</span></a>
and <a class="reference internal" href="../deep_dive/relax/index.html#relax-deep-dive"><span class="std std-ref">Relax Deep Dive</span></a> for more details about the two major components in the TVM stack.</p></li>
</ul>
<p>This guide provides a few complementary views of the architecture.
First, we review a single end-to-end compilation flow and discuss the key data structures and the transformations.
This runtime-based view focuses on the interactions of each components when running the compiler.
Then we will review the logical modules of the codebase and their relationship. This part provides a static overarching view of the design.</p>
<section id="overall-flow">
<h2>Overall Flow<a class="headerlink" href="#overall-flow" title="Link to this heading"></a></h2>
<p>In this guide, we will study an example compilation flow in the compiler. The figure below shows the flow. At a high-level, it contains several steps:</p>
<ul class="simple">
<li><p><strong>Model Creation</strong>: Create the IRModule to be optimized and compiled, which contains a collection of functions that internally represent the model.
Users can manually construct IRModule via NNModule, TVMScript, or import a pre-trained model from Relax frontend.</p></li>
<li><p><strong>Transformation</strong>: The compiler transforms an IRModule to another functionally equivalent or approximately
equivalent(e.g. in the case of quantization) IRModule. Many of the transformations are target (backend) independent.
We also allow target to affect the configuration of the transformation pipeline.</p></li>
<li><p><strong>Target Translation</strong>: The compiler translates(codegen) the IRModule to an executable format specified by the target.
The target translation result is encapsulated as a <cite>runtime.Module</cite> that can be exported, loaded, and executed on the target runtime environment.</p></li>
<li><p><strong>Runtime Execution</strong>: the user loads back a <cite>runtime.Module</cite> and runs the compiled functions in the supported runtime environment.</p></li>
</ul>
<figure class="align-center">
<a class="reference internal image-reference" href="../_static/downloads/tvm_overall_flow.svg"><img alt="../_static/downloads/tvm_overall_flow.svg" src="../_static/downloads/tvm_overall_flow.svg" style="width: 80%;" />
</a>
</figure>
<section id="key-data-structures">
<h3>Key data structures<a class="headerlink" href="#key-data-structures" title="Link to this heading"></a></h3>
<p>One of the best ways to design and understand a complex system is to identify the key data structures and APIs that
manipulate (transform) these data structures. Once we identified the key data structures, we can then breakdown a system into logical
components that either define a collection of key data structures or transformations among the data structures.</p>
<p><strong>IRModule</strong> is the primary data structure used across the entire stack. An IRModule (intermediate representation module)
contains a collection of functions. Currently, we support two primary variants of functions.</p>
<ul class="simple">
<li><p><strong>relax::Function</strong> is a high-level functional program representation. A relax.Function represents high-level graph structure,
usually corresponds to an end-to-end model or a sub-graph of the overall model. You can view a relax.Function as a computational
graph with additional support for control-flow, and complex data structures.</p></li>
<li><p><strong>tir::PrimFunc</strong> is a low-level program representation that contains elements including loop-nest choices, multi-dimensional load/store,
threading, and vector/tensor instructions. It is usually used to represent an operator program that executes a (possibly-fused) layer in a model.</p></li>
</ul>
<p>During the compilation and transformation, all relax operators are lowered to <code class="docutils literal notranslate"><span class="pre">tir::PrimFunc</span></code> or <code class="docutils literal notranslate"><span class="pre">TVM</span> <span class="pre">PackedFunc</span></code>, which can be executed directly
on the target device, while the calls to relax operators are lowered to calls to low-level functions (e.g. <code class="docutils literal notranslate"><span class="pre">R.call_tir</span></code> or <code class="docutils literal notranslate"><span class="pre">R.call_dps</span></code>).</p>
</section>
<section id="transformations">
<h3>Transformations<a class="headerlink" href="#transformations" title="Link to this heading"></a></h3>
<p>Now that we have covered the key data structures, let us talk about the transformations. Each transformation could serve one of the following purposes:</p>
<ul class="simple">
<li><p>optimization: transform a program to an equivalent, possibly more optimized version.</p></li>
<li><p>lowering: transform a program to a lower-level representation that is closer to the target.</p></li>
</ul>
<section id="relax-transformations">
<h4>relax transformations<a class="headerlink" href="#relax-transformations" title="Link to this heading"></a></h4>
<p>relax transformations contain a collection of passes that apply to relax functions. The optimizations include common graph-level
optimizations such as constant folding and dead-code elimination for operators, and backend-specific optimizations such as library dispatch.</p>
</section>
<section id="tir-transformations">
<h4>tir transformations<a class="headerlink" href="#tir-transformations" title="Link to this heading"></a></h4>
<p>tir transformations contain a collection of passes that apply to tir functions. There are two major types of transformations:</p>
<ul class="simple">
<li><p><strong>TensorIR schedule</strong>: TensorIR schedules are designed to optimize the TensorIR functions for a specific target, with user-guided instructions and control how the target code is generated.
For CPU targets, TIR PrimFunc can generate valid code and execute on the target device without schedule but with very-low performance. However, for GPU targets, the schedule is essential
for generating valid code with thread bindings. For more details, please refer to the <a class="reference internal" href="../deep_dive/tensor_ir/tutorials/tir_transformation.html#tir-transform"><span class="std std-ref">TensorIR Transformation</span></a> section. Additionally, we provides <code class="docutils literal notranslate"><span class="pre">MetaSchedule</span></code> to
automate the search of TensorIR schedule.</p></li>
<li><p><strong>Lowering Passes</strong>: These passes usually perform after the schedule is applied, transforming a TIR PrimFunc into another functionally equivalent PrimFunc, but closer to the
target-specific representation. For example, there are passes to flatten multi-dimensional access to one-dimensional pointer access, to expand the intrinsics into target-specific ones,
and to decorate the function entry to meet the runtime calling convention.</p></li>
</ul>
<dl class="simple">
<dt>Many low-level optimizations can be handled in the target phase by the LLVM, CUDA C, and other target compilers. As a result, we leave low-level optimizations such as register allocation</dt><dd><p>to the downstream compilers and only focus on optimizations that are not covered by them.</p>
</dd>
</dl>
</section>
<section id="cross-level-transformations">
<h4>cross-level transformations<a class="headerlink" href="#cross-level-transformations" title="Link to this heading"></a></h4>
<p>Apache TVM brings a unity strategy to optimize the end-to-end models. As the IRModule includes both relax and tir functions, the cross-level transformations are designed to mutate
the IRModule by applying different transformations to these two types of functions.</p>
<p>For example, <code class="docutils literal notranslate"><span class="pre">relax.LegalizeOps</span></code> pass mutates the IRModule by lowering relax operators, adding corresponding TIR PrimFunc into the IRModule, and replacing the relax operators
with calls to the lowered TIR PrimFunc. Another example is operator fusion pipeline in relax (including <code class="docutils literal notranslate"><span class="pre">relax.FuseOps</span></code> and <code class="docutils literal notranslate"><span class="pre">relax.FuseTIR</span></code>), which fuses multiple consecutive tensor operations
into one. Different from the previous implementations, relax fusion pipeline analyzes the pattern of TIR functions and detects the best fusion rules automatically rather
than human-defined operator fusion patterns.</p>
</section>
</section>
<section id="target-translation">
<h3>Target Translation<a class="headerlink" href="#target-translation" title="Link to this heading"></a></h3>
<p>The target translation phase transforms an IRModule to the corresponding target executable format.
For backends such as x86 and ARM, we use the LLVM IRBuilder to build in-memory LLVM IR.
We can also generate source-level languages such as CUDA C and OpenCL.
Finally, we support direct translations of a Relax function (sub-graph) to specific targets via external code generators.
It is important that the final code generation phase is as lightweight as possible. Vast majority of transformations
and lowering should be performed before the target translation phase.</p>
<p>We also provide a Target structure to specify the compilation target.
The transformations before the target translation phase can also be affected by the target — for example,
a target’s vector length would change the vectorization behavior.</p>
</section>
<section id="runtime-execution">
<h3>Runtime Execution<a class="headerlink" href="#runtime-execution" title="Link to this heading"></a></h3>
<p>The main goal of TVM’s runtime is to provide a minimal API for loading and executing the compiled artifact in a language of their choice, including Python, C++, Rust, Go, Java, and JavaScript. The code snippet below shows such an example in Python:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tvm</span>
<span class="c1"># Example runtime execution program in python, with type annotated</span>
<span class="n">mod</span><span class="p">:</span> <span class="n">tvm</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">load_module</span><span class="p">(</span><span class="s2">&quot;compiled_artifact.so&quot;</span><span class="p">)</span>
<span class="n">arr</span><span class="p">:</span> <span class="n">tvm</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">NDArray</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">tvm</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="n">fun</span><span class="p">:</span> <span class="n">tvm</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">PackedFunc</span> <span class="o">=</span> <span class="n">mod</span><span class="p">[</span><span class="s2">&quot;addone&quot;</span><span class="p">]</span>
<span class="n">fun</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.runtime.Module</span></code> encapsulates the result of compilation. A runtime.Module contains a GetFunction method to obtain PackedFuncs by name.</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.runtime.PackedFunc</span></code> is a type-erased function interface for both the generated functions. A runtime.PackedFunc can take arguments and return values with the
following types: POD types(int, float), string, runtime.PackedFunc, runtime.Module, runtime.NDArray, and other sub-classes of runtime.Object.</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.runtime.Module</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.runtime.PackedFunc</span></code> are powerful mechanisms to modularize the runtime. For example, to get the above <cite>addone</cite> function on CUDA, we can use LLVM to generate the host-side code to compute the launching parameters(e.g. size of the thread groups) and then call into another PackedFunc from a CUDAModule that is backed by the CUDA driver API. The same mechanism can be used for OpenCL kernels.</p>
<p>The above example only deals with a simple <cite>addone</cite> function. The code snippet below gives an example of an end-to-end model execution using the same interface:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tvm</span>
<span class="c1"># Example runtime execution program in python, with types annotated</span>
<span class="n">factory</span><span class="p">:</span> <span class="n">tvm</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">load_module</span><span class="p">(</span><span class="s2">&quot;resnet18.so&quot;</span><span class="p">)</span>
<span class="c1"># Create a stateful graph execution module for resnet18 on cuda(0)</span>
<span class="n">gmod</span><span class="p">:</span> <span class="n">tvm</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">factory</span><span class="p">[</span><span class="s2">&quot;resnet18&quot;</span><span class="p">](</span><span class="n">tvm</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="n">data</span><span class="p">:</span> <span class="n">tvm</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">NDArray</span> <span class="o">=</span> <span class="n">get_input_data</span><span class="p">()</span>
<span class="c1"># set input</span>
<span class="n">gmod</span><span class="p">[</span><span class="s2">&quot;set_input&quot;</span><span class="p">](</span><span class="mi">0</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="c1"># execute the model</span>
<span class="n">gmod</span><span class="p">[</span><span class="s2">&quot;run&quot;</span><span class="p">]()</span>
<span class="c1"># get the output</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">gmod</span><span class="p">[</span><span class="s2">&quot;get_output&quot;</span><span class="p">](</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
<p>The main take away is that runtime.Module and runtime.PackedFunc are sufficient to encapsulate both operator level programs (such as addone), as well as the end-to-end models.</p>
</section>
<section id="summary-and-discussions">
<h3>Summary and Discussions<a class="headerlink" href="#summary-and-discussions" title="Link to this heading"></a></h3>
<p>In summary, the key data structures in the compilation flows are:</p>
<ul class="simple">
<li><p>IRModule: contains relax.Function and tir.PrimFunc</p></li>
<li><p>runtime.Module: contains runtime.PackedFunc</p></li>
</ul>
<p>Most parts of the compilation are transformations among the key data structures.</p>
<ul class="simple">
<li><p>relax/transform and tir/transform are deterministic rule-based transformations</p></li>
<li><p>meta-schedule contains the search-based transformations</p></li>
</ul>
<p>Finally, the compilation flow example is only a typical use-case of the TVM stack.
We expose these key data structures and transformations to python and C++ APIs. As a result, you can use TVM just like the way you use numpy,
except that the data structure of interest changes from the numpy.ndarray to tvm.IRModule. Here are some example use-cases:</p>
<ul class="simple">
<li><p>Directly construct IRModule using the python API.</p></li>
<li><p>Compose a custom set of transformations(e.g. customize quantization).</p></li>
<li><p>Manipulate the IR directly using TVM’s python API.</p></li>
</ul>
</section>
</section>
<section id="tvm-support">
<h2>tvm/support<a class="headerlink" href="#tvm-support" title="Link to this heading"></a></h2>
<p>The support module contains the most common utilities for the infrastructure, such as generic arena allocator, socket, and logging.</p>
</section>
<section id="tvm-runtime">
<h2>tvm/runtime<a class="headerlink" href="#tvm-runtime" title="Link to this heading"></a></h2>
<p>The runtime serves as the foundation of the TVM stack. It provides the mechanism to load and execute compiled artifacts.
The runtime defines a stable standard set of C APIs to interface with frontend languages such as Python and Rust.</p>
<p><cite>runtime::Object</cite> is one of the primary data structures in TVM runtime besides the <cite>ffi::Function</cite>.
It is a reference-counted base class with a type index to support runtime type checking and downcasting.
The object system allows the developer to introduce new data structures to the runtime, such as Array, Map, and new IR data structures.</p>
<p>Besides deployment use-cases, the compiler itself also makes heavy use of TVM’s runtime mechanism.
All of the IR data structures are subclasses of <cite>runtime::Object</cite>, as a result, they can be directly accessed and manipulated from the Python frontend.
We use the PackedFunc mechanism to expose various APIs to the frontend.</p>
<p>Runtime support for different hardware backends are defined in subdirectories of runtime(e.g. runtime/opencl).
These hardware-specific runtime modules define APIs for device memory allocation and device function serialization.</p>
<p><cite>runtime/rpc</cite> implements an RPC support for PackedFunc. We can use the RPC mechanism to send a cross-compiled library to a remote
device and benchmark the execution performance. The rpc infrastructure enables data collection from a wide range of hardware backends
for learning-based optimizations.</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">TVM Runtime System</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html#runtime-specific-information">Runtime-Specific Information</a></li>
</ul>
</div>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="introduction_to_module_serialization.html">Introduction to Module Serialization</a></li>
<li class="toctree-l1"><a class="reference internal" href="device_target_interactions.html">Device/Target Interactions</a></li>
</ul>
</div>
</section>
<section id="tvm-node">
<h2>tvm/node<a class="headerlink" href="#tvm-node" title="Link to this heading"></a></h2>
<p>The node module adds additional features on top of the <cite>runtime::Object</cite> for IR data structures.
The main features include reflection, serialization, structural equivalence, and hashing.</p>
<p>Thanks to the node module, we can directly access any field of the TVM’s IRNode by their name in Python.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">tir</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;int32&quot;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">tir</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="c1"># a and b are fields of a tir.Add node</span>
<span class="c1"># we can directly use the field name to access the IR structures</span>
<span class="k">assert</span> <span class="n">y</span><span class="o">.</span><span class="n">a</span> <span class="o">==</span> <span class="n">x</span>
</pre></div>
</div>
<p>We can also serialize arbitrary IR node into a JSON format, and load them back.
The ability to save/store, and inspect an IR node provides a foundation for making the compiler more accessible.</p>
</section>
<section id="tvm-ir">
<h2>tvm/ir<a class="headerlink" href="#tvm-ir" title="Link to this heading"></a></h2>
<p>The <cite>tvm/ir</cite> folder contains the unified data structure and interfaces across all IR function variants.
The components in <cite>tvm/ir</cite> are shared by <cite>tvm/relax</cite> and <cite>tvm/tir</cite>, notable ones include</p>
<ul class="simple">
<li><p>IRModule</p></li>
<li><p>Type</p></li>
<li><p>PassContext and Pass</p></li>
<li><p>Op</p></li>
</ul>
<p>Different variants of functions(e.g. relax.Function and tir.PrimFunc) can co-exist in an IRModule.
While these variants may not have the same content representation, they use the same data structure to represent types.
As a consequence, we use the same data structure to represent function (type) signatures of these variants.
The unified type system allows one function variant to call another function
once we clearly define the calling convention. This opens doors for future cross-function-variant optimizations.</p>
<p>We also provide a unified PassContext for configuring the pass behavior, and common composite passes to execute a pass pipeline.
The following code snippet gives an example of PassContext configuration.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># configure the behavior of the tir.UnrollLoop pass</span>
<span class="k">with</span> <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;tir.UnrollLoop&quot;</span><span class="p">:</span> <span class="p">{</span> <span class="s2">&quot;auto_max_step&quot;</span><span class="p">:</span> <span class="mi">10</span> <span class="p">}}):</span>
    <span class="c1"># code affected by the pass context</span>
</pre></div>
</div>
<p>Op is the common class to represent all system-defined primitive operator/intrinsics.
Developers can register new Ops as well as their additional attributes(e.g. whether the Op is elementwise) to the system.</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="pass_infra.html">Pass Infrastructure</a></li>
</ul>
</div>
</section>
<section id="tvm-target">
<h2>tvm/target<a class="headerlink" href="#tvm-target" title="Link to this heading"></a></h2>
<p>The target module contains all the code generators that translate an IRModule to a target runtime.Module.
It also provides a common <cite>Target</cite> class that describes the target.</p>
<p>The compilation pipeline can be customized according to the target by querying the attribute information
in the target and builtin information registered to each target id(cuda, opencl).</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="device_target_interactions.html">Device/Target Interactions</a></li>
</ul>
</div>
</section>
<section id="tvm-relax">
<h2>tvm/relax<a class="headerlink" href="#tvm-relax" title="Link to this heading"></a></h2>
<p>Relax is the high-level IR used to represent the computational graph of a model. Various optimizations are defined in <code class="docutils literal notranslate"><span class="pre">relax.transform</span></code>.
Note that Relax usually works closely with the TensorIR IRModule, most of the transformations are applied on both Relax and TensorIR functions
in the IRModule. Please refer to the <a class="reference internal" href="../deep_dive/relax/index.html#relax-deep-dive"><span class="std std-ref">Relax Deep Dive</span></a> for more details.</p>
</section>
<section id="tvm-tir">
<h2>tvm/tir<a class="headerlink" href="#tvm-tir" title="Link to this heading"></a></h2>
<p>TIR contains the definition of the low-level program representations. We use <cite>tir::PrimFunc</cite> to represent functions that can be transformed by TIR passes.
Besides the IR data structures, the tir module also includes:</p>
<ul class="simple">
<li><p>A set of schedule primitives to control the generated code in <code class="docutils literal notranslate"><span class="pre">tir/schedule</span></code>.</p></li>
<li><p>A set of builtin intrinsics in <code class="docutils literal notranslate"><span class="pre">tir/tensor_intrin</span></code>.</p></li>
<li><p>A set of analysis passes to analyze the TIR functions in <code class="docutils literal notranslate"><span class="pre">tir/analysis</span></code>.</p></li>
<li><p>A set of transformation passes to lower or optimize the TIR functions in <code class="docutils literal notranslate"><span class="pre">tir/transform</span></code>.</p></li>
</ul>
<p>Please refer to the <a class="reference internal" href="../deep_dive/tensor_ir/index.html#tensor-ir-deep-dive"><span class="std std-ref">TensorIR Deep Dive</span></a> for more details.</p>
</section>
<section id="tvm-arith">
<h2>tvm/arith<a class="headerlink" href="#tvm-arith" title="Link to this heading"></a></h2>
<p>This module is closely tied to the TIR. One of the key problems in the low-level code generation is the analysis of the indices’
arithmetic properties — the positiveness, variable bound, and the integer set that describes the iterator space. arith module provides
a collection of tools that do (primarily integer) analysis. A TIR pass can use these analyses to simplify and optimize the code.</p>
</section>
<section id="tvm-te-and-tvm-topi">
<h2>tvm/te and tvm/topi<a class="headerlink" href="#tvm-te-and-tvm-topi" title="Link to this heading"></a></h2>
<p>TE stands for Tensor Expression. TE is a domain-specific language (DSL) for describing tensor computations. Importantly, a tensor expression
itself is not a self-contained function that can be stored into IRModule. We can use <code class="docutils literal notranslate"><span class="pre">te.create_prim_func</span></code> to convert a tensor expression to a <code class="docutils literal notranslate"><span class="pre">tir::PrimFunc</span></code>
and then integrate it into the IRModule.</p>
<p>While possible to construct operators directly via TIR or tensor expressions (TE) for each use case, it is tedious to do so.
<cite>topi</cite> (Tensor operator inventory) provides a set of pre-defined operators defined by numpy and found in common deep learning workloads.</p>
</section>
<section id="tvm-meta-schedule">
<h2>tvm/meta_schedule<a class="headerlink" href="#tvm-meta-schedule" title="Link to this heading"></a></h2>
<p>MetaSchedule is a system for automated search-based program optimization. It is designed to be a drop-in replacement for AutoTVM and AutoScheduler,
and can be used to optimize TensorIR schedules. Note that MetaSchedule only works with static-shape workloads.</p>
</section>
<section id="tvm-dlight">
<h2>tvm/dlight<a class="headerlink" href="#tvm-dlight" title="Link to this heading"></a></h2>
<p>DLight is a set of pre-defined, easy-to-use, and performant TIR schedules. DLight aims:</p>
<ul class="simple">
<li><p>Fully support <strong>dynamic shape workloads</strong>.</p></li>
<li><p><strong>Light weight</strong>. DLight schedules provides tuning-free or (very few-shots tuning) schedule with reasonable performance.</p></li>
<li><p><strong>Robust</strong>. DLight schedules are designed to be robust and general-purpose for a single rule. And if the rule is not applicable,
DLight not raise any error and switch to the next rule automatically.</p></li>
</ul>
</section>
</section>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="runtime.html" class="btn btn-neutral float-right" title="TVM Runtime System" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../errors.html" class="btn btn-neutral float-left" title="Handle TVM Errors" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2024 Apache Software Foundation | All rights reserved</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote">Copyright © 2024 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="../_static/downloads/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="../_static/downloads/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>