

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tvm.auto_scheduler &mdash; tvm 0.7.dev1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tvm_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="tvm.rpc" href="rpc.html" />
    <link rel="prev" title="tvm.autotvm" href="autotvm.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.7.dev1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">How to</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contribute to TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy/index.html">Deploy and Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to.html">Developer How-To Guide</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html">Get Started Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#compile-deep-learning-models">Compile Deep Learning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#tensor-expression-and-schedules">Tensor Expression and Schedules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#optimize-tensor-operators">Optimize Tensor Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#autotvm-template-based-auto-tuning">AutoTVM : Template-based Auto Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#autoscheduler-template-free-auto-scheduling">AutoScheduler : Template-free Auto Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#developer-tutorials">Developer Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#topi-tvm-operator-inventory">TOPI: TVM Operator Inventory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#micro-tvm">Micro TVM</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../langref/index.html">Language Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="runtime.html">tvm.runtime</a></li>
<li class="toctree-l2"><a class="reference internal" href="ndarray.html">tvm.runtime.ndarray</a></li>
<li class="toctree-l2"><a class="reference internal" href="error.html">tvm.error</a></li>
<li class="toctree-l2"><a class="reference internal" href="ir.html">tvm.ir</a></li>
<li class="toctree-l2"><a class="reference internal" href="ir.html#module-tvm.transform">tvm.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="target.html">tvm.target</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir.html">tvm.tir</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir.html#module-tvm.tir.transform">tvm.tir.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir.html#module-tvm.tir.analysis">tvm.tir.analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir.html#module-tvm.tir.stmt_functor">tvm.tir.stmt_functor</a></li>
<li class="toctree-l2"><a class="reference internal" href="te.html">tvm.te</a></li>
<li class="toctree-l2"><a class="reference internal" href="te.html#module-tvm.te.hybrid">tvm.te.hybrid</a></li>
<li class="toctree-l2"><a class="reference internal" href="driver.html">tvm.driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/index.html">tvm.relay</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/frontend.html">tvm.relay.frontend</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/nn.html">tvm.relay.nn</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/vision.html">tvm.relay.vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/image.html">tvm.relay.image</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/transform.html">tvm.relay.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/analysis.html">tvm.relay.analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/backend.html">tvm.relay.backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/dataflow_pattern.html">tvm.relay.dataflow_pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/testing.html">tvm.relay.testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="autotvm.html">tvm.autotvm</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">tvm.auto_scheduler</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-tvm.auto_scheduler.auto_schedule">tvm.auto_scheduler.auto_schedule</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm-auto-scheduler-workload-registry">tvm.auto_scheduler.workload_registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-tvm.auto_scheduler.measure">tvm.auto_scheduler.measure</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rpc.html">tvm.rpc</a></li>
<li class="toctree-l2"><a class="reference internal" href="micro.html">tvm.micro</a></li>
<li class="toctree-l2"><a class="reference internal" href="contrib.html">tvm.contrib</a></li>
<li class="toctree-l2"><a class="reference internal" href="graph_runtime.html">tvm.contrib.graph_runtime</a></li>
<li class="toctree-l2"><a class="reference internal" href="topi.html">tvm.topi</a></li>
<li class="toctree-l2"><a class="reference internal" href="vta/index.html">vta</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../links.html">Links to Other API References</a></li>
</ul>
<p class="caption"><span class="caption-text">Deep Dive</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/index.html">Design and Architecture</a></li>
</ul>
<p class="caption"><span class="caption-text">MISC</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../vta/index.html">VTA: Deep Learning Accelerator Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">tvm</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Python API</a> &raquo;</li>
        
      <li>tvm.auto_scheduler</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/api/python/auto_scheduler.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-tvm.auto_scheduler">
<span id="tvm-auto-scheduler"></span><h1>tvm.auto_scheduler<a class="headerlink" href="#module-tvm.auto_scheduler" title="Permalink to this headline">¶</a></h1>
<p>Namespace for TVM Auto-scheduler.</p>
<div class="section" id="module-tvm.auto_scheduler.auto_schedule">
<span id="tvm-auto-scheduler-auto-schedule"></span><h2>tvm.auto_scheduler.auto_schedule<a class="headerlink" href="#module-tvm.auto_scheduler.auto_schedule" title="Permalink to this headline">¶</a></h2>
<p>User interface for TVM Auto-scheduler.</p>
<p>The basic schedule search process for TVM Auto-scheduler is designed to be:
<cite>Program sampling</cite> -&gt; <cite>Performance Tuning</cite>.</p>
<p>In <cite>Program sampling</cite>, we use some predefined precise or heuristic rules to generate several
initial schedules. Based on these initial starting points, we perform <cite>Performance Tuning</cite> which
uses cost model based evolutionary search to select schedules with the best performance.</p>
<p>Candidate schedules are measured against the specific hardware target.</p>
<dl class="py class">
<dt id="tvm.auto_scheduler.auto_schedule.SearchTask">
<em class="property">class </em><code class="sig-prename descclassname">tvm.auto_scheduler.auto_schedule.</code><code class="sig-name descname">SearchTask</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dag</span></em>, <em class="sig-param"><span class="n">workload_key</span></em>, <em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">target_host</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hardware_params</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.auto_scheduler.auto_schedule.SearchTask" title="Permalink to this definition">¶</a></dt>
<dd><p>The computation information and hardware parameters for a schedule search task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dag</strong> (<em>ComputeDAG</em>) – The ComputeDAG for the corresponding compute declaration.</p></li>
<li><p><strong>workload_key</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The workload key for the corresponding compute declaration.</p></li>
<li><p><strong>target</strong> (<a class="reference internal" href="target.html#tvm.target.Target" title="tvm.target.Target"><em>tvm.target.Target</em></a>) – The target device of this search task.</p></li>
<li><p><strong>target_host</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="target.html#tvm.target.Target" title="tvm.target.Target"><em>tvm.target.Target</em></a><em>]</em>) – The target host device of this search task.</p></li>
<li><p><strong>hardware_params</strong> (<em>Optional</em><em>[</em><em>HardwareParams</em><em>]</em>) – Hardware parameters used in this search task.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="tvm.auto_scheduler.auto_schedule.TuningOptions">
<em class="property">class </em><code class="sig-prename descclassname">tvm.auto_scheduler.auto_schedule.</code><code class="sig-name descname">TuningOptions</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">num_measure_trials</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">early_stopping</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">num_measures_per_round</span><span class="o">=</span><span class="default_value">64</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">builder</span><span class="o">=</span><span class="default_value">'local'</span></em>, <em class="sig-param"><span class="n">runner</span><span class="o">=</span><span class="default_value">'local'</span></em>, <em class="sig-param"><span class="n">measure_callbacks</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.auto_scheduler.auto_schedule.TuningOptions" title="Permalink to this definition">¶</a></dt>
<dd><p>This controls the options of performance tuning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_measure_trials</strong> (<em>int = 0</em>) – The number of measurement trials.
The search policy measures <cite>num_measure_trials</cite> schedules in total and returns the best one
among them.
With <cite>num_measure_trials</cite> == 0, the policy will do the schedule search but won’t involve
measurement. This can be used to get a runnable schedule quickly without auto-tuning.</p></li>
<li><p><strong>early_stopping</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – Stop the tuning early if getting no improvement after n measurements.</p></li>
<li><p><strong>num_measures_per_round</strong> (<em>int = 64</em>) – The number of schedules to be measured at each search round.
The whole schedule search process will try a total number of <cite>num_measure_trials</cite> in several
rounds.</p></li>
<li><p><strong>verbose</strong> (<em>int = 1</em>) – Verbosity level. 0 for silent, 1 to output information during schedule search.</p></li>
<li><p><strong>builder</strong> (<em>Union</em><em>[</em><em>ProgramBuilder</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>] </em><em>= 'local'</em>) – ProgramBuilder which builds the program.</p></li>
<li><p><strong>runner</strong> (<em>Union</em><em>[</em><em>ProgramRunner</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>] </em><em>= 'local'</em>) – ProgramRunner which runs the program and measures time costs.</p></li>
<li><p><strong>measure_callbacks</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="relay/dataflow_pattern.html#tvm.relay.dataflow_pattern.List" title="tvm.relay.dataflow_pattern.List"><em>List</em></a><em>[</em><em>MeasureCallback</em><em>]</em><em>]</em>) – Callback functions called after each measurement.
Candidates:
- auto_scheduler.RecordToFile</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.auto_scheduler.auto_schedule.create_task">
<code class="sig-prename descclassname">tvm.auto_scheduler.auto_schedule.</code><code class="sig-name descname">create_task</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">func</span></em>, <em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">target_host</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hardware_params</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.auto_scheduler.auto_schedule.create_task" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a search task</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>Union</em><em>[</em><a class="reference internal" href="relay/index.html#tvm.relay.Function" title="tvm.relay.Function"><em>Function</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em>) – The function that returns the compute declaration Tensors.
Can be the a function or the function name.</p></li>
<li><p><strong>args</strong> (<em>Union</em><em>[</em><a class="reference internal" href="relay/index.html#tvm.relay.Tuple" title="tvm.relay.Tuple"><em>Tuple</em></a><em>[</em><a class="reference internal" href="tir.html#tvm.tir.Any" title="tvm.tir.Any"><em>Any</em></a><em>, </em><em>..</em><em>]</em><em>, </em><a class="reference internal" href="relay/dataflow_pattern.html#tvm.relay.dataflow_pattern.List" title="tvm.relay.dataflow_pattern.List"><em>List</em></a><em>[</em><a class="reference internal" href="tir.html#tvm.tir.Any" title="tvm.tir.Any"><em>Any</em></a><em>]</em><em>]</em>) – The args of the function.</p></li>
<li><p><strong>target</strong> (<a class="reference internal" href="target.html#tvm.target.Target" title="tvm.target.Target"><em>tvm.target.Target</em></a>) – The target device of this search task.</p></li>
<li><p><strong>target_host</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="target.html#tvm.target.Target" title="tvm.target.Target"><em>tvm.target.Target</em></a><em>]</em>) – The target host device of this search task.</p></li>
<li><p><strong>hardware_params</strong> (<em>Optional</em><em>[</em><em>HardwareParams</em><em>]</em>) – Hardware parameters used in this search task.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>SearchTask</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>the created task</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.auto_scheduler.auto_schedule.auto_schedule">
<code class="sig-prename descclassname">tvm.auto_scheduler.auto_schedule.</code><code class="sig-name descname">auto_schedule</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">task</span></em>, <em class="sig-param"><span class="n">search_policy</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tuning_options</span><span class="o">=</span><span class="default_value">auto_scheduler.TuningOptions(17864240)</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.auto_scheduler.auto_schedule.auto_schedule" title="Permalink to this definition">¶</a></dt>
<dd><p>Run auto scheduling search for a task</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="#tvm.auto_scheduler.auto_schedule.SearchTask" title="tvm.auto_scheduler.auto_schedule.SearchTask"><em>SearchTask</em></a>) – The SearchTask for the computation declaration.</p></li>
<li><p><strong>search_policy</strong> (<em>Optional</em><em>[</em><em>SearchPolicy</em><em>]</em>) – The search policy to be used for schedule search.</p></li>
<li><p><strong>tuning_options</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#tvm.auto_scheduler.auto_schedule.TuningOptions" title="tvm.auto_scheduler.auto_schedule.TuningOptions"><em>TuningOptions</em></a><em>]</em>) – Tuning and measurement options.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A <cite>te.schedule</cite> and the a list of <cite>te.Tensor</cite> to be used in <cite>tvm.lower</cite> or <cite>tvm.build</cite>.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="tvm-auto-scheduler-workload-registry">
<h2>tvm.auto_scheduler.workload_registry<a class="headerlink" href="#tvm-auto-scheduler-workload-registry" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="tvm.auto_scheduler.workload_registry.register_workload">
<code class="sig-prename descclassname">tvm.auto_scheduler.workload_registry.</code><code class="sig-name descname">register_workload</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">func_name</span></em>, <em class="sig-param"><span class="n">f</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">override</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.auto_scheduler.workload_registry.register_workload" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a function that generates a certain workload.</p>
<p>The input function should take hashable and jsonable arguments
(int, float, tuple of int, tvm.tensor.Tensor, …) and return a list of tvm.tensor.Tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func_name</strong> (<em>Union</em><em>[</em><a class="reference internal" href="relay/index.html#tvm.relay.Function" title="tvm.relay.Function"><em>Function</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em>) – The generation function that returns the compute declaration Tensors or its function name.</p></li>
<li><p><strong>f</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="relay/index.html#tvm.relay.Function" title="tvm.relay.Function"><em>Function</em></a><em>]</em>) – The generation function to be registered.</p></li>
<li><p><strong>override</strong> (<em>boolean = False</em>) – Whether override existing entry.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="nd">@auto_scheduler.register_workload</span>
<span class="k">def</span> <span class="nf">matmul</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">tvm</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="n">k</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="module-tvm.auto_scheduler.measure">
<span id="tvm-auto-scheduler-measure"></span><h2>tvm.auto_scheduler.measure<a class="headerlink" href="#module-tvm.auto_scheduler.measure" title="Permalink to this headline">¶</a></h2>
<p>Distributed measurement infrastructure to measure the runtime costs of tensor programs.</p>
<p>These functions are responsible for building the tvm module, uploading it to
remote devices, recording the running time costs, and checking the correctness of the output.</p>
<p>We separate the measurement into two steps: build and run.
A builder builds the executable binary files and a runner runs the binary files to
get the measurement results. The flow of data structures is</p>
<blockquote>
<div><p>.                <cite>ProgramBuilder</cite>                 <cite>ProgramRunner</cite>
<cite>MeasureInput</cite> —————–&gt; <cite>BuildResult</cite> —————-&gt; <cite>MeasureResult</cite></p>
</div></blockquote>
<p>We implement these in python to utilize python’s multiprocessing and error handling.</p>
<dl class="py class">
<dt id="tvm.auto_scheduler.measure.LocalRPCMeasureContext">
<em class="property">class </em><code class="sig-prename descclassname">tvm.auto_scheduler.measure.</code><code class="sig-name descname">LocalRPCMeasureContext</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">priority</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">n_parallel</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">timeout</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">number</span><span class="o">=</span><span class="default_value">3</span></em>, <em class="sig-param"><span class="n">repeat</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">min_repeat_ms</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">cooldown_interval</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">enable_cpu_cache_flush</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.auto_scheduler.measure.LocalRPCMeasureContext" title="Permalink to this definition">¶</a></dt>
<dd><p>A context wrapper for running RPCRunner locally.
This will launch a local RPC Tracker and local RPC Server.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>priority</strong> (<em>int = 1</em>) – The priority of this run request, larger is more prior.</p></li>
<li><p><strong>n_parallel</strong> (<em>int = 1</em>) – The number of tasks run in parallel.</p></li>
<li><p><strong>timeout</strong> (<em>int = 10</em>) – The timeout limit (in second) for each run.
This is used in a wrapper of the multiprocessing.Process.join().</p></li>
<li><p><strong>number</strong> (<em>int = 3</em>) – The number of times to run the generated code for taking average.
We call these runs as one <cite>repeat</cite> of measurement.</p></li>
<li><p><strong>repeat</strong> (<em>int = 1</em>) – The number of times to repeat the measurement.
In total, the generated code will be run (1 + number x repeat) times,
where the first “1” is warm up and will be discarded.
The returned result contains <cite>repeat</cite> costs,
each of which is an average of <cite>number</cite> costs.</p></li>
<li><p><strong>min_repeat_ms</strong> (<em>int = 0</em>) – The minimum duration of one <cite>repeat</cite> in milliseconds.
By default, one <cite>repeat</cite> contains <cite>number</cite> runs. If this parameter is set,
the parameters <cite>number</cite> will be dynamically adjusted to meet the
minimum duration requirement of one <cite>repeat</cite>.
i.e., When the run time of one <cite>repeat</cite> falls below this time, the <cite>number</cite> parameter
will be automatically increased.</p></li>
<li><p><strong>cooldown_interval</strong> (<em>float = 0.0</em>) – The cool down interval between two measurements.</p></li>
<li><p><strong>enable_cpu_cache_flush</strong> (<em>bool = False</em>) – Whether to flush cache on CPU between repeated measurements.
Flushing cache can make the measured latency of one operator closer to
its actual latency during end-to-end inference.
To make this option effective, the argument <cite>number</cite> should also be set to 1.
This is only has effect on CPU task.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="tvm.auto_scheduler.measure.LocalRunner">
<em class="property">class </em><code class="sig-prename descclassname">tvm.auto_scheduler.measure.</code><code class="sig-name descname">LocalRunner</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">timeout</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">number</span><span class="o">=</span><span class="default_value">3</span></em>, <em class="sig-param"><span class="n">repeat</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">min_repeat_ms</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">cooldown_interval</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">enable_cpu_cache_flush</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.auto_scheduler.measure.LocalRunner" title="Permalink to this definition">¶</a></dt>
<dd><p>LocalRunner that uses local CPU/GPU to measures the time cost of programs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>timeout</strong> (<em>int = 10</em>) – The timeout limit (in second) for each run.
This is used in a wrapper of the multiprocessing.Process.join().</p></li>
<li><p><strong>number</strong> (<em>int = 3</em>) – The number of times to run the generated code for taking average.
We call these runs as one <cite>repeat</cite> of measurement.</p></li>
<li><p><strong>repeat</strong> (<em>int = 1</em>) – The number of times to repeat the measurement.
In total, the generated code will be run (1 + number x repeat) times,
where the first “1” is warm up and will be discarded.
The returned result contains <cite>repeat</cite> costs,
each of which is an average of <cite>number</cite> costs.</p></li>
<li><p><strong>min_repeat_ms</strong> (<em>int = 100</em>) – The minimum duration of one <cite>repeat</cite> in milliseconds.
By default, one <cite>repeat</cite> contains <cite>number</cite> runs. If this parameter is set,
the parameters <cite>number</cite> will be dynamically adjusted to meet the
minimum duration requirement of one <cite>repeat</cite>.
i.e., When the run time of one <cite>repeat</cite> falls below this time, the <cite>number</cite> parameter
will be automatically increased.</p></li>
<li><p><strong>cooldown_interval</strong> (<em>float = 0.0</em>) – The cool down interval between two measurements.</p></li>
<li><p><strong>enable_cpu_cache_flush</strong> (<em>bool = False</em>) – Whether to flush cache on CPU between repeated measurements.
Flushing cache can make the measured latency of one operator closer to
its actual latency during end-to-end inference.
To make this option effective, the argument <cite>number</cite> should also be set to 1.
This is only has effect on CPU task.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="tvm.auto_scheduler.measure.LocalBuilder">
<em class="property">class </em><code class="sig-prename descclassname">tvm.auto_scheduler.measure.</code><code class="sig-name descname">LocalBuilder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">timeout</span><span class="o">=</span><span class="default_value">15</span></em>, <em class="sig-param"><span class="n">n_parallel</span><span class="o">=</span><span class="default_value">8</span></em>, <em class="sig-param"><span class="n">build_func</span><span class="o">=</span><span class="default_value">'default'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.auto_scheduler.measure.LocalBuilder" title="Permalink to this definition">¶</a></dt>
<dd><p>LocalBuilder use local CPU cores to build programs in parallel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>timeout</strong> (<em>int = 15</em>) – The timeout limit (in second) for each build thread.
This is used in a wrapper of the multiprocessing.Process.join().</p></li>
<li><p><strong>n_parallel</strong> (<em>int = multiprocessing.cpu_count</em><em>(</em><em>)</em>) – Number of threads used to build in parallel.</p></li>
<li><p><strong>build_func</strong> (<em>str = 'default'</em>) – The name of registered build function.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="tvm.auto_scheduler.measure.RPCRunner">
<em class="property">class </em><code class="sig-prename descclassname">tvm.auto_scheduler.measure.</code><code class="sig-name descname">RPCRunner</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">key</span></em>, <em class="sig-param"><span class="n">host</span></em>, <em class="sig-param"><span class="n">port</span></em>, <em class="sig-param"><span class="n">priority</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">n_parallel</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">timeout</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">number</span><span class="o">=</span><span class="default_value">3</span></em>, <em class="sig-param"><span class="n">repeat</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">min_repeat_ms</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">cooldown_interval</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">enable_cpu_cache_flush</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.auto_scheduler.measure.RPCRunner" title="Permalink to this definition">¶</a></dt>
<dd><p>RPCRunner that uses RPC call to measures the time cost of programs on remote devices.
Or sometime we may need to use RPC even in local running to insulate the thread environment.
(e.g. running CUDA programs)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The key of the device registered in the RPC tracker.</p></li>
<li><p><strong>host</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The host address of the RPC Tracker.</p></li>
<li><p><strong>port</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The port of RPC Tracker.</p></li>
<li><p><strong>priority</strong> (<em>int = 1</em>) – The priority of this run request, larger is more prior.</p></li>
<li><p><strong>n_parallel</strong> (<em>int = 1</em>) – The number of tasks run in parallel.</p></li>
<li><p><strong>timeout</strong> (<em>int = 10</em>) – The timeout limit (in second) for each run.
This is used in a wrapper of the multiprocessing.Process.join().</p></li>
<li><p><strong>number</strong> (<em>int = 3</em>) – The number of times to run the generated code for taking average.
We call these runs as one <cite>repeat</cite> of measurement.</p></li>
<li><p><strong>repeat</strong> (<em>int = 1</em>) – The number of times to repeat the measurement.
In total, the generated code will be run (1 + number x repeat) times,
where the first “1” is warm up and will be discarded.
The returned result contains <cite>repeat</cite> costs,
each of which is an average of <cite>number</cite> costs.</p></li>
<li><p><strong>min_repeat_ms</strong> (<em>int = 100</em>) – The minimum duration of one <cite>repeat</cite> in milliseconds.
By default, one <cite>repeat</cite> contains <cite>number</cite> runs. If this parameter is set,
the parameters <cite>number</cite> will be dynamically adjusted to meet the
minimum duration requirement of one <cite>repeat</cite>.
i.e., When the run time of one <cite>repeat</cite> falls below this time, the <cite>number</cite> parameter
will be automatically increased.</p></li>
<li><p><strong>cooldown_interval</strong> (<em>float = 0.0</em>) – The cool down interval between two measurements.</p></li>
<li><p><strong>enable_cpu_cache_flush</strong> (<em>bool = False</em>) – Whether to flush cache on CPU between repeated measurements.
Flushing cache can make the measured latency of one operator closer to
its actual latency during end-to-end inference.
To make this option effective, the argument <cite>number</cite> should also be set to 1.
This is only has effect on CPU task.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="rpc.html" class="btn btn-neutral float-right" title="tvm.rpc" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="autotvm.html" class="btn btn-neutral float-left" title="tvm.autotvm" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Apache Software Foundation

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>