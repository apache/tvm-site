





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Building a Graph Convolutional Network &mdash; tvm 0.15.0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tlcpack_theme.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Using External Libraries in Relay" href="using_external_lib.html" />
    <link rel="prev" title="Work With Relay" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/vta>VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <input type="checkbox" class="version-toggle-box" hidden id="version-toggle">
              <label for="version-toggle" class="version-toggle-label">
                  <div tabindex="0" class="version version-selector version-selector-show">
                    0.15.0 <span class="chevron versions-hidden"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m8 4 8 8-8 8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span><span class="chevron versions-shown"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m4 8 8 8 8-8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span>
                  </div>
                </label>
                <div class="version-details wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                  <p class="caption" role="heading"><span class="caption-text">Versions</span></p>
                  <ol style="text-align: left">
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="/">0.15.0 (main)</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.8.0/">v0.8.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.9.0/">v0.9.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.10.0/">v0.10.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.11.0/">v0.11.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.12.0/">v0.12.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.13.0/">v0.13.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.14.0/">v0.14.0</a></div></li>
                    
                  </ol>
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installing TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contributor Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/index.html">User Tutorial</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">How To Guides</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../compile_models/index.html">Compile Deep Learning Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deploy/index.html">Deploy Models and Integrate TVM</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Work With Relay</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Building a Graph Convolutional Network</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#define-gcn-in-dgl-with-pytorch-backend">Define GCN in DGL with PyTorch backend</a></li>
<li class="toctree-l4"><a class="reference internal" href="#define-the-functions-to-load-dataset-and-evaluate-accuracy">Define the functions to load dataset and evaluate accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="#load-the-data-and-set-up-model-parameters">Load the data and set up model parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#set-up-the-dgl-pytorch-model-and-get-the-golden-results">Set up the DGL-PyTorch model and get the golden results</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-the-dgl-model-and-test-for-accuracy">Run the DGL model and test for accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="#define-graph-convolution-layer-in-relay">Define Graph Convolution Layer in Relay</a></li>
<li class="toctree-l4"><a class="reference internal" href="#prepare-the-parameters-needed-in-the-graphconv-layers">Prepare the parameters needed in the GraphConv layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#put-layers-together">Put layers together</a></li>
<li class="toctree-l4"><a class="reference internal" href="#compile-and-run-with-tvm">Compile and run with TVM</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-the-tvm-model-test-for-accuracy-and-verify-with-dgl">Run the TVM model, test for accuracy and verify with DGL</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="using_external_lib.html">Using External Libraries in Relay</a></li>
<li class="toctree-l3"><a class="reference internal" href="using_pipeline_executor.html">Using Pipeline Executor in Relay</a></li>
<li class="toctree-l3"><a class="reference internal" href="using_relay_viz.html">Use Relay Visualizer to Visualize Relay</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_schedules/index.html">Work With Tensor Expression and Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../optimize_operators/index.html">Optimize Tensor Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autotvm/index.html">Auto-Tune with Templates and AutoTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autoscheduler/index.html">Use AutoScheduler for Template-Free Scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_microtvm/index.html">Work With microTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../extend_tvm/index.html">Extend TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../profile/index.html">Profile Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../errors.html">Handle TVM Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/tutorial/index.html">Developer Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to/how_to.html">Developer How-To Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Architecture  Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../arch/index.html">Design and Architecture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Topic Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../topic/microtvm/index.html">microTVM: TVM on bare-metal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../topic/vta/index.html">VTA: Versatile Tensor Accelerator</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/links.html">Other APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="../index.html">How To Guides</a> <span class="br-arrow">></span></li>
        
          <li><a href="index.html">Work With Relay</a> <span class="br-arrow">></span></li>
        
      <li>Building a Graph Convolutional Network</li>
    
    
      
      
        
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/tvm/edit/main/docs/how_to/work_with_relay/build_gcn.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial can be used interactively with Google Colab! You can also click
<a class="reference internal" href="#sphx-glr-download-how-to-work-with-relay-build-gcn-py"><span class="std std-ref">here</span></a> to run the Jupyter notebook locally.</p>
<a class="reference external image-reference" href="https://colab.research.google.com/github/apache/tvm-site/blob/asf-site/docs/_downloads/0.15.0/825671e45a9bdc4733400384984cd9dd/build_gcn.ipynb"><img alt="https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg" class="align-center" src="https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg" width="300px" /></a>
</div>
<div class="sphx-glr-example-title section" id="building-a-graph-convolutional-network">
<span id="sphx-glr-how-to-work-with-relay-build-gcn-py"></span><h1>Building a Graph Convolutional Network<a class="headerlink" href="#building-a-graph-convolutional-network" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://yulunyao.io/">Yulun Yao</a>,             <a class="reference external" href="https://homes.cs.washington.edu/~cyulin/">Chien-Yu Lin</a></p>
<p>This article is an introductory tutorial to build a Graph Convolutional Network (GCN) with Relay.
In this tutorial, we will run our GCN on Cora dataset to demonstrate.
Cora dataset is a common benchmark for Graph Neural Networks (GNN) and frameworks that support GNN training and inference.
We directly load the dataset from DGL library to do the apples to apples comparison against DGL.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="nv">torch</span><span class="o">==</span><span class="m">2</span>.0.0
pip<span class="w"> </span>install<span class="w"> </span><span class="nv">dgl</span><span class="o">==</span>v1.0.0
</pre></div>
</div>
<p>Please refer to DGL doc for installation at
<a class="reference external" href="https://docs.dgl.ai/install/index.html">https://docs.dgl.ai/install/index.html</a>.</p>
<p>Please refer to PyTorch guide for PyTorch installation at
<a class="reference external" href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>.</p>
<div class="section" id="define-gcn-in-dgl-with-pytorch-backend">
<h2>Define GCN in DGL with PyTorch backend<a class="headerlink" href="#define-gcn-in-dgl-with-pytorch-backend" title="Permalink to this headline">¶</a></h2>
<p>DGL example: <a class="reference external" href="https://github.com/dmlc/dgl/tree/master/examples/pytorch/gcn">https://github.com/dmlc/dgl/tree/master/examples/pytorch/gcn</a>
This part reuses the code from the above example.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">dgl</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">from</span> <span class="nn">dgl.nn.pytorch</span> <span class="kn">import</span> <span class="n">GraphConv</span>


<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">n_infeat</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GCN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">g</span> <span class="o">=</span> <span class="n">g</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">GraphConv</span><span class="p">(</span><span class="n">n_infeat</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">GraphConv</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">GraphConv</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">features</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="c1"># handle api changes for differnt DGL version</span>
            <span class="k">if</span> <span class="n">dgl</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&gt;</span> <span class="s2">&quot;0.3&quot;</span><span class="p">:</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">g</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span>
</pre></div>
</div>
</div>
<div class="section" id="define-the-functions-to-load-dataset-and-evaluate-accuracy">
<h2>Define the functions to load dataset and evaluate accuracy<a class="headerlink" href="#define-the-functions-to-load-dataset-and-evaluate-accuracy" title="Permalink to this headline">¶</a></h2>
<p>You may substitute this part with your own dataset, here we load data from DGL</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dgl.data</span> <span class="kn">import</span> <span class="n">load_data</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <a href="https://docs.python.org/3/library/collections.html#collections.namedtuple" title="collections.namedtuple" class="sphx-glr-backref-module-collections sphx-glr-backref-type-py-function"><span class="n">namedtuple</span></a>


<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>
    <span class="n">test_mask</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s2">&quot;test_mask&quot;</span><span class="p">]</span>

    <span class="n">pred</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="n">test_mask</span><span class="p">])</span> <span class="o">==</span> <span class="n">label</span><span class="p">[</span><span class="n">test_mask</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">acc</span>
</pre></div>
</div>
</div>
<div class="section" id="load-the-data-and-set-up-model-parameters">
<h2>Load the data and set up model parameters<a class="headerlink" href="#load-the-data-and-set-up-model-parameters" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Parameters</span>
<span class="sd">----------</span>
<span class="sd">num_layer: int</span>
<span class="sd">    number of hidden layers</span>

<span class="sd">num_hidden: int</span>
<span class="sd">    number of the hidden units in the hidden layer</span>

<span class="sd">infeat_dim: int</span>
<span class="sd">    dimension of the input features</span>

<span class="sd">num_classes: int</span>
<span class="sd">    dimension of model output (Number of classes)</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">CoraGraphDataset</span><span class="p">()</span>
<span class="n">dgl_g</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">num_hidden</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">dgl_g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s2">&quot;feat&quot;</span><span class="p">]</span>
<span class="n">infeat_dim</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">num_classes</span>
</pre></div>
</div>
</div>
<div class="section" id="set-up-the-dgl-pytorch-model-and-get-the-golden-results">
<h2>Set up the DGL-PyTorch model and get the golden results<a class="headerlink" href="#set-up-the-dgl-pytorch-model-and-get-the-golden-results" title="Permalink to this headline">¶</a></h2>
<p>The weights are trained with <a class="reference external" href="https://github.com/dmlc/dgl/blob/master/examples/pytorch/gcn/train.py">https://github.com/dmlc/dgl/blob/master/examples/pytorch/gcn/train.py</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="kn">import</span> <span class="n">download_testdata</span>

<span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="n">torch_model</span> <span class="o">=</span> <span class="n">GCN</span><span class="p">(</span><span class="n">dgl_g</span><span class="p">,</span> <span class="n">infeat_dim</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>

<span class="c1"># Download the pretrained weights</span>
<span class="n">model_url</span> <span class="o">=</span> <span class="s2">&quot;https://homes.cs.washington.edu/~cyulin/media/gnn_model/gcn_cora.torch&quot;</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">model_url</span><span class="p">,</span> <span class="s2">&quot;gcn_cora.pickle&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;gcn_model&quot;</span><span class="p">)</span>

<span class="c1"># Load the weights into the model</span>
<span class="n">torch_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="run-the-dgl-model-and-test-for-accuracy">
<h2>Run the DGL model and test for accuracy<a class="headerlink" href="#run-the-dgl-model-and-test-for-accuracy" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">logits_torch</span> <span class="o">=</span> <span class="n">torch_model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Print the first five outputs from DGL-PyTorch execution</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">logits_torch</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">dgl_g</span><span class="p">,</span> <span class="n">logits_torch</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy of DGL results: </span><span class="si">{:.2%}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="define-graph-convolution-layer-in-relay">
<h2>Define Graph Convolution Layer in Relay<a class="headerlink" href="#define-graph-convolution-layer-in-relay" title="Permalink to this headline">¶</a></h2>
<p>To run GCN on TVM, we first need to implement Graph Convolution Layer.
You may refer to <a class="reference external" href="https://github.com/dmlc/dgl/blob/master/python/dgl/nn/mxnet/conv/graphconv.py">https://github.com/dmlc/dgl/blob/master/python/dgl/nn/mxnet/conv/graphconv.py</a> for a GraphConv Layer implemented in DGL with MXNet Backend</p>
<p>The layer is defined with below operations, note that we apply two transposes to keep adjacency matrix on right hand side of sparse_dense operator,
this method is temporary and will be updated in next few weeks when we have sparse matrix transpose and support for left sparse operator.</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\mbox{GraphConv}(A, H, W)   = A * H * W
                            = ((H * W)^t * A^t)^t
                            = ((W^t * H^t) * A^t)^t\]</div>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">relay</span>
<span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="kn">import</span> <span class="n">graph_executor</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">te</span>


<span class="k">def</span> <span class="nf">GraphConv</span><span class="p">(</span><span class="n">layer_name</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">adj</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    layer_name: str</span>
<span class="sd">    Name of layer</span>

<span class="sd">    input_dim: int</span>
<span class="sd">    Input dimension per node feature</span>

<span class="sd">    output_dim: int,</span>
<span class="sd">    Output dimension per node feature</span>

<span class="sd">    adj: namedtuple,</span>
<span class="sd">    Graph representation (Adjacency Matrix) in Sparse Format (`data`, `indices`, `indptr`),</span>
<span class="sd">    where `data` has shape [num_nonzeros], indices` has shape [num_nonzeros], `indptr` has shape [num_nodes + 1]</span>

<span class="sd">    input: relay.Expr,</span>
<span class="sd">    Input feature to current layer with shape [num_nodes, input_dim]</span>

<span class="sd">    norm: relay.Expr,</span>
<span class="sd">    Norm passed to this layer to normalize features before and after Convolution.</span>

<span class="sd">    bias: bool</span>
<span class="sd">    Set bias to True to add bias when doing GCN layer</span>

<span class="sd">    activation: &lt;function relay.op.nn&gt;,</span>
<span class="sd">    Activation function applies to the output. e.g. relay.nn.{relu, sigmoid, log_softmax, softmax, leaky_relu}</span>

<span class="sd">    Returns</span>
<span class="sd">    ----------</span>
<span class="sd">    output: tvm.relay.Expr</span>
<span class="sd">    The Output Tensor for this layer [num_nodes, output_dim]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">norm</span><span class="p">)</span>

    <span class="n">weight</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">layer_name</span> <span class="o">+</span> <span class="s2">&quot;.weight&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">))</span>
    <span class="n">weight_t</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
    <span class="n">dense</span> <span class="o">=</span> <a href="../../reference/api/python/relay/nn.html#tvm.relay.nn.dense" title="tvm.relay.nn.dense" class="sphx-glr-backref-module-tvm-relay-nn sphx-glr-backref-type-py-function"><span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dense</span></a><span class="p">(</span><span class="n">weight_t</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <a href="../../reference/api/python/relay/nn.html#tvm.relay.nn.sparse_dense" title="tvm.relay.nn.sparse_dense" class="sphx-glr-backref-module-tvm-relay-nn sphx-glr-backref-type-py-function"><span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sparse_dense</span></a><span class="p">(</span><span class="n">dense</span><span class="p">,</span> <span class="n">adj</span><span class="p">)</span>
    <span class="n">output_t</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output_t</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">output_t</span><span class="p">,</span> <span class="n">norm</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">_bias</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">layer_name</span> <span class="o">+</span> <span class="s2">&quot;.bias&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">output_t</span> <span class="o">=</span> <a href="../../reference/api/python/relay/nn.html#tvm.relay.nn.bias_add" title="tvm.relay.nn.bias_add" class="sphx-glr-backref-module-tvm-relay-nn sphx-glr-backref-type-py-function"><span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span></a><span class="p">(</span><span class="n">output_t</span><span class="p">,</span> <span class="n">_bias</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output_t</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">output_t</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output_t</span>
</pre></div>
</div>
</div>
<div class="section" id="prepare-the-parameters-needed-in-the-graphconv-layers">
<h2>Prepare the parameters needed in the GraphConv layers<a class="headerlink" href="#prepare-the-parameters-needed-in-the-graphconv-layers" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>


<span class="k">def</span> <span class="nf">prepare_params</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">params</span><span class="p">[</span><span class="s2">&quot;infeats&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s2">&quot;feat&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

    <span class="c1"># Generate adjacency matrix</span>
    <span class="n">nx_graph</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">to_networkx</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="n">adjacency</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_scipy_sparse_array</span><span class="p">(</span><span class="n">nx_graph</span><span class="p">)</span>
    <span class="n">params</span><span class="p">[</span><span class="s2">&quot;g_data&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">adjacency</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="n">params</span><span class="p">[</span><span class="s2">&quot;indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">adjacency</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;int32&quot;</span><span class="p">)</span>
    <span class="n">params</span><span class="p">[</span><span class="s2">&quot;indptr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">adjacency</span><span class="o">.</span><span class="n">indptr</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;int32&quot;</span><span class="p">)</span>

    <span class="c1"># Normalization w.r.t. node degrees</span>
    <span class="n">degs</span> <span class="o">=</span> <span class="p">[</span><span class="n">g</span><span class="o">.</span><span class="n">in_degrees</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">())]</span>
    <span class="n">params</span><span class="p">[</span><span class="s2">&quot;norm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">degs</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="n">params</span><span class="p">[</span><span class="s2">&quot;norm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;norm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;norm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">params</span>


<span class="n">params</span> <span class="o">=</span> <span class="n">prepare_params</span><span class="p">(</span><span class="n">dgl_g</span><span class="p">)</span>

<span class="c1"># Check shape of features and the validity of adjacency matrix</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;infeats&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
<span class="k">assert</span> <span class="p">(</span>
    <span class="n">params</span><span class="p">[</span><span class="s2">&quot;g_data&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;indices&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;indptr&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="p">)</span>
<span class="k">assert</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;infeats&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;indptr&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="section" id="put-layers-together">
<h2>Put layers together<a class="headerlink" href="#put-layers-together" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define input features, norms, adjacency matrix in Relay</span>
<span class="n">infeats</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;infeats&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">norm</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><a href="../../reference/api/python/ndarray.html#tvm.nd.array" title="tvm.nd.array" class="sphx-glr-backref-module-tvm-nd sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;norm&quot;</span><span class="p">]))</span>
<span class="n">g_data</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><a href="../../reference/api/python/ndarray.html#tvm.nd.array" title="tvm.nd.array" class="sphx-glr-backref-module-tvm-nd sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;g_data&quot;</span><span class="p">]))</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><a href="../../reference/api/python/ndarray.html#tvm.nd.array" title="tvm.nd.array" class="sphx-glr-backref-module-tvm-nd sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;indices&quot;</span><span class="p">]))</span>
<span class="n">indptr</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><a href="../../reference/api/python/ndarray.html#tvm.nd.array" title="tvm.nd.array" class="sphx-glr-backref-module-tvm-nd sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;indptr&quot;</span><span class="p">]))</span>

<span class="n">Adjacency</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/collections.html#collections.namedtuple" title="collections.namedtuple" class="sphx-glr-backref-module-collections sphx-glr-backref-type-py-function"><span class="n">namedtuple</span></a><span class="p">(</span><span class="s2">&quot;Adjacency&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;indices&quot;</span><span class="p">,</span> <span class="s2">&quot;indptr&quot;</span><span class="p">])</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">Adjacency</span><span class="p">(</span><span class="n">g_data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">indptr</span><span class="p">)</span>

<span class="c1"># Construct the 2-layer GCN</span>
<span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
    <span class="n">GraphConv</span><span class="p">(</span>
        <span class="n">layer_name</span><span class="o">=</span><span class="s2">&quot;layers.0&quot;</span><span class="p">,</span>
        <span class="n">input_dim</span><span class="o">=</span><span class="n">infeat_dim</span><span class="p">,</span>
        <span class="n">output_dim</span><span class="o">=</span><span class="n">num_hidden</span><span class="p">,</span>
        <span class="n">adj</span><span class="o">=</span><span class="n">adj</span><span class="p">,</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">infeats</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><a href="../../reference/api/python/relay/nn.html#tvm.relay.nn.relu" title="tvm.relay.nn.relu" class="sphx-glr-backref-module-tvm-relay-nn sphx-glr-backref-type-py-function"><span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span></a><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
    <span class="n">GraphConv</span><span class="p">(</span>
        <span class="n">layer_name</span><span class="o">=</span><span class="s2">&quot;layers.1&quot;</span><span class="p">,</span>
        <span class="n">input_dim</span><span class="o">=</span><span class="n">num_hidden</span><span class="p">,</span>
        <span class="n">output_dim</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
        <span class="n">adj</span><span class="o">=</span><span class="n">adj</span><span class="p">,</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Analyze free variables and generate Relay function</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="compile-and-run-with-tvm">
<h2>Compile and run with TVM<a class="headerlink" href="#compile-and-run-with-tvm" title="Permalink to this headline">¶</a></h2>
<p>Export the weights from PyTorch model to Python Dict</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_params</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">param_tensor</span> <span class="ow">in</span> <span class="n">torch_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">():</span>
    <span class="n">model_params</span><span class="p">[</span><span class="n">param_tensor</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">param_tensor</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">params</span><span class="p">[</span><span class="s2">&quot;layers.</span><span class="si">%d</span><span class="s2">.weight&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">model_params</span><span class="p">[</span><span class="s2">&quot;layers.</span><span class="si">%d</span><span class="s2">.weight&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">)]</span>
    <span class="n">params</span><span class="p">[</span><span class="s2">&quot;layers.</span><span class="si">%d</span><span class="s2">.bias&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">model_params</span><span class="p">[</span><span class="s2">&quot;layers.</span><span class="si">%d</span><span class="s2">.bias&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">)]</span>

<span class="c1"># Set the TVM build target</span>
<span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;llvm&quot;</span>  <span class="c1"># Currently only support `llvm` as target</span>

<span class="n">func</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span><a href="../../reference/api/python/relay/analysis.html#tvm.relay.analysis.free_vars" title="tvm.relay.analysis.free_vars" class="sphx-glr-backref-module-tvm-relay-analysis sphx-glr-backref-type-py-function"><span class="n">relay</span><span class="o">.</span><span class="n">analysis</span><span class="o">.</span><span class="n">free_vars</span></a><span class="p">(</span><span class="n">output</span><span class="p">),</span> <span class="n">output</span><span class="p">)</span>
<span class="n">func</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build_module</span><span class="o">.</span><span class="n">bind_params_by_name</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="n">mod</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">IRModule</span><span class="p">()</span>
<span class="n">mod</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">func</span>
<span class="c1"># Build with Relay</span>
<span class="k">with</span> <a href="../../reference/api/python/ir.html#tvm.transform.PassContext" title="tvm.transform.PassContext" class="sphx-glr-backref-module-tvm-transform sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span></a><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>  <span class="c1"># Currently only support opt_level=0</span>
    <span class="n">lib</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="c1"># Generate graph executor</span>
<span class="n">dev</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <a href="../../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule" title="tvm.contrib.graph_executor.GraphModule" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">graph_executor</span><span class="o">.</span><span class="n">GraphModule</span></a><span class="p">(</span><span class="n">lib</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">](</span><span class="n">dev</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="run-the-tvm-model-test-for-accuracy-and-verify-with-dgl">
<h2>Run the TVM model, test for accuracy and verify with DGL<a class="headerlink" href="#run-the-tvm-model-test-for-accuracy-and-verify-with-dgl" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">logits_tvm</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">get_output</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Print the first five outputs from TVM execution</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">logits_tvm</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">dgl_g</span><span class="p">,</span> <span class="n">logits_tvm</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy of TVM results: </span><span class="si">{:.2%}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>

<span class="kn">import</span> <span class="nn">tvm.testing</span>

<span class="c1"># Verify the results with the DGL model</span>
<span class="n">tvm</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">logits_torch</span><span class="p">,</span> <span class="n">logits_tvm</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-how-to-work-with-relay-build-gcn-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/dabb6b43ea9ef9d7bd1a3912001deace/build_gcn.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">build_gcn.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/825671e45a9bdc4733400384984cd9dd/build_gcn.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">build_gcn.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="using_external_lib.html" class="btn btn-neutral float-right" title="Using External Libraries in Relay" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Work With Relay" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2023 Apache Software Foundation | All rights reserved</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote">Copyright © 2023 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    

    
   

</body>
</html>