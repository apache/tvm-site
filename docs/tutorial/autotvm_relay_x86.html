





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Compiling and Optimizing a Model with the Python Interface (AutoTVM) &mdash; tvm 0.11.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/tlcpack_theme.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Working with Operators Using Tensor Expression" href="tensor_expr_get_started.html" />
    <link rel="prev" title="Getting Starting using TVMC Python: a high-level API for TVM" href="tvmc_python.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/vta>VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <input type="checkbox" class="version-toggle-box" hidden id="version-toggle">
              <label for="version-toggle" class="version-toggle-label">
                  <div tabindex="0" class="version version-selector version-selector-show">
                    0.11.dev0 <span class="chevron versions-hidden"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m8 4 8 8-8 8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span><span class="chevron versions-shown"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m4 8 8 8 8-8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span>
                  </div>
                </label>
                <div class="version-details wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                  <p class="caption" role="heading"><span class="caption-text">Versions</span></p>
                  <ol style="text-align: left">
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="/">0.11.dev0 (main)</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.8.0/">v0.8.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.9.0/">v0.9.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.10.0/">v0.10.0</a></div></li>
                    
                  </ol>
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Installing TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribute/index.html">Contributor Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">User Tutorial</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#an-overview-of-tvm-and-model-optimization">An Overview of TVM and Model Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="install.html">Installing TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="tvmc_command_line_driver.html">Compiling and Optimizing a Model with TVMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="tvmc_python.html">Getting Starting using TVMC Python: a high-level API for TVM</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Compiling and Optimizing a Model with the Python Interface (AutoTVM)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#downloading-and-loading-the-onnx-model">Downloading and Loading the ONNX Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloading-preprocessing-and-loading-the-test-image">Downloading, Preprocessing, and Loading the Test Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compile-the-model-with-relay">Compile the Model With Relay</a></li>
<li class="toctree-l3"><a class="reference internal" href="#execute-on-the-tvm-runtime">Execute on the TVM Runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="#collect-basic-performance-data">Collect Basic Performance Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#postprocess-the-output">Postprocess the output</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tune-the-model">Tune the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compiling-an-optimized-model-with-tuning-data">Compiling an Optimized Model with Tuning Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#comparing-the-tuned-and-untuned-models">Comparing the Tuned and Untuned Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="#final-remarks">Final Remarks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tensor_expr_get_started.html">Working with Operators Using Tensor Expression</a></li>
<li class="toctree-l2"><a class="reference internal" href="autotvm_matmul_x86.html">Optimizing Operators with Schedule Templates and AutoTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_scheduler_matmul_x86.html">Optimizing Operators with Auto-scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_ir_blitz_course.html">Blitz Course to TensorIR</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay_quick_start.html">Quick Start Tutorial for Compiling Deep Learning Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="uma.html">Making your Hardware Accelerator TVM-ready with UMA</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro_topi.html">Introduction to TOPI</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../how_to/index.html">How To Guides</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dev/tutorial/index.html">Developer Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev/how_to/how_to.html">Developer How-To Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Architecture  Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../arch/index.html">Design and Architecture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Topic Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topic/microtvm/index.html">microTVM: TVM on bare-metal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic/vta/index.html">VTA: Versatile Tensor Accelerator</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/api/links.html">Other APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="index.html">User Tutorial</a> <span class="br-arrow">></span></li>
        
      <li>Compiling and Optimizing a Model with the Python Interface (AutoTVM)</li>
    
    
      
      
        
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/tvm/edit/main/gallery/tutorial/autotvm_relay_x86.py" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial can be used interactively with Google Colab! You can also click
<a class="reference internal" href="#sphx-glr-download-tutorial-autotvm-relay-x86-py"><span class="std std-ref">here</span></a> to run the Jupyter notebook locally.</p>
<a class="reference external image-reference" href="https://colab.research.google.com/github/apache/tvm-site/blob/asf-site/docs/_downloads/2f91b1346a0ba21b800081aa15fdaac2/autotvm_relay_x86.ipynb"><img alt="https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg" class="align-center" src="https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg" width="300px" /></a>
</div>
<div class="sphx-glr-example-title section" id="compiling-and-optimizing-a-model-with-the-python-interface-autotvm">
<span id="sphx-glr-tutorial-autotvm-relay-x86-py"></span><h1>Compiling and Optimizing a Model with the Python Interface (AutoTVM)<a class="headerlink" href="#compiling-and-optimizing-a-model-with-the-python-interface-autotvm" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>:
<a class="reference external" href="https://github.com/hogepodge">Chris Hoge</a></p>
<p>In the <a class="reference external" href="tvmc_command_line_driver">TVMC Tutorial</a>, we covered how to compile, run, and tune a
pre-trained vision model, ResNet-50 v2 using the command line interface for
TVM, TVMC. TVM is more that just a command-line tool though, it is an
optimizing framework with APIs available for a number of different languages
that gives you tremendous flexibility in working with machine learning models.</p>
<p>In this tutorial we will cover the same ground we did with TVMC, but show how
it is done with the Python API. Upon completion of this section, we will have
used the Python API for TVM to accomplish the following tasks:</p>
<ul class="simple">
<li><p>Compile a pre-trained ResNet-50 v2 model for the TVM runtime.</p></li>
<li><p>Run a real image through the compiled model, and interpret the output and model
performance.</p></li>
<li><p>Tune the model that model on a CPU using TVM.</p></li>
<li><p>Re-compile an optimized model using the tuning data collected by TVM.</p></li>
<li><p>Run the image through the optimized model, and compare the output and model
performance.</p></li>
</ul>
<p>The goal of this section is to give you an overview of TVM’s capabilites and
how to use them through the Python API.</p>
<p>TVM is a deep learning compiler framework, with a number of different modules
available for working with deep learning models and operators. In this
tutorial we will work through how to load, compile, and optimize a model
using the Python API.</p>
<p>We begin by importing a number of dependencies, including <code class="docutils literal notranslate"><span class="pre">onnx</span></code> for
loading and converting the model, helper utilities for downloading test data,
the Python Image Library for working with the image data, <code class="docutils literal notranslate"><span class="pre">numpy</span></code> for pre
and post-processing of the image data, the TVM Relay framework, and the TVM
Graph Executor.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="kn">import</span> <span class="n">download_testdata</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tvm.relay</span> <span class="k">as</span> <span class="nn">relay</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="kn">import</span> <span class="n">graph_executor</span>
</pre></div>
</div>
<div class="section" id="downloading-and-loading-the-onnx-model">
<h2>Downloading and Loading the ONNX Model<a class="headerlink" href="#downloading-and-loading-the-onnx-model" title="Permalink to this headline">¶</a></h2>
<p>For this tutorial, we will be working with ResNet-50 v2. ResNet-50 is a
convolutional neural network that is 50 layers deep and designed to classify
images. The model we will be using has been pre-trained on more than a
million images with 1000 different classifications. The network has an input
image size of 224x224. If you are interested exploring more of how the
ResNet-50 model is structured, we recommend downloading
<a class="reference external" href="https://netron.app">Netron</a>, a freely available ML model viewer.</p>
<p>TVM provides a helper library to download pre-trained models. By providing a
model URL, file name, and model type through the module, TVM will download
the model and save it to disk. For the instance of an ONNX model, you can
then load it into memory using the ONNX runtime.</p>
<div class="admonition-working-with-other-model-formats admonition">
<p class="admonition-title">Working with Other Model Formats</p>
<p>TVM supports many popular model formats. A list can be found in the
<a class="reference internal" href="../how_to/compile_models/index.html#tutorial-frontend"><span class="std std-ref">Compile Deep Learning Models</span></a> section of the TVM
Documentation.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_url</span></a> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;https://github.com/onnx/models/raw/main/&quot;</span>
    <span class="s2">&quot;vision/classification/resnet/model/&quot;</span>
    <span class="s2">&quot;resnet50-v2-7.onnx&quot;</span>
<span class="p">)</span>

<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_path</span></a> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_url</span></a><span class="p">,</span> <span class="s2">&quot;resnet50-v2-7.onnx&quot;</span><span class="p">,</span> <a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule" title="tvm.contrib.graph_executor.GraphModule" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">module</span></a><span class="o">=</span><span class="s2">&quot;onnx&quot;</span><span class="p">)</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_path</span></a><span class="p">)</span>

<span class="c1"># Seed numpy&#39;s RNG to get consistent results</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="downloading-preprocessing-and-loading-the-test-image">
<h2>Downloading, Preprocessing, and Loading the Test Image<a class="headerlink" href="#downloading-preprocessing-and-loading-the-test-image" title="Permalink to this headline">¶</a></h2>
<p>Each model is particular when it comes to expected tensor shapes, formats and
data types. For this reason, most models require some pre and
post-processing, to ensure the input is valid and to interpret the output.
TVMC has adopted NumPy’s <code class="docutils literal notranslate"><span class="pre">.npz</span></code> format for both input and output data.</p>
<p>As input for this tutorial, we will use the image of a cat, but you can feel
free to substitute this image for any of your choosing.</p>
<a class="reference internal image-reference" href="https://s3.amazonaws.com/model-server/inputs/kitten.jpg"><img alt="https://s3.amazonaws.com/model-server/inputs/kitten.jpg" class="align-center" src="https://s3.amazonaws.com/model-server/inputs/kitten.jpg" style="width: 224px; height: 224px;" /></a>
<p>Download the image data, then convert it to a numpy array to use as an input to the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_url</span></a> <span class="o">=</span> <span class="s2">&quot;https://s3.amazonaws.com/model-server/inputs/kitten.jpg&quot;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_path</span></a> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_url</span></a><span class="p">,</span> <span class="s2">&quot;imagenet_cat.png&quot;</span><span class="p">,</span> <a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule" title="tvm.contrib.graph_executor.GraphModule" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">module</span></a><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>

<span class="c1"># Resize it to 224x224</span>
<span class="n">resized_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_path</span></a><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">resized_image</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

<span class="c1"># Our input image is in HWC layout while ONNX expects CHW input, so convert the array</span>
<span class="n">img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img_data</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Normalize according to the ImageNet input specification</span>
<span class="n">imagenet_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">imagenet_stddev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">norm_img_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_data</span> <span class="o">/</span> <span class="mi">255</span> <span class="o">-</span> <span class="n">imagenet_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">imagenet_stddev</span>

<span class="c1"># Add the batch dimension, as we are expecting 4-dimensional input: NCHW.</span>
<span class="n">img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">norm_img_data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="compile-the-model-with-relay">
<h2>Compile the Model With Relay<a class="headerlink" href="#compile-the-model-with-relay" title="Permalink to this headline">¶</a></h2>
<p>The next step is to compile the ResNet model. We begin by importing the model
to relay using the <cite>from_onnx</cite> importer. We then build the model, with
standard optimizations, into a TVM library.  Finally, we create a TVM graph
runtime module from the library.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a> <span class="o">=</span> <span class="s2">&quot;llvm&quot;</span>
</pre></div>
</div>
<div class="admonition-defining-the-correct-target admonition">
<p class="admonition-title">Defining the Correct Target</p>
<p>Specifying the correct target can have a huge impact on the performance of
the compiled module, as it can take advantage of hardware features
available on the target. For more information, please refer to
<a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_x86.html#tune-relay-x86"><span class="std std-ref">Auto-tuning a convolutional network for x86 CPU</span></a>.
We recommend identifying which CPU you are running, along with optional
features, and set the target appropriately. For example, for some
processors <code class="docutils literal notranslate"><span class="pre">target</span> <span class="pre">=</span> <span class="pre">&quot;llvm</span> <span class="pre">-mcpu=skylake&quot;</span></code>, or <code class="docutils literal notranslate"><span class="pre">target</span> <span class="pre">=</span> <span class="pre">&quot;llvm</span>
<span class="pre">-mcpu=skylake-avx512&quot;</span></code> for processors with the AVX-512 vector instruction
set.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The input name may vary across model types. You can use a tool</span>
<span class="c1"># like Netron to check input names</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_name</span></a> <span class="o">=</span> <span class="s2">&quot;data&quot;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">shape_dict</span></a> <span class="o">=</span> <span class="p">{</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_name</span></a><span class="p">:</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_data</span><span class="o">.</span><span class="n">shape</span></a><span class="p">}</span>

<span class="n">mod</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a> <span class="o">=</span> <a href="../reference/api/python/relay/frontend.html#tvm.relay.frontend.from_onnx" title="tvm.relay.frontend.from_onnx" class="sphx-glr-backref-module-tvm-relay-frontend sphx-glr-backref-type-py-function"><span class="n">relay</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">from_onnx</span></a><span class="p">(</span><span class="n">onnx_model</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">shape_dict</span></a><span class="p">)</span>

<span class="k">with</span> <a href="../reference/api/python/ir.html#tvm.transform.PassContext" title="tvm.transform.PassContext" class="sphx-glr-backref-module-tvm-transform sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span></a><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">lib</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="p">)</span>

<span class="n">dev</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule" title="tvm.contrib.graph_executor.GraphModule" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">module</span></a> <span class="o">=</span> <a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule" title="tvm.contrib.graph_executor.GraphModule" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-class"><span class="n">graph_executor</span><span class="o">.</span><span class="n">GraphModule</span></a><span class="p">(</span><span class="n">lib</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">](</span><span class="n">dev</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="execute-on-the-tvm-runtime">
<h2>Execute on the TVM Runtime<a class="headerlink" href="#execute-on-the-tvm-runtime" title="Permalink to this headline">¶</a></h2>
<p>Now that we’ve compiled the model, we can use the TVM runtime to make
predictions with it. To use TVM to run the model and make predictions, we
need two things:</p>
<ul class="simple">
<li><p>The compiled model, which we just produced.</p></li>
<li><p>Valid input to the model to make predictions on.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dtype</span></a> <span class="o">=</span> <span class="s2">&quot;float32&quot;</span>
<a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule.set_input" title="tvm.contrib.graph_executor.GraphModule.set_input" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-method"><span class="n">module</span><span class="o">.</span><span class="n">set_input</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_name</span></a><span class="p">,</span> <span class="n">img_data</span><span class="p">)</span>
<a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule.run" title="tvm.contrib.graph_executor.GraphModule.run" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-method"><span class="n">module</span><span class="o">.</span><span class="n">run</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_shape</span></a> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">tvm_output</span> <span class="o">=</span> <a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule.get_output" title="tvm.contrib.graph_executor.GraphModule.get_output" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-method"><span class="n">module</span><span class="o">.</span><span class="n">get_output</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <a href="../reference/api/python/ndarray.html#tvm.nd.empty" title="tvm.nd.empty" class="sphx-glr-backref-module-tvm-nd sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">empty</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_shape</span></a><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="collect-basic-performance-data">
<h2>Collect Basic Performance Data<a class="headerlink" href="#collect-basic-performance-data" title="Permalink to this headline">¶</a></h2>
<p>We want to collect some basic performance data associated with this
unoptimized model and compare it to a tuned model later. To help account for
CPU noise, we run the computation in multiple batches in multiple
repetitions, then gather some basis statistics on the mean, median, and
standard deviation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">timeit</span>

<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timing_number</span></a> <span class="o">=</span> <span class="mi">10</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timing_repeat</span></a> <span class="o">=</span> <span class="mi">10</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">unoptimized</span></a> <span class="o">=</span> <span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><a href="https://docs.python.org/3/library/timeit.html#timeit.Timer" title="timeit.Timer" class="sphx-glr-backref-module-timeit sphx-glr-backref-type-py-class"><span class="n">timeit</span><span class="o">.</span><span class="n">Timer</span></a><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule.run" title="tvm.contrib.graph_executor.GraphModule.run" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-method"><span class="n">module</span><span class="o">.</span><span class="n">run</span></a><span class="p">())</span><span class="o">.</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">repeat</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">repeat</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timing_repeat</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">number</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timing_number</span></a><span class="p">))</span>
    <span class="o">*</span> <span class="mi">1000</span>
    <span class="o">/</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timing_number</span></a>
<span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">unoptimized</span></a> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">unoptimized</span></a><span class="p">),</span>
    <span class="s2">&quot;median&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">unoptimized</span></a><span class="p">),</span>
    <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">unoptimized</span></a><span class="p">),</span>
<span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">unoptimized</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;mean&#39;: 510.8778525799971, &#39;median&#39;: 510.608007299993, &#39;std&#39;: 1.4270214411428404}
</pre></div>
</div>
</div>
<div class="section" id="postprocess-the-output">
<h2>Postprocess the output<a class="headerlink" href="#postprocess-the-output" title="Permalink to this headline">¶</a></h2>
<p>As previously mentioned, each model will have its own particular way of
providing output tensors.</p>
<p>In our case, we need to run some post-processing to render the outputs from
ResNet-50 v2 into a more human-readable form, using the lookup-table provided
for the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">softmax</span>

<span class="c1"># Download a list of labels</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">labels_url</span></a> <span class="o">=</span> <span class="s2">&quot;https://s3.amazonaws.com/onnx-model-zoo/synset.txt&quot;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">labels_path</span></a> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">labels_url</span></a><span class="p">,</span> <span class="s2">&quot;synset.txt&quot;</span><span class="p">,</span> <a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule" title="tvm.contrib.graph_executor.GraphModule" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">module</span></a><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">labels_path</span></a><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <a href="https://docs.python.org/3/library/io.html#io.TextIOWrapper" title="io.TextIOWrapper" class="sphx-glr-backref-module-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">f</span></a><span class="p">:</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">labels</span></a> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/io.html#io.TextIOWrapper" title="io.TextIOWrapper" class="sphx-glr-backref-module-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">f</span></a><span class="p">]</span>

<span class="c1"># Open the output and read the output tensor</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">tvm_output</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="n">ranks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">scores</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;class=&#39;</span><span class="si">%s</span><span class="s2">&#39; with probability=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">labels</span></a><span class="p">[</span><span class="n">rank</span><span class="p">],</span> <span class="n">scores</span><span class="p">[</span><span class="n">rank</span><span class="p">]))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>class=&#39;n02123045 tabby, tabby cat&#39; with probability=0.621103
class=&#39;n02123159 tiger cat&#39; with probability=0.356379
class=&#39;n02124075 Egyptian cat&#39; with probability=0.019712
class=&#39;n02129604 tiger, Panthera tigris&#39; with probability=0.001215
class=&#39;n04040759 radiator&#39; with probability=0.000262
</pre></div>
</div>
<p>This should produce the following output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># class=&#39;n02123045 tabby, tabby cat&#39; with probability=0.610553</span>
<span class="c1"># class=&#39;n02123159 tiger cat&#39; with probability=0.367179</span>
<span class="c1"># class=&#39;n02124075 Egyptian cat&#39; with probability=0.019365</span>
<span class="c1"># class=&#39;n02129604 tiger, Panthera tigris&#39; with probability=0.001273</span>
<span class="c1"># class=&#39;n04040759 radiator&#39; with probability=0.000261</span>
</pre></div>
</div>
</div>
<div class="section" id="tune-the-model">
<h2>Tune the model<a class="headerlink" href="#tune-the-model" title="Permalink to this headline">¶</a></h2>
<p>The previous model was compiled to work on the TVM runtime, but did not
include any platform specific optimization. In this section, we will show you
how to build an optimized model using TVM to target your working platform.</p>
<p>In some cases, we might not get the expected performance when running
inferences using our compiled module. In cases like this, we can make use of
the auto-tuner, to find a better configuration for our model and get a boost
in performance. Tuning in TVM refers to the process by which a model is
optimized to run faster on a given target. This differs from training or
fine-tuning in that it does not affect the accuracy of the model, but only
the runtime performance. As part of the tuning process, TVM will try running
many different operator implementation variants to see which perform best.
The results of these runs are stored in a tuning records file.</p>
<p>In the simplest form, tuning requires you to provide three things:</p>
<ul class="simple">
<li><p>the target specification of the device you intend to run this model on</p></li>
<li><p>the path to an output file in which the tuning records will be stored</p></li>
<li><p>a path to the model to be tuned.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tvm.auto_scheduler</span> <span class="k">as</span> <span class="nn">auto_scheduler</span>
<span class="kn">from</span> <span class="nn">tvm.autotvm.tuner</span> <span class="kn">import</span> <a href="../reference/api/python/autotvm.html#tvm.autotvm.tuner.XGBTuner" title="tvm.autotvm.tuner.XGBTuner" class="sphx-glr-backref-module-tvm-autotvm-tuner sphx-glr-backref-type-py-class"><span class="n">XGBTuner</span></a>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">autotvm</span>
</pre></div>
</div>
<p>Set up some basic parameters for the runner. The runner takes compiled code
that is generated with a specific set of parameters and measures the
performance of it. <code class="docutils literal notranslate"><span class="pre">number</span></code> specifies the number of different
configurations that we will test, while <code class="docutils literal notranslate"><span class="pre">repeat</span></code> specifies how many
measurements we will take of each configuration. <code class="docutils literal notranslate"><span class="pre">min_repeat_ms</span></code> is a value
that specifies how long need to run configuration test. If the number of
repeats falls under this time, it will be increased. This option is necessary
for accurate tuning on GPUs, and is not required for CPU tuning. Setting this
value to 0 disables it. The <code class="docutils literal notranslate"><span class="pre">timeout</span></code> places an upper limit on how long to
run training code for each tested configuration.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">number</span></a> <span class="o">=</span> <span class="mi">10</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">repeat</span></a> <span class="o">=</span> <span class="mi">1</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">min_repeat_ms</span></a> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># since we&#39;re tuning on a CPU, can be set to 0</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timeout</span></a> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># in seconds</span>

<span class="c1"># create a TVM runner</span>
<span class="n">runner</span> <span class="o">=</span> <span class="n">autotvm</span><span class="o">.</span><span class="n">LocalRunner</span><span class="p">(</span>
    <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">number</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">number</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">repeat</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">repeat</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timeout</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timeout</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">min_repeat_ms</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">min_repeat_ms</span></a><span class="p">,</span>
    <span class="n">enable_cpu_cache_flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Create a simple structure for holding tuning options. We use an XGBoost
algorithim for guiding the search. For a production job, you will want to set
the number of trials to be larger than the value of 20 used here. For CPU we
recommend 1500, for GPU 3000-4000. The number of trials required can depend
on the particular model and processor, so it’s worth spending some time
evaluating performance across a range of values to find the best balance
between tuning time and model optimization. Because running tuning is time
intensive we set number of trials to 10, but do not recommend a value this
small. The <code class="docutils literal notranslate"><span class="pre">early_stopping</span></code> parameter is the minimum number of trails to
run before a condition that stops the search early can be applied. The
measure option indicates where trial code will be built, and where it will be
run. In this case, we’re using the <code class="docutils literal notranslate"><span class="pre">LocalRunner</span></code> we just created and a
<code class="docutils literal notranslate"><span class="pre">LocalBuilder</span></code>. The <code class="docutils literal notranslate"><span class="pre">tuning_records</span></code> option specifies a file to write
the tuning data to.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tuning_option</span></a> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;tuner&quot;</span><span class="p">:</span> <span class="s2">&quot;xgb&quot;</span><span class="p">,</span>
    <span class="s2">&quot;trials&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="s2">&quot;early_stopping&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s2">&quot;measure_option&quot;</span><span class="p">:</span> <span class="n">autotvm</span><span class="o">.</span><span class="n">measure_option</span><span class="p">(</span>
        <span class="n">builder</span><span class="o">=</span><span class="n">autotvm</span><span class="o">.</span><span class="n">LocalBuilder</span><span class="p">(</span><span class="n">build_func</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">),</span> <span class="n">runner</span><span class="o">=</span><span class="n">runner</span>
    <span class="p">),</span>
    <span class="s2">&quot;tuning_records&quot;</span><span class="p">:</span> <span class="s2">&quot;resnet-50-v2-autotuning.json&quot;</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="admonition-defining-the-tuning-search-algorithm admonition">
<p class="admonition-title">Defining the Tuning Search Algorithm</p>
<p>By default this search is guided using an <cite>XGBoost Grid</cite> algorithm.
Depending on your model complexity and amount of time available, you might
want to choose a different algorithm.</p>
</div>
<div class="admonition-setting-tuning-parameters admonition">
<p class="admonition-title">Setting Tuning Parameters</p>
<p>In this example, in the interest of time, we set the number of trials and
early stopping to 20 and 100. You will likely see more performance improvements if
you set these values to be higher but this comes at the expense of time
spent tuning. The number of trials required for convergence will vary
depending on the specifics of the model and the target platform.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># begin by extracting the tasks from the onnx model</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tasks</span></a> <span class="o">=</span> <span class="n">autotvm</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">extract_from_program</span><span class="p">(</span><span class="n">mod</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">],</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="p">)</span>

<span class="c1"># Tune the extracted tasks sequentially.</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a><span class="p">,</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tasks</span></a><span class="p">):</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">prefix</span></a> <span class="o">=</span> <span class="s2">&quot;[Task </span><span class="si">%2d</span><span class="s2">/</span><span class="si">%2d</span><span class="s2">] &quot;</span> <span class="o">%</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tasks</span></a><span class="p">))</span>
    <a href="../reference/api/python/autotvm.html#tvm.autotvm.tuner.XGBTuner" title="tvm.autotvm.tuner.XGBTuner" class="sphx-glr-backref-module-tvm-autotvm-tuner sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tuner_obj</span></a> <span class="o">=</span> <a href="../reference/api/python/autotvm.html#tvm.autotvm.tuner.XGBTuner" title="tvm.autotvm.tuner.XGBTuner" class="sphx-glr-backref-module-tvm-autotvm-tuner sphx-glr-backref-type-py-class"><span class="n">XGBTuner</span></a><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">loss_type</span><span class="o">=</span><span class="s2">&quot;rank&quot;</span><span class="p">)</span>
    <a href="../reference/api/python/autotvm.html#tvm.autotvm.tuner.XGBTuner.tune" title="tvm.autotvm.tuner.XGBTuner.tune" class="sphx-glr-backref-module-tvm-autotvm-tuner sphx-glr-backref-type-py-method"><span class="n">tuner_obj</span><span class="o">.</span><span class="n">tune</span></a><span class="p">(</span>
        <span class="n">n_trial</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tuning_option</span></a><span class="p">[</span><span class="s2">&quot;trials&quot;</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">config_space</span><span class="p">)),</span>
        <span class="n">early_stopping</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tuning_option</span></a><span class="p">[</span><span class="s2">&quot;early_stopping&quot;</span><span class="p">],</span>
        <span class="n">measure_option</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tuning_option</span></a><span class="p">[</span><span class="s2">&quot;measure_option&quot;</span><span class="p">],</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span>
            <span class="n">autotvm</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">progress_bar</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tuning_option</span></a><span class="p">[</span><span class="s2">&quot;trials&quot;</span><span class="p">],</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">prefix</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">prefix</span></a><span class="p">),</span>
            <span class="n">autotvm</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">log_to_file</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tuning_option</span></a><span class="p">[</span><span class="s2">&quot;tuning_records&quot;</span><span class="p">]),</span>
        <span class="p">],</span>
    <span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[Task  1/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task  1/25]  Current/Best:   19.10/  19.10 GFLOPS | Progress: (4/20) | 7.39 s
[Task  1/25]  Current/Best:    1.82/  22.72 GFLOPS | Progress: (8/20) | 11.51 s
[Task  1/25]  Current/Best:    6.70/  22.72 GFLOPS | Progress: (12/20) | 15.42 s
[Task  1/25]  Current/Best:    8.62/  22.72 GFLOPS | Progress: (16/20) | 18.71 s
[Task  1/25]  Current/Best:   14.03/  22.72 GFLOPS | Progress: (20/20) | 21.97 s Done.

[Task  2/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task  2/25]  Current/Best:   20.03/  20.03 GFLOPS | Progress: (4/20) | 3.95 s
[Task  2/25]  Current/Best:   12.24/  20.84 GFLOPS | Progress: (8/20) | 5.43 s
[Task  2/25]  Current/Best:   14.56/  20.84 GFLOPS | Progress: (12/20) | 7.58 s
[Task  2/25]  Current/Best:   22.32/  22.32 GFLOPS | Progress: (16/20) | 9.19 s
[Task  2/25]  Current/Best:   19.79/  22.32 GFLOPS | Progress: (20/20) | 11.10 s Done.

[Task  3/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task  3/25]  Current/Best:   12.58/  19.21 GFLOPS | Progress: (4/20) | 4.10 s
[Task  3/25]  Current/Best:   17.18/  20.46 GFLOPS | Progress: (8/20) | 6.09 s
[Task  3/25]  Current/Best:    9.72/  20.46 GFLOPS | Progress: (12/20) | 8.34 s
[Task  3/25]  Current/Best:   21.61/  21.61 GFLOPS | Progress: (16/20) | 10.73 s
[Task  3/25]  Current/Best:   12.88/  23.43 GFLOPS | Progress: (20/20) | 12.89 s Done.

[Task  4/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task  4/25]  Current/Best:   16.14/  16.14 GFLOPS | Progress: (4/20) | 4.26 s
[Task  4/25]  Current/Best:    8.40/  16.14 GFLOPS | Progress: (8/20) | 6.79 s
[Task  4/25]  Current/Best:    5.15/  16.30 GFLOPS | Progress: (12/20) | 12.10 s
[Task  4/25]  Current/Best:   11.96/  16.30 GFLOPS | Progress: (16/20) | 14.22 s
[Task  4/25]  Current/Best:    6.76/  21.71 GFLOPS | Progress: (20/20) | 17.07 s Done.

[Task  5/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task  5/25]  Current/Best:    1.68/  17.02 GFLOPS | Progress: (4/20) | 4.55 s
[Task  5/25]  Current/Best:    6.08/  17.02 GFLOPS | Progress: (8/20) | 6.85 s
[Task  5/25]  Current/Best:   14.14/  17.02 GFLOPS | Progress: (12/20) | 9.93 s
[Task  5/25]  Current/Best:    5.83/  18.48 GFLOPS | Progress: (16/20) | 11.96 s
[Task  5/25]  Current/Best:    9.02/  18.48 GFLOPS | Progress: (20/20) | 13.78 s Done.

[Task  6/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task  6/25]  Current/Best:   17.72/  17.72 GFLOPS | Progress: (4/20) | 4.36 s
[Task  6/25]  Current/Best:    8.89/  17.72 GFLOPS | Progress: (8/20) | 11.53 s
[Task  6/25]  Current/Best:    6.07/  17.72 GFLOPS | Progress: (12/20) | 14.55 s
[Task  6/25]  Current/Best:   11.63/  17.72 GFLOPS | Progress: (16/20) | 16.97 s
[Task  6/25]  Current/Best:   17.12/  20.33 GFLOPS | Progress: (20/20) | 18.86 s Done.

[Task  7/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task  7/25]  Current/Best:    1.58/  16.66 GFLOPS | Progress: (4/20) | 5.24 s
[Task  7/25]  Current/Best:   11.84/  18.50 GFLOPS | Progress: (8/20) | 8.34 s
[Task  7/25]  Current/Best:   18.74/  18.74 GFLOPS | Progress: (12/20) | 11.10 s
[Task  7/25]  Current/Best:   18.75/  18.75 GFLOPS | Progress: (16/20) | 13.26 s
[Task  7/25]  Current/Best:    9.93/  21.74 GFLOPS | Progress: (20/20) | 15.34 s Done.

[Task  8/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task  8/25]  Current/Best:   11.66/  11.66 GFLOPS | Progress: (4/20) | 13.85 s
[Task  8/25]  Current/Best:    5.61/  14.32 GFLOPS | Progress: (8/20) | 17.46 s
[Task  8/25]  Current/Best:   13.72/  15.03 GFLOPS | Progress: (12/20) | 22.11 s
[Task  8/25]  Current/Best:    5.95/  15.03 GFLOPS | Progress: (16/20) | 25.48 s
[Task  8/25]  Current/Best:   11.95/  15.03 GFLOPS | Progress: (20/20) | 32.65 s
[Task  9/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task  9/25]  Current/Best:   21.99/  21.99 GFLOPS | Progress: (4/20) | 7.59 s
[Task  9/25]  Current/Best:   10.48/  21.99 GFLOPS | Progress: (8/20) | 14.06 s
[Task  9/25]  Current/Best:    6.82/  21.99 GFLOPS | Progress: (12/20) | 25.44 s
[Task  9/25]  Current/Best:    5.84/  21.99 GFLOPS | Progress: (16/20) | 28.41 s
[Task  9/25]  Current/Best:   20.75/  21.99 GFLOPS | Progress: (20/20) | 30.16 s
[Task 10/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 10/25]  Current/Best:   14.94/  15.42 GFLOPS | Progress: (4/20) | 3.99 s
[Task 10/25]  Current/Best:    6.68/  15.42 GFLOPS | Progress: (8/20) | 7.07 s
[Task 10/25]  Current/Best:   16.15/  16.15 GFLOPS | Progress: (12/20) | 8.75 s
[Task 10/25]  Current/Best:    5.31/  19.57 GFLOPS | Progress: (16/20) | 11.08 s
[Task 10/25]  Current/Best:   16.59/  19.57 GFLOPS | Progress: (20/20) | 12.67 s Done.

[Task 11/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 11/25]  Current/Best:   12.36/  12.36 GFLOPS | Progress: (4/20) | 5.73 s
[Task 11/25]  Current/Best:   15.41/  15.41 GFLOPS | Progress: (8/20) | 8.46 s
[Task 11/25]  Current/Best:   13.23/  17.80 GFLOPS | Progress: (12/20) | 11.00 s
[Task 11/25]  Current/Best:   15.64/  17.80 GFLOPS | Progress: (16/20) | 13.15 s
[Task 11/25]  Current/Best:   10.19/  17.80 GFLOPS | Progress: (20/20) | 15.83 s Done.

[Task 12/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 12/25]  Current/Best:    9.42/  18.19 GFLOPS | Progress: (4/20) | 3.77 s
[Task 12/25]  Current/Best:   20.34/  20.34 GFLOPS | Progress: (8/20) | 7.02 s
[Task 12/25]  Current/Best:   10.87/  20.34 GFLOPS | Progress: (12/20) | 9.96 s
[Task 12/25]  Current/Best:    1.51/  20.34 GFLOPS | Progress: (16/20) | 13.83 s
[Task 12/25]  Current/Best:   11.36/  20.34 GFLOPS | Progress: (20/20) | 16.61 s Done.

[Task 13/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 13/25]  Current/Best:    3.06/  16.36 GFLOPS | Progress: (4/20) | 4.98 s Done.
 Done.

[Task 13/25]  Current/Best:   21.93/  21.93 GFLOPS | Progress: (8/20) | 8.55 s
[Task 13/25]  Current/Best:    1.57/  21.93 GFLOPS | Progress: (12/20) | 14.53 s
[Task 13/25]  Current/Best:   20.16/  21.93 GFLOPS | Progress: (16/20) | 18.12 s
[Task 13/25]  Current/Best:    8.67/  21.93 GFLOPS | Progress: (20/20) | 20.52 s Done.

[Task 14/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 14/25]  Current/Best:   10.58/  16.35 GFLOPS | Progress: (4/20) | 3.40 s
[Task 14/25]  Current/Best:   15.22/  16.35 GFLOPS | Progress: (8/20) | 7.45 s
[Task 14/25]  Current/Best:    5.76/  16.35 GFLOPS | Progress: (12/20) | 11.73 s
[Task 14/25]  Current/Best:    2.75/  16.35 GFLOPS | Progress: (16/20) | 14.99 s
[Task 14/25]  Current/Best:   15.73/  16.35 GFLOPS | Progress: (20/20) | 17.20 s
[Task 15/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 15/25]  Current/Best:    6.82/  19.41 GFLOPS | Progress: (4/20) | 7.47 s
[Task 15/25]  Current/Best:   10.01/  19.41 GFLOPS | Progress: (8/20) | 9.32 s
[Task 15/25]  Current/Best:   10.90/  20.43 GFLOPS | Progress: (12/20) | 11.64 s
[Task 15/25]  Current/Best:    7.84/  20.43 GFLOPS | Progress: (16/20) | 16.06 s
[Task 15/25]  Current/Best:   15.16/  20.43 GFLOPS | Progress: (20/20) | 18.54 s
[Task 16/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 16/25]  Current/Best:   14.97/  14.97 GFLOPS | Progress: (4/20) | 4.27 s
[Task 16/25]  Current/Best:   11.81/  17.87 GFLOPS | Progress: (8/20) | 6.16 s
[Task 16/25]  Current/Best:   11.82/  17.87 GFLOPS | Progress: (12/20) | 8.16 s
[Task 16/25]  Current/Best:   12.23/  17.87 GFLOPS | Progress: (16/20) | 10.70 s Done.
 Done.

[Task 16/25]  Current/Best:   13.14/  18.05 GFLOPS | Progress: (20/20) | 12.49 s Done.

[Task 17/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 17/25]  Current/Best:   19.33/  19.33 GFLOPS | Progress: (4/20) | 4.15 s
[Task 17/25]  Current/Best:   18.74/  19.33 GFLOPS | Progress: (8/20) | 7.16 s
[Task 17/25]  Current/Best:    3.10/  19.33 GFLOPS | Progress: (12/20) | 10.26 s
[Task 17/25]  Current/Best:    6.22/  23.86 GFLOPS | Progress: (16/20) | 12.59 s
[Task 17/25]  Current/Best:   11.19/  23.86 GFLOPS | Progress: (20/20) | 16.29 s Done.

[Task 18/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 18/25]  Current/Best:   16.03/  17.31 GFLOPS | Progress: (4/20) | 5.64 s
[Task 18/25]  Current/Best:    9.82/  17.61 GFLOPS | Progress: (8/20) | 7.81 s
[Task 18/25]  Current/Best:   12.20/  17.79 GFLOPS | Progress: (12/20) | 10.32 s
[Task 18/25]  Current/Best:   14.46/  17.79 GFLOPS | Progress: (16/20) | 12.55 s
[Task 18/25]  Current/Best:   16.76/  17.79 GFLOPS | Progress: (20/20) | 14.55 s Done.

[Task 19/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 19/25]  Current/Best:    3.09/  13.64 GFLOPS | Progress: (4/20) | 9.05 s
[Task 19/25]  Current/Best:   12.62/  18.18 GFLOPS | Progress: (8/20) | 11.95 s
[Task 19/25]  Current/Best:   11.02/  20.23 GFLOPS | Progress: (12/20) | 14.84 s
[Task 19/25]  Current/Best:   18.88/  20.23 GFLOPS | Progress: (16/20) | 19.12 s
[Task 19/25]  Current/Best:   12.81/  20.23 GFLOPS | Progress: (20/20) | 25.96 s Done.

[Task 20/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 20/25]  Current/Best:    9.86/   9.86 GFLOPS | Progress: (4/20) | 8.52 s
[Task 20/25]  Current/Best:    7.68/   9.86 GFLOPS | Progress: (8/20) | 12.51 s
[Task 20/25]  Current/Best:    9.92/  10.65 GFLOPS | Progress: (12/20) | 16.01 s
[Task 20/25]  Current/Best:   11.62/  11.62 GFLOPS | Progress: (16/20) | 20.58 s
[Task 20/25]  Current/Best:   12.27/  12.27 GFLOPS | Progress: (20/20) | 22.36 s
[Task 21/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 21/25]  Current/Best:    6.36/  18.55 GFLOPS | Progress: (4/20) | 4.26 s
[Task 21/25]  Current/Best:   20.69/  20.69 GFLOPS | Progress: (8/20) | 6.20 s
[Task 21/25]  Current/Best:    8.95/  20.69 GFLOPS | Progress: (12/20) | 7.98 s
[Task 21/25]  Current/Best:   20.06/  20.69 GFLOPS | Progress: (16/20) | 9.64 s
[Task 21/25]  Current/Best:    8.74/  20.69 GFLOPS | Progress: (20/20) | 14.36 s
[Task 22/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 22/25]  Current/Best:   10.41/  12.32 GFLOPS | Progress: (4/20) | 5.09 s
[Task 22/25]  Current/Best:    2.40/  16.71 GFLOPS | Progress: (8/20) | 7.68 s
[Task 22/25]  Current/Best:   14.85/  21.91 GFLOPS | Progress: (12/20) | 9.57 s
[Task 22/25]  Current/Best:    6.19/  21.91 GFLOPS | Progress: (16/20) | 11.44 s
[Task 22/25]  Current/Best:   12.39/  21.91 GFLOPS | Progress: (20/20) | 13.63 s Done.

[Task 23/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 23/25]  Current/Best:   12.14/  21.45 GFLOPS | Progress: (4/20) | 4.80 s
[Task 23/25]  Current/Best:   13.40/  21.45 GFLOPS | Progress: (8/20) | 7.11 s
[Task 23/25]  Current/Best:   16.48/  23.90 GFLOPS | Progress: (12/20) | 10.25 s
[Task 23/25]  Current/Best:   10.70/  23.90 GFLOPS | Progress: (16/20) | 14.26 s
[Task 23/25]  Current/Best:   14.79/  23.90 GFLOPS | Progress: (20/20) | 17.86 s Done.

[Task 24/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 24/25]  Current/Best:    3.34/   6.42 GFLOPS | Progress: (4/20) | 7.82 s
[Task 24/25]  Current/Best:    3.41/   8.38 GFLOPS | Progress: (8/20) | 9.17 s
[Task 24/25]  Current/Best:    1.16/   9.27 GFLOPS | Progress: (12/20) | 19.84 s
[Task 24/25]  Current/Best:    5.17/   9.95 GFLOPS | Progress: (16/20) | 30.78 s Done.
 Done.

[Task 24/25]  Current/Best:    1.85/   9.95 GFLOPS | Progress: (20/20) | 42.27 s
[Task 25/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s
[Task 25/25]  Current/Best:    8.44/   9.99 GFLOPS | Progress: (4/20) | 5.82 s
[Task 25/25]  Current/Best:    8.11/   9.99 GFLOPS | Progress: (8/20) | 11.50 s
[Task 25/25]  Current/Best:    1.55/   9.99 GFLOPS | Progress: (12/20) | 13.17 s
[Task 25/25]  Current/Best:    2.99/   9.99 GFLOPS | Progress: (16/20) | 18.63 s
[Task 25/25]  Current/Best:    8.72/   9.99 GFLOPS | Progress: (20/20) | 29.28 s
</pre></div>
</div>
<p>The output from this tuning process will look something like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># [Task  1/24]  Current/Best:   10.71/  21.08 GFLOPS | Progress: (60/1000) | 111.77 s Done.</span>
<span class="c1"># [Task  1/24]  Current/Best:    9.32/  24.18 GFLOPS | Progress: (192/1000) | 365.02 s Done.</span>
<span class="c1"># [Task  2/24]  Current/Best:   22.39/ 177.59 GFLOPS | Progress: (960/1000) | 976.17 s Done.</span>
<span class="c1"># [Task  3/24]  Current/Best:   32.03/ 153.34 GFLOPS | Progress: (800/1000) | 776.84 s Done.</span>
<span class="c1"># [Task  4/24]  Current/Best:   11.96/ 156.49 GFLOPS | Progress: (960/1000) | 632.26 s Done.</span>
<span class="c1"># [Task  5/24]  Current/Best:   23.75/ 130.78 GFLOPS | Progress: (800/1000) | 739.29 s Done.</span>
<span class="c1"># [Task  6/24]  Current/Best:   38.29/ 198.31 GFLOPS | Progress: (1000/1000) | 624.51 s Done.</span>
<span class="c1"># [Task  7/24]  Current/Best:    4.31/ 210.78 GFLOPS | Progress: (1000/1000) | 701.03 s Done.</span>
<span class="c1"># [Task  8/24]  Current/Best:   50.25/ 185.35 GFLOPS | Progress: (972/1000) | 538.55 s Done.</span>
<span class="c1"># [Task  9/24]  Current/Best:   50.19/ 194.42 GFLOPS | Progress: (1000/1000) | 487.30 s Done.</span>
<span class="c1"># [Task 10/24]  Current/Best:   12.90/ 172.60 GFLOPS | Progress: (972/1000) | 607.32 s Done.</span>
<span class="c1"># [Task 11/24]  Current/Best:   62.71/ 203.46 GFLOPS | Progress: (1000/1000) | 581.92 s Done.</span>
<span class="c1"># [Task 12/24]  Current/Best:   36.79/ 224.71 GFLOPS | Progress: (1000/1000) | 675.13 s Done.</span>
<span class="c1"># [Task 13/24]  Current/Best:    7.76/ 219.72 GFLOPS | Progress: (1000/1000) | 519.06 s Done.</span>
<span class="c1"># [Task 14/24]  Current/Best:   12.26/ 202.42 GFLOPS | Progress: (1000/1000) | 514.30 s Done.</span>
<span class="c1"># [Task 15/24]  Current/Best:   31.59/ 197.61 GFLOPS | Progress: (1000/1000) | 558.54 s Done.</span>
<span class="c1"># [Task 16/24]  Current/Best:   31.63/ 206.08 GFLOPS | Progress: (1000/1000) | 708.36 s Done.</span>
<span class="c1"># [Task 17/24]  Current/Best:   41.18/ 204.45 GFLOPS | Progress: (1000/1000) | 736.08 s Done.</span>
<span class="c1"># [Task 18/24]  Current/Best:   15.85/ 222.38 GFLOPS | Progress: (980/1000) | 516.73 s Done.</span>
<span class="c1"># [Task 19/24]  Current/Best:   15.78/ 203.41 GFLOPS | Progress: (1000/1000) | 587.13 s Done.</span>
<span class="c1"># [Task 20/24]  Current/Best:   30.47/ 205.92 GFLOPS | Progress: (980/1000) | 471.00 s Done.</span>
<span class="c1"># [Task 21/24]  Current/Best:   46.91/ 227.99 GFLOPS | Progress: (308/1000) | 219.18 s Done.</span>
<span class="c1"># [Task 22/24]  Current/Best:   13.33/ 207.66 GFLOPS | Progress: (1000/1000) | 761.74 s Done.</span>
<span class="c1"># [Task 23/24]  Current/Best:   53.29/ 192.98 GFLOPS | Progress: (1000/1000) | 799.90 s Done.</span>
<span class="c1"># [Task 24/24]  Current/Best:   25.03/ 146.14 GFLOPS | Progress: (1000/1000) | 1112.55 s Done.</span>
</pre></div>
</div>
</div>
<div class="section" id="compiling-an-optimized-model-with-tuning-data">
<h2>Compiling an Optimized Model with Tuning Data<a class="headerlink" href="#compiling-an-optimized-model-with-tuning-data" title="Permalink to this headline">¶</a></h2>
<p>As an output of the tuning process above, we obtained the tuning records
stored in <code class="docutils literal notranslate"><span class="pre">resnet-50-v2-autotuning.json</span></code>. The compiler will use the results to
generate high performance code for the model on your specified target.</p>
<p>Now that tuning data for the model has been collected, we can re-compile the
model using optimized operators to speed up our computations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <a href="../reference/api/python/autotvm.html#tvm.autotvm.apply_history_best" title="tvm.autotvm.apply_history_best" class="sphx-glr-backref-module-tvm-autotvm sphx-glr-backref-type-py-function"><span class="n">autotvm</span><span class="o">.</span><span class="n">apply_history_best</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tuning_option</span></a><span class="p">[</span><span class="s2">&quot;tuning_records&quot;</span><span class="p">]):</span>
    <span class="k">with</span> <a href="../reference/api/python/ir.html#tvm.transform.PassContext" title="tvm.transform.PassContext" class="sphx-glr-backref-module-tvm-transform sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span></a><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{}):</span>
        <span class="n">lib</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="p">)</span>

<span class="n">dev</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule" title="tvm.contrib.graph_executor.GraphModule" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">module</span></a> <span class="o">=</span> <a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule" title="tvm.contrib.graph_executor.GraphModule" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-class"><span class="n">graph_executor</span><span class="o">.</span><span class="n">GraphModule</span></a><span class="p">(</span><span class="n">lib</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">](</span><span class="n">dev</span><span class="p">))</span>
</pre></div>
</div>
<p>Verify that the optimized model runs and produces the same results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dtype</span></a> <span class="o">=</span> <span class="s2">&quot;float32&quot;</span>
<a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule.set_input" title="tvm.contrib.graph_executor.GraphModule.set_input" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-method"><span class="n">module</span><span class="o">.</span><span class="n">set_input</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_name</span></a><span class="p">,</span> <span class="n">img_data</span><span class="p">)</span>
<a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule.run" title="tvm.contrib.graph_executor.GraphModule.run" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-method"><span class="n">module</span><span class="o">.</span><span class="n">run</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_shape</span></a> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">tvm_output</span> <span class="o">=</span> <a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule.get_output" title="tvm.contrib.graph_executor.GraphModule.get_output" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-method"><span class="n">module</span><span class="o">.</span><span class="n">get_output</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <a href="../reference/api/python/ndarray.html#tvm.nd.empty" title="tvm.nd.empty" class="sphx-glr-backref-module-tvm-nd sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">empty</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_shape</span></a><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">tvm_output</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="n">ranks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">scores</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;class=&#39;</span><span class="si">%s</span><span class="s2">&#39; with probability=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">labels</span></a><span class="p">[</span><span class="n">rank</span><span class="p">],</span> <span class="n">scores</span><span class="p">[</span><span class="n">rank</span><span class="p">]))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>class=&#39;n02123045 tabby, tabby cat&#39; with probability=0.621103
class=&#39;n02123159 tiger cat&#39; with probability=0.356379
class=&#39;n02124075 Egyptian cat&#39; with probability=0.019712
class=&#39;n02129604 tiger, Panthera tigris&#39; with probability=0.001215
class=&#39;n04040759 radiator&#39; with probability=0.000262
</pre></div>
</div>
<p>Verifying that the predictions are the same:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># class=&#39;n02123045 tabby, tabby cat&#39; with probability=0.610550</span>
<span class="c1"># class=&#39;n02123159 tiger cat&#39; with probability=0.367181</span>
<span class="c1"># class=&#39;n02124075 Egyptian cat&#39; with probability=0.019365</span>
<span class="c1"># class=&#39;n02129604 tiger, Panthera tigris&#39; with probability=0.001273</span>
<span class="c1"># class=&#39;n04040759 radiator&#39; with probability=0.000261</span>
</pre></div>
</div>
</div>
<div class="section" id="comparing-the-tuned-and-untuned-models">
<h2>Comparing the Tuned and Untuned Models<a class="headerlink" href="#comparing-the-tuned-and-untuned-models" title="Permalink to this headline">¶</a></h2>
<p>We want to collect some basic performance data associated with this optimized
model to compare it to the unoptimized model. Depending on your underlying
hardware, number of iterations, and other factors, you should see a performance
improvement in comparing the optimized model to the unoptimized model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">timeit</span>

<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timing_number</span></a> <span class="o">=</span> <span class="mi">10</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timing_repeat</span></a> <span class="o">=</span> <span class="mi">10</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimized</span></a> <span class="o">=</span> <span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><a href="https://docs.python.org/3/library/timeit.html#timeit.Timer" title="timeit.Timer" class="sphx-glr-backref-module-timeit sphx-glr-backref-type-py-class"><span class="n">timeit</span><span class="o">.</span><span class="n">Timer</span></a><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <a href="../reference/api/python/graph_executor.html#tvm.contrib.graph_executor.GraphModule.run" title="tvm.contrib.graph_executor.GraphModule.run" class="sphx-glr-backref-module-tvm-contrib-graph_executor sphx-glr-backref-type-py-method"><span class="n">module</span><span class="o">.</span><span class="n">run</span></a><span class="p">())</span><span class="o">.</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">repeat</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">repeat</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timing_repeat</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">number</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timing_number</span></a><span class="p">))</span>
    <span class="o">*</span> <span class="mi">1000</span>
    <span class="o">/</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">timing_number</span></a>
<span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimized</span></a> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimized</span></a><span class="p">),</span> <span class="s2">&quot;median&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimized</span></a><span class="p">),</span> <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimized</span></a><span class="p">)}</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;optimized: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimized</span></a><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;unoptimized: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">unoptimized</span></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>optimized: {&#39;mean&#39;: 425.82463468999777, &#39;median&#39;: 425.7106710500011, &#39;std&#39;: 0.8921467986797177}
unoptimized: {&#39;mean&#39;: 510.8778525799971, &#39;median&#39;: 510.608007299993, &#39;std&#39;: 1.4270214411428404}
</pre></div>
</div>
</div>
<div class="section" id="final-remarks">
<h2>Final Remarks<a class="headerlink" href="#final-remarks" title="Permalink to this headline">¶</a></h2>
<p>In this tutorial, we gave a short example of how to use the TVM Python API
to compile, run, and tune a model. We also discussed the need for pre and
post-processing of inputs and outputs. After the tuning process, we
demonstrated how to compare the performance of the unoptimized and optimize
models.</p>
<p>Here we presented a simple example using ResNet-50 v2 locally. However, TVM
supports many more features including cross-compilation, remote execution and
profiling/benchmarking.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 11 minutes  47.645 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorial-autotvm-relay-x86-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/57a45d9bef1af358191e7d50043e652c/autotvm_relay_x86.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">autotvm_relay_x86.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/2f91b1346a0ba21b800081aa15fdaac2/autotvm_relay_x86.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">autotvm_relay_x86.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tensor_expr_get_started.html" class="btn btn-neutral float-right" title="Working with Operators Using Tensor Expression" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="tvmc_python.html" class="btn btn-neutral float-left" title="Getting Starting using TVMC Python: a high-level API for TVM" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2022 Apache Software Foundation | All rights reserved</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote">Copyright © 2022 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>