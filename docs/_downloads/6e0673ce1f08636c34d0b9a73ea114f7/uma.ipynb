{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%shell\n# Installs the latest dev build of TVM from PyPI. If you wish to build\n# from source, see https://tvm.apache.org/docs/install/from_source.html\npip install apache-tvm --pre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Making your Hardware Accelerator TVM-ready with UMA\n**Authors**: [Michael J. Klaiber](https://github.com/MichaelJKlaiber), [Christoph Gerum](https://github.com/cgerum),\n[Paul Palomero Bernardo](https://github.com/PaulPalomeroBernardo/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is an introductory tutorial to the **Universal Modular Accelerator Interface** (UMA).\nUMA provides an easy-to-use API to integrate new hardware accelerators into TVM.\n\nThis tutorial gives you step-by-step guidance how to use UMA to\nmake your hardware accelerator TVM-ready.\nWhile there is no one-fits-all solution for this problem, UMA targets to provide a stable and Python-only\nAPI to integrate a number of hardware accelerator classes into TVM.\n\n\nIn this tutorial you will get to know the UMA API in three use cases of increasing complexity.\nIn these use case the three mock-accelerators\n**Vanilla**, **Strawberry** and **Chocolate** are introduced and\nintegrated into TVM using UMA.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vanilla\n**Vanilla** is a simple accelerator consisting of a MAC array and has no internal memory.\nIt is can ONLY process Conv2D layers, all other layers are executed on a CPU, that also orchestrates **Vanilla**.\nBoth the CPU and Vanilla use a shared memory.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://raw.githubusercontent.com/tlc-pack/web-data/main/images/tutorial/uma_vanilla_block_diagram.png\" width=\"100%\" alt=\"A block diagram of Vanilla\">\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Vanilla** has a C interface ``vanilla_conv2dnchw(...)``` for carrying out a Conv2D operation (including same-padding),\nthat accepts pointers to input feature map, weights and result,\nas well as the dimensions of `Conv2D`: `oc`, `iw`, `ih`, `ic`, `kh`, `kw`.\n\n```c++\nint vanilla_conv2dnchw(float* ifmap, float*  weights, float*  result, int oc, int iw, int ih, int ic, int kh, int kw);\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The script `uma_cli` creates code skeletons with API-calls into the UMA-API for new accelerators.\n\nFor **Vanilla** we use it as follows: (``--tutorial vanilla`` adds all the additional files required for this part of the tutorial)\n\n```bash\npip install inflection\ncd $TVM_HOME/apps/uma\npython uma_cli.py --add_hardware vanilla_accelerator --tutorial vanilla\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "uma_cli.py generates these files in the directory ``vanilla_accelerator`` which we are going to revist.\n\n```bash\nbackend.py\ncodegen.py\nconv2dnchw.cc\npasses.py\npatterns.py\nrun.py\nstrategies.py\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vanilla backend\n\n The generated backend for vanilla is found in `vanilla_accelerator/backend.py`:\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\nclass VanillaAcceleratorBackend(UMABackend):\n    \"\"\"UMA backend for VanillaAccelerator.\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n        self._register_pattern(\"conv2d\", conv2d_pattern())\n        self._register_tir_pass(PassPhase.TIR_PHASE_0, VanillaAcceleratorConv2DPass())\n        self._register_codegen(fmt=\"c\", includes=gen_includes)\n\n    @property\n    def target_name(self):\n        return \"vanilla_accelerator\"\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define offloaded patterns\n\nTo specify that `Conv2D` is offloaded to **Vanilla**, it is described as Relay dataflow pattern\n([DFPattern](https://tvm.apache.org/docs/reference/langref/relay_pattern.html)) in `vanilla_accelerator/patterns.py`\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\ndef conv2d_pattern():\n    pattern = is_op(\"nn.conv2d\")(wildcard(), wildcard())\n    pattern = pattern.has_attr({\"strides\": [1, 1]})\n    return pattern\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To map **Conv2D** operations from the input graph  to **Vanilla**'s\nlow level function call ``vanilla_conv2dnchw(...)``, the TIR pass\n*VanillaAcceleratorConv2DPass* (that will be discussed later in this tutorial)\nis registered in `VanillaAcceleratorBackend`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Codegen\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The file ``vanilla_accelerator/codegen.py`` defines static  C-code that is added to the\nresulting C-Code generated by TVM\u015b C-Codegen in ``gen_includes``.\nHere C-code is added to include **Vanilla**'s low level library``vanilla_conv2dnchw()``.\n\n```python\ndef gen_includes() -> str:\n    topdir = pathlib.Path(__file__).parent.absolute()\n\n    includes = \"\"\n    includes += f'#include \"{topdir}/conv2dnchw.cc\"'\n    return includes\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As shown above in `VanillaAcceleratorBackend` it is registered to UMA with\nthe `self._register_codegen`\n\n```python\nself._register_codegen(fmt=\"c\", includes=gen_includes)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Building the Neural Network and run it on Vanilla\n\nTo demonstrate UMA's functionality, we will generate C code for a single Conv2D layer and run it on\nthe Vanilla accelerator.\nThe file ``vanilla_accelerator/run.py`` provides a demo running a Conv2D layer\nmaking use of Vanilla's C-API.\n\n\n```python\ndef main():\n    mod, inputs, output_list, runner = create_conv2d()\n\n    uma_backend = VanillaAcceleratorBackend()\n    uma_backend.register()\n    mod = uma_backend.partition(mod)\n    target = tvm.target.Target(\"vanilla_accelerator\", host=tvm.target.Target(\"c\"))\n\n    export_directory = tvm.contrib.utils.tempdir(keep_for_debug=True).path\n    print(f\"Generated files are in {export_directory}\")\n    compile_and_run(\n        AOTModel(module=mod, inputs=inputs, outputs=output_list),\n        runner,\n        interface_api=\"c\",\n        use_unpacked_api=True,\n        target=target,\n        test_dir=str(export_directory),\n    )\n\n\nmain()\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By running ``vanilla_accelerator/run.py`` the output files are generated in the model library format (MLF).\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n\n```bash\nGenerated files are in /tmp/tvm-debug-mode-tempdirs/2022-07-13T13-26-22___x5u76h0p/00000\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine the generated files:\n\n\nOutput:\n\n```bash\ncd /tmp/tvm-debug-mode-tempdirs/2022-07-13T13-26-22___x5u76h0p/00000\ncd build/\nls -1\n\ncodegen\nlib.tar\nmetadata.json\nparameters\nruntime\nsrc\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To evaluate the generated C code go to ``codegen/host/src/default_lib2.c``\n\n```bash\ncd codegen/host/src/\nls -1\n\ndefault_lib0.c\ndefault_lib1.c\ndefault_lib2.c\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In `default_lib2.c` you can now see that the generated code calls\ninto Vanilla's C-API and executes a Conv2D layer:\n\n```c++\nTVM_DLL int32_t tvmgen_default_vanilla_accelerator_main_0(float* placeholder, float* placeholder1, float* conv2d_nchw, uint8_t* global_workspace_1_var) {\n     vanilla_accelerator_conv2dnchw(placeholder, placeholder1, conv2d_nchw, 32, 14, 14, 32, 3, 3);\n     return 0;\n}\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strawberry\nComing soon ...\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chocolate\nComing soon ...\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Request for Community Input\nIf this tutorial **did not** fit to your accelerator, lease add your requirements to the UMA thread in\nthe TVM discuss forum: [Link](https://discuss.tvm.apache.org/t/rfc-uma-universal-modular-accelerator-interface/12039).\nWe are eager to extend this tutorial to provide guidance on making further classes of AI hardware\naccelerators TVM-ready using the UMA interface.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n[UMA-RFC] [UMA: Universal Modular Accelerator Interface](https://github.com/apache/tvm-rfcs/blob/main/rfcs/0060_UMA_Unified_Modular_Accelerator_Interface.md),\nTVM RFC, June 2022.\n\n[DFPattern] [Pattern Matching in Relay](https://tvm.apache.org/docs/reference/langref/relay_pattern.html)\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}