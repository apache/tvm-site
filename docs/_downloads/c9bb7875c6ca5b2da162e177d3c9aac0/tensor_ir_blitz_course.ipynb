{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%shell\n# Installs the latest dev build of TVM from PyPI, with CUDA enabled. To use this,\n# you must request a Google Colab instance with a GPU by going to Runtime ->\n# Change runtime type -> Hardware accelerator -> GPU. If you wish to build from\n# source, see see https://tvm.apache.org/docs/install/from_source.html\npip install tlcpack-nightly-cu113 --pre -f https://tlcpack.ai/wheels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Blitz Course to TensorIR\n**Author**: [Siyuan Feng](https://github.com/Hzfengsy)\n\nTensorIR is a domain specific language for deep learning programs serving two broad purposes:\n\n- An implementation for transforming and optimizing programs on various hardware backends.\n\n- An abstraction for automatic _tensorized_ program optimization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tvm\nfrom tvm.ir.module import IRModule\nfrom tvm.script import tir as T\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IRModule\nAn IRModule is the central data structure in TVM, which contains deep learning programs.\nIt is the basic object of interest of IR transformation and model building.\n\n<img src=\"https://raw.githubusercontent.com/tlc-pack/web-data/main/images/design/tvm_life_of_irmodule.png\" align=\"center\" width=\"85%\">\n\nThis is the life cycle of an IRModule, which can be created from TVMScript. TensorIR schedule\nprimitives and passes are two major ways to transform an IRModule. Also, a sequence of\ntransformations on an IRModule is acceptable. Note that we can print an IRModule at **ANY** stage\nto TVMScript. After all transformations and optimizations are complete, we can build the IRModule\nto a runnable module to deploy on target devices.\n\nBased on the design of TensorIR and IRModule, we are able to create a new programming method:\n\n1. Write a program by TVMScript in a python-AST based syntax.\n\n2. Transform and optimize a program with python api.\n\n3. Interactively inspect and try the performance with an imperative style transformation API.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create an IRModule\nIRModule can be created by writing TVMScript, which is a round-trippable syntax for TVM IR.\n\nDifferent than creating a computational expression by Tensor Expression\n(`tutorial-tensor-expr-get-started`), TensorIR allow users to program through TVMScript,\na language embedded in python AST. The new method makes it possible to write complex programs\nand further schedule and optimize it.\n\nFollowing is a simple example for vector addition.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@tvm.script.ir_module\nclass MyModule:\n    @T.prim_func\n    def main(a: T.handle, b: T.handle):\n        # We exchange data between function by handles, which are similar to pointer.\n        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n        # Create buffer from handles.\n        A = T.match_buffer(a, (8,), dtype=\"float32\")\n        B = T.match_buffer(b, (8,), dtype=\"float32\")\n        for i in range(8):\n            # A block is an abstraction for computation.\n            with T.block(\"B\"):\n                # Define a spatial block iterator and bind it to value i.\n                vi = T.axis.spatial(8, i)\n                B[vi] = A[vi] + 1.0\n\n\nir_module = MyModule\nprint(type(ir_module))\nprint(ir_module.script())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Besides, we can also use tensor expression DSL to write simple operators, and convert them\nto an IRModule.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tvm import te\n\nA = te.placeholder((8,), dtype=\"float32\", name=\"A\")\nB = te.compute((8,), lambda *i: A(*i) + 1.0, name=\"B\")\nfunc = te.create_prim_func([A, B])\nir_module_from_te = IRModule({\"main\": func})\nprint(ir_module_from_te.script())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build and Run an IRModule\nWe can build the IRModule into a runnable module with specific target backends.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod = tvm.build(ir_module, target=\"llvm\")  # The module for CPU backends.\nprint(type(mod))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare the input array and output array, then run the module.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a = tvm.nd.array(np.arange(8).astype(\"float32\"))\nb = tvm.nd.array(np.zeros((8,)).astype(\"float32\"))\nmod(a, b)\nprint(a)\nprint(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform an IRModule\nThe IRModule is the central data structure for program optimization, which can be transformed\nby :code:`Schedule`.\nA schedule contains multiple primitive methods to interactively transform the program.\nEach primitive transforms the program in certain ways to bring additional performance optimizations.\n\n<img src=\"https://raw.githubusercontent.com/tlc-pack/web-data/main/images/design/tvm_tensor_ir_opt_flow.png\" align=\"center\" width=\"100%\">\n\nThe image above is a typical workflow for optimizing a tensor program. First, we need to create a\nschedule on the initial IRModule created from either TVMScript or Tensor Expression. Then, a\nsequence of schedule primitives will help to improve the performance. And at last, we can lower\nand build it into a runnable module.\n\nHere we just demonstrate a very simple transformation. First we create schedule on the input `ir_module`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sch = tvm.tir.Schedule(ir_module)\nprint(type(sch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tile the loop into 3 loops and print the result.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get block by its name\nblock_b = sch.get_block(\"B\")\n# Get loops surrounding the block\n(i,) = sch.get_loops(block_b)\n# Tile the loop nesting.\ni_0, i_1, i_2 = sch.split(i, factors=[2, 2, 2])\nprint(sch.mod.script())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also reorder the loops. Now we move loop `i_2` to outside of `i_1`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sch.reorder(i_0, i_2, i_1)\nprint(sch.mod.script())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transform to a GPU program\nIf we want to deploy models on GPUs, thread binding is necessary. Fortunately, we can\nalso use primitives and do incrementally transformation.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sch.bind(i_0, \"blockIdx.x\")\nsch.bind(i_2, \"threadIdx.x\")\nprint(sch.mod.script())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After binding the threads, now build the IRModule with :code:`cuda` backends.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ctx = tvm.cuda(0)\ncuda_mod = tvm.build(sch.mod, target=\"cuda\")\ncuda_a = tvm.nd.array(np.arange(8).astype(\"float32\"), ctx)\ncuda_b = tvm.nd.array(np.zeros((8,)).astype(\"float32\"), ctx)\ncuda_mod(cuda_a, cuda_b)\nprint(cuda_a)\nprint(cuda_b)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}