{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%shell\n# Installs the latest dev build of TVM from PyPI. If you wish to build\n# from source, see https://tvm.apache.org/docs/install/from_source.html\npip install apache-tvm --pre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Getting Starting using TVMC Python: a high-level API for TVM\n**Author**:\n[Jocelyn Shiue](https://github.com/CircleSpin)\n\nHi! Here we explain the scripting tool designed for the complete TVM beginner. \ud83d\ude42\n\nBefore we get started let's get an example model if you don't already have one.\nFollow the steps to download a resnet model via the terminal:\n\n```python\nmkdir myscripts\ncd myscripts\nwget https://github.com/onnx/models/raw/b9a54e89508f101a1611cd64f4ef56b9cb62c7cf/vision/classification/resnet/model/resnet50-v2-7.onnx\nmv resnet50-v2-7.onnx my_model.onnx\ntouch tvmcpythonintro.py\n```\nLet's start editing the python file in your favorite text editor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Imports\n\n```python\nfrom tvm.driver import tvmc\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load a model\n\nLet's import our model into tvmc. This step converts a machine learning model from\na supported framework into TVM's high level graph representation language called Relay.\nThis is to have a unified starting point for all models in tvm. The frameworks we currently\nsupport are: Keras, ONNX, Tensorflow, TFLite, and PyTorch.\n\n```python\nmodel = tvmc.load('my_model.onnx') #Step 1: Load\n```\nIf you'd like to see the Relay, you can run:\n``model.summary()``\n\nAll frameworks support overwriting the input shapes with a shape_dict argument.\nFor most frameworks this is optional, but for Pytorch this is necessary as\nTVM cannot automatically search for it.\n\n```python\n#model = tvmc.load('my_model.onnx', shape_dict={'input1' : [1, 2, 3, 4], 'input2' : [1, 2, 3, 4]}) #Step 1: Load + shape_dict\n```\nA suggested way to see the model's input/shape_dict is via [netron](https://netron.app/). After opening the model,\nclick the first node to see the name(s) and shape(s) in the inputs section.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Compile\n\nNow that our model is in Relay, our next step is to compile it to a desired\nhardware to run on. We refer to this hardware as a target. This compilation process\ntranslates the model from Relay into a lower-level language that the\ntarget machine can understand.\n\nIn order to compile a model a tvm.target string is required.\nTo learn more about tvm.targets and their options look at the [documentation](https://tvm.apache.org/docs/api/python/target.html).\nSome examples include:\n\n   1. cuda (Nvidia GPU)\n   2. llvm (CPU)\n   3. llvm -mcpu=cascadelake (Intel CPU)\n\n```python\npackage = tvmc.compile(model, target=\"llvm\") #Step 2: Compile\n```\nThe compilation step returns a package.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Run\n\nThe compiled package can now be run on the hardware target. The device\ninput options are: CPU, Cuda, CL, Metal, and Vulkan.\n\n```python\nresult = tvmc.run(package, device=\"cpu\") #Step 3: Run\n```\nAnd you can print the results:\n``print(result)``\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.5: Tune [Optional & Recommended]\n\nRun speed can further be improved by tuning. This optional step uses\nmachine learning to look at each operation within a model (a function) and\ntries to find a faster way to run it. We do this through a cost model, and\nbenchmarking possible schedules.\n\nThe target is the same as compile.\n\n```python\ntvmc.tune(model, target=\"llvm\") #Step 1.5: Optional Tune\n```\nThe terminal output should look like:\n\n```python\n[Task  1/13]  Current/Best:   82.00/ 106.29 GFLOPS | Progress: (48/769) | 18.56 s\n[Task  1/13]  Current/Best:   54.47/ 113.50 GFLOPS | Progress: (240/769) | 85.36 s\n.....\n```\nThere may be UserWarnings that can be ignored.\nThis should make the end result faster, but it can take hours to tune.\n\nSee the section 'Saving the Tuning Results' below. Be sure to pass the tuning\nresults into compile if you want the results to apply.\n\n```python\n#tvmc.compile(model, target=\"llvm\", tuning_records = \"records.log\") #Step 2: Compile\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save and then start the process in the terminal:\n\n```python\npython my_tvmc_script.py\n```\nNote: Your fans may become very active\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example results:\n\n```python\nTime elapsed for training: 18.99 s\nExecution time summary:\nmean (ms)   max (ms)   min (ms)   std (ms)\n  25.24      26.12      24.89       0.38\n\n\nOutput Names:\n['output_0']\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional TVMC Functionalities\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving the model\n\nTo make things faster for later, after loading the model (Step 1) save the Relay version.\nThe model will then appear where you saved it for later in the coverted syntax.\n\n```python\nmodel = tvmc.load('my_model.onnx') #Step 1: Load\nmodel.save(desired_model_path)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving the package\n\nAfter the model has been compiled (Step 2) the package also is also saveable.\n\n```python\ntvmc.compile(model, target=\"llvm\", package_path=\"whatever\") #Step 2: Compile\n\nnew_package = tvmc.TVMCPackage(package_path=\"whatever\")\nresult = tvmc.run(new_package, device=\"cpu\") #Step 3: Run\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Autoscheduler\n\nUse the next generation of tvm to enable potentially faster run speed results.\nThe search space of the schedules is automatically generated unlike\npreviously where they needed to be hand written. (Learn more:\n[1](https://tvm.apache.org/2021/03/03/intro-auto-scheduler),\n[2](https://arxiv.org/abs/2006.06762))\n\n```python\ntvmc.tune(model, target=\"llvm\", enable_autoscheduler = True)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving the tuning results\n\nThe tuning results can be saved in a file for later reuse.\n\nMethod 1:\n```python\nlog_file = \"hello.json\"\n\n# Run tuning\ntvmc.tune(model, target=\"llvm\", tuning_records=log_file)\n\n...\n\n# Later run tuning and reuse tuning results\ntvmc.tune(model, target=\"llvm\", prior_records=log_file)\n```\nMethod 2:\n```python\n# Run tuning\ntuning_records = tvmc.tune(model, target=\"llvm\")\n\n...\n\n# Later run tuning and reuse tuning results\ntvmc.tune(model, target=\"llvm\", prior_records=tuning_records)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tuning a more complex model:\n\nIf you notice T's printing that look like ``.........T.T..T..T..T.T.T.T.T.T.``\nincrease the searching time frame:\n\n```python\ntvmc.tune(model,trials=10000,timeout=10,)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compiling a model for a remote device:\n\nA remote procedural call (RPC) is useful when you would like to compile for hardware\nthat is not on your local machine. The tvmc methods support this.\nTo set up the RPC server take a look at the 'Set up RPC Server on Device'\nsection in this [document](https://tvm.apache.org/docs/tutorials/get_started/cross_compilation_and_rpc.html).\n\nWithin the TVMC Script include the following and adjust accordingly:\n\n```python\ntvmc.tune(\n     model,\n     target=target, # Compilation target as string // Device to compile for\n     target_host=target_host, # Host processor\n     hostname=host_ip_address, # The IP address of an RPC tracker, used when benchmarking remotely.\n     port=port_number, # The port of the RPC tracker to connect to. Defaults to 9090.\n     rpc_key=your_key, # The RPC tracker key of the target device. Required when rpc_tracker is provided\n)\n```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}