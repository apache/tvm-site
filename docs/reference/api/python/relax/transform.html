



<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tvm.relax.transform &mdash; tvm 0.20.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/downloads/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/tlcpack_theme.css" type="text/css" />

  
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../../_static/documentation_options.js?v=1b5e2a23"></script>
        <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="tvm.tir" href="../tir/tir.html" />
    <link rel="prev" title="tvm.relax.op" href="op.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://tvm.apache.org/docs/reference/security.html>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://tvm.apache.org/docs/reference/security.html>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="sidetitle" alt="Documentation Home"> tvm
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../get_started/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../install/index.html">Installing TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../get_started/tutorials/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../get_started/tutorials/ir_module.html">IRModule</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">How To</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../how_to/tutorials/e2e_opt_model.html">End-to-End Optimize Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../how_to/tutorials/customize_opt.html">Customize Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../how_to/tutorials/optimize_llm.html">Optimize Large Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../how_to/tutorials/cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../how_to/dev/index.html">Development Guides</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Dive</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../arch/index.html">Design and Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deep_dive/tensor_ir/index.html">TensorIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deep_dive/relax/index.html">Relax</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../error.html">tvm.error</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ir.html">tvm.ir</a></li>
<li class="toctree-l2"><a class="reference internal" href="../instrument.html">tvm.instrument</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform.html">tvm.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../target.html">tvm.target</a></li>
<li class="toctree-l2"><a class="reference internal" href="../driver.html">tvm.driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../runtime/runtime.html">tvm.runtime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../runtime/ndarray.html">tvm.runtime.ndarray</a></li>
<li class="toctree-l2"><a class="reference internal" href="../runtime/relax_vm.html">tvm.runtime.relax_vm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../runtime/disco.html">tvm.runtime.disco</a></li>
<li class="toctree-l2"><a class="reference internal" href="../runtime/profiling.html">tvm.runtime.profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="relax.html">tvm.relax</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis.html">tvm.relax.analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="block_builder.html">tvm.relax.block_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="frontend.html">tvm.relax.frontend</a></li>
<li class="toctree-l2"><a class="reference internal" href="op.html">tvm.relax.op</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">tvm.relax.transform</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.AdjustMatmulOrder"><code class="docutils literal notranslate"><span class="pre">AdjustMatmulOrder()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.AllocateWorkspace"><code class="docutils literal notranslate"><span class="pre">AllocateWorkspace()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.AlterOpImpl"><code class="docutils literal notranslate"><span class="pre">AlterOpImpl()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.AnnotateTIROpPattern"><code class="docutils literal notranslate"><span class="pre">AnnotateTIROpPattern()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.AttachAttrLayoutFreeBuffers"><code class="docutils literal notranslate"><span class="pre">AttachAttrLayoutFreeBuffers()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.AttachGlobalSymbol"><code class="docutils literal notranslate"><span class="pre">AttachGlobalSymbol()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.BindParams"><code class="docutils literal notranslate"><span class="pre">BindParams()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.BindSymbolicVars"><code class="docutils literal notranslate"><span class="pre">BindSymbolicVars()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.BundleModelParams"><code class="docutils literal notranslate"><span class="pre">BundleModelParams()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.CallTIRRewrite"><code class="docutils literal notranslate"><span class="pre">CallTIRRewrite()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.CanonicalizeBindings"><code class="docutils literal notranslate"><span class="pre">CanonicalizeBindings()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.CombineParallelMatmul"><code class="docutils literal notranslate"><span class="pre">CombineParallelMatmul()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.ComputePrimValue"><code class="docutils literal notranslate"><span class="pre">ComputePrimValue()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.ConvertLayout"><code class="docutils literal notranslate"><span class="pre">ConvertLayout()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.ConvertToDataflow"><code class="docutils literal notranslate"><span class="pre">ConvertToDataflow()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.DataflowBlockPass"><code class="docutils literal notranslate"><span class="pre">DataflowBlockPass</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.DataflowUseInplaceCalls"><code class="docutils literal notranslate"><span class="pre">DataflowUseInplaceCalls()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.DeadCodeElimination"><code class="docutils literal notranslate"><span class="pre">DeadCodeElimination()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.DecomposeOpsForInference"><code class="docutils literal notranslate"><span class="pre">DecomposeOpsForInference()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.DecomposeOpsForTraining"><code class="docutils literal notranslate"><span class="pre">DecomposeOpsForTraining()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.EliminateCommonSubexpr"><code class="docutils literal notranslate"><span class="pre">EliminateCommonSubexpr()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.ExpandMatmulOfSum"><code class="docutils literal notranslate"><span class="pre">ExpandMatmulOfSum()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.ExpandTupleArguments"><code class="docutils literal notranslate"><span class="pre">ExpandTupleArguments()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.FewShotTuning"><code class="docutils literal notranslate"><span class="pre">FewShotTuning()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.FoldConstant"><code class="docutils literal notranslate"><span class="pre">FoldConstant()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.FunctionPass"><code class="docutils literal notranslate"><span class="pre">FunctionPass</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.FuseOps"><code class="docutils literal notranslate"><span class="pre">FuseOps()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.FuseOpsByPattern"><code class="docutils literal notranslate"><span class="pre">FuseOpsByPattern()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.FuseTIR"><code class="docutils literal notranslate"><span class="pre">FuseTIR()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.FusionPattern"><code class="docutils literal notranslate"><span class="pre">FusionPattern</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.Gradient"><code class="docutils literal notranslate"><span class="pre">Gradient()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.InlinePrivateFunctions"><code class="docutils literal notranslate"><span class="pre">InlinePrivateFunctions()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.KillAfterLastUse"><code class="docutils literal notranslate"><span class="pre">KillAfterLastUse()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.LambdaLift"><code class="docutils literal notranslate"><span class="pre">LambdaLift()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.LazyGetInput"><code class="docutils literal notranslate"><span class="pre">LazyGetInput()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.LazySetOutput"><code class="docutils literal notranslate"><span class="pre">LazySetOutput()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.LegalizeOps"><code class="docutils literal notranslate"><span class="pre">LegalizeOps()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.LiftTransformParams"><code class="docutils literal notranslate"><span class="pre">LiftTransformParams()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.LowerAllocTensor"><code class="docutils literal notranslate"><span class="pre">LowerAllocTensor()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.LowerRuntimeBuiltin"><code class="docutils literal notranslate"><span class="pre">LowerRuntimeBuiltin()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.MergeCompositeFunctions"><code class="docutils literal notranslate"><span class="pre">MergeCompositeFunctions()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.MetaScheduleApplyDatabase"><code class="docutils literal notranslate"><span class="pre">MetaScheduleApplyDatabase()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.MetaScheduleTuneIRMod"><code class="docutils literal notranslate"><span class="pre">MetaScheduleTuneIRMod()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.MetaScheduleTuneTIR"><code class="docutils literal notranslate"><span class="pre">MetaScheduleTuneTIR()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.Normalize"><code class="docutils literal notranslate"><span class="pre">Normalize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.NormalizeGlobalVar"><code class="docutils literal notranslate"><span class="pre">NormalizeGlobalVar()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.PatternCheckContext"><code class="docutils literal notranslate"><span class="pre">PatternCheckContext</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.RealizeVDevice"><code class="docutils literal notranslate"><span class="pre">RealizeVDevice()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.RemovePurityChecking"><code class="docutils literal notranslate"><span class="pre">RemovePurityChecking()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.RemoveUnusedOutputs"><code class="docutils literal notranslate"><span class="pre">RemoveUnusedOutputs()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.RemoveUnusedParameters"><code class="docutils literal notranslate"><span class="pre">RemoveUnusedParameters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.ReorderPermuteDimsAfterConcat"><code class="docutils literal notranslate"><span class="pre">ReorderPermuteDimsAfterConcat()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.ReorderTakeAfterMatmul"><code class="docutils literal notranslate"><span class="pre">ReorderTakeAfterMatmul()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.RewriteCUDAGraph"><code class="docutils literal notranslate"><span class="pre">RewriteCUDAGraph()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.RewriteDataflowReshape"><code class="docutils literal notranslate"><span class="pre">RewriteDataflowReshape()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.RunCodegen"><code class="docutils literal notranslate"><span class="pre">RunCodegen()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.SplitCallTIRByPattern"><code class="docutils literal notranslate"><span class="pre">SplitCallTIRByPattern()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.SplitLayoutRewritePreproc"><code class="docutils literal notranslate"><span class="pre">SplitLayoutRewritePreproc()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.StaticPlanBlockMemory"><code class="docutils literal notranslate"><span class="pre">StaticPlanBlockMemory()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.ToMixedPrecision"><code class="docutils literal notranslate"><span class="pre">ToMixedPrecision()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.ToNonDataflow"><code class="docutils literal notranslate"><span class="pre">ToNonDataflow()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.TopologicalSort"><code class="docutils literal notranslate"><span class="pre">TopologicalSort()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.UpdateParamStructInfo"><code class="docutils literal notranslate"><span class="pre">UpdateParamStructInfo()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.UpdateVDevice"><code class="docutils literal notranslate"><span class="pre">UpdateVDevice()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.VMBuiltinLower"><code class="docutils literal notranslate"><span class="pre">VMBuiltinLower()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.VMShapeLower"><code class="docutils literal notranslate"><span class="pre">VMShapeLower()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.dataflowblock_pass"><code class="docutils literal notranslate"><span class="pre">dataflowblock_pass()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.function_pass"><code class="docutils literal notranslate"><span class="pre">function_pass()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.AttachExternModules"><code class="docutils literal notranslate"><span class="pre">AttachExternModules</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.FastMathTransform"><code class="docutils literal notranslate"><span class="pre">FastMathTransform</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.FuseTransposeMatmul"><code class="docutils literal notranslate"><span class="pre">FuseTransposeMatmul</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.IPCAllReduceRewrite"><code class="docutils literal notranslate"><span class="pre">IPCAllReduceRewrite</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.LazyTransformParams"><code class="docutils literal notranslate"><span class="pre">LazyTransformParams</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.LowerGPUIPCAllocStorage"><code class="docutils literal notranslate"><span class="pre">LowerGPUIPCAllocStorage</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.OptimizeLayoutTransform"><code class="docutils literal notranslate"><span class="pre">OptimizeLayoutTransform</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tvm.relax.transform.RemoveRedundantReshape"><code class="docutils literal notranslate"><span class="pre">RemoveRedundantReshape</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tir/tir.html">tvm.tir</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tir/analysis.html">tvm.tir.analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tir/schedule.html">tvm.tir.schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tir/stmt_functor.html">tvm.tir.stmt_functor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tir/transform.html">tvm.tir.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../te.html">tvm.te</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topi.html">tvm.topi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../meta_schedule.html">tvm.meta_schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dlight.html">tvm.dlight</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rpc.html">tvm.rpc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contrib.html">tvm.contrib</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../links.html">Other APIs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../contribute/index.html">Contributor Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../security.html">Security Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Index</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="../index.html">Python API</a> <span class="br-arrow">></span></li>
        
      <li>tvm.relax.transform</li>
    
    
      
      
        
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/tvm/edit/main/docs/reference/api/python/relax/transform.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="module-tvm.relax.transform">
<span id="tvm-relax-transform"></span><span id="api-relax-transformation"></span><h1>tvm.relax.transform<a class="headerlink" href="#module-tvm.relax.transform" title="Link to this heading"></a></h1>
<p>Relax transformations.</p>
<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.AdjustMatmulOrder">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">AdjustMatmulOrder</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.AdjustMatmulOrder" title="Link to this definition"></a></dt>
<dd><p>Reorder <cite>x*(A*B)</cite> to <cite>(x*A)*B</cite></p>
<p>Useful for optimizing LoRA computations, where <cite>matmul(x,
LoraA*LoraB)</cite> may be computed as <cite>matmul(matmul(x, LoraA),
LoraB)</cite>, reducing the total memory usage.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The corresponding pass.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.AllocateWorkspace">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">AllocateWorkspace</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.AllocateWorkspace" title="Link to this definition"></a></dt>
<dd><p>Allocate a workspace, represented by a tensor of size big enough for all external
functions that require a temporary storage, and append it to the arguments of external
functions.</p>
<p>An external function can specify its workspace requirement by the kWorkspaceSize attribute.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The registered pass for allocating workspace.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.AlterOpImpl">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">AlterOpImpl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">op_impl_map</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../tir/tir.html#tvm.tir.PrimFunc" title="tvm.tir.function.PrimFunc"><span class="pre">PrimFunc</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op_buffer_transforms</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../tir/tir.html#tvm.tir.IndexMap" title="tvm.tir.function.IndexMap"><span class="pre">IndexMap</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op_buffer_axis_separators</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">axis_separator</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op_buffer_input_axis_separators</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">axis_separator</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.AlterOpImpl" title="Link to this definition"></a></dt>
<dd><p>Replace all PrimFunc’s which have matching ‘operator_name’ attribute, with replacement
PrimFunc that could possibly have different layouts on i/o buffers. The layout
transformations on i/o buffers is present in the op_buffer_transforms map. Inserts the layout
transformations in the call sites of PrimFuncs being replaced to transform i/o
tensors into expected layout by new PrimFunc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>op_impl_map</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference internal" href="../tir/tir.html#tvm.tir.PrimFunc" title="tvm.tir.PrimFunc"><em>PrimFunc</em></a><em>]</em>) – op_kind to PrimFunc map</p></li>
<li><p><strong>op_buffer_transforms</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Union</em><em>[</em><a class="reference internal" href="../tir/tir.html#tvm.tir.IndexMap" title="tvm.tir.IndexMap"><em>IndexMap</em></a><em>, </em><em>Callable</em><em>]</em><em>]</em>) – op_kind to layout transformation map for each of the buffers</p></li>
<li><p><strong>op_buffer_axis_separators</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Union</em><em>[</em><em>IndexMap.AXIS_SEPARATOR</em><em>, </em><em>Callable</em><em>]</em><em>]</em><em>]</em>) – op_kind to axis_separator for each index_map</p></li>
<li><p><strong>op_buffer_input_axis_separators</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Union</em><em>[</em><em>IndexMap.AXIS_SEPARATOR</em><em>, </em><em>Callable</em><em>]</em><em>]</em><em>]</em>) – op_kind to axis_separator for input index_map</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.AnnotateTIROpPattern">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">AnnotateTIROpPattern</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.AnnotateTIROpPattern" title="Link to this definition"></a></dt>
<dd><p>Annotate Op Pattern Kind for TIR functions</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.AttachAttrLayoutFreeBuffers">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">AttachAttrLayoutFreeBuffers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.AttachAttrLayoutFreeBuffers" title="Link to this definition"></a></dt>
<dd><p>Attach layout free buffers to the tir::PrimFunc.</p>
<p>This pass is used to attach layout free buffers to the tir::PrimFunc according to
the function usage in the relax function. Currently, the layout free buffers are the model
weights and relax constants.</p>
<p>Note that we recommend applying CanonicalizeBindings before this pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The registered pass for attaching layout free buffers.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.AttachGlobalSymbol">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">AttachGlobalSymbol</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.AttachGlobalSymbol" title="Link to this definition"></a></dt>
<dd><p>Attach global_symbol to Relax functions and TIR Primfuncs for codegen.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.BindParams">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">BindParams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.expr.Var"><span class="pre">Var</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../runtime/ndarray.html#tvm.runtime.ndarray.NDArray" title="tvm.runtime.ndarray.NDArray"><span class="pre">NDArray</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.BindParams" title="Link to this definition"></a></dt>
<dd><p>Bind params of function of the module to constant tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The function name to be bound</p></li>
<li><p><strong>params</strong> (<em>Dict</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>,</em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a><em>]</em><em>, </em><em>Union</em><em>[</em><em>tvm.runtime.NDArray</em><em>, </em><em>np.ndarray</em><em>]</em><em>]</em>) – The map from parameter or parameter name to constant tensors.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.BindSymbolicVars">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">BindSymbolicVars</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">binding_map</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.13)"><span class="pre">Mapping</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../tir/tir.html#tvm.tir.Var" title="tvm.tir.expr.Var"><span class="pre">Var</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../ir.html#tvm.ir.PrimExpr" title="tvm.ir.expr.PrimExpr"><span class="pre">PrimExpr</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.BindSymbolicVars" title="Link to this definition"></a></dt>
<dd><p>Bind params of function of the module to constant tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>binding_map</strong> (<em>Mapping</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference internal" href="../tir/tir.html#tvm.tir.Var" title="tvm.tir.Var"><em>tvm.tir.Var</em></a><em>]</em><em>, </em><em>tvm.tir.PrimExpr</em><em>]</em>) – The map from symbolic varname to integer.</p></li>
<li><p><strong>func_name</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The function name to be bound. If None (default), all
functions within the module will be updated.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.BundleModelParams">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">BundleModelParams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">param_tuple_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.BundleModelParams" title="Link to this definition"></a></dt>
<dd><p>Bundle several model parameters into a single tuple paramters</p>
<p>For each function, if the function has the attribute “num_input”,
separate between run-time parameters and compile-time weights.
Run-time parameters (e.g. activations) are the first <cite>num_input</cite>
parameters, and the remainder are compile-time weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>param_tuple_name</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The name of the tuple parameter. If unspecified, defaults to
“model_params”.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass for bundling model parameters.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.CallTIRRewrite">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">CallTIRRewrite</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.CallTIRRewrite" title="Link to this definition"></a></dt>
<dd><p>Perform explicit tensor allocation for call_tir and call_dps_packed.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.CanonicalizeBindings">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">CanonicalizeBindings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.CanonicalizeBindings" title="Link to this definition"></a></dt>
<dd><p>Canonicalizes variable definitions
(e.g., if there is y = x and z = y, it replaces uses of y and z with x).
Also simplifies match cast nodes (eliminating redundant checks)
and tuple indices.</p>
<p>Best combined with constant folding and the elimination of unused definitions.</p>
<p>Note: If a dataflow var is used only in a binding to the dataflow block
output var (i.e., a non-dataflow var), this pass will also remove the dataflow var
and replaces the output var’s binding with the dataflow var’s direct definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.CombineParallelMatmul">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">CombineParallelMatmul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.CombineParallelMatmul" title="Link to this definition"></a></dt>
<dd><p>Combine multiple matmul operators sharing the same LHS matrix into one,
followed by slicing. When all matmul branches in a tree have the same set of fused ops,
the fused ops are applied to the combined matmul output before slicing.</p>
<p>Currently, only a limited set of fused ops is supported. It includes bias add,
relu, gelu, gelu_tanh and silu activation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>check</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a><em>, </em><em>List</em><em>[</em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a><em>]</em><em>, </em><em>Dict</em><em>[</em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a><em>, </em><em>Expr</em><em>]</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>]</em>) – A function to filter out unwanted branches, with the signature
(input, [rhs], [bias], binding) -&gt; bool.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The corresponding pass.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.ComputePrimValue">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">ComputePrimValue</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.ComputePrimValue" title="Link to this definition"></a></dt>
<dd><p>Compute all R.prim_value instances</p>
<p>While high-level relax can include expressions in terms of its
symbolic variables, these expressions cannot natively be computed
within relax.  In order to provide values for symbolic expressions
(e.g. <cite>R.prim_value(N*N)</cite>, where <cite>N</cite> is a symbolic variable), this
pass generates a PrimFunc in which the expression can be computed.
The relax graph is then updated to include a call to that
PrimFunc, in place of the original <cite>R.prim_value(expr)</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.ConvertLayout">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">ConvertLayout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desired_layouts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.ConvertLayout" title="Link to this definition"></a></dt>
<dd><p>Automatic layout conversion pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>desired_layouts</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>]</em>) – The desired layout of conv2d ops is a map from the name of the op to the desired layout
of the desired feature map, weight and output. For example, if we want to convert the
layout of conv2d from NCHW to NHWC, we can set the desired layout of conv2d to be
<code class="docutils literal notranslate"><span class="pre">{&quot;relax.nn.conv2d&quot;:</span> <span class="pre">[&quot;NHWC&quot;,</span> <span class="pre">&quot;OHWI&quot;]}</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass for layout conversion.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.ConvertToDataflow">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">ConvertToDataflow</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">min_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.ConvertToDataflow" title="Link to this definition"></a></dt>
<dd><p>A pass that converts consecutive dataflow operations
inside binding blocks into dataflow blocks.</p>
<p>Note: ConvertToDataflow may need to be called first.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>min_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The minimum number of consecutive dataflow bindings
the pass needs to extract a new block.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The pass.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tvm.relax.transform.DataflowBlockPass">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">DataflowBlockPass</span></span><a class="headerlink" href="#tvm.relax.transform.DataflowBlockPass" title="Link to this definition"></a></dt>
<dd><p>A pass that works on each tvm.relax.DataflowBlock in a module.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.DataflowUseInplaceCalls">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">DataflowUseInplaceCalls</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.DataflowUseInplaceCalls" title="Link to this definition"></a></dt>
<dd><p>Pass that changes calls to operators that can be done in-place
(generally, these are elementwise operations) into in-place implementations.
Supported operators will be replaced by calls to <cite>call_tir_inplace</cite> that invoke
in-place PrimFunc implementations of those operators (which are based on the legalizations of
those operators).</p>
<p>Note: ConvertToDataflow may need to be called first to provide dataflow blocks.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The pass</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.DeadCodeElimination">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">DeadCodeElimination</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">entry_functions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.DeadCodeElimination" title="Link to this definition"></a></dt>
<dd><p>Remove dead code in the IRModule.
Currently it removes:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Unused local VarBindings
(those where the bound var is unused and no impure operation is used).</p></li>
<li><p>Unused Relax functions in the module.
We detect the call chain from the entry function, and remove all unused functions.</p></li>
</ol>
</div></blockquote>
<p>Any binding blocks that are left empty will be removed by the normalizer.</p>
<p class="rubric">Notes</p>
<p>For function-wise DCE, use py:func:<cite>tvm.relax.analysis.remove_all_unused</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>entry_functions</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>]</em>) – The set of entry functions to start from.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.DecomposeOpsForInference">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">DecomposeOpsForInference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.DecomposeOpsForInference" title="Link to this definition"></a></dt>
<dd><p>Decompose composite operators that are composed by other operators during inference.
For example, the result of batch norm (a triple) will be simplified. Attention, tensor_to_shape,
etc. can be also decomposed into a number of simplified operators as well.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>func_name</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The name of the specified function. If not specified, the pass will run in
all functions.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.DecomposeOpsForTraining">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">DecomposeOpsForTraining</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.DecomposeOpsForTraining" title="Link to this definition"></a></dt>
<dd><p>Decompose composite operators that are composed by other operators during training.
For example, the result of batch norm (a triple) will be simplified. Attention, tensor_to_shape,
etc. can be also decomposed into a number of simplified operators as well.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>func_name</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The name of the specified function. If not specified, the pass will run in
all functions.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.EliminateCommonSubexpr">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">EliminateCommonSubexpr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">call_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#tvm.relax.transform.FunctionPass" title="tvm.relax.transform.transform.FunctionPass"><span class="pre">FunctionPass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.EliminateCommonSubexpr" title="Link to this definition"></a></dt>
<dd><p>Eliminate common subexpressions within functions.</p>
<p>Note: For nested functions, this pass performs CSE <em>within</em> those functions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>call_only</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If True, enable eliminating only call nodes.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass that eliminates common subexpressions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.ExpandMatmulOfSum">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">ExpandMatmulOfSum</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.ExpandMatmulOfSum" title="Link to this definition"></a></dt>
<dd><p>Expand <cite>matmul(x, A+B)</cite> to <cite>matmul(x,A) + matmul(x,B)</cite></p>
<p>If either operand can be fully computed at compile-time (only
depends on function parameters after kNumInput), this expansion is
suppressed.</p>
<p>Useful for optimizing LoRA computations, where <cite>matmul(x, Base +
LoraA*LoraB)</cite> may be expanded to <cite>matmul(x, Base) + matmul(x,
LoraA*LoraB)</cite>, allowing it to optimized with  <cite>CombineParallelMatmul</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The corresponding pass.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.ExpandTupleArguments">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">ExpandTupleArguments</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.ExpandTupleArguments" title="Link to this definition"></a></dt>
<dd><p>Expand tuple arguments to internal functions</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.FewShotTuning">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">FewShotTuning</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">valid_count</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">benchmark</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.FewShotTuning" title="Link to this definition"></a></dt>
<dd><p>The pass is designed for few shot tuning for static shape PrimFuncs. It examines all the
blocks within the PrimFunc and conducts loop fusion, splitting, and other transformations based
on MetaSchedule schedule rules but directly samples from the search space instead of using the
tuning algorithm. User can specify the number of valid counts to try and whether to use runner
for benchmarking.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>valid_count</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The number of valid counts to try.</p></li>
<li><p><strong>benchmark</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether to use runner for benchmarking.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.FoldConstant">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">FoldConstant</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.FoldConstant" title="Link to this definition"></a></dt>
<dd><p>Fold constant expressions within dataflow blocks.</p>
<p>Note: ConvertToDataflow may need to be called first to provide dataflow blocks.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tvm.relax.transform.FunctionPass">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">FunctionPass</span></span><a class="headerlink" href="#tvm.relax.transform.FunctionPass" title="Link to this definition"></a></dt>
<dd><p>A pass that works on each tvm.relax.Function in a module. A function
pass class should be created through <cite>function_pass</cite>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.FuseOps">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">FuseOps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fuse_opt_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.FuseOps" title="Link to this definition"></a></dt>
<dd><p>This pass groups bindings in a dataflow block of Relax functions and generate a new grouped
Relax function for each group, according to the fusion algorithm described in the pass
implementation. By grouping bindings into new Relax functions, we substitute the bindings in
the function being manipulated into function calls to the new grouped function.</p>
<p>A follow-up pass named “FuseTIR” will generate a TIR PrimFunc for each grouped function.</p>
<p>Note: ConvertToDataflow may need to be called first to provide dataflow blocks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>fuse_opt_level</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The level of fuse optimization. -1 indicates that the level will be
inferred from pass context.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass for operator fusion.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.FuseOpsByPattern">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">FuseOpsByPattern</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patterns</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#tvm.relax.transform.FusionPattern" title="tvm.relax.transform.transform.FusionPattern"><span class="pre">FusionPattern</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bind_constants</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">annotate_codegen</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entry_functions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.FuseOpsByPattern" title="Link to this definition"></a></dt>
<dd><p>Apply pattern matching to each function in the given module, and group matched expressions
into a new function.</p>
<p>The end result is similar to FuseOps, but fusion is driven completely by the provided patterns.</p>
<p>Note: Only operates within dataflow blocks. ConvertToDataflow may need to be called first.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patterns</strong> (<em>List</em><em>[</em><em>Union</em><em>[</em><a class="reference internal" href="#tvm.relax.transform.FusionPattern" title="tvm.relax.transform.FusionPattern"><em>FusionPattern</em></a><em>, </em><a class="reference internal" href="relax.html#tvm.relax.Tuple" title="tvm.relax.Tuple"><em>Tuple</em></a><em>]</em><em>]</em>) – <p>A list of patterns to be matched. The order of the patterns determines the order of priority
in which they are matched. Higher-priority patterns should come earlier in the list.</p>
<p>In addition to FusionPattern, a tuple can be passed as item of this list. The pattern
will be constructed through <code class="code docutils literal notranslate"><span class="pre">FusionPattern(*item)</span></code></p>
</p></li>
<li><p><strong>bind_constants</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether or not to keep bound constants in the grouped function.</p></li>
<li><p><strong>annotate_codegen</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – <p>If True, wrap each created composite function with another function, whose body consists
only of a call to the composite function, and annotate the outer function with “Codegen”
and “global_symbol” attributes. The “Codegen” attribute is set as the prefix of the
corresponding pattern name. For example, “dnnl” if the pattern name is “dnnl.conv2d_relu”.</p>
<p>This must be True if the created composite functions are intended to be offloaded to
an external backend without using the MergeCompositeFunctions pass.</p>
</p></li>
<li><p><strong>entry_functions</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>]</em>) – The set of entry functions to start from.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass for pattern-based fusion.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.FuseTIR">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">FuseTIR</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.FuseTIR" title="Link to this definition"></a></dt>
<dd><p>Fuse primitive relax function into a larger TIR function if possible</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The registered pass for tir fusion.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tvm.relax.transform.FusionPattern">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">FusionPattern</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">pattern</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DFPattern</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">annotation_patterns</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.13)"><span class="pre">Mapping</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">DFPattern</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#tvm.relax.transform.PatternCheckContext" title="tvm.relax.transform.transform.PatternCheckContext"><span class="pre">PatternCheckContext</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attrs_getter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../ir.html#tvm.ir.RelaxExpr" title="tvm.ir.expr.RelaxExpr"><span class="pre">RelaxExpr</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.FusionPattern" title="Link to this definition"></a></dt>
<dd><p>The pattern used by <cite>FuseOpsByPattern</cite>. It’s mainly DFPattern but with other
information to help during the fusion pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The name of pattern. Usually it starts with the name of backend, like ‘cutlass.matmul’.</p></li>
<li><p><strong>pattern</strong> (<em>DFPattern</em>) – The dataflow pattern that will be used to match expressions that can be handled
by external backends.</p></li>
<li><p><strong>annotation_patterns</strong> (<em>Mapping</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>DFPattern</em><em>]</em>) – The map which is used to extract important expressions from the pattern match
result. All DFPattern in this map should be part of the <cite>pattern</cite>.</p></li>
<li><p><strong>check</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="#tvm.relax.transform.PatternCheckContext" title="tvm.relax.transform.PatternCheckContext"><em>PatternCheckContext</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>]</em>) – The function to check whether the match result is accepted.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.Gradient">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">Gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">require_grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.expr.Var"><span class="pre">Var</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.expr.Var"><span class="pre">Var</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.Gradient" title="Link to this definition"></a></dt>
<dd><p>Reverse-mode automatic differentiation.</p>
<p>This pass will differentiate one function in the IRModule. Now the input function must have only
one dataflow block (ConvertToDataflow may need to be called first).</p>
<p>For a given function specified by <cite>func_name</cite>, it generates a new function with the name
<cite>func_name + “_adjoint”</cite>. The new function computes the gradient of the <strong>differentiation
target</strong> with respect to the arguments specified by <cite>require_grads</cite> of the original function.</p>
<p>If the function has only one return value, the return value will be specified as target. If the
function has more than one return values, the target will be specified as the target_index-th
return value. The target must be a scalar (0-dim tensor).</p>
<p>The new function will be like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">main_adjoint</span><span class="p">(</span><span class="n">original_parameters</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">R</span><span class="o">.</span><span class="n">dataflow</span><span class="p">():</span>
        <span class="c1"># the bindings of the original function</span>
        <span class="o">...</span>
        <span class="c1"># calculating the gradients</span>
        <span class="o">...</span>
        <span class="n">R</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">original_outputs</span><span class="p">,</span> <span class="n">grad_1</span><span class="p">,</span> <span class="n">grad_2</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">original_return_value</span><span class="p">,</span> <span class="p">(</span><span class="n">grad_1</span><span class="p">,</span> <span class="n">grad_2</span><span class="p">,</span> <span class="o">...</span><span class="p">))</span>
</pre></div>
</div>
<p>This AD pass also supports checkpointing as described in
“Training deep nets with sublinear memory cost.” - Chen, Tianqi, et al. (2016).
See tvm.relax.testing.nn.checkpoint for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The name of the specific function.</p></li>
<li><p><strong>require_grads</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a><em>, </em><em>List</em><em>[</em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a><em>]</em><em>]</em><em>]</em>) – The relax variables whose adjoints is needed. Must be parameters of the given function and
should not be duplicate. If it is not specified, adjoints of all parameters would be
computed.</p></li>
<li><p><strong>target_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – If the specified function has more than one return values, specify the index of the return
value as the target. If it is not specified, the first return value will be the target.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The Pass.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>The following code shows how to use this pass:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@I</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Module</span><span class="p">:</span>
    <span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">y</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">R</span><span class="o">.</span><span class="n">dataflow</span><span class="p">():</span>
            <span class="n">lv1</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="c1"># use R.sum to reduce the tensor to a scalar</span>
            <span class="n">lv2</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lv1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">R</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">lv2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lv2</span>

<span class="n">After</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span><span class="s2">&quot;main&quot;</span><span class="p">)(</span><span class="n">Module</span><span class="p">)</span>
</pre></div>
</div>
<p>The module after the Gradient pass will be:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@I</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">After</span><span class="p">:</span>
    <span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">y</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">R</span><span class="o">.</span><span class="n">dataflow</span><span class="p">():</span>
            <span class="n">lv1</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">lv2</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lv1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">R</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">lv2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lv2</span>

    <span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">main_adjoint</span><span class="p">(</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">y</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">R</span><span class="o">.</span><span class="n">Tuple</span><span class="p">(</span>
        <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span>
        <span class="n">R</span><span class="o">.</span><span class="n">Tuple</span><span class="p">(</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)),</span>
    <span class="p">):</span>
        <span class="k">with</span> <span class="n">R</span><span class="o">.</span><span class="n">dataflow</span><span class="p">():</span>
            <span class="c1"># original bindings</span>
            <span class="n">lv1</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">lv2</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lv1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="c1"># bindings w.r.t. intermediate variables</span>
            <span class="n">lv2_adjoint</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">ones</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
            <span class="n">lv1_adjoint</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
                <span class="n">lv2_adjoint</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="c1"># bindings w.r.t. parameters</span>
            <span class="n">x_adjoint</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">lv1_adjoint</span>
            <span class="n">y_adjoint</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">lv1_adjoint</span>
            <span class="n">R</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">lv2</span><span class="p">,</span> <span class="n">x_adjoint</span><span class="p">,</span> <span class="n">y_adjoint</span><span class="p">)</span>
        <span class="c1"># return value: (orig_return_values, tuple(adjoints))</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">lv2</span><span class="p">,</span> <span class="p">(</span><span class="n">x_adjoint</span><span class="p">,</span> <span class="n">y_adjoint</span><span class="p">))</span>
</pre></div>
</div>
<p>The second example is returning multiple values and specifying the target with <cite>target_index</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@I</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Module</span><span class="p">:</span>
    <span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">y</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">R</span><span class="o">.</span><span class="n">Tuple</span><span class="p">(</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)):</span>
        <span class="k">with</span> <span class="n">R</span><span class="o">.</span><span class="n">dataflow</span><span class="p">():</span>
            <span class="n">lv1</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">lv2</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">R</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">lv1</span><span class="p">,</span> <span class="n">lv2</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">lv1</span><span class="p">,</span> <span class="n">lv2</span><span class="p">)</span>

<span class="n">After</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span><span class="s2">&quot;main&quot;</span><span class="p">,</span> <span class="n">target_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">Module</span><span class="p">)</span>
</pre></div>
</div>
<p>The module after the Gradient pass will be:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@I</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Module</span><span class="p">:</span>
    <span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">y</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">R</span><span class="o">.</span><span class="n">Tuple</span><span class="p">(</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)):</span>
        <span class="k">with</span> <span class="n">R</span><span class="o">.</span><span class="n">dataflow</span><span class="p">():</span>
            <span class="n">lv1</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">lv2</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">R</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">lv1</span><span class="p">,</span> <span class="n">lv2</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">lv1</span><span class="p">,</span> <span class="n">lv2</span><span class="p">)</span>

    <span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">main_adjoint</span><span class="p">(</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">y</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">R</span><span class="o">.</span><span class="n">Tuple</span><span class="p">(</span>
        <span class="n">R</span><span class="o">.</span><span class="n">Tuple</span><span class="p">(</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)),</span>
        <span class="n">R</span><span class="o">.</span><span class="n">Tuple</span><span class="p">(</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)),</span>
    <span class="p">):</span>
        <span class="k">with</span> <span class="n">R</span><span class="o">.</span><span class="n">dataflow</span><span class="p">():</span>
            <span class="c1"># original bindings</span>
            <span class="n">lv1</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">lv2</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="c1"># bindings w.r.t. intermediate variables</span>
            <span class="c1"># gradient of intermediate variables that is not related to the target will not</span>
            <span class="c1"># be calculated</span>
            <span class="n">lv2_adjoint</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">ones</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
            <span class="c1"># bindings w.r.t. parameters</span>
            <span class="n">x_adjoint</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
            <span class="n">y_adjoint</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
                <span class="n">lv2_adjoint</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">R</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">lv1</span><span class="p">,</span> <span class="n">lv2</span><span class="p">,</span> <span class="n">x_adjoint</span><span class="p">,</span> <span class="n">y_adjoint</span><span class="p">)</span>
        <span class="c1"># return value: (orig_return_values, tuple(adjoints))</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">lv1</span><span class="p">,</span> <span class="n">lv2</span><span class="p">),</span> <span class="p">(</span><span class="n">x_adjoint</span><span class="p">,</span> <span class="n">y_adjoint</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.InlinePrivateFunctions">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">InlinePrivateFunctions</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.InlinePrivateFunctions" title="Link to this definition"></a></dt>
<dd><p>Inline all private relax functions</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.KillAfterLastUse">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">KillAfterLastUse</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.KillAfterLastUse" title="Link to this definition"></a></dt>
<dd><p>Drop all tensor/storage objects after last use</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.LambdaLift">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">LambdaLift</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.LambdaLift" title="Link to this definition"></a></dt>
<dd><p>A pass that lifts local functions into global.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.LazyGetInput">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">LazyGetInput</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.LazyGetInput" title="Link to this definition"></a></dt>
<dd><p>A pass that requests inputs lazily.</p>
<p>In many cases, the size of the model weights exceeds the available
memory on a GPU.  In these cases, a function that accepts all
model weights as arguments would not be able to be called.  In
these cases, parameters must be loaded as they are required by the
function, and unloaded once they are no longer needed.</p>
<p>This pass mutates a function such that all model weights
(arguments after the first <cite>func.attrs[“num_input”]</cite> arguments)
are loaded on demand.  Rather than accepting the weights as
function arguments, the function accepts a callback argument,
which can load each parameter as needed.  The callback accepts two
arguments, first the index of the model weight, and second the
name of the parameter.  The callback should return the parameter
as specified.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">before</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span><span class="mi">32</span><span class="p">],</span><span class="s2">&quot;float32&quot;</span><span class="p">)):</span>
    <span class="o">...</span>

<span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">after</span><span class="p">(</span><span class="n">fget_param</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Callable</span><span class="p">([</span><span class="n">R</span><span class="o">.</span><span class="n">Prim</span><span class="p">(</span><span class="s1">&#39;int64&#39;</span><span class="p">),</span> <span class="n">R</span><span class="o">.</span><span class="n">Object</span><span class="p">],</span> <span class="n">R</span><span class="o">.</span><span class="n">Object</span><span class="p">)):</span>
    <span class="n">A_untyped</span> <span class="o">=</span> <span class="n">fget_param</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">R</span><span class="o">.</span><span class="n">str</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">))</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">match_cast</span><span class="p">(</span><span class="n">A_untyped</span><span class="p">,</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span><span class="mi">32</span><span class="p">],</span> <span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.LazySetOutput">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">LazySetOutput</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.LazySetOutput" title="Link to this definition"></a></dt>
<dd><p>A pass that sets function outputs when available</p>
<p>In many cases, the size of the model weights exceeds the available
memory on a GPU.  In these cases, a function that produces all
model weights as a single return value would not be able to be
called.  In these cases, parameters must be returned as they are
produced, unloaded from the GPU (or saved to disk), before
producing additional outputs.</p>
<p>This pass mutates a function such that all outputs from a function
are returned when they are available.  The function accepts an
additional callback argument, which is called with each output of
the function.  The callback accepts two arguments, first the index
of the output tuple that was produced (or zero if the output is
not a tuple), and second the value itself.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">before</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>

<span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">after</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">fset_param</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Callable</span><span class="p">([</span><span class="n">R</span><span class="o">.</span><span class="n">Prim</span><span class="p">(</span><span class="s1">&#39;int64&#39;</span><span class="p">),</span> <span class="n">R</span><span class="o">.</span><span class="n">Object</span><span class="p">])):</span>
    <span class="o">...</span>
    <span class="n">fset_param</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
    <span class="o">...</span>
    <span class="n">fset_param</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.LegalizeOps">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">LegalizeOps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">customize_legalize_map</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="block_builder.html#tvm.relax.block_builder.BlockBuilder" title="tvm.relax.block_builder.BlockBuilder"><span class="pre">BlockBuilder</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="relax.html#tvm.relax.Call" title="tvm.relax.expr.Call"><span class="pre">Call</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../ir.html#tvm.ir.RelaxExpr" title="tvm.ir.expr.RelaxExpr"><span class="pre">RelaxExpr</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_warning</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.LegalizeOps" title="Link to this definition"></a></dt>
<dd><p>Legalize high-level operator calls in Relax functions to call_tir
with corresponding low-level TIR PrimFuncs.</p>
<p>For each high-level operator, we register the way of legalizing it as a
function, which takes a context BlockBuilder and the relax.Call being legalized
as input, and returns the legalized call. Here the input BlockBuilder is
mainly used for adding the PrimFunc created by call_te into the context
IRModule.</p>
<p>The legalization function for each operator is registered as an attribute (with
attribute key <cite>FLegalize</cite>) of the operator.</p>
<p>This pass provides customizability for users to use their own legalization
function for operators. The pass takes an optional customized map,
with the key to be the operator name (<cite>str</cite>) and value to be the function
(<cite>LegalizeFunc</cite>). The default legalization function will be overridden by the customized
one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>customize_legalize_map</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>LegalizeFunc</em><em>]</em><em>]</em>) – The customized operator legalization function map. The customized function will override
the default one.</p></li>
<li><p><strong>enable_warning</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – A boolean value indicating if to print warnings for CallNode whose op’s
legalization function is not registered. By default we don’t print
warnings.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>The following code shows how to use this pass:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the pass input IRModule</span>
<span class="nd">@tvm</span><span class="o">.</span><span class="n">script</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Module</span><span class="p">:</span>
    <span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">y</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">):</span>
        <span class="n">z</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">r</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">r</span>

<span class="c1"># Define the customized legalization function for &quot;relax.add&quot;</span>
<span class="k">def</span><span class="w"> </span><span class="nf">customize_legalize_add</span><span class="p">(</span><span class="n">bb</span><span class="p">:</span> <span class="n">relax</span><span class="o">.</span><span class="n">BlockBuilder</span><span class="p">,</span> <span class="n">call</span><span class="p">:</span> <span class="n">relax</span><span class="o">.</span><span class="n">Call</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">relax</span><span class="o">.</span><span class="n">Expr</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">tvm</span><span class="w"> </span><span class="kn">import</span> <span class="n">topi</span>
    <span class="k">return</span> <span class="n">bb</span><span class="o">.</span><span class="n">call_te</span><span class="p">(</span><span class="n">topi</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">call</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">call</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Apply the pass with the customized function to the module.</span>
<span class="n">mod</span> <span class="o">=</span> <span class="n">LegalizeOps</span><span class="p">({</span><span class="s2">&quot;relax.add&quot;</span><span class="p">:</span> <span class="n">customize_legalize_add</span><span class="p">})(</span><span class="n">Module</span><span class="p">)</span>
</pre></div>
</div>
<p>Print out the result by <cite>mod.show()</cite>, we can see the IRModule after
legalization becomes</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@tvm</span><span class="o">.</span><span class="n">script</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Module</span><span class="p">:</span>
    <span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">y</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">call_tir</span><span class="p">(</span><span class="n">add</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">call_tir</span><span class="p">(</span><span class="n">multiply</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">r</span>

    <span class="nd">@T</span><span class="o">.</span><span class="n">prim_func</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">add</span><span class="p">(</span>
        <span class="n">A</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
        <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
        <span class="n">T_add</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
    <span class="p">):</span>
        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&quot;tir.noalias&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">ax0</span><span class="p">,</span> <span class="n">ax1</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;T_add&quot;</span><span class="p">):</span>
                <span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&quot;SS&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">ax0</span><span class="p">,</span> <span class="n">ax1</span><span class="p">])</span>
                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span><span class="p">])</span>
                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">T_add</span><span class="p">[</span><span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span><span class="p">])</span>
                <span class="n">T_add</span><span class="p">[</span><span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span><span class="p">]</span> <span class="o">+</span> <span class="n">B</span><span class="p">[</span><span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span><span class="p">]</span>

    <span class="nd">@T</span><span class="o">.</span><span class="n">prim_func</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">multiply</span><span class="p">(</span>
        <span class="n">A</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
        <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
        <span class="n">T_multiply</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
    <span class="p">):</span>
        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&quot;tir.noalias&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">ax0</span><span class="p">,</span> <span class="n">ax1</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;T_multiply&quot;</span><span class="p">):</span>
                <span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&quot;SS&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">ax0</span><span class="p">,</span> <span class="n">ax1</span><span class="p">])</span>
                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span><span class="p">])</span>
                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">T_multiply</span><span class="p">[</span><span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span><span class="p">])</span>
                <span class="n">T_multiply</span><span class="p">[</span><span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">v_ax0</span><span class="p">,</span> <span class="n">v_ax1</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.LiftTransformParams">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">LiftTransformParams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shared_transform</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.LiftTransformParams" title="Link to this definition"></a></dt>
<dd><p>Lift transformation of the parameters of a function.</p>
<p>When some inputs of the function is marked as ‘parameters’ (the model weights), this pass
identifies the transformation of the parameters and lifts them to a separate function called
<cite>transform_params</cite>. <cite>transform_params</cite> takes a tuple of the original parameters as input and
returns a tuple of the transformed parameters. The original function will be rewritten to accept
a tuple of transformed parameters as input.</p>
<p>Users are expected to invoke the <cite>transform_params</cite> function in runtime and pass the transformed
parameters to the original function as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>shared_transform</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>]</em>) – <p>Indicates how the parameter transformation function will be produced</p>
<ul class="simple">
<li><p><cite>False</cite> (default): A separate parameter transformation function will be
produced for each function with the <cite>“num_input”</cite> attribute.</p></li>
<li><p><cite>True</cite>: A single parameter transformation function will be produced,
containing the preprocessing steps common across all functions with
the <cite>“num_input”</cite> attribute.</p></li>
<li><p>List[str]: A single parameter transformation function will be produced,
containing the preprocessing steps common across each function whose
name is in the list.  Passing a list of all functions with the <cite>“num_input”</cite>
attribute or an empty list is equivalent to passing <cite>True</cite>.</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass for lifting transformation of parameters.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.LowerAllocTensor">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">LowerAllocTensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.LowerAllocTensor" title="Link to this definition"></a></dt>
<dd><p>Lower remaining instances of R.builtin.alloc_tensor</p>
<p>The static memory planner removes static instances of
<cite>R.builtin.alloc_tensor</cite>, replacing with <cite>R.memory.alloc_storage</cite>
and <cite>R.memory.alloc_tensor</cite>.  However, <cite>R.builtin.alloc_tensor</cite>
still remains for any dynamic allocations.</p>
<p>This transform replaces any remaining <cite>R.builtin.alloc_tensor</cite>
instances with <cite>R.memory.alloc_storage</cite> and
<cite>R.memory.alloc_tensor</cite>.  If no <cite>R.builtin.alloc_tensor</cite> are
present, this pass has no effect.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.LowerRuntimeBuiltin">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">LowerRuntimeBuiltin</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.LowerRuntimeBuiltin" title="Link to this definition"></a></dt>
<dd><p>Lowering generic intrinsic to VM intrinsics.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.MergeCompositeFunctions">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">MergeCompositeFunctions</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.MergeCompositeFunctions" title="Link to this definition"></a></dt>
<dd><p>Group one or multiple composite functions created by FuseOpsByPattern into a new function.
The new function will be annotated with “Codegen” and “global_symbol” attributes, and it
is intented to be offloaded to an external backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The registered pass for merging composite functions.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.MetaScheduleApplyDatabase">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">MetaScheduleApplyDatabase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">work_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_warning</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.MetaScheduleApplyDatabase" title="Link to this definition"></a></dt>
<dd><p>Apply the best schedule from tuning database.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>work_dir</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – work directory to deduce default database if database is not provided
(it will be ignored when an user passes database)</p></li>
<li><p><strong>enable_warning</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – A boolean value indicating if to print warnings for TIR functions not
showing up in the database. By default we don’t print warning.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.MetaScheduleTuneIRMod">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">MetaScheduleTuneIRMod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../runtime/ndarray.html#tvm.runtime.ndarray.NDArray" title="tvm.runtime.ndarray.NDArray"><span class="pre">NDArray</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">work_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_trials_global</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_trials_per_task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.MetaScheduleTuneIRMod" title="Link to this definition"></a></dt>
<dd><p>Tune Relax IRModule with MetaSchedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference internal" href="../runtime/ndarray.html#tvm.runtime.ndarray.NDArray" title="tvm.runtime.ndarray.NDArray"><em>NDArray</em></a><em>]</em>) – model params</p></li>
<li><p><strong>work_dir</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – work directory</p></li>
<li><p><strong>max_trials_gloabl</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – maximum number of total trials allowed for tuning</p></li>
<li><p><strong>max_trials_per_task</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – maximum number of trials per task</p></li>
<li><p><strong>op_names</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>]</em>) – A list of operator names to specify which op to tune. When it is None, all operators
are tuned.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.MetaScheduleTuneTIR">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">MetaScheduleTuneTIR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">work_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_trials_global</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.MetaScheduleTuneTIR" title="Link to this definition"></a></dt>
<dd><p>Tune TIR with MetaSchedule.
:param work_dir: work directory
:type work_dir: str
:param max_trials_gloabl: maximum number of total trials allowed for tuning
:type max_trials_gloabl: int</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.Normalize">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">Normalize</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.Normalize" title="Link to this definition"></a></dt>
<dd><p>Transforming Relax IR to normal form, i.e., the expressions are normalized(no nesting
and hence the AST is in ANF), and all <code class="docutils literal notranslate"><span class="pre">checked_type_</span></code> and <code class="docutils literal notranslate"><span class="pre">shape_</span></code> of expressions are
available.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.NormalizeGlobalVar">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">NormalizeGlobalVar</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.NormalizeGlobalVar" title="Link to this definition"></a></dt>
<dd><p>Possibly rename the GlobalVar in an IRModule to ensure these properties:</p>
<p>1. (Invariant) First ensure every public function has the same name as its “global_symbol”
attribute
2. To ensure 1., we may need to rename private functions with conflicting names;
3. Finally, the name of every GlobalVar is unique in the IRModule.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tvm.relax.transform.PatternCheckContext">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">PatternCheckContext</span></span><a class="headerlink" href="#tvm.relax.transform.PatternCheckContext" title="Link to this definition"></a></dt>
<dd><p>The input of check function <cite>FusionPattern.check</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>matched_expr</strong> (<em>Expr</em>) – The expression that’s matched with the FusionPattern.pattern.</p></li>
<li><p><strong>annotated_expr</strong> (<em>Mapping</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>Expr</em><em>]</em>) – A map which contains all expressions matched by the sub patterns in
FusionPattern.annotation_patterns.</p></li>
<li><p><strong>matched_bindings</strong> (<em>Mapping</em><em>[</em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a><em>, </em><em>Expr</em><em>]</em>) – Map from variable to its value. It contains variables from bindings that is
being fused by FuseOpsByPattern.</p></li>
<li><p><strong>var_usages</strong> (<em>Mapping</em><em>[</em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a><em>, </em><em>Sequence</em><em>[</em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a><em>]</em><em>]</em>) – A map mapping variable definitions to a set of uses. It has all variables
used in the function.</p></li>
<li><p><strong>value_to_bound_var</strong> (<em>Mapping</em><em>[</em><em>Expr</em><em>, </em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a><em>]</em>) – Map from value to its bound variable. It doesn’t have variables after the
matched expression.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.RealizeVDevice">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">RealizeVDevice</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.RealizeVDevice" title="Link to this definition"></a></dt>
<dd><p>Propagate virtual device information.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The registered pass</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.RemovePurityChecking">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">RemovePurityChecking</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.RemovePurityChecking" title="Link to this definition"></a></dt>
<dd><p>Activate relax.force_pure on all pure functions in the module
and unwrap all pure override ops into the normal versions.</p>
<p>This effectively means that there will be no more purity tracking,
useful for low-level code generation.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The Pass.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Should be used after ToNonDataflow()</p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.RemoveUnusedOutputs">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">RemoveUnusedOutputs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.RemoveUnusedOutputs" title="Link to this definition"></a></dt>
<dd><p>Remove unused outputs from internal functions</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.RemoveUnusedParameters">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">RemoveUnusedParameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.RemoveUnusedParameters" title="Link to this definition"></a></dt>
<dd><p>Remove unused arguments to internal functions</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.ReorderPermuteDimsAfterConcat">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">ReorderPermuteDimsAfterConcat</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.ReorderPermuteDimsAfterConcat" title="Link to this definition"></a></dt>
<dd><p>Reorder <cite>concat(permute_dims(A), permute_dims(B))</cite> into <cite>permute_dims(concat(A,B))</cite></p>
<p>Useful for optimizing computations after <cite>CombineParallelMatmul</cite>.
The patterns for optimized <cite>nn.Linear</cite> implementations look for
<cite>matmul(activations, permute_dims(weights))</cite>.  After
<cite>CombineParallelMatmul</cite>, the <cite>matmul(activations,
concat(permute_dims(A), permute_dims(B)))</cite> no longer matches this
pattern.  Rearranging into <cite>matmul(activations,
permute_dims(concat(A,B)))</cite> restores the pattern match.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The corresponding pass.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.ReorderTakeAfterMatmul">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">ReorderTakeAfterMatmul</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.ReorderTakeAfterMatmul" title="Link to this definition"></a></dt>
<dd><p>Reorder <cite>matmul(x, take(weights, indices))</cite> to <cite>take(matmul(x,weights),indices)</cite></p>
<p>Useful for optimizing LoRA computations, where several LoRAs may
be batched together.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The corresponding pass.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.RewriteCUDAGraph">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">RewriteCUDAGraph</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.RewriteCUDAGraph" title="Link to this definition"></a></dt>
<dd><p>Rewrite a Relax module for executing with CUDA graph. This pass identifies the regions that
can be executed with CUDA graph and lifts them into new functions for runtime graph capturing.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The registered pass for rewriting cuda graph</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.RewriteDataflowReshape">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">RewriteDataflowReshape</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.RewriteDataflowReshape" title="Link to this definition"></a></dt>
<dd><p>Convert all reshape-like call_tir to VM reshape operator call.
The VM reshape operator calls will be further lowered to a CreateView
operation at runtime, instead of doing real data copy.
Here “reshape-like” includes reshape, expand_dims, flatten, etc.</p>
<p>Note: Operates only in dataflow blocks. ConvertToDataflow may need to be called first.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.RunCodegen">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">RunCodegen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_options</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><span class="pre">dict</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entry_functions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.RunCodegen" title="Link to this definition"></a></dt>
<dd><p>Produce the runtime::Module with an annotated codegen and global symbol.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_options</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a><em>]</em>) – Pairs of a target name and compilation options</p></li>
<li><p><strong>entry_functions</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>]</em>) – The set of entry functions to start from.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass to remove unused functions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.SplitCallTIRByPattern">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">SplitCallTIRByPattern</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patterns</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../tir/tir.html#tvm.tir.PrimFunc" title="tvm.tir.function.PrimFunc"><span class="pre">PrimFunc</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fcodegen</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.SplitCallTIRByPattern" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Split a PrimFunc into 2 parts: the first part is a TIR PrimFunc which is</dt><dd><p>matched with some pattern, and the second part is the rest of the original
PrimFunc. It will call fcodegen to generate the code for the matched pattern
to replace it with a ExternFunc call.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patterns</strong> (<em>List</em><em>[</em><a class="reference internal" href="../tir/tir.html#tvm.tir.PrimFunc" title="tvm.tir.PrimFunc"><em>PrimFunc</em></a><em>]</em>) – The list of patterns to match.</p></li>
<li><p><strong>fcodegen</strong> (<em>Callable</em><em>[</em><em>[</em><em>List</em><em>[</em><em>MatchResult</em><em>]</em><em>]</em><em>, </em><em>List</em><em>[</em><em>Object</em><em>]</em><em>]</em>) – The function to generate the code for the matched patterns.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass for splitting call_tir.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.SplitLayoutRewritePreproc">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">SplitLayoutRewritePreproc</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.SplitLayoutRewritePreproc" title="Link to this definition"></a></dt>
<dd><p>Split the TIR layout rewrite into multiple TIR functions.
This pass is used in the prepack weight after meta_schedule tuning.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong> – The registered pass for splitting TIR layout rewrite.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.StaticPlanBlockMemory">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">StaticPlanBlockMemory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.StaticPlanBlockMemory" title="Link to this definition"></a></dt>
<dd><p>The static memory planning pass on BindingBlock level.
The pass will reuse allocated memory to its best effort, in order to
reduce the total amount of allocated memory size.</p>
<p>The pass “supports” dynamic shape in the way of TIR variable upper bound
annotation. We can optionally annotate the attribute “tir_var_upper_bound”
to Relax functions. The attribute value is a dict from strings to integers,
denoting the name of TIR variables to the upper bound values of the TIR vars.
Note: The annotated upper bound attribute only applies to TIR vars in the
function signature for clarity.</p>
<p>For example, we can annotate a Relax function with
<code class="code docutils literal notranslate"><span class="pre">R.func_attr({&quot;tir_var_upper_bound&quot;:</span> <span class="pre">{&quot;n&quot;:</span> <span class="pre">1024}})</span></code>.
It means the maximum value of variable that names “n” in the function
signature will have upper bound 1024. And we will use 1024 as its value
during memory planning.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.ToMixedPrecision">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">ToMixedPrecision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'float32'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp16_input_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.ToMixedPrecision" title="Link to this definition"></a></dt>
<dd><p>Automatic mixed precision pass. Currently the pass assumes the input module to be fp32
only, and will automatically cast fp32 to fp16 for certain ops.</p>
<p>Note: Mainly operates within dataflow blocks. ConvertToDataflow may need to be called first.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output data type of gemm/conv, which is the data type of the accumulator.</p></li>
<li><p><strong>fp16_input_names</strong> (<em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The names of function parameters whose dtype should become fp16. The  function signature
would change accordingly.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass for mixed precision.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.ToNonDataflow">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">ToNonDataflow</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.ToNonDataflow" title="Link to this definition"></a></dt>
<dd><p>Transform all dataflow structure to non-dataflow version.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.TopologicalSort">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">TopologicalSort</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'depth-first'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">direction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'from-inputs'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.TopologicalSort" title="Link to this definition"></a></dt>
<dd><p>Sort bindings in relax.Dataflow blocks in the order specified</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>order</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The order in which bindings should be emitted.  Allowed values
are “depth-first” and “breadth-first”.</p></li>
<li><p><strong>direciton</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The direction in which the sort should be performed.  Allowed
values are “from-inputs” and “from-outputs”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.UpdateParamStructInfo">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">UpdateParamStructInfo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sinfo_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.expr.Var"><span class="pre">Var</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="relax.html#tvm.relax.StructInfo" title="tvm.relax.expr.StructInfo"><span class="pre">StructInfo</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.UpdateParamStructInfo" title="Link to this definition"></a></dt>
<dd><p>Update struct info of parameters</p>
<p>Update struct info of parameters.  Internal bindings and function
return type will be updated using relax’s struct inference rules.
Errors resulting from struct inference will be propagated to the
user.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sinfo_func</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a><em>]</em><em>, </em><em>Optional</em><em>[</em><a class="reference internal" href="relax.html#tvm.relax.StructInfo" title="tvm.relax.StructInfo"><em>StructInfo</em></a><em>]</em><em>]</em>) – A function that is called once for each function parameter,
and returns the updated struct info to be used for it.  If the
function returns <cite>None</cite>, the parameter is not modified.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The corresponding pass.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.transform.Pass">tvm.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.UpdateVDevice">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">UpdateVDevice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_vdevice</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../ir.html#tvm.ir.VDevice" title="tvm.ir.global_info.VDevice"><span class="pre">VDevice</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.UpdateVDevice" title="Link to this definition"></a></dt>
<dd><p>Update virtual device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>new_vdevice</strong> (<a class="reference internal" href="../ir.html#tvm.ir.VDevice" title="tvm.ir.VDevice"><em>tvm.ir.VDevice</em></a>) – The new virtual device.</p></li>
<li><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The device index indicates the device on which the update will be performed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The registered pass that modifies the virtual device.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.VMBuiltinLower">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">VMBuiltinLower</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.VMBuiltinLower" title="Link to this definition"></a></dt>
<dd><p>Lowering generic intrinsic to VM intrinsics.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ret</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.VMShapeLower">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">VMShapeLower</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emit_err_ctx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass"><span class="pre">Pass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.VMShapeLower" title="Link to this definition"></a></dt>
<dd><p>Lower the symbolic shape and argument and match-cast structinfo matching.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>emit_err_ctx</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>]</em>) – Whether emit err context string, can be turned off for testing purposes.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../transform.html#tvm.transform.Pass" title="tvm.ir.transform.Pass">tvm.ir.transform.Pass</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.dataflowblock_pass">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">dataflowblock_pass</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pass_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">required</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">traceable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#tvm.relax.transform.DataflowBlockPass" title="tvm.relax.transform.transform.DataflowBlockPass"><span class="pre">DataflowBlockPass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.dataflowblock_pass" title="Link to this definition"></a></dt>
<dd><p>Decorate a dataflowblock pass.</p>
<p>This function returns a callback when pass_func
is provided. Otherwise, it returns the created dataflowblock pass using the
given optimization function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pass_func</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>(</em><a class="reference internal" href="relax.html#tvm.relax.DataflowBlock" title="tvm.relax.DataflowBlock"><em>DataflowBlock</em></a><em>, </em><em>Module</em><em>, </em><a class="reference internal" href="../transform.html#tvm.transform.PassContext" title="tvm.transform.PassContext"><em>PassContext</em></a><em>) </em><em>-&gt; DataflowBlock</em><em>]</em><em>]</em>) – The transformation function or class.</p></li>
<li><p><strong>opt_level</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The optimization level of this dataflowblock pass.</p></li>
<li><p><strong>name</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The name of the dataflowblock pass. The name could be empty. In this case, the
name of the optimization function will be used as the pass name.</p></li>
<li><p><strong>required</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>]</em>) – The list of passes that the dataflowblock pass is dependent on.</p></li>
<li><p><strong>traceable</strong> (<em>Boolean</em>) – Boolean variable whether the dataflowblock pass is traceable</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>create_dataflowblock_pass</strong> – A decorator will be returned if pass_func is not provided,
otherwise return the decorated result.
The returned decorator has two behaviors depending on the input:
A new DataflowBlockPass will be returned when we decorate a pass function.
A new DataflowBlockPass class will be returned when we decorate a class type.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[Callable, <a class="reference internal" href="#tvm.relax.transform.DataflowBlockPass" title="tvm.relax.transform.DataflowBlockPass">DataflowBlockPass</a>]</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>The following code block decorates a dataflowblock pass class.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@relax</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">dataflowblock_pass</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TestReplaceBinding</span><span class="p">:</span>
    <span class="c1"># Simple test function to replace the first VarBinding to another.</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># create a new VarBinding</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">tir</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="s2">&quot;int64&quot;</span><span class="p">),</span> <span class="n">tir</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="s2">&quot;n&quot;</span><span class="p">,</span> <span class="s2">&quot;int64&quot;</span><span class="p">)</span>
        <span class="n">lv0</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="s2">&quot;lv1&quot;</span><span class="p">,</span> <span class="n">relax</span><span class="o">.</span><span class="n">TensorStructInfo</span><span class="p">([</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">],</span> <span class="s2">&quot;float32&quot;</span><span class="p">))</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">56</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">new_binding</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">VarBinding</span><span class="p">(</span><span class="n">lv0</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_dataflowblock</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">mod</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
        <span class="c1"># just for demo purposes</span>
        <span class="c1"># Replace the first binding in the DataflowBlock</span>
        <span class="n">new_bindings</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">new_binding</span><span class="p">,</span> <span class="n">block</span><span class="o">.</span><span class="n">bindings</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
        <span class="n">new_block</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">expr</span><span class="o">.</span><span class="n">DataflowBlock</span><span class="p">(</span><span class="n">new_bindings</span><span class="p">,</span> <span class="n">block</span><span class="o">.</span><span class="n">span</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_block</span>

<span class="nd">@tvm</span><span class="o">.</span><span class="n">script</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">InputMod</span><span class="p">:</span>
    <span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">f1</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">[(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">]):</span>
        <span class="k">with</span> <span class="n">relax</span><span class="o">.</span><span class="n">dataflow</span><span class="p">():</span>
            <span class="n">lv0</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
            <span class="n">gv0</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
            <span class="n">relax</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">gv0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gv0</span>
<span class="c1"># block_pass is now a special pass that replaces every</span>
<span class="c1"># first binding to the constant value binding</span>
<span class="n">block_pass</span> <span class="o">=</span> <span class="n">TestReplaceBinding</span><span class="p">()</span>
<span class="c1"># now every first binding in DataflowBlock of InputMod</span>
<span class="c1"># is replaced by new_binding</span>
<span class="n">updated_mod</span> <span class="o">=</span> <span class="n">block_pass</span><span class="p">(</span><span class="n">InputMod</span><span class="p">)</span>
</pre></div>
</div>
<p>The following code creates a dataflowblock pass by decorating
a user defined transform function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@relax</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">dataflowblock_pass</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">mod</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
    <span class="c1"># my transformations here.</span>
    <span class="k">return</span> <span class="n">block</span>

<span class="n">block_pass</span> <span class="o">=</span> <span class="n">transform</span>
<span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">block_pass</span><span class="p">,</span> <span class="n">relax</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">DataflowBlockPass</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">block_pass</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">opt_level</span> <span class="o">==</span> <span class="mi">2</span>

<span class="c1"># Given a module m, the optimization could be invoked as the follwoing:</span>
<span class="n">updated_mod</span> <span class="o">=</span> <span class="n">block_pass</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="c1"># Now transform should have been applied to every DataflowBlock in</span>
<span class="c1"># the provided module m. And the updated module will be returned.</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.relax.transform.function_pass">
<span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">function_pass</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pass_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">required</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">traceable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#tvm.relax.transform.FunctionPass" title="tvm.relax.transform.transform.FunctionPass"><span class="pre">FunctionPass</span></a></span></span><a class="headerlink" href="#tvm.relax.transform.function_pass" title="Link to this definition"></a></dt>
<dd><p>Decorate a function pass.</p>
<p>This function returns a callback when pass_func
is provided. Otherwise, it returns the created function pass using the
given optimization function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pass_func</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>(</em><a class="reference internal" href="relax.html#tvm.relax.Function" title="tvm.relax.Function"><em>Function</em></a><em>, </em><em>Module</em><em>, </em><a class="reference internal" href="../transform.html#tvm.transform.PassContext" title="tvm.transform.PassContext"><em>PassContext</em></a><em>) </em><em>-&gt; Function</em><em>]</em><em>]</em>) – The transformation function or class.</p></li>
<li><p><strong>opt_level</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The optimization level of this function pass.</p></li>
<li><p><strong>name</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The name of the function pass. The name could be empty. In this case, the
name of the optimization function will be used as the pass name.</p></li>
<li><p><strong>required</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>]</em>) – The list of passes that the function pass is dependent on.</p></li>
<li><p><strong>traceable</strong> (<em>Boolean</em>) – Boolean variable whether the function pass is traceable</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>create_function_pass</strong> – A decorator will be returned if pass_func is not provided,
otherwise return the decorated result.
The returned decorator has two behaviors depending on the input:
A new FunctionPass will be returned when we decorate a pass function.
A new FunctionPass class will be returned when we decorate a class type.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[Callable, <a class="reference internal" href="#tvm.relax.transform.FunctionPass" title="tvm.relax.transform.FunctionPass">FunctionPass</a>]</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>The following code block decorates a function pass class.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@relax</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">function_pass</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TestReplaceFunc</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_func</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">new_func</span> <span class="o">=</span> <span class="n">new_func</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">mod</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
        <span class="c1"># just for demo purposes</span>
        <span class="c1"># transform func to new_func</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_func</span>

<span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">f1</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">[(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">]):</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="nd">@tvm</span><span class="o">.</span><span class="n">script</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">InputMod</span><span class="p">:</span>
    <span class="nd">@R</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">f2</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">[(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">]):</span>
        <span class="n">gv0</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gv0</span>
<span class="c1"># fpass is now a special pass that replaces every</span>
<span class="c1"># function to f1</span>
<span class="n">fpass</span> <span class="o">=</span> <span class="n">TestReplaceFunc</span><span class="p">(</span><span class="n">f1</span><span class="p">)</span>
<span class="c1"># now every function in InputMod is replaced by f1</span>
<span class="n">updated_mod</span> <span class="o">=</span> <span class="n">fpass</span><span class="p">(</span><span class="n">InputMod</span><span class="p">)</span>
</pre></div>
</div>
<p>The following code creates a function pass by decorating
a user defined transform function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@relax</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">function_pass</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">mod</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
    <span class="c1"># my transformations here.</span>
    <span class="k">return</span> <span class="n">func</span>

<span class="n">function_pass</span> <span class="o">=</span> <span class="n">transform</span>
<span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">function_pass</span><span class="p">,</span> <span class="n">relax</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">FunctionPass</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">function_pass</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">opt_level</span> <span class="o">==</span> <span class="mi">2</span>

<span class="c1"># Given a module m, the optimization could be invoked as the follwoing:</span>
<span class="n">updated_mod</span> <span class="o">=</span> <span class="n">function_pass</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="c1"># Now transform should have been applied to every function in</span>
<span class="c1"># the provided module m. And the updated module will be returned.</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tvm.relax.transform.AttachExternModules">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">AttachExternModules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">extern_modules</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">ExternModule</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.AttachExternModules" title="Link to this definition"></a></dt>
<dd><p>Attach variable bounds to each Relax function, which primarily helps with memory planning.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tvm.relax.transform.FastMathTransform">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">FastMathTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.FastMathTransform" title="Link to this definition"></a></dt>
<dd><p>Pass to convert the expensive non linear functions to their fast but approximate counterparts.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tvm.relax.transform.FuseTransposeMatmul">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">FuseTransposeMatmul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.FuseTransposeMatmul" title="Link to this definition"></a></dt>
<dd><p>A compiler pass that fuses transpose + matmul.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tvm.relax.transform.IPCAllReduceRewrite">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">IPCAllReduceRewrite</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allreduce_strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.IPCAllReduceRewrite" title="Link to this definition"></a></dt>
<dd><p>Rewrite all-reduce operation to customized all-reduce impl with IPC memory.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tvm.relax.transform.LazyTransformParams">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">LazyTransformParams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fget_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'get_item'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fset_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'set_item'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extra_get_item_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extra_set_item_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.LazyTransformParams" title="Link to this definition"></a></dt>
<dd><p>Convert transform_params functions into a lazy version.
(Load the input to memory on demand, and immediately free it after the last use.)</p>
<p>Note: ToNonDataflow() and RemovePurityTracking() should be invoked before this pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fget_item</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The name of the get_item function.</p></li>
<li><p><strong>fset_item</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The name of the set_item function.</p></li>
<li><p><strong>extra_get_item_params</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a>) – The parameters of the get_item function except index.
The given parameters will be placed before index.
For example, if extra_get_item_params is [param1, param2], then the pass will generate
call_packed(fget_item, [param1, param2, index])</p></li>
<li><p><strong>extra_set_item_params</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference internal" href="relax.html#tvm.relax.Var" title="tvm.relax.Var"><em>relax.Var</em></a>) – The parameters of the set_item function except index and value.
The given parameters will be placed before index and value.
For example, if extra_set_item_params is [param1, param2], then the pass will generate
call_packed(fset_item, [param1, param2, index, value])</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tvm.relax.transform.LowerGPUIPCAllocStorage">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">LowerGPUIPCAllocStorage</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.relax.transform.LowerGPUIPCAllocStorage" title="Link to this definition"></a></dt>
<dd><p>Lower the storage/tensor allocation on IPC memory.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tvm.relax.transform.OptimizeLayoutTransform">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">OptimizeLayoutTransform</span></span><a class="headerlink" href="#tvm.relax.transform.OptimizeLayoutTransform" title="Link to this definition"></a></dt>
<dd><p>Pass to remove redundant transform layout operators
introduced by AlterOpImpl pass.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tvm.relax.transform.RemoveRedundantReshape">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.relax.transform.</span></span><span class="sig-name descname"><span class="pre">RemoveRedundantReshape</span></span><a class="headerlink" href="#tvm.relax.transform.RemoveRedundantReshape" title="Link to this definition"></a></dt>
<dd><p>Transformation pass to remove redundant reshape operator</p>
</dd></dl>

</section>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../tir/tir.html" class="btn btn-neutral float-right" title="tvm.tir" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="op.html" class="btn btn-neutral float-left" title="tvm.relax.op" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../../../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2024 Apache Software Foundation | All rights reserved</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote">Copyright © 2024 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="../../../../_static/downloads/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="../../../../_static/downloads/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>