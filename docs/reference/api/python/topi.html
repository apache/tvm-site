



<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tvm.topi &mdash; tvm 0.20.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/downloads/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/tlcpack_theme.css" type="text/css" />

  
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=1b5e2a23"></script>
        <script src="../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script async="async" src="../../../_static/downloads/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="tvm.meta_schedule" href="meta_schedule.html" />
    <link rel="prev" title="tvm.te" href="te.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://tvm.apache.org/docs/reference/security.html>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://tvm.apache.org/docs/reference/security.html>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="sidetitle" alt="Documentation Home"> tvm
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../get_started/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install/index.html">Installing TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../get_started/tutorials/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../get_started/tutorials/ir_module.html">IRModule</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">How To</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../how_to/tutorials/e2e_opt_model.html">End-to-End Optimize Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../how_to/tutorials/customize_opt.html">Customize Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../how_to/tutorials/optimize_llm.html">Optimize Large Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../how_to/tutorials/cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../how_to/dev/index.html">Development Guides</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Dive</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../arch/index.html">Design and Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deep_dive/tensor_ir/index.html">TensorIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deep_dive/relax/index.html">Relax</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="error.html">tvm.error</a></li>
<li class="toctree-l2"><a class="reference internal" href="ir.html">tvm.ir</a></li>
<li class="toctree-l2"><a class="reference internal" href="instrument.html">tvm.instrument</a></li>
<li class="toctree-l2"><a class="reference internal" href="transform.html">tvm.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="target.html">tvm.target</a></li>
<li class="toctree-l2"><a class="reference internal" href="driver.html">tvm.driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="runtime/runtime.html">tvm.runtime</a></li>
<li class="toctree-l2"><a class="reference internal" href="runtime/ndarray.html">tvm.runtime.ndarray</a></li>
<li class="toctree-l2"><a class="reference internal" href="runtime/relax_vm.html">tvm.runtime.relax_vm</a></li>
<li class="toctree-l2"><a class="reference internal" href="runtime/disco.html">tvm.runtime.disco</a></li>
<li class="toctree-l2"><a class="reference internal" href="runtime/profiling.html">tvm.runtime.profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="relax/relax.html">tvm.relax</a></li>
<li class="toctree-l2"><a class="reference internal" href="relax/analysis.html">tvm.relax.analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="relax/block_builder.html">tvm.relax.block_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="relax/frontend.html">tvm.relax.frontend</a></li>
<li class="toctree-l2"><a class="reference internal" href="relax/op.html">tvm.relax.op</a></li>
<li class="toctree-l2"><a class="reference internal" href="relax/transform.html">tvm.relax.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir/tir.html">tvm.tir</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir/analysis.html">tvm.tir.analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir/schedule.html">tvm.tir.schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir/stmt_functor.html">tvm.tir.stmt_functor</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir/transform.html">tvm.tir.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="te.html">tvm.te</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">tvm.topi</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-tvm.topi.nn">tvm.topi.nn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.Workload"><code class="docutils literal notranslate"><span class="pre">Workload</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.adaptive_pool"><code class="docutils literal notranslate"><span class="pre">adaptive_pool()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.adaptive_pool1d"><code class="docutils literal notranslate"><span class="pre">adaptive_pool1d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.adaptive_pool3d"><code class="docutils literal notranslate"><span class="pre">adaptive_pool3d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.add"><code class="docutils literal notranslate"><span class="pre">add()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.batch_matmul"><code class="docutils literal notranslate"><span class="pre">batch_matmul()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.batch_norm"><code class="docutils literal notranslate"><span class="pre">batch_norm()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.batch_to_space_nd"><code class="docutils literal notranslate"><span class="pre">batch_to_space_nd()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.binarize_pack"><code class="docutils literal notranslate"><span class="pre">binarize_pack()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.binary_dense"><code class="docutils literal notranslate"><span class="pre">binary_dense()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.bitpack"><code class="docutils literal notranslate"><span class="pre">bitpack()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.bitserial_conv2d_nchw"><code class="docutils literal notranslate"><span class="pre">bitserial_conv2d_nchw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.bitserial_conv2d_nhwc"><code class="docutils literal notranslate"><span class="pre">bitserial_conv2d_nhwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.bitserial_dense"><code class="docutils literal notranslate"><span class="pre">bitserial_dense()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.concatenate"><code class="docutils literal notranslate"><span class="pre">concatenate()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv"><code class="docutils literal notranslate"><span class="pre">conv()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv1d"><code class="docutils literal notranslate"><span class="pre">conv1d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv1d_ncw"><code class="docutils literal notranslate"><span class="pre">conv1d_ncw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv1d_nwc"><code class="docutils literal notranslate"><span class="pre">conv1d_nwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv1d_transpose_ncw"><code class="docutils literal notranslate"><span class="pre">conv1d_transpose_ncw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d"><code class="docutils literal notranslate"><span class="pre">conv2d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d_NCHWc"><code class="docutils literal notranslate"><span class="pre">conv2d_NCHWc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d_NCHWc_int8"><code class="docutils literal notranslate"><span class="pre">conv2d_NCHWc_int8()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d_hwcn"><code class="docutils literal notranslate"><span class="pre">conv2d_hwcn()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d_nchw"><code class="docutils literal notranslate"><span class="pre">conv2d_nchw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d_nhwc"><code class="docutils literal notranslate"><span class="pre">conv2d_nhwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d_transpose_nchw"><code class="docutils literal notranslate"><span class="pre">conv2d_transpose_nchw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d_transpose_nchw_preprocess"><code class="docutils literal notranslate"><span class="pre">conv2d_transpose_nchw_preprocess()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d_winograd_nchw"><code class="docutils literal notranslate"><span class="pre">conv2d_winograd_nchw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d_winograd_nchw_without_weight_transform"><code class="docutils literal notranslate"><span class="pre">conv2d_winograd_nchw_without_weight_transform()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d_winograd_nhwc"><code class="docutils literal notranslate"><span class="pre">conv2d_winograd_nhwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d_winograd_nhwc_without_weight_transform"><code class="docutils literal notranslate"><span class="pre">conv2d_winograd_nhwc_without_weight_transform()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv2d_winograd_weight_transform"><code class="docutils literal notranslate"><span class="pre">conv2d_winograd_weight_transform()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv3d_ncdhw"><code class="docutils literal notranslate"><span class="pre">conv3d_ncdhw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv3d_ndhwc"><code class="docutils literal notranslate"><span class="pre">conv3d_ndhwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv3d_transpose_ncdhw"><code class="docutils literal notranslate"><span class="pre">conv3d_transpose_ncdhw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv3d_transpose_ncdhw_preprocess"><code class="docutils literal notranslate"><span class="pre">conv3d_transpose_ncdhw_preprocess()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.conv3d_winograd_weight_transform"><code class="docutils literal notranslate"><span class="pre">conv3d_winograd_weight_transform()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.correlation_nchw"><code class="docutils literal notranslate"><span class="pre">correlation_nchw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.declaration_conv2d_transpose_impl"><code class="docutils literal notranslate"><span class="pre">declaration_conv2d_transpose_impl()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.declaration_conv3d_transpose_impl"><code class="docutils literal notranslate"><span class="pre">declaration_conv3d_transpose_impl()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.deformable_conv2d_nchw"><code class="docutils literal notranslate"><span class="pre">deformable_conv2d_nchw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.deformable_conv2d_nhwc"><code class="docutils literal notranslate"><span class="pre">deformable_conv2d_nhwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.dense"><code class="docutils literal notranslate"><span class="pre">dense()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.dense_pack"><code class="docutils literal notranslate"><span class="pre">dense_pack()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.depth_to_space"><code class="docutils literal notranslate"><span class="pre">depth_to_space()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.depthwise_conv2d_NCHWc"><code class="docutils literal notranslate"><span class="pre">depthwise_conv2d_NCHWc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.depthwise_conv2d_backward_input_nhwc"><code class="docutils literal notranslate"><span class="pre">depthwise_conv2d_backward_input_nhwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.depthwise_conv2d_backward_weight_nhwc"><code class="docutils literal notranslate"><span class="pre">depthwise_conv2d_backward_weight_nhwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.depthwise_conv2d_nchw"><code class="docutils literal notranslate"><span class="pre">depthwise_conv2d_nchw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.depthwise_conv2d_nhwc"><code class="docutils literal notranslate"><span class="pre">depthwise_conv2d_nhwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.dilate"><code class="docutils literal notranslate"><span class="pre">dilate()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.equal_const_int"><code class="docutils literal notranslate"><span class="pre">equal_const_int()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.fast_softmax"><code class="docutils literal notranslate"><span class="pre">fast_softmax()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.fifo_buffer"><code class="docutils literal notranslate"><span class="pre">fifo_buffer()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.flatten"><code class="docutils literal notranslate"><span class="pre">flatten()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.get_const_int"><code class="docutils literal notranslate"><span class="pre">get_const_int()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.get_const_tuple"><code class="docutils literal notranslate"><span class="pre">get_const_tuple()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.get_pad_tuple"><code class="docutils literal notranslate"><span class="pre">get_pad_tuple()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.get_pad_tuple1d"><code class="docutils literal notranslate"><span class="pre">get_pad_tuple1d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.get_pad_tuple3d"><code class="docutils literal notranslate"><span class="pre">get_pad_tuple3d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.get_pad_tuple_generic"><code class="docutils literal notranslate"><span class="pre">get_pad_tuple_generic()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.global_pool"><code class="docutils literal notranslate"><span class="pre">global_pool()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.group_conv1d_ncw"><code class="docutils literal notranslate"><span class="pre">group_conv1d_ncw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.group_conv1d_nwc"><code class="docutils literal notranslate"><span class="pre">group_conv1d_nwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.group_conv1d_transpose_ncw"><code class="docutils literal notranslate"><span class="pre">group_conv1d_transpose_ncw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.group_conv2d_nchw"><code class="docutils literal notranslate"><span class="pre">group_conv2d_nchw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.group_conv2d_nhwc"><code class="docutils literal notranslate"><span class="pre">group_conv2d_nhwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.group_conv2d_transpose_nchw"><code class="docutils literal notranslate"><span class="pre">group_conv2d_transpose_nchw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.group_conv3d_transpose_ncdhw"><code class="docutils literal notranslate"><span class="pre">group_conv3d_transpose_ncdhw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.leaky_relu"><code class="docutils literal notranslate"><span class="pre">leaky_relu()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.log_softmax"><code class="docutils literal notranslate"><span class="pre">log_softmax()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.lrn"><code class="docutils literal notranslate"><span class="pre">lrn()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.lstm"><code class="docutils literal notranslate"><span class="pre">lstm()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.matmul"><code class="docutils literal notranslate"><span class="pre">matmul()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.mirror_pad"><code class="docutils literal notranslate"><span class="pre">mirror_pad()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.namedtuple"><code class="docutils literal notranslate"><span class="pre">namedtuple()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.nll_loss"><code class="docutils literal notranslate"><span class="pre">nll_loss()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.pad"><code class="docutils literal notranslate"><span class="pre">pad()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.pool1d"><code class="docutils literal notranslate"><span class="pre">pool1d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.pool2d"><code class="docutils literal notranslate"><span class="pre">pool2d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.pool3d"><code class="docutils literal notranslate"><span class="pre">pool3d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.pool_grad"><code class="docutils literal notranslate"><span class="pre">pool_grad()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.prelu"><code class="docutils literal notranslate"><span class="pre">prelu()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.reduce"><code class="docutils literal notranslate"><span class="pre">reduce()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.relu"><code class="docutils literal notranslate"><span class="pre">relu()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.scale_shift_nchw"><code class="docutils literal notranslate"><span class="pre">scale_shift_nchw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.scale_shift_nchwc"><code class="docutils literal notranslate"><span class="pre">scale_shift_nchwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.scale_shift_nhwc"><code class="docutils literal notranslate"><span class="pre">scale_shift_nhwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.simplify"><code class="docutils literal notranslate"><span class="pre">simplify()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.simulated_dequantize"><code class="docutils literal notranslate"><span class="pre">simulated_dequantize()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.simulated_quantize"><code class="docutils literal notranslate"><span class="pre">simulated_quantize()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.softmax"><code class="docutils literal notranslate"><span class="pre">softmax()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.softmax_common"><code class="docutils literal notranslate"><span class="pre">softmax_common()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.space_to_batch_nd"><code class="docutils literal notranslate"><span class="pre">space_to_batch_nd()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.space_to_depth"><code class="docutils literal notranslate"><span class="pre">space_to_depth()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.strided_slice"><code class="docutils literal notranslate"><span class="pre">strided_slice()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.unpack_NCHWc_to_nchw"><code class="docutils literal notranslate"><span class="pre">unpack_NCHWc_to_nchw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.upsampling"><code class="docutils literal notranslate"><span class="pre">upsampling()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.upsampling3d"><code class="docutils literal notranslate"><span class="pre">upsampling3d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.winograd_transform_matrices"><code class="docutils literal notranslate"><span class="pre">winograd_transform_matrices()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.instance_norm"><code class="docutils literal notranslate"><span class="pre">instance_norm()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.layer_norm"><code class="docutils literal notranslate"><span class="pre">layer_norm()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.group_norm"><code class="docutils literal notranslate"><span class="pre">group_norm()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.nn.rms_norm"><code class="docutils literal notranslate"><span class="pre">rms_norm()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-tvm.topi.image">tvm.topi.image</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.affine_grid"><code class="docutils literal notranslate"><span class="pre">affine_grid()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.can_convert_multiply_to_intdiv"><code class="docutils literal notranslate"><span class="pre">can_convert_multiply_to_intdiv()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.crop_and_resize"><code class="docutils literal notranslate"><span class="pre">crop_and_resize()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.dilation2d_nchw"><code class="docutils literal notranslate"><span class="pre">dilation2d_nchw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.dilation2d_nhwc"><code class="docutils literal notranslate"><span class="pre">dilation2d_nhwc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.get_1d_indices"><code class="docutils literal notranslate"><span class="pre">get_1d_indices()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.get_1d_pixel"><code class="docutils literal notranslate"><span class="pre">get_1d_pixel()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.get_2d_indices"><code class="docutils literal notranslate"><span class="pre">get_2d_indices()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.get_2d_pixel"><code class="docutils literal notranslate"><span class="pre">get_2d_pixel()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.get_3d_indices"><code class="docutils literal notranslate"><span class="pre">get_3d_indices()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.get_3d_pixel"><code class="docutils literal notranslate"><span class="pre">get_3d_pixel()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.get_closest_index"><code class="docutils literal notranslate"><span class="pre">get_closest_index()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.get_inx"><code class="docutils literal notranslate"><span class="pre">get_inx()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.get_pad_tuple"><code class="docutils literal notranslate"><span class="pre">get_pad_tuple()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.grid_sample"><code class="docutils literal notranslate"><span class="pre">grid_sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.nchw_pack_layout"><code class="docutils literal notranslate"><span class="pre">nchw_pack_layout()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.nchw_xc_layout"><code class="docutils literal notranslate"><span class="pre">nchw_xc_layout()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.pad"><code class="docutils literal notranslate"><span class="pre">pad()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.resize1d"><code class="docutils literal notranslate"><span class="pre">resize1d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.resize2d"><code class="docutils literal notranslate"><span class="pre">resize2d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.resize3d"><code class="docutils literal notranslate"><span class="pre">resize3d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tvm.topi.image.simplify"><code class="docutils literal notranslate"><span class="pre">simplify()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="meta_schedule.html">tvm.meta_schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="dlight.html">tvm.dlight</a></li>
<li class="toctree-l2"><a class="reference internal" href="rpc.html">tvm.rpc</a></li>
<li class="toctree-l2"><a class="reference internal" href="contrib.html">tvm.contrib</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../links.html">Other APIs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../contribute/index.html">Contributor Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../security.html">Security Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Index</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="index.html">Python API</a> <span class="br-arrow">></span></li>
        
      <li>tvm.topi</li>
    
    
      
      
        
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/tvm/edit/main/docs/reference/api/python/topi.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="tvm-topi">
<h1>tvm.topi<a class="headerlink" href="#tvm-topi" title="Link to this heading"></a></h1>
<p>TVM Operator Inventory.</p>
<p>TOPI is the operator collection library for TVM, to provide sugars
for constructing compute declaration as well as optimized schedules.</p>
<p>Some of the schedule function may have been specially optimized for a
specific workload.</p>
<p><strong>Classes:</strong></p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">Analyzer</span></code>()</p></td>
<td><p>Integer arithmetic analyzer</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">Cast</span></code>(dtype, value[, span])</p></td>
<td><p>Cast expression.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">PrimExpr</span></code></p></td>
<td><p>Base class of all primitive expressions.</p></td>
</tr>
</tbody>
</table>
<p><strong>Functions:</strong></p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">abs</span></code>(x)</p></td>
<td><p>Take absolute value of the input of x, element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">acos</span></code>(x)</p></td>
<td><p>Take arc cos of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">acosh</span></code>(x)</p></td>
<td><p>Take arc cosh of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code>(lhs, rhs)</p></td>
<td><p>Addition with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">adv_index</span></code>(data, indices)</p></td>
<td><p>Numpy style indexing with tensors.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">all</span></code>(data[, axis, keepdims])</p></td>
<td><p>Logical AND of array elements over a given axis or a list of axes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">any</span></code>(data[, axis, keepdims])</p></td>
<td><p>Logical OR of array elements over a given axis or a list of axes</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">arange</span></code>(start[, stop, step, dtype])</p></td>
<td><p>Creates a tensor with evenly spaced values within a given interval.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">argmax</span></code>(data[, axis, keepdims, select_last_index])</p></td>
<td><p>Returns the indices of the maximum values along an axis.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">argmin</span></code>(data[, axis, keepdims, select_last_index])</p></td>
<td><p>Returns the indices of the minimum values along an axis.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">argsort</span></code>(data[, valid_count, axis, ...])</p></td>
<td><p>Performs sorting along the given axis and returns an array of indices having the same shape as an input array that index data in sorted order.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">asin</span></code>(x)</p></td>
<td><p>Take arc sin of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">asinh</span></code>(x)</p></td>
<td><p>Take arc sinh of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">atan</span></code>(x)</p></td>
<td><p>Take atan of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">atanh</span></code>(x)</p></td>
<td><p>Take atanh of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">binary_search</span></code>(ib, sequence_offset, ...)</p></td>
<td><p>Common IR generator for binary search used by CPU and GPU backends.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwise_and</span></code>(lhs, rhs)</p></td>
<td><p>Compute element-wise bitwise and of data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwise_not</span></code>(data)</p></td>
<td><p>Compute element-wise bitwise not of data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwise_or</span></code>(lhs, rhs)</p></td>
<td><p>Compute element-wise bitwise or of data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwise_xor</span></code>(lhs, rhs)</p></td>
<td><p>Compute element-wise bitwise xor of data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">broadcast_to</span></code>(data, shape)</p></td>
<td><p>Broadcast the src to the target shape</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code>(x, dtype[, span])</p></td>
<td><p>Cast input to specified data type.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">ceil</span></code>(x)</p></td>
<td><p>Take ceil of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">ceil_log2</span></code>(x)</p></td>
<td><p>Compute integer ceil log2 with a special code path for vulkan SPIR-V does not support log2 on fp64.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">clip</span></code>(x, a_min, a_max)</p></td>
<td><p>Clip (limit) the values in an array.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">collapse_sum</span></code>(data, target_shape)</p></td>
<td><p>Return a summation of data to the given shape.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">concatenate</span></code>(a_tuple[, axis])</p></td>
<td><p>Join a sequence of arrays along an existing axis.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">const_vector</span></code>(vector[, name])</p></td>
<td><p>convert a const numpy 1-dimensional vector to tvm tensor</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cos</span></code>(x)</p></td>
<td><p>Take cos of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cosh</span></code>(x)</p></td>
<td><p>Take cosh of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cumprod</span></code>(data[, axis, dtype, exclusive])</p></td>
<td><p>Numpy style cumprod op.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cumsum</span></code>(data[, axis, dtype, exclusive])</p></td>
<td><p>Numpy style cumsum op.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">decl_buffer</span></code>(shape[, dtype, name, data, ...])</p></td>
<td><p>Declare a new symbolic buffer.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dft</span></code>(re_data, im_data, inverse)</p></td>
<td><p>Computes the discrete Fourier transform of input (calculation along the last axis).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">div</span></code>(a, b[, span])</p></td>
<td><p>Compute a / b as in C/C++ semantics.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">divide</span></code>(lhs, rhs)</p></td>
<td><p>Division with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dynamic_strided_slice</span></code>(a, begin, end, ...)</p></td>
<td><p>Slice of an array.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">einsum</span></code>(subscripts, *operand)</p></td>
<td><p>Evaluates the Einstein summation convention on the operands.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">elemwise_sum</span></code>(xs)</p></td>
<td><p>Perform element-wise sum on inputs</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">equal</span></code>(lhs, rhs)</p></td>
<td><p>Compute (lhs==rhs) with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">erf</span></code>(x)</p></td>
<td><p>Take gauss error function of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">exp</span></code>(x)</p></td>
<td><p>Take exponential of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">expand_dims</span></code>(a, axis[, num_newaxis])</p></td>
<td><p>Expand the shape of an array.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">expand_like</span></code>(a, shape_like, axis)</p></td>
<td><p>Expand an input array with the shape of second array.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">extern</span></code>(shape, inputs, fcompute[, name, ...])</p></td>
<td><p>Compute several tensors via an extern function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">eye</span></code>(n[, m, k, dtype])</p></td>
<td><p>Generate an identity matrix or a matrix with ones on the k-th diagonal.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fast_erf</span></code>(x)</p></td>
<td><p>Take gauss error function of input x using fast_erf implementation.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fast_exp</span></code>(x)</p></td>
<td><p>Take exponential of input x using fast_exp implementation</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fast_tanh</span></code>(x)</p></td>
<td><p>Take hyperbolic tangent of input x using fast_tanh implementation</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fixed_point_multiply</span></code>(x, multiplier, shift)</p></td>
<td><p>Fixed point multiplication between data and a fixed point constant expressed as multiplier * 2^(-shift), where multiplier is a Q-number with 31 fractional bits</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fixed_point_multiply_per_axis</span></code>(x, y, lshift, ...)</p></td>
<td><p>Fixed point multiplication between data and a fixed point constant expressed as multiplier * 2^(-shift), where multiplier is a Q-number with 31 fractional bits</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">flip</span></code>(a[, axis])</p></td>
<td><p>Flip/reverse elements of an array in a particular axis.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">floor</span></code>(x)</p></td>
<td><p>Take floor of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">floor_divide</span></code>(lhs, rhs)</p></td>
<td><p>Floor division with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">floor_mod</span></code>(lhs, rhs)</p></td>
<td><p>Floor modulus with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">floordiv</span></code>(a, b[, span])</p></td>
<td><p>Compute the floordiv of two expressions.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">floormod</span></code>(a, b[, span])</p></td>
<td><p>Compute the floormod of two expressions.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">full</span></code>(shape, dtype, fill_value)</p></td>
<td><p>Fill tensor with fill_value</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">full_like</span></code>(x, fill_value)</p></td>
<td><p>Construct a tensor with same shape as input tensor,</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">gather</span></code>(data, axis, indices)</p></td>
<td><p>Gather values along given axis from given indices.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">gather_nd</span></code>(a, indices[, batch_dims])</p></td>
<td><p>Gather elements from a n-dimension array..</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_const_tuple</span></code>(in_tuple)</p></td>
<td><p>Verifies input tuple is IntImm or Var, returns tuple of int or Var.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">greater</span></code>(lhs, rhs)</p></td>
<td><p>Compute (lhs&gt;rhs) with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">greater_equal</span></code>(lhs, rhs)</p></td>
<td><p>Compute (lhs&gt;=rhs) with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">identity</span></code>(x)</p></td>
<td><p>Take identity of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">isfinite</span></code>(x)</p></td>
<td><p>Check if value of x is finite, element-wise.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">isinf</span></code>(x)</p></td>
<td><p>Check if value of x is infinite, element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">isnan</span></code>(x)</p></td>
<td><p>Check if value of x is NaN, element-wise.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">layout_transform</span></code>(array, src_layout, dst_layout)</p></td>
<td><p>Transform the layout according to src_layout and dst_layout</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">left_shift</span></code>(lhs, rhs)</p></td>
<td><p>Left shift with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">less</span></code>(lhs, rhs)</p></td>
<td><p>Compute (lhs&lt;rhs) with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">less_equal</span></code>(lhs, rhs)</p></td>
<td><p>Compute (lhs&lt;=rhs) with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">log</span></code>(x)</p></td>
<td><p>Take logarithm of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">log10</span></code>(x)</p></td>
<td><p>Take logarithm to the base 10 of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">log2</span></code>(x)</p></td>
<td><p>Take logarithm to the base 2 of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">logical_and</span></code>(lhs, rhs)</p></td>
<td><p>Compute element-wise logical and of data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">logical_not</span></code>(data)</p></td>
<td><p>Compute element-wise logical not of data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">logical_or</span></code>(lhs, rhs)</p></td>
<td><p>Compute element-wise logical or of data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">logical_xor</span></code>(lhs, rhs)</p></td>
<td><p>Compute element-wise logical xor of data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_idx</span></code>(b, e, s, z, i)</p></td>
<td><p>Return the array position in the selection that corresponds to an array position in the full array.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">matmul</span></code>(a, b[, transp_a, transp_b])</p></td>
<td><p>Creates an operation that calculates a matrix multiplication (row-major notation): A(i, k) * B(k, j) if trans_a == trans_b, the usual transposed combinations, otherwise</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">matrix_set_diag</span></code>(data, diagonal[, k, align])</p></td>
<td><p>Returns a tensor with the diagonals of input tensor replaced with the provided diagonal values.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">max</span></code>(data[, axis, keepdims])</p></td>
<td><p>Maximum of array elements over a given axis or a list of axes</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">maximum</span></code>(lhs, rhs)</p></td>
<td><p>Take element-wise maximum of two tensors with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">meshgrid</span></code>(a_tuple, indexing)</p></td>
<td><p>Create coordinate matrices from coordinate vectors.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">min</span></code>(data[, axis, keepdims])</p></td>
<td><p>Minimum of array elements over a given axis or a list of axes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">minimum</span></code>(lhs, rhs)</p></td>
<td><p>Take element-wise maximum of two tensors with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">mod</span></code>(lhs, rhs)</p></td>
<td><p>Modulus with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">multiply</span></code>(lhs, rhs)</p></td>
<td><p>Multiplication with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">ndarray_size</span></code>(array[, dtype])</p></td>
<td><p>Get the number of elements of input array</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">negative</span></code>(x)</p></td>
<td><p>Take negation of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">not_equal</span></code>(lhs, rhs)</p></td>
<td><p>Compute (lhs!=rhs) with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">one_hot</span></code>(indices, on_value, off_value, depth, ...)</p></td>
<td><p>Returns a one-hot tensor where the locations repsented by indices take value on_value, other locations take value off_value.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">power</span></code>(lhs, rhs)</p></td>
<td><p>Power with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">prod</span></code>(data[, axis, keepdims])</p></td>
<td><p>Product of array elements over a given axis or a list of axes</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">reinterpret</span></code>(x, dtype)</p></td>
<td><p>Reinterpret input to specified data type.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">repeat</span></code>(a, repeats, axis)</p></td>
<td><p>Repeats elements of an array.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">reshape</span></code>(a, newshape)</p></td>
<td><p>Reshape the array</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">reverse_sequence</span></code>(a, seq_lengths[, seq_axis, ...])</p></td>
<td><p>Reverse the tensor for variable length slices.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">right_shift</span></code>(lhs, rhs)</p></td>
<td><p>Right shift with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">round</span></code>(x)</p></td>
<td><p>Round elements of x to nearest integer.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">rsqrt</span></code>(x)</p></td>
<td><p>Take inverse square root of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">scanop</span></code>(data, binop, identity_value, op_name)</p></td>
<td><p>Cumulative binary operator (scan) with similar axis behavior as np.cumsum and np.cumprod.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">scatter_elements</span></code>(data, indices, updates[, ...])</p></td>
<td><p>Scatter elements from updates to corresponding indices of copied data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">scatter_nd</span></code>(data, indices, updates, mode)</p></td>
<td><p>Scatter elements from a n-dimension array.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">searchsorted</span></code>(sorted_sequence, values[, ...])</p></td>
<td><p>Find indices where elements should be inserted to maintain order.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sequence_mask</span></code>(data, valid_length[, ...])</p></td>
<td><p>Sets all elements outside the expected length of the sequence to a constant value.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">shape</span></code>(array[, dtype])</p></td>
<td><p>Get the shape of input array</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sigmoid</span></code>(x)</p></td>
<td><p>Take sigmoid tanh of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sign</span></code>(x)</p></td>
<td><p>Returns -1, 0, 1 based on sign of x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sin</span></code>(x)</p></td>
<td><p>Take sin of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sinh</span></code>(x)</p></td>
<td><p>Take sinh of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sliding_window</span></code>(data, axis, window_shape, strides)</p></td>
<td><p>Slide a window over the data tensor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sort</span></code>(data[, axis, is_ascend])</p></td>
<td><p>Performs sorting along the given axis and returns an array in sorted order.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse_reshape</span></code>(sparse_indices, prev_shape, ...)</p></td>
<td><p>Reshape a Sparse Tensor</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse_to_dense</span></code>(sparse_indices, ...[, ...])</p></td>
<td><p>Converts a sparse representation into a dense tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">split</span></code>(ary, indices_or_sections[, axis])</p></td>
<td><p>Split an array into multiple sub-arrays.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sqrt</span></code>(x)</p></td>
<td><p>Take square root of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">squeeze</span></code>(a[, axis])</p></td>
<td><p>Remove single-dimensional entries from the shape of an array.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">stack</span></code>(a, axis)</p></td>
<td><p>Repeats the whole array multiple times.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">stft</span></code>(data, n_fft, hop_length, win_length, ...)</p></td>
<td><p>The STFT computes the Fourier transform of short overlapping windows of the input.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">strided_set</span></code>(a, v, begin, end[, strides])</p></td>
<td><p>Set slice of an array.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">strided_slice</span></code>(a, begin, end[, strides, ...])</p></td>
<td><p>Slice of an array.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">subtract</span></code>(lhs, rhs)</p></td>
<td><p>Subtraction with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sum</span></code>(data[, axis, keepdims])</p></td>
<td><p>Sum of array elements over a given axis or a list of axes</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">take</span></code>(a, indices[, axis, batch_dims, mode])</p></td>
<td><p>Take elements from an array along an axis.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tan</span></code>(x)</p></td>
<td><p>Take tan of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tanh</span></code>(x)</p></td>
<td><p>Take hyperbolic tanh of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensordot</span></code>(a, b, axes)</p></td>
<td><p>A generalization of matrix multiplication to tensor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tile</span></code>(a, reps)</p></td>
<td><p>Repeats the whole array multiple times.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">topk</span></code>(data[, k, axis, ret_type, is_ascend, dtype])</p></td>
<td><p>Get the top k elements in an input tensor along the given axis.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">transpose</span></code>(a[, axes])</p></td>
<td><p>Permute the dimensions of an array.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">trilu</span></code>(data, k, upper)</p></td>
<td><p>Given a 2-D matrix or batches of 2-D matrices, returns the upper or lower triangular part of the tensor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">trunc</span></code>(x)</p></td>
<td><p>Take truncated value of the input of x, element-wise.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">unravel_index</span></code>(indices, shape)</p></td>
<td><p>Convert a flat index or array of flat indices into a tuple of coordinate arrays.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">where</span></code>(condition, x, y)</p></td>
<td><p>Get the elements, either from x or y, depending on the condition.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">within_index</span></code>(b, e, s, i)</p></td>
<td><p>Return a boolean value that indicates if i is within the given index.</p></td>
</tr>
</tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">InvalidShapeError</span></code></p></td>
<td><p>Invalid shape for a topi function.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">Analyzer</span></span></dt>
<dd><p>Integer arithmetic analyzer</p>
<p>This is a stateful analyzer class that can
be used to perform various symbolic integer analysis.</p>
<p><strong>Methods:</strong></p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">const_int_bound</span></code>(expr)</p></td>
<td><p>Find constant integer bound for expr.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">modular_set</span></code>(expr)</p></td>
<td><p>Find a modular set that expr belongs to.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">simplify</span></code>(expr[, steps])</p></td>
<td><p>Simplify expression via both rewrite and canonicalization.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">rewrite_simplify</span></code>(expr)</p></td>
<td><p>Simplify expression via rewriting rules.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">canonical_simplify</span></code>(expr)</p></td>
<td><p>Simplify expression via canonicalization.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">int_set</span></code>(expr, dom_map)</p></td>
<td><p>Compute a symbolic IntSet that covers expr for all values in dom_map.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">can_prove</span></code>(expr[, strength])</p></td>
<td><p>Check whether we can prove expr to be true.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bind</span></code>(var, expr)</p></td>
<td><p>Bind a variable to the expression.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">constraint_scope</span></code>(constraint)</p></td>
<td><p>Create a constraint scope.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">update</span></code>(var, info[, override])</p></td>
<td><p>Update infomation about var</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">can_prove_equal</span></code>(lhs, rhs)</p></td>
<td><p>Whether we can prove that lhs == rhs</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">enabled_extensions</span></code></p></td>
<td><p>Return the currently enabled extensions</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">const_int_bound</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expr</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Find constant integer bound for expr.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>expr</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The expression.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>bound</strong> – The result bound</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ConstIntBound</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">modular_set</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expr</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Find a modular set that expr belongs to.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>expr</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The expression.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ModularSet</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">simplify</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Simplify expression via both rewrite and canonicalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>expr</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The expression.</p></li>
<li><p><strong>steps</strong> (<em>The simplification runs in the order of</em>) – rewrite_simplify (step 1) -&gt; canonical_simplify (step 2) -&gt;
rewrite_simplify (step 3) -&gt; canonical_simplify (step 4) -&gt; …
param steps controls how many steps to run.
Default is 2, i.e., rewrite_simplify + canonical_simplify.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">rewrite_simplify</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expr</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Simplify expression via rewriting rules.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>expr</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The expression.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">canonical_simplify</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expr</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Simplify expression via canonicalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>expr</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The expression.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">int_set</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dom_map</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute a symbolic IntSet that covers expr for all values in dom_map.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>expr</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The expression.</p></li>
<li><p><strong>dom_map</strong> (<em>Dict</em><em>[</em><a class="reference internal" href="tir/tir.html#tvm.tir.Var" title="tvm.tir.Var"><em>tvm.tir.Var</em></a><em>, </em><em>tvm.arith.IntSet</em><em>]</em>) – The domain for variables to be relaxed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>IntSet</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">can_prove</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">ProofStrength.DEFAULT</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Check whether we can prove expr to be true.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>expr</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The expression.</p></li>
<li><p><strong>strength</strong> (<em>ProofStrength</em>) – The proof strength</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">bind</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tir/tir.html#tvm.tir.Var" title="tvm.tir.expr.Var"><span class="pre">Var</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">expr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.expr.PrimExpr"><span class="pre">PrimExpr</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="ir.html#tvm.ir.Range" title="tvm.ir.expr.Range"><span class="pre">Range</span></a></span></em><span class="sig-paren">)</span></dt>
<dd><p>Bind a variable to the expression.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>var</strong> (<a class="reference internal" href="tir/tir.html#tvm.tir.Var" title="tvm.tir.Var"><em>tvm.tir.Var</em></a>) – The variable.</p></li>
<li><p><strong>expr</strong> (<em>Union</em><em>[</em><em>tir.PrimExpr</em><em>, </em><a class="reference internal" href="ir.html#tvm.ir.Range" title="tvm.ir.Range"><em>ir.Range</em></a><em>]</em>) – The expression or the range to bind to.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">constraint_scope</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constraint</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Create a constraint scope.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>constraint</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The constraint expression.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>scope</strong> – The constraint scope</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ConstraintScope</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">analyzer</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">arith</span><span class="o">.</span><span class="n">Analyzer</span><span class="p">()</span>
<span class="k">with</span> <span class="n">analzyer</span><span class="o">.</span><span class="n">constraint_scope</span><span class="p">(</span><span class="n">x</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    <span class="c1"># constraint in effect</span>
    <span class="k">assert</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">modular_set</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">coeff</span> <span class="o">==</span> <span class="mi">3</span>
<span class="c1"># constraint no longer in effect</span>
<span class="k">assert</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">modular_set</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">coeff</span> <span class="o">!=</span> <span class="mi">3</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">var</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">info</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Update infomation about var</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>var</strong> (<a class="reference internal" href="tir/tir.html#tvm.tir.Var" title="tvm.tir.Var"><em>tvm.tir.Var</em></a>) – The variable.</p></li>
<li><p><strong>info</strong> (<em>tvm.Object</em>) – Related information.</p></li>
<li><p><strong>override</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether allow override.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">can_prove_equal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><span class="pre">PrimExpr</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><span class="pre">PrimExpr</span></a></span></em><span class="sig-paren">)</span></dt>
<dd><p>Whether we can prove that lhs == rhs</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The left-hand side of the comparison</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The right-hand side of the comparison</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – Whether we can prove that lhs == rhs</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">enabled_extensions</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Extension</span></em></dt>
<dd><p>Return the currently enabled extensions</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">Cast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.base.Span"><span class="pre">Span</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Cast expression.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The data type</p></li>
<li><p><strong>value</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The value of the function.</p></li>
<li><p><strong>span</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.Span"><em>Span</em></a><em>]</em>) – The location of this expression in the source code.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">PrimExpr</span></span></dt>
<dd><p>Base class of all primitive expressions.</p>
<p>PrimExpr is used in the low-level code
optimizations and integer analysis.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">abs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take absolute value of the input of x, element-wise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">acos</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take arc cos of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">acosh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take arc cosh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Addition with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">adv_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Numpy style indexing with tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input data.</p></li>
<li><p><strong>indices</strong> (<em>A list</em><em> of </em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Tensor index.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – Output tensor</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Logical AND of array elements over a given axis or a list of axes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input tvm boolean tensor</p></li>
<li><p><strong>axis</strong> (<em>None</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis or axes along which a logical AND is performed.
The default, axis=None, will perform logical AND over all elements of the input array.
If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">any</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Logical OR of array elements over a given axis or a list of axes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input tvm boolean tensor</p></li>
<li><p><strong>axis</strong> (<em>None</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis or axes along which a logical OR is performed.
The default, axis=None, will perform logical OR over all elements of the input array.
If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">arange</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'float32'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Creates a tensor with evenly spaced values within a given interval.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>start</strong> (<em>tvm.Expr</em><em>, </em><em>optional</em>) – Start of interval. The interval includes this value. The default start
value is 0.</p></li>
<li><p><strong>stop</strong> (<em>tvm.Expr</em>) – Stop of interval. The interval does not include this value.</p></li>
<li><p><strong>step</strong> (<em>tvm.Expr</em><em>, </em><em>optional</em>) – Spacing between values. The default step size is 1.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The target data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The resulting tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">argmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">select_last_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Returns the indices of the maximum values along an axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input tvm tensor</p></li>
<li><p><strong>axis</strong> (<em>None</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis or axes along which a argmax operation is performed.
The default, axis=None, will find the indices of the maximum element of the elements of
the input array. If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
<li><p><strong>select_last_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether to select the last index if the maximum element appears multiple times, else
select the first index.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">argmin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">select_last_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Returns the indices of the minimum values along an axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input tvm tensor</p></li>
<li><p><strong>axis</strong> (<em>None</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis or axes along which a argmin operation is performed.
The default, axis=None, will find the indices of minimum element all of the elements of
the input array. If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
<li><p><strong>select_last_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether to select the last index if the minimum element appears multiple times, else
select the first index.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">argsort</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_count</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_ascend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'float32'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Performs sorting along the given axis and returns an array
of indices having the same shape as an input array that index
data in sorted order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>valid_count</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) – 1-D tensor for valid number of boxes.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Axis along which to sort the input tensor.
By default the flattened array is used.</p></li>
<li><p><strong>is_ascend</strong> (<em>boolean</em><em>, </em><em>optional</em>) – Whether to sort in ascending or descending order.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) – DType of the output indices.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>out</strong> – Sorted index tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># An example to use argsort</span>
<span class="n">dshape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dshape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">is_ascend</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">argsort</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">is_ascend</span><span class="o">=</span><span class="n">is_ascend</span><span class="p">)</span>
<span class="n">np_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">dshape</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">generic</span><span class="o">.</span><span class="n">schedule_argsort</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">out</span><span class="p">],</span> <span class="s2">&quot;llvm&quot;</span><span class="p">)</span>
<span class="n">dev</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="n">tvm_data</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np_data</span><span class="p">,</span> <span class="n">dev</span><span class="p">)</span>
<span class="n">tvm_out</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dshape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">dev</span><span class="p">)</span>
<span class="n">f</span><span class="p">(</span><span class="n">tvm_data</span><span class="p">,</span> <span class="n">tvm_out</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">asin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take arc sin of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">asinh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take arc sinh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">atan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take atan of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">atanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take atanh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">binary_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ib</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequence_offset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_range</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sorted_sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">right</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Common IR generator for binary search used by CPU and GPU backends.</p>
<p><cite>sorted_sequence</cite> is a N-D Buffer whose innermost dimension we want to search for <cite>value</cite>,
and <cite>search_range</cite> is the size of the innermost dimension. <cite>sequence_offset</cite> is
a 1-D linearlized offset specifying which of innermost sequences to search.</p>
<p>So the search for <cite>value</cite> is performed over
<cite>sorted_sequence[sequence_offset:(sequence_offset + search_range)]</cite>.
Note that we index N-D Buffer by 1-D linearlized indices.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">bitwise_and</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute element-wise bitwise and of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">bitwise_not</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute element-wise bitwise not of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if the operand are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">bitwise_or</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute element-wise bitwise or of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">bitwise_xor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute element-wise bitwise xor of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">broadcast_to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Broadcast the src to the target shape</p>
<p>We follows the numpy broadcasting rule.
See also <a class="reference external" href="https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input data</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a>) – The target shape to be broadcasted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">cast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Cast input to specified data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – Input argument.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Data type.</p></li>
<li><p><strong>span</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.Span"><em>Span</em></a><em>]</em>) – The location of the cast in the source.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">ceil</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take ceil of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">ceil_log2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute integer ceil log2 with a special code path for vulkan
SPIR-V does not support log2 on fp64. Instead, we compute integer ceil_log2 via clz
intrinsic when the target is vulkan.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">clip</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a_min</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a_max</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Clip (limit) the values in an array. Given an interval, values
outside the interval are clipped to the interval edges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p></li>
<li><p><strong>a_min</strong> (<em>tvm.tir.PrimExpr</em>) – Minimum value.</p></li>
<li><p><strong>a_max</strong> (<em>tvm.tir.PrimExpr</em>) – Maximum value.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">collapse_sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_shape</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Return a summation of data to the given shape.</p>
<p>collapse_sum is intended as the backward operator of topi broadcast operators in the automatic
differentiation process.</p>
<p>We expect that data is the result of broadcasting some tensor of target_shape in some
broadcast operation. Thus target_shape and data.shape must follow broadcast rules.</p>
<p>During computation, the axes of data.shape and target_shape are checked from right to left.
For every axis, if it either:
- exist in data but not in target_shape, or
- is larger than 1 in data and equals to 1 in target_shape,
data will be summed over this axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>shape</strong> (<a class="reference internal" href="relax/relax.html#tvm.relax.Tuple" title="tvm.relax.Tuple"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em>) – The shape to collapse to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The result tensor after summation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">concatenate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a_tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Join a sequence of arrays along an existing axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_tuple</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The arrays to concatenate</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The axis along which the arrays will be joined. Default is 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">const_vector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vector</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'const_vector'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>convert a const numpy 1-dimensional vector to tvm tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vector</strong> (<em>numpy.ndarray</em>) – Const input array</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The name of output op</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>tensor</strong> – The created tensor</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">cos</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take cos of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">cosh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take cosh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">cumprod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclusive</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></span></dt>
<dd><p>Numpy style cumprod op. Return the cumulative product of the elements along a given axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input data to the operator.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Axis along which the cumulative product is computed. The default (None) is to compute
the cumproduct over the flattened array.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) – Type of the returned array and of the accumulator in which the elements are multiplied.
If dtype is not specified, it defaults to the dtype of data.</p></li>
<li><p><strong>exclusive</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, will return exclusive product in which the first element is not
included. In other terms, if True, the j-th output element would be
the product of the first (j-1) elements. Otherwise, it would be the product of
the first j elements.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The result has the same size as data, and the same shape as data if axis is not None.
If axis is None, the result is a 1-d array.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">cumsum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclusive</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></span></dt>
<dd><p>Numpy style cumsum op. Return the cumulative sum of the elements along a given axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input data to the operator.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Axis along which the cumulative sum is computed. The default (None) is to compute
the cumsum over the flattened array.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) – Type of the returned array and of the accumulator in which the elements are summed.
If dtype is not specified, it defaults to the dtype of data.</p></li>
<li><p><strong>exclusive</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, will return exclusive sum in which the first element is not
included. In other terms, if True, the j-th output element would be
the sum of the first (j-1) elements. Otherwise, it would be the sum of
the first j elements.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The result has the same size as data, and the same shape as data if axis is not None.
If axis is None, the result is a 1-d array.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">decl_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'buffer'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">elem_offset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scope</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_alignment</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis_separators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Declare a new symbolic buffer.</p>
<p>Normally buffer is created automatically during lower and build.
This is only needed if user want to specify their own buffer layout.</p>
<p>See the note below for detailed discussion on usage of buffer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>Expr</em>) – The shape of the buffer.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The data type of the buffer.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The name of the buffer.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="tir/tir.html#tvm.tir.Var" title="tvm.tir.Var"><em>tir.Var</em></a><em>, </em><em>optional</em>) – The data pointer in the buffer.</p></li>
<li><p><strong>strides</strong> (<em>array</em><em> of </em><em>Expr</em>) – The stride of the buffer.</p></li>
<li><p><strong>elem_offset</strong> (<em>Expr</em><em>, </em><em>optional</em>) – The beginning offset of the array to data.
In terms of number of elements of dtype.</p></li>
<li><p><strong>scope</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The storage scope of the buffer, if not global.
If scope equals empty string, it means it is global memory.</p></li>
<li><p><strong>data_alignment</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The alignment of data pointer in bytes.
If -1 is passed, the alignment will be set to TVM’s internal default.</p></li>
<li><p><strong>offset_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The factor of elem_offset field, when set,
elem_offset is required to be multiple of offset_factor.
If 0 is pssed, the alignment will be set to 1.
if non-zero is passed, we will created a Var for elem_offset if elem_offset is not None.</p></li>
<li><p><strong>buffer_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em><em>, </em><em>{&quot;&quot;</em><em>, </em><em>&quot;auto_broadcast&quot;}</em>) – auto_broadcast buffer allows one to implement broadcast computation
without considering whether dimension size equals to one.
TVM maps buffer[i][j][k] -&gt; buffer[i][0][k] if dimension j’s shape equals 1.</p></li>
<li><p><strong>axis_separators</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – If passed, a list of separators between groups of axes,
each of which is flattened to an output axis.  For flat
memory spaces, should either be None, or an empty list.</p></li>
<li><p><strong>span</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.Span"><em>Span</em></a><em>]</em>) – The location of the decl_buffer creation in the source.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>buffer</strong> – The created buffer</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="tir/tir.html#tvm.tir.Buffer" title="tvm.tir.Buffer">tvm.tir.Buffer</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Buffer data structure reflects the DLTensor structure in dlpack.
While DLTensor data structure is very general, it is usually helpful
to create function that only handles specific case of data structure
and make compiled function benefit from it.</p>
<p>If user pass strides and elem_offset is passed as None
when constructing the function, then the function will be specialized
for the DLTensor that is compact and aligned.
If user pass a fully generic symbolic array to the strides,
then the resulting function becomes fully generic.</p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">dft</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">re_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">im_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tir/tir.html#tvm.tir.IntImm" title="tvm.tir.expr.IntImm"><span class="pre">IntImm</span></a></span></em><span class="sig-paren">)</span></dt>
<dd><p>Computes the discrete Fourier transform of input (calculation along the last axis).
This gives frequency components of the signal as they change over time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>re_data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a>) – N-D tensor, real part of the input signal.</p></li>
<li><p><strong>im_data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a>) – N-D tensor, imaginary part of the input signal.
If the signal is real, then the values of this tensor are zeros.</p></li>
<li><p><strong>inverse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether to perform the inverse discrete fourier transform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>re_output</strong> (<em>te.Tensor</em>) – The Fourier Transform of the input (Real part).</p></li>
<li><p><strong>im_output</strong> (<em>te.Tensor</em>) – The Fourier Transform of the input (Imaginary part).</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">div</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute a / b as in C/C++ semantics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The left hand operand, known to be non-negative.</p></li>
<li><p><strong>b</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The right hand operand, known to be non-negative.</p></li>
<li><p><strong>span</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.Span"><em>Span</em></a><em>]</em>) – The location of this operator in the source.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>res</strong> – The result expression.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr">PrimExpr</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When operands are integers, returns truncdiv(a, b, span).</p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">divide</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Division with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">dynamic_strided_slice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">begin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Slice of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be sliced.</p></li>
<li><p><strong>begin</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The indices to begin with in the slicing.</p></li>
<li><p><strong>end</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Indices indicating end of the slice.</p></li>
<li><p><strong>strides</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Specifies the stride values, it can be negative
in that case, the input tensor will be reversed
in that particular axis.</p></li>
<li><p><strong>output_shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – Specifies the output shape</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">einsum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subscripts</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">operand</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Evaluates the Einstein summation convention on the operands.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>subscripts</strong> (<em>string</em>) – Specifies the subscripts for summation as comma separated list of subscript labels.
An implicit (classical Einstein summation) calculation is performed unless the
explicit indicator ‘-&gt;’ is included as well as subscript labels of the precise
output form.</p></li>
<li><p><strong>a_tuple</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – These are the Tensors for the operation.
The only difference of einsum between in tvm and numpy is it needs an extra brackets
for the tensors. For example, topi.einsum(“ij, jk -&gt; ik”, (A, B)).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>out</strong> – The calculation based on the Einstein summation convention.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">elemwise_sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">xs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Perform element-wise sum on inputs</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>xs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input arguments.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">equal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute (lhs==rhs) with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">erf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take gauss error function of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">exp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take exponential of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">expand_dims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_newaxis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Expand the shape of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be expanded.</p></li>
<li><p><strong>num_newaxis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of newaxis to be inserted on axis</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">expand_like</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape_like</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Expand an input array with the shape of second array.
This operation can always be composed of unsqueezing and
expanding dims on those unsqueezed axes.</p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">12.</span>  <span class="mf">19.</span>  <span class="mf">27.</span><span class="p">]</span>
<span class="nb">input</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,)</span>

<span class="n">new_shape_array</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">3</span><span class="p">]]]</span>
<span class="n">new_shape_array</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">expand_like</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">new_shape_array</span><span class="p">)</span> <span class="o">=</span>
                <span class="p">[[[</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">],[</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">],[</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mi">19</span><span class="p">,</span><span class="mi">19</span><span class="p">],[</span><span class="mi">19</span><span class="p">,</span><span class="mi">19</span><span class="p">],[</span><span class="mi">19</span><span class="p">,</span><span class="mi">19</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mi">27</span><span class="p">,</span><span class="mi">27</span><span class="p">],[</span><span class="mi">27</span><span class="p">,</span><span class="mi">27</span><span class="p">],[</span><span class="mi">27</span><span class="p">,</span><span class="mi">27</span><span class="p">]]]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be expanded.</p></li>
<li><p><strong>shape_like</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to with target shape.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – axis to be expanded on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">extern</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fcompute</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'extern'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_buffers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_buffers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attrs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute several tensors via an extern function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>tuples.</em>) – The shape of the outputs.</p></li>
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>Tensor</em></a>) – The inputs</p></li>
<li><p><strong>fcompute</strong> (<em>lambda function</em><em> of </em><em>inputs</em><em>, </em><em>outputs-&gt; stmt</em>) – <p>Specifies the IR statement to do the computation.
See the following note for function signature of fcompute</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Parameters</strong></p>
<ul>
<li><p><strong>ins</strong> (list of <a class="reference internal" href="tir/tir.html#tvm.tir.Buffer" title="tvm.tir.Buffer"><code class="xref any py py-class docutils literal notranslate"><span class="pre">tvm.tir.Buffer</span></code></a>) - Placeholder for each inputs</p></li>
<li><p><strong>outs</strong> (list of <a class="reference internal" href="tir/tir.html#tvm.tir.Buffer" title="tvm.tir.Buffer"><code class="xref any py py-class docutils literal notranslate"><span class="pre">tvm.tir.Buffer</span></code></a>) - Placeholder for each outputs</p></li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><p><strong>stmt</strong> (<a class="reference internal" href="tir/tir.html#tvm.tir.Stmt" title="tvm.tir.Stmt"><code class="xref any py py-class docutils literal notranslate"><span class="pre">tvm.tir.Stmt</span></code></a>) - The statement that carries out array computation.</p></li>
</ul>
</div>
</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The name hint of the tensor</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The data types of outputs,
by default dtype will be same as inputs.</p></li>
<li><p><strong>in_buffers</strong> (<a class="reference internal" href="tir/tir.html#tvm.tir.Buffer" title="tvm.tir.Buffer"><em>tvm.tir.Buffer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference internal" href="tir/tir.html#tvm.tir.Buffer" title="tvm.tir.Buffer"><em>tvm.tir.Buffer</em></a><em>, </em><em>optional</em>) – Input buffers.</p></li>
<li><p><strong>out_buffers</strong> (<a class="reference internal" href="tir/tir.html#tvm.tir.Buffer" title="tvm.tir.Buffer"><em>tvm.tir.Buffer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference internal" href="tir/tir.html#tvm.tir.Buffer" title="tvm.tir.Buffer"><em>tvm.tir.Buffer</em></a><em>, </em><em>optional</em>) – Output buffers.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>tag: str, optional</dt><dd><p>Additonal tag information about the compute.</p>
</dd>
<dt>attrs: dict, optional</dt><dd><p>The additional auxiliary attributes about the compute.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tensor</strong> – The created tensor or tuple of tensors contains multiple outputs.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">Tensor</a> or <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a> of Tensors</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>In the code below, C is generated by calling external PackedFunc
<cite>tvm.contrib.cblas.matmul</cite></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">l</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;A&quot;</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="n">l</span><span class="p">,</span> <span class="n">m</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;B&quot;</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">extern</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">),</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span>
               <span class="k">lambda</span> <span class="n">ins</span><span class="p">,</span> <span class="n">outs</span><span class="p">:</span> <span class="n">tvm</span><span class="o">.</span><span class="n">tir</span><span class="o">.</span><span class="n">call_packed</span><span class="p">(</span>
                  <span class="s2">&quot;tvm.contrib.cblas.matmul&quot;</span><span class="p">,</span>
                    <span class="n">ins</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ins</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">outs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">eye</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'float32'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></span></dt>
<dd><p>Generate an identity matrix or a matrix with ones on the k-th diagonal.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Number of rows</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of columns. If None, defaults to n.</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Index of the diagonal. 0 (default) refers to the main diagonal.
A positive value refers to an upper diagonal, and a negative value
to a lower diagonal.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Data type of the returned array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">fast_erf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take gauss error function of input x using fast_erf implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">fast_exp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take exponential of input x using fast_exp implementation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">fast_tanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take hyperbolic tangent of input x using fast_tanh implementation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">fixed_point_multiply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiplier</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shift</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Fixed point multiplication between data and a fixed point
constant expressed as multiplier * 2^(-shift), where multiplier
is a Q-number with 31 fractional bits</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – Input argument.</p></li>
<li><p><strong>multiplier</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Multiplier of a fixed floating point number described as multiplier*2^(-shift).</p></li>
<li><p><strong>shift</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Shift of a fixed floating point number described as multiplier*2^(-shift).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">fixed_point_multiply_per_axis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">lshift</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">rshift</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_lshift_required</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_rshift_required</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Fixed point multiplication between data and a fixed point constant expressed as
multiplier * 2^(-shift), where multiplier is a Q-number with 31 fractional bits</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p></li>
<li><p><strong>y</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Multiplier of a fixed floating point number described as multiplier*2^(-shift).</p></li>
<li><p><strong>lshift</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Left shifts of a fixed floating point number described as multiplier*2^(-shift).</p></li>
<li><p><strong>rshift</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Right shifts of a fixed floating point number described as multiplier*2^(-shift).</p></li>
<li><p><strong>is_lshift_required</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Whether we need to do left shift or not.</p></li>
<li><p><strong>is_rshift_required</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Whether we need to do right shift or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>z</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">flip</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Flip/reverse elements of an array in a particular axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be expanded.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The axis along which the tensors will be reveresed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">floor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take floor of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">floor_divide</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Floor division with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">floor_mod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Floor modulus with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">floordiv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute the floordiv of two expressions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The left hand operand</p></li>
<li><p><strong>b</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The right hand operand</p></li>
<li><p><strong>span</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.Span"><em>Span</em></a><em>]</em>) – The location of this operator in the source.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>res</strong> – The result expression.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr">PrimExpr</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">floormod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute the floormod of two expressions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The left hand operand</p></li>
<li><p><strong>b</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) – The right hand operand</p></li>
<li><p><strong>span</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.Span"><em>Span</em></a><em>]</em>) – The location of this operator in the source.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>res</strong> – The result expression.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr">PrimExpr</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">full</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill_value</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Fill tensor with fill_value</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a>) – Input tensor shape.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Data type</p></li>
<li><p><strong>fill_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Value to be filled</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">full_like</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill_value</span></span></em><span class="sig-paren">)</span></dt>
<dd><dl class="simple">
<dt>Construct a tensor with same shape as input tensor,</dt><dd><p>then fill tensor with fill_value.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p></li>
<li><p><strong>fill_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Value to be filled</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">gather</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Gather values along given axis from given indices.</p>
<p>E.g. for a 3D tensor, output is computed as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if axis == 0</span>
<span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if axis == 1</span>
<span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]]</span>  <span class="c1"># if axis == 2</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">indices</span></code> must have same shape as <code class="docutils literal notranslate"><span class="pre">data</span></code>, except at dimension <code class="docutils literal notranslate"><span class="pre">axis</span></code>
which must just be not null. Output will have same shape as <code class="docutils literal notranslate"><span class="pre">indices</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input data to the operator.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The axis along which to index.</p></li>
<li><p><strong>indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The indices of the values to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">gather_nd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Gather elements from a n-dimension array..</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The source array.</p></li>
<li><p><strong>indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The indices of the values to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">get_const_tuple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_tuple</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Verifies input tuple is IntImm or Var, returns tuple of int or Var.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>in_tuple</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>Expr</em>) – The input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>out_tuple</strong> – The output.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a> of <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">greater</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute (lhs&gt;rhs) with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">greater_equal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute (lhs&gt;=rhs) with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">identity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take identity of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">isfinite</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Check if value of x is finite, element-wise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">isinf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Check if value of x is infinite, element-wise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">isnan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Check if value of x is NaN, element-wise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">layout_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_layout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dst_layout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schedule_rule</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'None'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Transform the layout according to src_layout and dst_layout</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>array</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The source array.</p></li>
<li><p><strong>src_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – the source layout.</p></li>
<li><p><strong>dst_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – the destination layout.</p></li>
<li><p><strong>schedule_rule</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – the schedule rule to apply if any</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">left_shift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Left shift with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">less</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute (lhs&lt;rhs) with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">less_equal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute (lhs&lt;=rhs) with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take logarithm of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">log10</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take logarithm to the base 10 of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">log2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take logarithm to the base 2 of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">logical_and</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute element-wise logical and of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">logical_not</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute element-wise logical not of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if the operand are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">logical_or</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute element-wise logical or of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">logical_xor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute element-wise logical xor of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">make_idx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">e</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Return the array position in the selection that corresponds to an
array position in the full array.</p>
<p>The returned value is only meaningful if within_index() returns True
for the same set of parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>Expr</em>) – beginning of the index</p></li>
<li><p><strong>e</strong> (<em>Expr</em>) – end of the index</p></li>
<li><p><strong>s</strong> (<em>Expr</em>) – strides of index</p></li>
<li><p><strong>z</strong> (<em>Expr</em>) – size of the indexed dimension</p></li>
<li><p><strong>i</strong> (<em>Expr</em>) – array position</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>position</strong> – int expression that corresponds to an array position in the selection.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">matmul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transp_a</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transp_b</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Creates an operation that calculates a matrix multiplication (row-major notation):
A(i, k) * B(k, j)
if trans_a == trans_b, the usual transposed combinations, otherwise</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>The matrix A</em>)</p></li>
<li><p><strong>b</strong> (<em>The matrix B</em>)</p></li>
<li><p><strong>trans_a</strong> (<em>Is A's layout transposed?</em>)</p></li>
<li><p><strong>trans_b</strong> (<em>Is B's layout transposed?</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A Tensor whose op member is the matmul operation</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">matrix_set_diag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diagonal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'RIGHT_LEFT'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Returns a tensor with the diagonals of input tensor replaced with the provided diagonal values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input Tensor.</p></li>
<li><p><strong>diagonal</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Values to be filled in the diagonal.</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Diagonal Offset(s). The diagonal or range of diagonals to set. (0 by default)
Positive value means superdiagonal, 0 refers to the main diagonal, and
negative value means subdiagonals. k can be a single integer (for a single diagonal)
or a pair of integers specifying the low and high ends of a matrix band.
k[0] must not be larger than k[1].</p></li>
<li><p><strong>align</strong> (<em>string</em><em>, </em><em>optional</em>) – Some diagonals are shorter than max_diag_len and need to be padded.
align is a string specifying how superdiagonals and subdiagonals should be aligned,
respectively. There are four possible alignments: “RIGHT_LEFT” (default), “LEFT_RIGHT”,
“LEFT_LEFT”, and “RIGHT_RIGHT”. “RIGHT_LEFT” aligns superdiagonals to the right
(left-pads the row) and subdiagonals to the left (right-pads the row). It is the packing
format LAPACK uses. cuSPARSE uses “LEFT_RIGHT”, which is the opposite alignment.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – New tensor with given diagonal values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">]]]</span>

<span class="n">diagonal</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
            <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]</span>

<span class="n">topi</span><span class="o">.</span><span class="n">matrix_set_diag</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">)</span> <span class="o">=</span>
    <span class="p">[[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span>
     <span class="p">[[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Maximum of array elements over a given axis or a list of axes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input tvm tensor</p></li>
<li><p><strong>axis</strong> (<em>None</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis or axes along which the max operation is performed.
The default, axis=None, will find the max element from all of the elements of the input
array. If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">maximum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take element-wise maximum of two tensors with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">meshgrid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a_tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indexing</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Create coordinate matrices from coordinate vectors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_tuple</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The coordinate vectors or scalars.</p></li>
<li><p><strong>indexing</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Indexing mode, either “ij” or “xy”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The resulting grids for each axis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a> of <a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">min</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Minimum of array elements over a given axis or a list of axes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input tvm tensor</p></li>
<li><p><strong>axis</strong> (<em>None</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis or axes along which a minimum operation is performed.
The default, axis=None, will find the minimum element from all of the elements of the
input array. If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">minimum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take element-wise maximum of two tensors with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">mod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Modulus with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">multiply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Multiplication with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">ndarray_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'int32'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Get the number of elements of input array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>array</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The source tensor.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The target data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The resulting tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">negative</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take negation of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">not_equal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute (lhs!=rhs) with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">one_hot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">off_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Returns a one-hot tensor where the locations repsented by indices take value on_value,
other locations take value off_value.
Final dimension is &lt;indices outer dimensions&gt; x depth x &lt;indices inner dimensions&gt;.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Locations to set to on_value.</p></li>
<li><p><strong>on_value</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Value to fill at indices.</p></li>
<li><p><strong>off_value</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Value to fill at all other positions besides indices.</p></li>
<li><p><strong>depth</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Depth of the one-hot dimension.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis to fill.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Data type of the output tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The one-hot tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="n">topi</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">=</span>
    <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">power</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Power with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">prod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Product of array elements over a given axis or a list of axes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input tvm tensor</p></li>
<li><p><strong>axis</strong> (<em>None</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis or axes along which a prod operation is performed.
The default, axis=None, will get the prod element over all of the elements of the
input array. If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">reinterpret</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Reinterpret input to specified data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">repeat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repeats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Repeats elements of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be repeated.</p></li>
<li><p><strong>repeats</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>required</em>) – Number of repetitions for each element</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The axis along which to repeat values</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">reshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">newshape</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Reshape the array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be reshaped</p></li>
<li><p><strong>newshape</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>ints</em>) – The new shape</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">reverse_sequence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_lengths</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Reverse the tensor for variable length slices.
Input is first sliced along batch axis and then elements are reversed along seq axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be reversed.</p></li>
<li><p><strong>seq_lengths</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – A 1D Tensor with length a.dims[batch_axis]
Must be one of the following types: int32, int64
if seq_lengths[i] &gt; a.dims[seq_axis], it is rounded to a.dims[seq_axis]
if seq_lengths[i] &lt; 1, it is rounded to 1</p></li>
<li><p><strong>seq_axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The axis along which the elements will be reversed. Default is 1.</p></li>
<li><p><strong>batch_axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The axis along which the tensor will be sliced. Default is 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The computed result of same shape and type as of input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">right_shift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Right shift with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">round</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Round elements of x to nearest integer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">rsqrt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take inverse square root of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">scanop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">binop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">tvm.Expr</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tvm.Expr</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tvm.Expr</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">identity_value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tvm.Expr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclusive</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></span></dt>
<dd><p>Cumulative binary operator (scan) with similar axis behavior as np.cumsum and np.cumprod.</p>
<p>See cumprod and cumsum for an example of use.</p>
<p>E.g. if * is your binary operator and the input tensor is [1, 2, 3, 4] the output may be
[1, 1 * 2, 1 * 2 * 3, 1 * 2 * 3 * 4]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input data to the operator.</p></li>
<li><p><strong>binop</strong> (<em>Callable</em><em> (</em><em>tvm.Expr</em><em>, </em><em>tvm.Expr</em><em>) </em><em>-&gt; tvm.Expr</em>) – A binary operator which should be associative and commutative. E.g. if * is your
operator then a * (b * c) = (a * b) * c and a * b = b * a</p></li>
<li><p><strong>identity_value</strong> (<em>tvm.Expr</em>) – A value for the binary operation which provides the identity property. E.g. if * is
your operator and i is the identity_value then a * i = a for all a in the domain of
your operation.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Axis along which the operation is computed. The default (None) is to compute
the cumulative operation over the flattened array.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) – Type of the returned array and of the accumulator in which the elements are computed.
If dtype is not specified, it defaults to the dtype of data.</p></li>
<li><p><strong>exclusive</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True will return exclusive cumulative operation in which the first element is not
included. In other terms, if True, the j-th output element would be
the cumulative operation of the first (j-1) elements. Otherwise, it would be the
cumulative operation of the first j elements. The cumulative operation of zero elements
is assumed to be the identity_value.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The result has the same size as data, and the same shape as data if axis is not None.
If axis is None, the result is a 1-d array.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">scatter_elements</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">updates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'update'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Scatter elements from updates to corresponding indices of copied data.</p>
<p>Data, indices, updates and output have the same shape.
Indices can not have duplicates (if idx1 != idx2, then indices[idx1] != indices[idx2])
if reduction == “update”.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]][</span><span class="n">j</span><span class="p">],</span> <span class="n">updates</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">])</span> <span class="k">if</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]],</span> <span class="n">updates</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">])</span> <span class="k">if</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>where the update function f is determined by the reduction.
Five types of the function are supported: “update”, “add”, “mul”, “min” and “max” (see below)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The source array.</p></li>
<li><p><strong>indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The indices of the values to extract.</p></li>
<li><p><strong>updates</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The updates to apply at the Indices</p></li>
<li><p><strong>axis</strong> (<em>optional</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The axis to scatter on. It is zero by default.</p></li>
<li><p><strong>reduction</strong> (<em>optional</em><em>, </em><em>string</em>) – The update mode for the algorithm, either “update”, “add”, “mul”, “min” or “max”
If update, the update values will replace the input data
If add, the update values will be added to the input data
If mul, the input data will be multiplied on the update values
If mean, the input data will be mean between the update values and the input data
If min, there is choice of minimal between the update values and the input data
If max, there is choice of maximal between the update values and the input data
It is “update” by default</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">scatter_nd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">updates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Scatter elements from a n-dimension array.</p>
<p>Given updates with shape (Y_0, …, Y_{K-1}, X_M, …, X_{N-1}), indices with shape
(M, Y_0, …, Y_{K-1}), and output copied from data with shape (X_0, X_1, …, X_{N-1}),
scatter_nd computes</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">y_0</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">y_</span><span class="p">{</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">}],</span>
       <span class="o">...</span><span class="p">,</span>
       <span class="n">indices</span><span class="p">[</span><span class="n">M</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">y_0</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">y_</span><span class="p">{</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">}],</span>
       <span class="n">x_M</span><span class="p">,</span>
       <span class="o">...</span><span class="p">,</span>
       <span class="n">x_</span><span class="p">{</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">}</span>
      <span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="o">...</span><span class="p">],</span> <span class="n">updates</span><span class="p">[</span><span class="n">y_0</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">y_</span><span class="p">{</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">},</span> <span class="n">x_M</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">x_</span><span class="p">{</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">}])</span>
</pre></div>
</div>
<p>where the update function f is determinted by the mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The source array.</p></li>
<li><p><strong>indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The indices of the values to extract.</p></li>
<li><p><strong>updates</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The updates to apply at the Indices</p></li>
<li><p><strong>mode</strong> (<em>string</em>) – The update mode for the algorithm, either “update” or “add”
If update, the update values will replace the input data
If add, the update values will be added to the input data</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">searchsorted</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sorted_sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">right</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'int64'</span></span></em><span class="sig-paren">)</span></dt>
<dd><dl class="simple">
<dt>Find indices where elements should be inserted to maintain order.</dt><dd><p>If <cite>sorted_sequence</cite> is N-dimensional, the innermost dimension of
<cite>values</cite> are searched in the corresponding dimension of <cite>sorted_sequence</cite>.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sorted_sequence</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a>) – N-D or 1-D Tensor, containing monotonically increasing sequence
on the innermost dimension.</p></li>
<li><p><strong>values</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a>) – N-D Tensor containing the search values. When <cite>sorted_sequence</cite> is 1-D,
the shape of <cite>values</cite> can be arbitrary. Otherwise, ranks of <cite>sorted_sequence</cite>
and <cite>values</cite> must be the same, and outer N-1 axes must have the same size.</p></li>
<li><p><strong>right</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Controls which index is returned if a value lands exactly on one of sorted values. If
False, the index of the first suitable location found is given. If true, return the
last such index. If there is no suitable index, return either 0 or N (where N is the
size of the innermost dimension).</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) – The data type of the output indices.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>indices</strong> – Tensor with same shape as values, representing the indices of
elements of <cite>values</cite> if they are inserted in <cite>sorted_sequence</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">sequence_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Sets all elements outside the expected length of the sequence to a constant value.</p>
<p>This function takes an n-dimensional input array of the form [MAX_LENGTH, batch_size, …] or
[batch_size, MAX_LENGTH, …] and returns an array of the same shape.</p>
<p><cite>axis</cite> means the axis of the length dimension and can only be 0 or 1. If <cite>axis</cite> is 0,
the data must have shape [MAX_LENGTH, batch_size, …]. Otherwise (axis=1), the data must have
shape [batch_size, MAX_LENGTH, …].</p>
<p><cite>valid_length</cite> gives the length of each sequence. <cite>valid_length</cite> should be
a 1D int array with positive ints and has dimension [batch_size,].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – N-D with shape [MAX_LENGTH, batch_size, …] or [batch_size, MAX_LENGTH, …]
depending on the value of <cite>axis</cite>.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 1-D with shape [batch_size,]</p></li>
<li><p><strong>mask_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – The masking value, default 0</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – axis of the length dimension, must be 0 or 1, default 0</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – N-D with shape [MAX_LENGTH, batch_size, …] or [batch_size, MAX_LENGTH, …]
depending on the value of <cite>axis</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'int32'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Get the shape of input array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>array</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The source tensor.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The target data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The resulting tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">sigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take sigmoid tanh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">sign</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Returns -1, 0, 1 based on sign of x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">sin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take sin of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">sinh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take sinh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">window_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Slide a window over the data tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input data to the operator.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – What axis the window begins sliding over. Window will be slid over
this axis and all following axes. The axis value determines the window
shape (and thus, the number of strides): window shape and strides must
both be of length <cite>data.ndim-axis</cite>.</p></li>
<li><p><strong>window_shape</strong> (<em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em>) – The window shape to form over the input. Window shape must be of length
<cite>data.ndim-axis</cite>.</p></li>
<li><p><strong>strides</strong> (<em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em>) – How to stride the window along each dimension. Strides must be of length
<cite>data.ndim-axis</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The resulting tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">sort</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_ascend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Performs sorting along the given axis and returns an array
in sorted order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Axis along which to sort the input tensor.
By default the flattened array is used.</p></li>
<li><p><strong>is_ascend</strong> (<em>boolean</em><em>, </em><em>optional</em>) – Whether to sort in ascending or descending order.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) – DType of the output indices.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>out</strong> – Sorted index tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">sparse_reshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sparse_indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prev_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_sparse_indices_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_shape_shape</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Reshape a Sparse Tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sparse_indices</strong> (<em>te.Expr</em>) – A 2-D tensor[N, n_dim] of integers containing location of sparse values, where N is the
number of sparse values and n_dim is the number of dimensions of the dense_shape</p></li>
<li><p><strong>prev_shape</strong> (<em>te.Expr</em>) – A 1-D tensor containing the previous shape of the dense tensor</p></li>
<li><p><strong>new_shape</strong> (<em>te.Expr</em>) – A 1-D tensor containing the new shape of the dense tensor</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – Output tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>te.Expr</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sparse_indices</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span>
<span class="n">prev_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">new_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">new_sparse_indices</span><span class="p">,</span> <span class="n">new_shape</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">sparse_reshape</span><span class="p">(</span>
    <span class="n">sparse_indices</span><span class="p">,</span> <span class="n">prev_shape</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span>
<span class="n">new_sparse_indices</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                      <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                      <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                      <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                      <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">new_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">sparse_to_dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sparse_indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Converts a sparse representation into a dense tensor.</p>
<p>Example::
-   sparse_to_dense([[0, 0], [1, 1]], [2, 2], [3, 3], 0) = [[3, 0], [0, 3]]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sparse_indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – A 0-D, 1-D, or 2-D tensor of integers containing location of sparse values.</p></li>
<li><p><strong>output_shape</strong> (<em>A list</em><em> of </em><em>integers</em>) – Shape of the dense output tensor.</p></li>
<li><p><strong>sparse_values</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – A 0-D or 1-D tensor containing the sparse values for the sparse indices.</p></li>
<li><p><strong>default_value</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – A 0-D tensor containing the default value for the remaining locations.
Defaults to 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – Dense tensor of shape output_shape. Has the same type as sparse_values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ary</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices_or_sections</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Split an array into multiple sub-arrays.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ary</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>)</p></li>
<li><p><strong>indices_or_sections</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>1-D array</em>)</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a> of <a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">sqrt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take square root of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">squeeze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Remove single-dimensional entries from the shape of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>)</p></li>
<li><p><strong>axis</strong> (<em>None</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>ints</em><em>, </em><em>optional</em>) – Selects a subset of the single-dimensional entries in the shape.
If an axis is selected with shape entry greater than one, an error is raised.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>squeezed</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">stack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Repeats the whole array multiple times.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be stacked.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The axis in the result array along which the input arrays are stacked.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">stft</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_fft</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hop_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">win_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">window</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onesided</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>The STFT computes the Fourier transform of short overlapping windows of the input.
This gives frequency components of the signal as they change over time.
:param data: Either a 1-D tensor or a 2-D batch tensor.
:type data: te.Tensor
:param n_fft: The size of Fourier transform
:type n_fft: int
:param hop_length: The distance between neighboring sliding window frames
:type hop_length: int
:param win_length: The size of window frame and STFT filter
:type win_length: int
:param window: A 1-D tensor window frame
:type window: te.Tensor
:param normalized: Whether to return the normalized STFT results
:type normalized: bool
:param onesided: Whether to return onesided result or fill with conjugate symmetry
:type onesided: bool</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>output</strong> – Tensor containing the STFT result</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">te.Tensor</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="n">window</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="p">[</span><span class="n">n_fft</span><span class="p">,</span> <span class="n">hop_length</span><span class="p">,</span> <span class="n">win_length</span><span class="p">,</span> <span class="n">normalized</span><span class="p">,</span> <span class="n">onesided</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]</span>
<span class="n">topi</span><span class="o">.</span><span class="n">stft</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">n_fft</span><span class="p">,</span> <span class="n">hop_length</span><span class="p">,</span> <span class="n">win_length</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">normalized</span><span class="p">,</span> <span class="n">onesided</span><span class="p">)</span>
<span class="o">-&gt;</span> <span class="p">[[[</span><span class="mf">15.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span> <span class="p">[</span><span class="mf">34.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">]],</span> <span class="p">[[</span> <span class="mf">4.5000</span><span class="p">,</span>  <span class="mf">0.8660</span><span class="p">],</span> <span class="p">[</span> <span class="mf">1.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7321</span><span class="p">]]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">strided_set</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">begin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Set slice of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be sliced.</p></li>
<li><p><strong>v</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The values to set</p></li>
<li><p><strong>begin</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The indices to begin with in the slicing.</p></li>
<li><p><strong>end</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Indices indicating end of the slice.</p></li>
<li><p><strong>strides</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) – Specifies the stride values, it can be negative
in that case, the input tensor will be reversed
in that particular axis.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">strided_slice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">begin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slice_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'end'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assume_inbound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Slice of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be sliced.</p></li>
<li><p><strong>begin</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The indices to begin with in the slicing.</p></li>
<li><p><strong>end</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Indices indicating end of the slice.</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Specifies the stride values, it can be negative
in that case, the input tensor will be reversed
in that particular axis.</p></li>
<li><p><strong>axes</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Axes along which slicing is applied. When it is specified, begin, end
strides, and axes need to a list of integers of the same length.</p></li>
<li><p><strong>slice_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The slice mode [end, size].
end - The ending indices for the slice [default].
size - The input strides will be ignored, input end in this mode indicates
the sizeof a slice starting at the location specified by begin. If end[i]
is -1, all remaining elements in that dimension are included in the slice.</p></li>
<li><p><strong>assume_inbound</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – A flag to indicate if all indices are assumed to be inbound</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">subtract</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Subtraction with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Sum of array elements over a given axis or a list of axes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input tvm tensor</p></li>
<li><p><strong>axis</strong> (<em>None</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis or axes along which a sum is performed.
The default, axis=None, will sum all of the elements of the input array.
If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">take</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'clip'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take elements from an array along an axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The source array.</p></li>
<li><p><strong>indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The indices of the values to extract.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The axis over which to select values. By default,
the flattened input array is used.</p></li>
<li><p><strong>batch_dims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The number of batch dimensions. By default is 0.</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Specifies how out-of-bound indices will behave.
clip - clip to the range (default)
wrap - wrap around the indices
fast - no clip or wrap around (user must make sure indices are in-bound)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">tan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take tan of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">tanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take hyperbolic tanh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">tensordot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>A generalization of matrix multiplication to tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>The tensor A</em>)</p></li>
<li><p><strong>b</strong> (<em>The tensor B</em>)</p></li>
<li><p><strong>axes</strong> (<em>The number</em><em> of </em><em>dimensions to reduce over</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A Tensor computing the result</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">tile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reps</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Repeats the whole array multiple times.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be tiled.</p></li>
<li><p><strong>reps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>ints</em><em>, </em><em>required</em>) – The number of times for repeating the tensor</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">topk</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ret_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'both'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_ascend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'int64'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Get the top k elements in an input tensor along the given axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) – Number of top elements to select. Return all elements if k &lt; 1.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Axis long which to sort the input tensor.</p></li>
<li><p><strong>ret_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The return type [both, values, indices].
“both”: return both top k data and indices.
“values”: return top k data only.
“indices”: return top k indices only.</p></li>
<li><p><strong>is_ascend</strong> (<em>boolean</em><em>, </em><em>optional</em>) – Whether to sort in ascending or descending order.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) – The data type of the indices output.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>out</strong> – The computed result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or List[<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">transpose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Permute the dimensions of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be expanded.</p></li>
<li><p><strong>axes</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>ints</em><em>, </em><em>optional</em>) – By default, reverse the dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">trilu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Given a 2-D matrix or batches of 2-D matrices, returns the
upper or lower triangular part of the tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor that trilu will be applied to. Must be either
a 2D matrix or a tensor of batches of 2D matrices.</p></li>
<li><p><strong>k</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The number of diagonals above or below the main diagonal
to exclude or include.</p></li>
<li><p><strong>upper</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If True, only upper triangular values of input are kept,
if False, the lower triangular values are kept.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – The new tensor with appropriate diagonals set to zero.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>

<span class="n">topi</span><span class="o">.</span><span class="n">trilu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">=</span>
    <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">trunc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Take truncated value of the input of x, element-wise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">unravel_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Convert a flat index or array of flat indices into a tuple of coordinate arrays.</p>
<p>Example::
-   unravel_index([22, 41, 37], [7, 6]) = [[3, 6, 6], [4, 5, 1]]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – An integer array containing indices.</p></li>
<li><p><strong>shape</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The shape of the array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – The tuple of coordinate arrays.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">where</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">condition</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Get the elements, either from x or y, depending on the condition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>condition</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The condition array.</p></li>
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – First array to be selected.</p></li>
<li><p><strong>y</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Second array to be selected.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – A Tensor selected from x or y depending on condition.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">within_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">e</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Return a boolean value that indicates if i is within the given index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>Expr</em>) – beginning of the index</p></li>
<li><p><strong>e</strong> (<em>Expr</em>) – end of the index</p></li>
<li><p><strong>s</strong> (<em>Expr</em>) – strides of index</p></li>
<li><p><strong>i</strong> (<em>Expr</em>) – array position</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>selected</strong> – bool expression that is True is the array position would be selected
by the index and False otherwise</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py exception">
<dt class="sig sig-object py">
<em class="property"><span class="pre">exception</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.topi.</span></span><span class="sig-name descname"><span class="pre">InvalidShapeError</span></span></dt>
<dd><p>Invalid shape for a topi function. i.e. call winograd template for non-3x3 kernel)</p>
</dd></dl>

<section id="module-tvm.topi.nn">
<span id="tvm-topi-nn"></span><h2>tvm.topi.nn<a class="headerlink" href="#module-tvm.topi.nn" title="Link to this heading"></a></h2>
<p>Neural network operators</p>
<p><strong>Classes:</strong></p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload" title="tvm.topi.nn.Workload"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Workload</span></code></a>(in_dtype, out_dtype, height, width, ...)</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p><strong>Functions:</strong></p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.adaptive_pool" title="tvm.topi.nn.adaptive_pool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adaptive_pool</span></code></a>(data, output_size, pool_type)</p></td>
<td><p>Perform pooling on height and width dimension of data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.adaptive_pool1d" title="tvm.topi.nn.adaptive_pool1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adaptive_pool1d</span></code></a>(data, output_size, pool_type)</p></td>
<td><p>Perform pooling on three dimensional data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.adaptive_pool3d" title="tvm.topi.nn.adaptive_pool3d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adaptive_pool3d</span></code></a>(data, output_size, pool_type)</p></td>
<td><p>Perform pooling on three dimensional data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.add" title="tvm.topi.nn.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a>(lhs, rhs)</p></td>
<td><p>Addition with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.batch_matmul" title="tvm.topi.nn.batch_matmul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_matmul</span></code></a>(tensor_a, tensor_b[, oshape, ...])</p></td>
<td><p>Compute batch matrix multiplication of <cite>tensor_a</cite> and <cite>tensor_b</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.batch_norm" title="tvm.topi.nn.batch_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_norm</span></code></a>(data, gamma, beta, moving_mean, ...)</p></td>
<td><p>Batch normalization layer (Ioffe and Szegedy, 2014).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.batch_to_space_nd" title="tvm.topi.nn.batch_to_space_nd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_to_space_nd</span></code></a>(data, block_shape, ...)</p></td>
<td><p>Perform space to batch transformation on the data</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.binarize_pack" title="tvm.topi.nn.binarize_pack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">binarize_pack</span></code></a>(data[, axis, name])</p></td>
<td><p>Binarization and bit-packing along a certain axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.binary_dense" title="tvm.topi.nn.binary_dense"><code class="xref py py-obj docutils literal notranslate"><span class="pre">binary_dense</span></code></a>(data, weight)</p></td>
<td><p>Binary matrix multiplication using xor and bit-count.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.bitpack" title="tvm.topi.nn.bitpack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitpack</span></code></a>(data, bits, pack_axis, bit_axis, ...)</p></td>
<td><p>Packs data into format necessary for bitserial computation</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.bitserial_conv2d_nchw" title="tvm.topi.nn.bitserial_conv2d_nchw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitserial_conv2d_nchw</span></code></a>(data, kernel, stride, ...)</p></td>
<td><p>Bitserial Conv2D operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.bitserial_conv2d_nhwc" title="tvm.topi.nn.bitserial_conv2d_nhwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitserial_conv2d_nhwc</span></code></a>(data, kernel, stride, ...)</p></td>
<td><p>Bitserial Conv2D operator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.bitserial_dense" title="tvm.topi.nn.bitserial_dense"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitserial_dense</span></code></a>(data, weight, data_bits, ...)</p></td>
<td><p>The default implementation of bitserial dense in topi.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.concatenate" title="tvm.topi.nn.concatenate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">concatenate</span></code></a>(a_tuple[, axis])</p></td>
<td><p>Join a sequence of arrays along an existing axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.conv" title="tvm.topi.nn.conv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv</span></code></a>(inp, filt, stride, padding, dilation, ...)</p></td>
<td><p>Convolution operator in NCHW or NHWC layout.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.conv1d" title="tvm.topi.nn.conv1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv1d</span></code></a>(data, kernel[, strides, padding, ...])</p></td>
<td><p>1D convolution forward operator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.conv1d_ncw" title="tvm.topi.nn.conv1d_ncw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv1d_ncw</span></code></a>(data, kernel[, strides, padding, ...])</p></td>
<td><p>1D convolution in NCW layout.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.conv1d_nwc" title="tvm.topi.nn.conv1d_nwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv1d_nwc</span></code></a>(data, kernel[, strides, padding, ...])</p></td>
<td><p>1D convolution in NWC layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.conv1d_transpose_ncw" title="tvm.topi.nn.conv1d_transpose_ncw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv1d_transpose_ncw</span></code></a>(data, kernel, stride, ...)</p></td>
<td><p>Transposed 1D convolution ncw forward operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d" title="tvm.topi.nn.conv2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d</span></code></a>(input, filter, strides, padding, dilation)</p></td>
<td><p>Conv2D operator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d_NCHWc" title="tvm.topi.nn.conv2d_NCHWc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_NCHWc</span></code></a>(data, kernel, stride, padding, ...)</p></td>
<td><p>Conv2D operator for nChw[x]c layout.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d_NCHWc_int8" title="tvm.topi.nn.conv2d_NCHWc_int8"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_NCHWc_int8</span></code></a>(data, kernel, stride, ...)</p></td>
<td><p>Conv2D operator for nChw[x]c layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d_hwcn" title="tvm.topi.nn.conv2d_hwcn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_hwcn</span></code></a>(Input, Filter, stride, padding, ...)</p></td>
<td><p>Convolution operator in HWCN layout.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d_nchw" title="tvm.topi.nn.conv2d_nchw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_nchw</span></code></a>(Input, Filter, stride, padding, ...)</p></td>
<td><p>Convolution operator in NCHW layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d_nhwc" title="tvm.topi.nn.conv2d_nhwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_nhwc</span></code></a>(Input, Filter, stride, padding, ...)</p></td>
<td><p>Convolution operator in NHWC layout.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d_transpose_nchw" title="tvm.topi.nn.conv2d_transpose_nchw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_transpose_nchw</span></code></a>(Input, Filter, ...)</p></td>
<td><p>Transposed 2D convolution nchw forward operator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d_transpose_nchw_preprocess" title="tvm.topi.nn.conv2d_transpose_nchw_preprocess"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_transpose_nchw_preprocess</span></code></a>(data, ...)</p></td>
<td><p>Preprocess data and kernel to make the compute pattern of conv2d_transpose the same as conv2d</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d_winograd_nchw" title="tvm.topi.nn.conv2d_winograd_nchw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_winograd_nchw</span></code></a>(data, weight, strides, ...)</p></td>
<td><p>Conv2D Winograd in NCHW layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d_winograd_nchw_without_weight_transform" title="tvm.topi.nn.conv2d_winograd_nchw_without_weight_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_winograd_nchw_without_weight_transform</span></code></a>(...)</p></td>
<td><p>Conv2D Winograd without layout transform in NCHW layout.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d_winograd_nhwc" title="tvm.topi.nn.conv2d_winograd_nhwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_winograd_nhwc</span></code></a>(data, weight, strides, ...)</p></td>
<td><p>Conv2D Winograd in NHWC layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d_winograd_nhwc_without_weight_transform" title="tvm.topi.nn.conv2d_winograd_nhwc_without_weight_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_winograd_nhwc_without_weight_transform</span></code></a>(...)</p></td>
<td><p>Conv2D Winograd without layout transform in NHWC layout.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.conv2d_winograd_weight_transform" title="tvm.topi.nn.conv2d_winograd_weight_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_winograd_weight_transform</span></code></a>(kernel, ...)</p></td>
<td><p>Weight transformation for winograd</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.conv3d_ncdhw" title="tvm.topi.nn.conv3d_ncdhw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv3d_ncdhw</span></code></a>(Input, Filter, stride, padding, ...)</p></td>
<td><p>Conv3D operator in NCDHW layout.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.conv3d_ndhwc" title="tvm.topi.nn.conv3d_ndhwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv3d_ndhwc</span></code></a>(Input, Filter, stride, padding, ...)</p></td>
<td><p>Convolution operator in NDHWC layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.conv3d_transpose_ncdhw" title="tvm.topi.nn.conv3d_transpose_ncdhw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv3d_transpose_ncdhw</span></code></a>(Input, Filter, ...)</p></td>
<td><p>Transposed 3D convolution ncdhw forward operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.conv3d_transpose_ncdhw_preprocess" title="tvm.topi.nn.conv3d_transpose_ncdhw_preprocess"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv3d_transpose_ncdhw_preprocess</span></code></a>(data, ...)</p></td>
<td><p>Preprocess data and kernel to make the compute pattern of conv3d_transpose the same as conv3d</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.conv3d_winograd_weight_transform" title="tvm.topi.nn.conv3d_winograd_weight_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv3d_winograd_weight_transform</span></code></a>(kernel, ...)</p></td>
<td><p>Weight transformation for 3D winograd</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.correlation_nchw" title="tvm.topi.nn.correlation_nchw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">correlation_nchw</span></code></a>(data1, data2, kernel_size, ...)</p></td>
<td><p>Correlation operator in NCHW layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.declaration_conv2d_transpose_impl" title="tvm.topi.nn.declaration_conv2d_transpose_impl"><code class="xref py py-obj docutils literal notranslate"><span class="pre">declaration_conv2d_transpose_impl</span></code></a>(data, ...)</p></td>
<td><p>Implementation of conv2d transpose</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.declaration_conv3d_transpose_impl" title="tvm.topi.nn.declaration_conv3d_transpose_impl"><code class="xref py py-obj docutils literal notranslate"><span class="pre">declaration_conv3d_transpose_impl</span></code></a>(data, ...)</p></td>
<td><p>Implementation of conv3d transpose</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.deformable_conv2d_nchw" title="tvm.topi.nn.deformable_conv2d_nchw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">deformable_conv2d_nchw</span></code></a>(data, offset, kernel, ...)</p></td>
<td><p>Deformable conv2D operator in NCHW layout.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.deformable_conv2d_nhwc" title="tvm.topi.nn.deformable_conv2d_nhwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">deformable_conv2d_nhwc</span></code></a>(data, offset, kernel, ...)</p></td>
<td><p>Deformable conv2D operator in NHWC layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.dense" title="tvm.topi.nn.dense"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dense</span></code></a>(data, weight[, bias, out_dtype, ...])</p></td>
<td><p>The default implementation of dense in topi.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.dense_pack" title="tvm.topi.nn.dense_pack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dense_pack</span></code></a>(data, weight[, bias, out_dtype])</p></td>
<td><p>The default implementation of dense_pack in topi.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.depth_to_space" title="tvm.topi.nn.depth_to_space"><code class="xref py py-obj docutils literal notranslate"><span class="pre">depth_to_space</span></code></a>(data, block_size[, layout, mode])</p></td>
<td><p>Perform depth to space transformation on the data</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.depthwise_conv2d_NCHWc" title="tvm.topi.nn.depthwise_conv2d_NCHWc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_conv2d_NCHWc</span></code></a>(Input, Filter, ...[, ...])</p></td>
<td><p>Depthwise convolution NCHW[x]c forward operator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.depthwise_conv2d_backward_input_nhwc" title="tvm.topi.nn.depthwise_conv2d_backward_input_nhwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_conv2d_backward_input_nhwc</span></code></a>(Filter, ...)</p></td>
<td><p>Depthwise convolution nhwc backward wrt input operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.depthwise_conv2d_backward_weight_nhwc" title="tvm.topi.nn.depthwise_conv2d_backward_weight_nhwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_conv2d_backward_weight_nhwc</span></code></a>(Input, ...)</p></td>
<td><p>Depthwise convolution nhwc backward wrt weight operator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.depthwise_conv2d_nchw" title="tvm.topi.nn.depthwise_conv2d_nchw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_conv2d_nchw</span></code></a>(Input, Filter, stride, ...)</p></td>
<td><p>Depthwise convolution nchw forward operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.depthwise_conv2d_nhwc" title="tvm.topi.nn.depthwise_conv2d_nhwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_conv2d_nhwc</span></code></a>(Input, Filter, stride, ...)</p></td>
<td><p>Depthwise convolution nhwc forward operator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.dilate" title="tvm.topi.nn.dilate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dilate</span></code></a>(data, strides[, dilation_value, name])</p></td>
<td><p>Dilate data with given dilation value (0 by default).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.equal_const_int" title="tvm.topi.nn.equal_const_int"><code class="xref py py-obj docutils literal notranslate"><span class="pre">equal_const_int</span></code></a>(expr, value)</p></td>
<td><p>Returns if expr equals value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.fast_softmax" title="tvm.topi.nn.fast_softmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fast_softmax</span></code></a>(x[, axis])</p></td>
<td><p>Perform softmax activation on the data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.fifo_buffer" title="tvm.topi.nn.fifo_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fifo_buffer</span></code></a>(data, buffer, axis)</p></td>
<td><p>FIFO buffer to enable computation reuse in CNNs with sliding indow input</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.flatten" title="tvm.topi.nn.flatten"><code class="xref py py-obj docutils literal notranslate"><span class="pre">flatten</span></code></a>(data)</p></td>
<td><p>Flattens the input array into a 2-D array by collapsing the higher dimensions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.get_const_int" title="tvm.topi.nn.get_const_int"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_const_int</span></code></a>(expr)</p></td>
<td><p>Verifies expr is integer and get the constant value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.get_const_tuple" title="tvm.topi.nn.get_const_tuple"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_const_tuple</span></code></a>(in_tuple)</p></td>
<td><p>Verifies input tuple is IntImm or Var, returns tuple of int or Var.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.get_pad_tuple" title="tvm.topi.nn.get_pad_tuple"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_pad_tuple</span></code></a>(padding, kernel)</p></td>
<td><p>Common code to get the pad option</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.get_pad_tuple1d" title="tvm.topi.nn.get_pad_tuple1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_pad_tuple1d</span></code></a>(padding, kernel)</p></td>
<td><p>Common code to get the pad option</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.get_pad_tuple3d" title="tvm.topi.nn.get_pad_tuple3d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_pad_tuple3d</span></code></a>(padding, kernel)</p></td>
<td><p>Common code to get the pad option</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.get_pad_tuple_generic" title="tvm.topi.nn.get_pad_tuple_generic"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_pad_tuple_generic</span></code></a>(padding, kernel)</p></td>
<td><p>Common code to get the pad option</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.global_pool" title="tvm.topi.nn.global_pool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_pool</span></code></a>(data, pool_type[, layout])</p></td>
<td><p>Perform global pooling on height and width dimension of data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.group_conv1d_ncw" title="tvm.topi.nn.group_conv1d_ncw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">group_conv1d_ncw</span></code></a>(data, kernel[, strides, ...])</p></td>
<td><p>1D convolution forward operator for NCW layout.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.group_conv1d_nwc" title="tvm.topi.nn.group_conv1d_nwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">group_conv1d_nwc</span></code></a>(data, kernel[, strides, ...])</p></td>
<td><p>1D convolution forward operator for NWC layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.group_conv1d_transpose_ncw" title="tvm.topi.nn.group_conv1d_transpose_ncw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">group_conv1d_transpose_ncw</span></code></a>(data, kernel, ...)</p></td>
<td><p>Transposed 1D group convolution ncw forward operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.group_conv2d_nchw" title="tvm.topi.nn.group_conv2d_nchw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">group_conv2d_nchw</span></code></a>(Input, Filter, stride, ...)</p></td>
<td><p>Group convolution operator in NCHW layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.group_conv2d_nhwc" title="tvm.topi.nn.group_conv2d_nhwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">group_conv2d_nhwc</span></code></a>(Input, Filter, stride, ...)</p></td>
<td><p>Group convolution operator in NHWC layout.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.group_conv2d_transpose_nchw" title="tvm.topi.nn.group_conv2d_transpose_nchw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">group_conv2d_transpose_nchw</span></code></a>(data, kernel, ...)</p></td>
<td><p>Group convolution operator in NCHW layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.group_conv3d_transpose_ncdhw" title="tvm.topi.nn.group_conv3d_transpose_ncdhw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">group_conv3d_transpose_ncdhw</span></code></a>(data, kernel, ...)</p></td>
<td><p>Transposed group 3D convolution ncdhw forward operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.leaky_relu" title="tvm.topi.nn.leaky_relu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">leaky_relu</span></code></a>(x, alpha)</p></td>
<td><p>Take leaky relu of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.log_softmax" title="tvm.topi.nn.log_softmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log_softmax</span></code></a>(x[, axis])</p></td>
<td><p>Perform log softmax activation on the data</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.lrn" title="tvm.topi.nn.lrn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lrn</span></code></a>(data, size[, axis, alpha, beta, bias])</p></td>
<td><p>Perform the across channels local response normalisation on the input data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.lstm" title="tvm.topi.nn.lstm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lstm</span></code></a>(Xs, Wi, Wh[, Bi, Bh, h_init, c_init, ...])</p></td>
<td><p>General LSTM implemented using TE scan.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.matmul" title="tvm.topi.nn.matmul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">matmul</span></code></a>(tensor_a, tensor_b[, bias, ...])</p></td>
<td><p>The default implementation of matmul in topi.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.mirror_pad" title="tvm.topi.nn.mirror_pad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mirror_pad</span></code></a>(data, pad_before[, pad_after, ...])</p></td>
<td><p>Pad Input with mirroring either symmetric or reflected.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.namedtuple" title="tvm.topi.nn.namedtuple"><code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code></a>(typename, field_names, *[, ...])</p></td>
<td><p>Returns a new subclass of tuple with named fields.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.nll_loss" title="tvm.topi.nn.nll_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nll_loss</span></code></a>(predictions, targets, weights, ...)</p></td>
<td><p>Negative log likelihood loss on the input data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.pad" title="tvm.topi.nn.pad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pad</span></code></a>(data, pad_before[, pad_after, ...])</p></td>
<td><p>Pad Input with zeros.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.pool1d" title="tvm.topi.nn.pool1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pool1d</span></code></a>(data, kernel, stride, dilation, ...)</p></td>
<td><p>Perform pooling on width dimension of data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.pool2d" title="tvm.topi.nn.pool2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pool2d</span></code></a>(data, kernel, stride, dilation, ...)</p></td>
<td><p>Perform pooling on height and width dimension of data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.pool3d" title="tvm.topi.nn.pool3d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pool3d</span></code></a>(data, kernel, stride, dilation, ...)</p></td>
<td><p>Perform pooling on depth, height and width dimension of data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.pool_grad" title="tvm.topi.nn.pool_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pool_grad</span></code></a>(grads, data, kernel, stride, ...)</p></td>
<td><p>Gradient of pooling on height and width dimension of data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.prelu" title="tvm.topi.nn.prelu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prelu</span></code></a>(x, slope[, axis])</p></td>
<td><p>PReLU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.reduce" title="tvm.topi.nn.reduce"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reduce</span></code></a>(function, sequence[, initial])</p></td>
<td><p>Apply a function of two arguments cumulatively to the items of a sequence, from left to right, so as to reduce the sequence to a single value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.relu" title="tvm.topi.nn.relu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">relu</span></code></a>(x)</p></td>
<td><p>Take relu of input x.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.scale_shift_nchw" title="tvm.topi.nn.scale_shift_nchw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale_shift_nchw</span></code></a>(Input, Scale, Shift)</p></td>
<td><p>Batch normalization operator in inference.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.scale_shift_nchwc" title="tvm.topi.nn.scale_shift_nchwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale_shift_nchwc</span></code></a>(Input, Scale, Shift)</p></td>
<td><p>Batch normalization operator in inference.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.scale_shift_nhwc" title="tvm.topi.nn.scale_shift_nhwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale_shift_nhwc</span></code></a>(Input, Scale, Shift)</p></td>
<td><p>Batch normalization operator in inference.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.simplify" title="tvm.topi.nn.simplify"><code class="xref py py-obj docutils literal notranslate"><span class="pre">simplify</span></code></a>(expr)</p></td>
<td><p>Simplify the expression if it is Expr, directly return if it is int.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.simulated_dequantize" title="tvm.topi.nn.simulated_dequantize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">simulated_dequantize</span></code></a>(data, in_dtype[, ...])</p></td>
<td><p>Simulated QNN dequantize operator that mimics QNN outputs without changing datatype.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.simulated_quantize" title="tvm.topi.nn.simulated_quantize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">simulated_quantize</span></code></a>(data, out_dtype[, ...])</p></td>
<td><p>Simulated QNN quantize operator that mimics QNN outputs without changing datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.softmax" title="tvm.topi.nn.softmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">softmax</span></code></a>(x[, axis])</p></td>
<td><p>Perform softmax activation on the data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.softmax_common" title="tvm.topi.nn.softmax_common"><code class="xref py py-obj docutils literal notranslate"><span class="pre">softmax_common</span></code></a>(x, axis, use_fast_exp)</p></td>
<td><p>The common part of softmax and fast_softmax</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.space_to_batch_nd" title="tvm.topi.nn.space_to_batch_nd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">space_to_batch_nd</span></code></a>(data, block_shape, ...[, ...])</p></td>
<td><p>Perform batch to space transformation on the data</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.space_to_depth" title="tvm.topi.nn.space_to_depth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">space_to_depth</span></code></a>(data, block_size[, layout])</p></td>
<td><p>Perform space to depth transformation on the data</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.strided_slice" title="tvm.topi.nn.strided_slice"><code class="xref py py-obj docutils literal notranslate"><span class="pre">strided_slice</span></code></a>(a, begin, end[, strides, ...])</p></td>
<td><p>Slice of an array.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.unpack_NCHWc_to_nchw" title="tvm.topi.nn.unpack_NCHWc_to_nchw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unpack_NCHWc_to_nchw</span></code></a>(packed_out, out_dtype)</p></td>
<td><p>Unpack conv2d_NCHWc output from layout NCHWc to NCHW</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.upsampling" title="tvm.topi.nn.upsampling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">upsampling</span></code></a>(data, scale_h, scale_w[, layout, ...])</p></td>
<td><p>Perform upsampling on the data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.upsampling3d" title="tvm.topi.nn.upsampling3d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">upsampling3d</span></code></a>(data, scale_d, scale_h, scale_w)</p></td>
<td><p>Perform upsampling on the data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.winograd_transform_matrices" title="tvm.topi.nn.winograd_transform_matrices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">winograd_transform_matrices</span></code></a>(tile_size, ...)</p></td>
<td><p>Compute the A, B, and G transform matrices for <cite>tile_size</cite> as a <cite>tvm.Expr</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.instance_norm" title="tvm.topi.nn.instance_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">instance_norm</span></code></a>(data, gamma, beta, axis[, epsilon])</p></td>
<td><p>Instance normalization operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.layer_norm" title="tvm.topi.nn.layer_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">layer_norm</span></code></a>(data, gamma, beta, axis[, epsilon])</p></td>
<td><p>Layer normalization operator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.group_norm" title="tvm.topi.nn.group_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">group_norm</span></code></a>(data, gamma, beta, num_groups, ...)</p></td>
<td><p>Group normalization operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.rms_norm" title="tvm.topi.nn.rms_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rms_norm</span></code></a>(data, weight, axis[, epsilon])</p></td>
<td><p>Root mean square normalization operator.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">Workload</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">height</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padl</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padb</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation_h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride_h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride_w</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.Workload" title="Link to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.dilation_h" title="tvm.topi.nn.Workload.dilation_h"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dilation_h</span></code></a></p></td>
<td><p>Alias for field number 12</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.dilation_w" title="tvm.topi.nn.Workload.dilation_w"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dilation_w</span></code></a></p></td>
<td><p>Alias for field number 13</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.height" title="tvm.topi.nn.Workload.height"><code class="xref py py-obj docutils literal notranslate"><span class="pre">height</span></code></a></p></td>
<td><p>Alias for field number 2</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.in_dtype" title="tvm.topi.nn.Workload.in_dtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">in_dtype</span></code></a></p></td>
<td><p>Alias for field number 0</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.in_filter" title="tvm.topi.nn.Workload.in_filter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">in_filter</span></code></a></p></td>
<td><p>Alias for field number 4</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.kernel_h" title="tvm.topi.nn.Workload.kernel_h"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kernel_h</span></code></a></p></td>
<td><p>Alias for field number 6</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.kernel_w" title="tvm.topi.nn.Workload.kernel_w"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kernel_w</span></code></a></p></td>
<td><p>Alias for field number 7</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.out_dtype" title="tvm.topi.nn.Workload.out_dtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">out_dtype</span></code></a></p></td>
<td><p>Alias for field number 1</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.out_filter" title="tvm.topi.nn.Workload.out_filter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">out_filter</span></code></a></p></td>
<td><p>Alias for field number 5</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.padb" title="tvm.topi.nn.Workload.padb"><code class="xref py py-obj docutils literal notranslate"><span class="pre">padb</span></code></a></p></td>
<td><p>Alias for field number 10</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.padl" title="tvm.topi.nn.Workload.padl"><code class="xref py py-obj docutils literal notranslate"><span class="pre">padl</span></code></a></p></td>
<td><p>Alias for field number 9</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.padr" title="tvm.topi.nn.Workload.padr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">padr</span></code></a></p></td>
<td><p>Alias for field number 11</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.padt" title="tvm.topi.nn.Workload.padt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">padt</span></code></a></p></td>
<td><p>Alias for field number 8</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.stride_h" title="tvm.topi.nn.Workload.stride_h"><code class="xref py py-obj docutils literal notranslate"><span class="pre">stride_h</span></code></a></p></td>
<td><p>Alias for field number 14</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.stride_w" title="tvm.topi.nn.Workload.stride_w"><code class="xref py py-obj docutils literal notranslate"><span class="pre">stride_w</span></code></a></p></td>
<td><p>Alias for field number 15</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.nn.Workload.width" title="tvm.topi.nn.Workload.width"><code class="xref py py-obj docutils literal notranslate"><span class="pre">width</span></code></a></p></td>
<td><p>Alias for field number 3</p></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.dilation_h">
<span class="sig-name descname"><span class="pre">dilation_h</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.dilation_h" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 12</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.dilation_w">
<span class="sig-name descname"><span class="pre">dilation_w</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.dilation_w" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 13</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.height">
<span class="sig-name descname"><span class="pre">height</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.height" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.in_dtype">
<span class="sig-name descname"><span class="pre">in_dtype</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.in_dtype" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.in_filter">
<span class="sig-name descname"><span class="pre">in_filter</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.in_filter" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.kernel_h">
<span class="sig-name descname"><span class="pre">kernel_h</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.kernel_h" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.kernel_w">
<span class="sig-name descname"><span class="pre">kernel_w</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.kernel_w" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.out_dtype">
<span class="sig-name descname"><span class="pre">out_dtype</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.out_dtype" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.out_filter">
<span class="sig-name descname"><span class="pre">out_filter</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.out_filter" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.padb">
<span class="sig-name descname"><span class="pre">padb</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.padb" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 10</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.padl">
<span class="sig-name descname"><span class="pre">padl</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.padl" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 9</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.padr">
<span class="sig-name descname"><span class="pre">padr</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.padr" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 11</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.padt">
<span class="sig-name descname"><span class="pre">padt</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.padt" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.stride_h">
<span class="sig-name descname"><span class="pre">stride_h</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.stride_h" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 14</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.stride_w">
<span class="sig-name descname"><span class="pre">stride_w</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.stride_w" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 15</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="tvm.topi.nn.Workload.width">
<span class="sig-name descname"><span class="pre">width</span></span><a class="headerlink" href="#tvm.topi.nn.Workload.width" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.adaptive_pool">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">adaptive_pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCHW'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.adaptive_pool" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Perform pooling on height and width dimension of data.</dt><dd><p>The pooling kernel and stride sizes are automatically chosen for desired
output sizes.
It decides the height and width dimension according to the layout string,
in which ‘W’ and ‘H’ means width and height respectively.
Width and height dimension cannot be split.
For example, NCHW, NCHW16c, etc. are valid for pool,
while NCHW16w, NCHW16h are not.
See parameter <cite>layout</cite> for more information of the layout string convention.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – n-D with shape of layout</p></li>
<li><p><strong>output_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – output height and width.</p></li>
<li><p><strong>pool_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Pool type, ‘max’ or ‘avg’</p></li>
<li><p><strong>layout</strong> (<em>string</em>) – Layout of the input data.
The layout is supposed to be composed of upper cases, lower cases and numbers,
where upper case indicates a dimension and
the corresponding lower case with factor size indicates the split dimension.
For example, NCHW16c can describe a 5-D tensor of
[batch_size, channel, height, width, channel_block],
in which channel_block=16 is a split of dimension channel.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – n-D in the same layout</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.adaptive_pool1d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">adaptive_pool1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCW'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.adaptive_pool1d" title="Link to this definition"></a></dt>
<dd><p>Perform pooling on three dimensional data.
See the two dimensional version above for details.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.adaptive_pool3d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">adaptive_pool3d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCDHW'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.adaptive_pool3d" title="Link to this definition"></a></dt>
<dd><p>Perform pooling on three dimensional data.
See the two dimensional version above for details.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.add">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lhs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.add" title="Link to this definition"></a></dt>
<dd><p>Addition with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) – The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong> – Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.batch_matmul">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">batch_matmul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor_a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oshape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transpose_a</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transpose_b</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_scheduler_rewritten_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">meta_schedule_original_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.batch_matmul" title="Link to this definition"></a></dt>
<dd><p>Compute batch matrix multiplication of <cite>tensor_a</cite> and <cite>tensor_b</cite>.</p>
<p>Both <cite>tensor_a</cite> and <cite>tensor_b</cite> can be transposed. For legacy reason, we use NT format
(transpose_a=False, transpose_b=True) by default.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor_a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D with shape [batch, M, K] or [batch, K, M].</p></li>
<li><p><strong>tensor_b</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D with shape [batch, K, N] or [batch, N, K].</p></li>
<li><p><strong>oshape</strong> (<em>List</em><em>[</em><em>Optional</em><em>]</em>) – Explicit intended output shape of the computation. Can be useful in cases
with dynamic input shapes.</p></li>
<li><p><strong>out_dtype</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – Specifies the output data type for mixed precision batch matmul.</p></li>
<li><p><strong>transpose_a</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>] </em><em>= False</em>) – Whether the first tensor is in transposed format.</p></li>
<li><p><strong>transpose_b</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>] </em><em>= True</em>) – Whether the second tensor is in transposed format.</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>] </em><em>= &quot;&quot;</em>) – The layout after auto-scheduler’s layout rewrite pass.</p></li>
<li><p><strong>meta_schedule_original_shape</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a><em>]</em><em>] </em><em>= None</em>) – The original shape of the tensor</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 3-D with shape [batch, M, N]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.batch_norm">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">batch_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">moving_mean</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">moving_var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">center</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#tvm.topi.nn.batch_norm" title="Link to this definition"></a></dt>
<dd><p>Batch normalization layer (Ioffe and Szegedy, 2014).</p>
<p>Normalizes the input at each batch, i.e. applies a transformation
that maintains the mean activation close to 0 and the activation
standard deviation close to 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input to be batch-normalized.</p></li>
<li><p><strong>gamma</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Scale factor to be applied to the normalized tensor.</p></li>
<li><p><strong>beta</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Offset to be applied to the normalized tensor.</p></li>
<li><p><strong>moving_mean</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Running mean of input.</p></li>
<li><p><strong>moving_var</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Running variance of input.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=1</em>) – Specify along which shape axis the normalization should occur.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default=1e-5</em>) – Small float added to variance to avoid dividing by zero.</p></li>
<li><p><strong>center</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em>, </em><em>default=True</em>) – If True, add offset of beta to normalized tensor, If False,
beta is ignored.</p></li>
<li><p><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em>, </em><em>defualt=True</em>) – If True, scale normalized tensor by gamma. If False, gamma
is ignored.</p></li>
<li><p><strong>training</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em>, </em><em>defualt=False</em>) – Indicating whether it is in training mode. If True, update
moving_mean and moving_var.</p></li>
<li><p><strong>momentum</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default=0.1</em>) – The value used for the moving_mean and moving_var update.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>list of tvm.te.Tensor</em>) – Normalized data with same shape as input</p></li>
<li><p><strong>moving_mean</strong> (<em>tvm.te.Tensor</em>) – Running mean of input.</p></li>
<li><p><strong>moving_var</strong> (<em>tvm.te.Tensor</em>) – Running variance of input.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.batch_to_space_nd">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">batch_to_space_nd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_begin_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_end_list</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.batch_to_space_nd" title="Link to this definition"></a></dt>
<dd><p>Perform space to batch transformation on the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – N-D Tensor with shape [batch, spatial_shape, remaining_shapes],
where spatial_shape has M dimensions.</p></li>
<li><p><strong>block_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>ints</em>) – list of size [M] where M is number of spatial dims, specifies block
size for each spatial dimension.</p></li>
<li><p><strong>crop_begin_list</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>ints</em>) – list of shape [M] where M is number of spatial dims, specifies
begin crop size for each spatial dimension.</p></li>
<li><p><strong>crop_end_list</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>ints</em>) – list of shape [M] where M is number of spatial dims, specifies
end crop size for each spatial dimension.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.binarize_pack">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">binarize_pack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PackedInput'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.binarize_pack" title="Link to this definition"></a></dt>
<dd><p>Binarization and bit-packing along a certain axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – n-D input, can be any layout.</p></li>
<li><p><strong>axis</strong> (<em>None</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The axis along which to do binarization and bit-packing,
default is the last axis.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The name prefix operators generate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – n-D, the same layout as input, dtype is uint32.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.binary_dense">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">binary_dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.binary_dense" title="Link to this definition"></a></dt>
<dd><p>Binary matrix multiplication using xor and bit-count.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 2-D with shape [batch, in_dim], dtype is uint32.</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 2-D with shape [out_dim, in_dim], dtype is uint32.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 2-D with shape [batch, out_dim], dtype is float32.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.bitpack">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">bitpack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pack_axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bit_axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pack_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'QuantizeInput'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.bitpack" title="Link to this definition"></a></dt>
<dd><p>Packs data into format necessary for bitserial computation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pack_axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – index of the axis to pack in data</p></li>
<li><p><strong>bit_axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – index of axis to place bit axis in resulting packed data</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.bitserial_conv2d_nchw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">bitserial_conv2d_nchw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pack_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uint32'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'int16'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unipolar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.bitserial_conv2d_nchw" title="Link to this definition"></a></dt>
<dd><p>Bitserial Conv2D operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [num_filter, in_channel, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two</em><em> or </em><em>four ints</em>) – padding size, [pad_height, pad_width], [pad_top, pad_left, pad_down, pad_right]</p></li>
<li><p><strong>activation_bits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of bits used for activations/input elements</p></li>
<li><p><strong>weight_bits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of bits used for weight elements</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – return type of convolution</p></li>
<li><p><strong>pack_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – bit packing type</p></li>
<li><p><strong>unipolar</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if binarization style is in unipolar 1/0 format, instead of bipolar -1/+1 format</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.bitserial_conv2d_nhwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">bitserial_conv2d_nhwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pack_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uint32'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'int16'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unipolar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.bitserial_conv2d_nhwc" title="Link to this definition"></a></dt>
<dd><p>Bitserial Conv2D operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two</em><em> or </em><em>four ints</em>) – padding size, [pad_height, pad_width], [pad_top, pad_left, pad_down, pad_right]</p></li>
<li><p><strong>activation_bits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of bits used for activations/input elements</p></li>
<li><p><strong>weight_bits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of bits used for weight elements</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – return type of convolution</p></li>
<li><p><strong>pack_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – bit packing type</p></li>
<li><p><strong>unipolar</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if binarization style is in unipolar 1/0 format, instead of bipolar -1/+1 format</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.bitserial_dense">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">bitserial_dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pack_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uint32'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'int16'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unipolar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.bitserial_dense" title="Link to this definition"></a></dt>
<dd><p>The default implementation of bitserial dense in topi.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 2-D with shape [batch, in_dim]</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 2-D with shape [out_dim, in_dim] or
3-D with shape [out_dim, weight_bits, in_dim]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 2-D with shape [batch, out_dim]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.concatenate">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">concatenate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a_tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.concatenate" title="Link to this definition"></a></dt>
<dd><p>Join a sequence of arrays along an existing axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_tuple</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The arrays to concatenate</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The axis along which the arrays will be joined. Default is 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">filt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.13)"><span class="pre">Sequence</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.13)"><span class="pre">Sequence</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.13)"><span class="pre">Sequence</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_layout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_layout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_scheduler_rewritten_layout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">meta_schedule_original_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_scheduler_should_rewrite_layout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv" title="Link to this definition"></a></dt>
<dd><p>Convolution operator in NCHW or NHWC layout.</p>
<p>Supports 1D, 2D, 3D, … and grouping.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inp</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – N-D with shape [batch, in_channel, in_height, in_width, …] in <cite>data_layout</cite></p></li>
<li><p><strong>filt</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – N-D with shape [num_filter, in_channel // groups, filter_height, filter_width, …] in
<cite>kernel_layout</cite></p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>dim ints</em>) – (where dim=2 for NCHW, dim=1 for NCH, etc.)
Stride size, or [stride_height, stride_width, …]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>dim</em><em> or </em><em>2*dim ints</em>) – (where dim=2 for NCHW, dim=1 for NCH, etc.)
padding size, or
[pad_height, pad_width, …] for dim ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 2*dim ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of groups</p></li>
<li><p><strong>data_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Layout of the input. N indicates batch dimension, C indicates
channels, any other character indicates HW (or H or HWD for 1D and 3D).</p></li>
<li><p><strong>kernel_layout</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – Layout of the filter. I indicates input channels, O indicates output channels,
any other character indicates HW dimension of the filter (or H or HWD for 1D and 3D).
If kernel_layout is empty, use data_layout to infer the default kernel_layout. Default
kernel_layout is OIHW for NCHW data layout, HWIO for NHWC data layout.</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Elements are converted to this type before elementwise multiplication
and summation.</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Layout from autoscheduler’s layout rewritting.</p></li>
<li><p><strong>meta_schedule_original_shape</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a><em>]</em><em>]</em>) – The original shape of the input tensor.</p></li>
<li><p><strong>auto_scheduler_should_rewrite_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Should auto scheduler be allowed to rewrite the layout of the filter
tensor. Defaults to false. This can cause errors if used with grouped
convs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – N-D with shape [batch, out_channel, out_height, out_width, …] in <cite>data_layout</cite></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv1d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'VALID'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv1d" title="Link to this definition"></a></dt>
<dd><p>1D convolution forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D input shape [batch, in_channel, in_width] for data_layout == ‘NCW’
and [batch, in_width, in_channel] for data_layout == ‘NWC’</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D kernel with shape [num_filter, in_channel, filter_size] for kernel_layout == ‘OIW’
and [filter_size, in_channel, num_filter] for kernel_layout == ‘WIO’</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a>) – The spatial stride along width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a>) – Dilation rate if convolution should be dilated.</p></li>
<li><p><strong>data_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – How input data is laid out, must be one of [‘NCW’, ‘NWC’]</p></li>
<li><p><strong>kernel_layout</strong> (<em>Optiona</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The layout of the kernel. If unspecified, use default layout. “OIW” if data_layout == “NCW”,
“WIO” if data_layout == “NWC”.</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output data type. If None then output is same type as input.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv1d_ncw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv1d_ncw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'VALID'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv1d_ncw" title="Link to this definition"></a></dt>
<dd><p>1D convolution in NCW layout. See <a class="reference internal" href="#tvm.topi.nn.conv" title="tvm.topi.nn.conv"><code class="xref py py-func docutils literal notranslate"><span class="pre">conv()</span></code></a> for details on parameters</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv1d_nwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv1d_nwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'VALID'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv1d_nwc" title="Link to this definition"></a></dt>
<dd><p>1D convolution in NWC layout. See <a class="reference internal" href="#tvm.topi.nn.conv" title="tvm.topi.nn.conv"><code class="xref py py-func docutils literal notranslate"><span class="pre">conv()</span></code></a> for details on parameters</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv1d_transpose_ncw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv1d_transpose_ncw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv1d_transpose_ncw" title="Link to this definition"></a></dt>
<dd><p>Transposed 1D convolution ncw forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D with shape [batch, in_channel, in_width]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D with shape [in_channel, num_filter, filter_width]</p></li>
<li><p><strong>stride</strong> (<em>ints</em>) – The spatial stride along width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output data type. This is used for mixed precision.</p></li>
<li><p><strong>output_padding</strong> (<em>ints</em>) – Used to recover the actual output shape in case there are more
than one possible shape.  Must be smaller than stride.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 3-D with shape [batch, out_channel, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCHW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d" title="Link to this definition"></a></dt>
<dd><p>Conv2D operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_channel, in_height, in_width] in data_layout</p></li>
<li><p><strong>filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [num_filter, in_channel, filter_height, filter_width] in kernel_layout</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>2</em><em> or </em><em>4 ints</em>) – padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>data_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – layout of data</p></li>
<li><p><strong>kernel_layout</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – layout of kernel. If unspecified, use default layout inferred from data_layout. “OIHW” if
data_layout == “NCHW”, “HWIO” if data_layout == “NHWC”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d_NCHWc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d_NCHWc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_layout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'float32'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_NCHWc" title="Link to this definition"></a></dt>
<dd><p>Conv2D operator for nChw[x]c layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 5-D with shape [batch, in_channel_chunk, in_height, in_width, in_channel_block]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 6-D with shape
[num_filter_chunk, in_channel_chunk, filter_height, filter_width,
in_channel_block, num_filter_block]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>2</em><em> or </em><em>4 ints</em>) – padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Input data layout</p></li>
<li><p><strong>out_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Output data layout</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – output data type</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 5-D with shape [batch, out_channel_chunk, out_height, out_width, out_channel_block]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d_NCHWc_int8">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d_NCHWc_int8</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_layout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'int32'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_elems</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_NCHWc_int8" title="Link to this definition"></a></dt>
<dd><p>Conv2D operator for nChw[x]c layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 5-D with shape [batch, in_channel_chunk, in_height, in_width, in_channel_block]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 7-D with shape
[num_filter_chunk, in_channel_chunk, filter_height, filter_width, in_channel_block/4,
num_filter_block, 4]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>2</em><em> or </em><em>4 ints</em>) – padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Input data layout</p></li>
<li><p><strong>out_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Output data layout</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – output data type</p></li>
<li><p><strong>n_elems</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – numer of int8 elements accumulated</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 5-D with shape [batch, out_channel_chunk, out_height, out_width, out_channel_block]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d_hwcn">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d_hwcn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_hwcn" title="Link to this definition"></a></dt>
<dd><p>Convolution operator in HWCN layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [in_height, in_width, in_channel, batch]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>2</em><em> or </em><em>4 ints</em>) – padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [out_height, out_width, out_channel, batch]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d_nchw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d_nchw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_nchw" title="Link to this definition"></a></dt>
<dd><p>Convolution operator in NCHW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [num_filter, in_channel, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>2</em><em> or </em><em>4 ints</em>) – padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d_nhwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d_nhwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'float32'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_scheduler_rewritten_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">meta_schedule_original_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_nhwc" title="Link to this definition"></a></dt>
<dd><p>Convolution operator in NHWC layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>2</em><em> or </em><em>4 ints</em>) – padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<em>str = &quot;float32&quot;</em><em>,</em>) – The type of output tensor</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) – The layout after auto-scheduler’s layout rewrite pass.</p></li>
<li><p><strong>meta_schedule_original_shape</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a><em>]</em><em>] </em><em>= None</em>) – The original shape of the input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d_transpose_nchw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d_transpose_nchw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_transpose_nchw" title="Link to this definition"></a></dt>
<dd><p>Transposed 2D convolution nchw forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [in_channel, num_filter, filter_height, filter_width]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>two ints</em>) – The spatial stride along height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output data type. This is used for mixed precision.</p></li>
<li><p><strong>output_padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>ints</em>) – Used to get the right output shape for gradients</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d_transpose_nchw_preprocess">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d_transpose_nchw_preprocess</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_transpose_nchw_preprocess" title="Link to this definition"></a></dt>
<dd><p>Preprocess data and kernel to make the compute pattern
of conv2d_transpose the same as conv2d</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d_winograd_nchw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d_winograd_nchw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_computed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_scheduler_rewritten_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">meta_schedule_original_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_winograd_nchw" title="Link to this definition"></a></dt>
<dd><p>Conv2D Winograd in NCHW layout.
This is a clean version to be used by the auto-scheduler for both CPU and GPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – padding size, or [pad_height, pad_width]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Specifies the output data type.</p></li>
<li><p><strong>pre_computed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether the kernel is precomputed</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) – The layout after auto-scheduler’s layout rewrite pass.</p></li>
<li><p><strong>meta_schedule_original_shape</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a><em>]</em><em>] </em><em>= None</em>) – The original shape of the input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d_winograd_nchw_without_weight_transform">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d_winograd_nchw_without_weight_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_scheduler_rewritten_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">meta_schedule_original_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_winograd_nchw_without_weight_transform" title="Link to this definition"></a></dt>
<dd><p>Conv2D Winograd without layout transform in NCHW layout.
This is a clean version to be used by meta-schedule for both CPU and GPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – padding size, or [pad_height, pad_width]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Specifies the output data type.</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) – The layout after auto-scheduler’s layout rewrite pass.</p></li>
<li><p><strong>meta_schedule_original_shape</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a><em>]</em><em>] </em><em>= None</em>) – The original shape of the input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d_winograd_nhwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d_winograd_nhwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_computed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_scheduler_rewritten_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">meta_schedule_original_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_winograd_nhwc" title="Link to this definition"></a></dt>
<dd><p>Conv2D Winograd in NHWC layout.
This is a clean version to be used by the auto-scheduler for both CPU and GPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – padding size, or [pad_height, pad_width]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Specifies the output data type.</p></li>
<li><p><strong>pre_computed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether the kernel is precomputed</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) – The layout after auto-scheduler’s layout rewrite pass.</p></li>
<li><p><strong>meta_schedule_original_shape</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a><em>]</em><em>] </em><em>= None</em>) – The original shape of the input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d_winograd_nhwc_without_weight_transform">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d_winograd_nhwc_without_weight_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_scheduler_rewritten_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">meta_schedule_original_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_winograd_nhwc_without_weight_transform" title="Link to this definition"></a></dt>
<dd><p>Conv2D Winograd without layout transform in NHWC layout.
This is a clean version to be used by the auto-scheduler for both CPU and GPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – padding size, or [pad_height, pad_width]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Specifies the output data type.</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) – The layout after auto-scheduler’s layout rewrite pass.</p></li>
<li><p><strong>meta_schedule_original_shape</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a><em>]</em><em>] </em><em>= None</em>) – The original shape of the input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv2d_winograd_weight_transform">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv2d_winograd_weight_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tile_size</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_winograd_weight_transform" title="Link to this definition"></a></dt>
<dd><p>Weight transformation for winograd</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>Tensor</em></a>) – The raw kernel tensor with layout “NCHW”.</p></li>
<li><p><strong>tile_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Tile size of winograd transform. e.g. 2 for F(2x2, 3x3) and 4 for F(4x4, 3x3)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [alpha, alpha, CO, CI]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv3d_ncdhw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv3d_ncdhw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv3d_ncdhw" title="Link to this definition"></a></dt>
<dd><p>Conv3D operator in NCDHW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 5-D with shape [batch, in_channel, in_depth, in_height, in_width]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 5-D with shape [num_filter, in_channel, filter_depth, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>three ints</em>) – Stride size, or [strid_depth, stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>three ints</em>) – dilation size, or [dilation_depth, dilation_height, dilation_width]</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Number of groups.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 5-D with shape [batch, out_channel, out_depth, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv3d_ndhwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv3d_ndhwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'float32'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_scheduler_rewritten_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">meta_schedule_origin_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv3d_ndhwc" title="Link to this definition"></a></dt>
<dd><p>Convolution operator in NDHWC layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 5-D with shape [batch, in_depth, in_height, in_width, in_channel]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 5-D with shape [filter_depth, filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>three ints</em>) – Stride size, or [stride_depth, stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>three ints</em>) – dilation size, or [dilation_depth, dilation_height, dilation_width]</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Number of groups.</p></li>
<li><p><strong>out_dtype</strong> (<em>str = &quot;float32&quot;</em><em>,</em>) – The type of output tensor</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) – The layout after auto-scheduler’s layout rewrite pass.</p></li>
<li><p><strong>meta_schedule_origin_shape</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a><em>]</em><em>] </em><em>= None</em>) – The original shape of the input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 5-D with shape [batch, out_depth, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv3d_transpose_ncdhw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv3d_transpose_ncdhw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv3d_transpose_ncdhw" title="Link to this definition"></a></dt>
<dd><p>Transposed 3D convolution ncdhw forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 5-D with shape [batch, in_channel, in_depth, in_height, in_width]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 5-D with shape [in_channel, num_filter, filter_depth, filter_height, filter_width]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>three ints</em>) – The spatial stride along depth,height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output data type. This is used for mixed precision.</p></li>
<li><p><strong>output_padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>ints</em>) – Used to get the right output shape for gradients</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 5-D with shape [batch, out_channel, out_depth, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv3d_transpose_ncdhw_preprocess">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv3d_transpose_ncdhw_preprocess</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv3d_transpose_ncdhw_preprocess" title="Link to this definition"></a></dt>
<dd><p>Preprocess data and kernel to make the compute pattern
of conv3d_transpose the same as conv3d</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.conv3d_winograd_weight_transform">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">conv3d_winograd_weight_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tile_size</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv3d_winograd_weight_transform" title="Link to this definition"></a></dt>
<dd><p>Weight transformation for 3D winograd</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>Tensor</em></a>) – The raw kernel tensor with layout “NCDHW”.</p></li>
<li><p><strong>tile_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Tile size of winograd transform. e.g. 2 for F(2x2, 3x3) and 4 for F(4x4, 3x3)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 5-D with shape [alpha, alpha, alpha, CO, CI]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.correlation_nchw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">correlation_nchw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_displacement</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_multiply</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.correlation_nchw" title="Link to this definition"></a></dt>
<dd><p>Correlation operator in NCHW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data1</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, channel, height, width]</p></li>
<li><p><strong>data2</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, channel, height, width]</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Kernel size for correlation, must be an odd number</p></li>
<li><p><strong>max_displacement</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Max displacement of Correlation</p></li>
<li><p><strong>stride1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Stride for data1</p></li>
<li><p><strong>stride2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Stride for data2 within the neightborhood centered around data1</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>2</em><em> or </em><em>4 ints</em>) – Padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>is_multiply</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – operation type is either multiplication or substraction</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.declaration_conv2d_transpose_impl">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">declaration_conv2d_transpose_impl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.declaration_conv2d_transpose_impl" title="Link to this definition"></a></dt>
<dd><p>Implementation of conv2d transpose</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.declaration_conv3d_transpose_impl">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">declaration_conv3d_transpose_impl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.declaration_conv3d_transpose_impl" title="Link to this definition"></a></dt>
<dd><p>Implementation of conv3d transpose</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.deformable_conv2d_nchw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">deformable_conv2d_nchw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deformable_groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.deformable_conv2d_nchw" title="Link to this definition"></a></dt>
<dd><p>Deformable conv2D operator in NCHW layout.</p>
<p>The deformable convolution operation is described in <a class="reference external" href="https://arxiv.org/abs/1703.06211">https://arxiv.org/abs/1703.06211</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>offset</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, deformable_groups * filter_height * filter_width * 2,
out_height, out_width].</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [num_filter, in_channel, filter_height, filter_width]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – padding size, or [pad_height, pad_width]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>deformable_groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of deformable groups</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of groups</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.deformable_conv2d_nhwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">deformable_conv2d_nhwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deformable_groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.deformable_conv2d_nhwc" title="Link to this definition"></a></dt>
<dd><p>Deformable conv2D operator in NHWC layout.</p>
<p>The deformable convolution operation is described in <a class="reference external" href="https://arxiv.org/abs/1703.06211">https://arxiv.org/abs/1703.06211</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>offset</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – <dl class="simple">
<dt>4-D with shape [batch, out_height, out_width,</dt><dd><p>deformable_groups * filter_height * filter_width * 2].</p>
</dd>
</dl>
</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – padding size, or [pad_height, pad_width]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>deformable_groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of deformable groups</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of groups</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.dense">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_scheduler_rewritten_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">meta_schedule_original_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.dense" title="Link to this definition"></a></dt>
<dd><p>The default implementation of dense in topi.
This is an alias of matmul_nt operator for data tensor in non-transposed format and weight
tensor in transposed format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 2-D with shape [batch, in_dim]</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 2-D with shape [out_dim, in_dim]</p></li>
<li><p><strong>bias</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>]</em>) – 1-D with shape [out_dim]</p></li>
<li><p><strong>out_dtype</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The output type. This is used for mixed precision.</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) – The layout after auto-scheduler’s layout rewrite pass.</p></li>
<li><p><strong>meta_schedule_original_shape</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a><em>]</em><em>] </em><em>= None</em>) – The original shape of the input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 2-D with shape [batch, out_dim]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.dense_pack">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">dense_pack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.dense_pack" title="Link to this definition"></a></dt>
<dd><p>The default implementation of dense_pack in topi.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 2-D with shape [batch, in_dim]</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 2-D with shape [out_dim, in_dim]</p></li>
<li><p><strong>bias</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>]</em>) – 1-D with shape [out_dim]</p></li>
<li><p><strong>out_dtype</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The output type. This is used for mixed precision.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 2-D with shape [batch, out_dim]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.depth_to_space">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">depth_to_space</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCHW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'DCR'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depth_to_space" title="Link to this definition"></a></dt>
<dd><p>Perform depth to space transformation on the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D tensor in either NCHW or NHWC layout.</p></li>
<li><p><strong>block_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size of blocks to compose from channel dimension.</p></li>
<li><p><strong>layout</strong> (<em>string</em>) – Either NCHW or NHWC, indicating data layout.</p></li>
<li><p><strong>mode</strong> (<em>string</em>) – Either DCR or CDR, indicates how channels should be accessed.
In DCR, channels are interwoven in the Tensorflow style while
in CDR channels are accessed sequentially as in Pytorch.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – Output of shape [N, C / block_size**2, H * block_size, W * block_size]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.depthwise_conv2d_NCHWc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">depthwise_conv2d_NCHWc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_layout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depthwise_conv2d_NCHWc" title="Link to this definition"></a></dt>
<dd><p>Depthwise convolution NCHW[x]c forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 5-D with shape [batch, in_channel_chunk, in_height, in_width, in_channel_block]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 6-D with shape [out_channel_chunk, 1, filter_height, filter_width, 1, out_channel_block]
In NCHWc depthwise convolution,
we group kernel’s in_channel and channel_multiplier together then do the tiling.</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>two ints</em>) – The spatial stride along height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Input data layout</p></li>
<li><p><strong>out_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Output data layout</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Output data type</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 5-D with shape [batch, out_channel_chunk, out_height, out_width, out_channel_block]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.depthwise_conv2d_backward_input_nhwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">depthwise_conv2d_backward_input_nhwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Out_grad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oshape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ishape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depthwise_conv2d_backward_input_nhwc" title="Link to this definition"></a></dt>
<dd><p>Depthwise convolution nhwc backward wrt input operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [filter_height, filter_width, in_channel, channel_multiplier]</p></li>
<li><p><strong>Out_grad</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, out_height, out_width, out_channel]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>two ints</em>) – The spatial stride along height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, in_height, in_width, in_channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.depthwise_conv2d_backward_weight_nhwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">depthwise_conv2d_backward_weight_nhwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Out_grad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oshape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fshape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depthwise_conv2d_backward_weight_nhwc" title="Link to this definition"></a></dt>
<dd><p>Depthwise convolution nhwc backward wrt weight operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>Out_grad</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, out_height, out_width, out_channel]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>two ints</em>) – The spatial stride along height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [filter_height, filter_width, in_channel, channel_multiplier]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.depthwise_conv2d_nchw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">depthwise_conv2d_nchw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depthwise_conv2d_nchw" title="Link to this definition"></a></dt>
<dd><p>Depthwise convolution nchw forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [in_channel, channel_multiplier, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – The spatial stride, or (stride_height, stride_width).</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Output data type</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.depthwise_conv2d_nhwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">depthwise_conv2d_nhwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'HWOI'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depthwise_conv2d_nhwc" title="Link to this definition"></a></dt>
<dd><p>Depthwise convolution nhwc forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [filter_height, filter_width, in_channel, channel_multiplier]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>two ints</em>) – The spatial stride along height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Output data type</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.dilate">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">dilate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'DilatedInput'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.dilate" title="Link to this definition"></a></dt>
<dd><p>Dilate data with given dilation value (0 by default).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – n-D, can be any layout.</p></li>
<li><p><strong>strides</strong> (<em>list / tuple</em><em> of </em><em>n ints</em>) – Dilation stride on each dimension, 1 means no dilation.</p></li>
<li><p><strong>dilation_value</strong> (<em>int/float</em><em>, </em><em>optional</em>) – Value used to dilate the input.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The name prefix operators generated</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – n-D, the same layout as data.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.equal_const_int">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">equal_const_int</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.equal_const_int" title="Link to this definition"></a></dt>
<dd><p>Returns if expr equals value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>expr</strong> (<em>tvm.Expr</em>) – The input expression.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>equal</strong> – Whether they equals.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.fast_softmax">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">fast_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.fast_softmax" title="Link to this definition"></a></dt>
<dd><p>Perform softmax activation on the data.
Use approximation to compute exponent for faster speed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – can be any dimension</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – channel axis</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – output shape is the same as input</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.fifo_buffer">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">fifo_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.fifo_buffer" title="Link to this definition"></a></dt>
<dd><p>FIFO buffer to enable computation reuse in CNNs with sliding indow input</p>
<p>Compute equivalent of</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">concat</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
<span class="o">.</span><span class="n">slice_axis</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
            <span class="n">begin</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">],</span>
            <span class="n">end</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="o">+</span><span class="n">buffer</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">])</span>
</pre></div>
</div>
<p>Useful for</p>
<ul class="simple">
<li><p>Encoding explicit re-use of computation in convolution ops operated on a sliding window input</p></li>
<li><p>Implementing a FIFO queue to cache intermediate results, e.g. as in Fast WaveNet.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The input data</p></li>
<li><p><strong>buffer</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Previous value of the FIFO buffer</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Specify which axis should be used for buffering</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – Updated value for the buffer</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.flatten">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.flatten" title="Link to this definition"></a></dt>
<dd><p>Flattens the input array into a 2-D array by collapsing the higher dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input array.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 2-D array with collapsed higher dimensions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.get_const_int">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">get_const_int</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expr</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.get_const_int" title="Link to this definition"></a></dt>
<dd><p>Verifies expr is integer and get the constant value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>expr</strong> (<em>tvm.Expr</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The input expression.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>out_value</strong> – The output.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.get_const_tuple">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">get_const_tuple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_tuple</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.get_const_tuple" title="Link to this definition"></a></dt>
<dd><p>Verifies input tuple is IntImm or Var, returns tuple of int or Var.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>in_tuple</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>Expr</em>) – The input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>out_tuple</strong> – The output.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a> of <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.get_pad_tuple">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">get_pad_tuple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.get_pad_tuple" title="Link to this definition"></a></dt>
<dd><p>Common code to get the pad option</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Conv kernel size</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pad_top</strong> (<em>int</em>) – Padding size on top</p></li>
<li><p><strong>pad_left</strong> (<em>int</em>) – Padding size on left</p></li>
<li><p><strong>pad_down</strong> (<em>int</em>) – Padding size on down.</p></li>
<li><p><strong>pad_right</strong> (<em>int</em>) – Padding size on right.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.get_pad_tuple1d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">get_pad_tuple1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.get_pad_tuple1d" title="Link to this definition"></a></dt>
<dd><p>Common code to get the pad option</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Conv kernel size</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pad_left</strong> (<em>int</em>) – Padding size on left</p></li>
<li><p><strong>pad_right</strong> (<em>int</em>) – Padding size on right.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.get_pad_tuple3d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">get_pad_tuple3d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.get_pad_tuple3d" title="Link to this definition"></a></dt>
<dd><p>Common code to get the pad option</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Conv kernel size</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pad_front</strong> (<em>int</em>) – Padding size on front.</p></li>
<li><p><strong>pad_top</strong> (<em>int</em>) – Padding size on top</p></li>
<li><p><strong>pad_left</strong> (<em>int</em>) – Padding size on left</p></li>
<li><p><strong>pad_back</strong> (<em>int</em>) – Padding size on back.</p></li>
<li><p><strong>pad_down</strong> (<em>int</em>) – Padding size on down.</p></li>
<li><p><strong>pad_right</strong> (<em>int</em>) – Padding size on right.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.get_pad_tuple_generic">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">get_pad_tuple_generic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.get_pad_tuple_generic" title="Link to this definition"></a></dt>
<dd><p>Common code to get the pad option</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Conv kernel size</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pad_top</strong> (<em>int</em>) – Padding size on top</p></li>
<li><p><strong>pad_down</strong> (<em>int</em>) – Padding size on down.</p></li>
<li><p><strong>pad_left</strong> (<em>int</em>) – Padding size on left</p></li>
<li><p><strong>pad_right</strong> (<em>int</em>) – Padding size on right.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.global_pool">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">global_pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCHW'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.global_pool" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Perform global pooling on height and width dimension of data.</dt><dd><p>It decides the height and width dimension according to the layout string,
in which ‘W’ and ‘H’ means width and height respectively.
Width and height dimension cannot be split.
For example, NCHW, NCHW16c, etc. are valid for pool,
while NCHW16w, NCHW16h are not.
See parameter <cite>layout</cite> for more information of the layout string convention.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – n-D with shape of layout</p></li>
<li><p><strong>pool_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Pool type, ‘max’ or ‘avg’</p></li>
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Layout of the input data.
The layout is supposed to be composed of upper cases, lower cases and numbers,
where upper case indicates a dimension and
the corresponding lower case with factor size indicates the split dimension.
For example, NCHW16c can describe a 5-D tensor of
[batch_size, channel, height, width, channel_block],
in which channel_block=16 is a split of dimension channel.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – n-D in same layout with height and width dimension size of 1.
e.g., for NCHW, the output shape will be [batch, channel, 1, 1]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.group_conv1d_ncw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">group_conv1d_ncw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'VALID'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.group_conv1d_ncw" title="Link to this definition"></a></dt>
<dd><p>1D convolution forward operator for NCW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D with shape [batch, in_channel, in_width]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D with shape [num_filter, in_channel, filter_size]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a>) – The spatial stride along width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size can be an integer for equal padding,
a tuple of (left, right) or a string in [‘VALID’, ‘SAME’].</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a>) – Dilation rate if convolution should be dilated.</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Number of groups</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output data type. If None then output is same type as input.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.group_conv1d_nwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">group_conv1d_nwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'VALID'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.group_conv1d_nwc" title="Link to this definition"></a></dt>
<dd><p>1D convolution forward operator for NWC layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D with shape [batch, in_width, in_channel]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D with shape [filter_size, in_channel, num_filter]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a>) – The spatial stride along width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size can be an integer for equal padding,
a tuple of (left, right) or a string in [‘VALID’, ‘SAME’].</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a>) – Dilation rate if convolution should be dilated.</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Number of groups</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output data type. If None then output is same type as input.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.group_conv1d_transpose_ncw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">group_conv1d_transpose_ncw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.group_conv1d_transpose_ncw" title="Link to this definition"></a></dt>
<dd><p>Transposed 1D group convolution ncw forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D with shape [batch, in_channel, in_width]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D with shape [in_channel, num_filter, filter_width]</p></li>
<li><p><strong>stride</strong> (<em>ints</em>) – The spatial stride along width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output data type. This is used for mixed precision.</p></li>
<li><p><strong>output_padding</strong> (<em>ints</em>) – <dl class="simple">
<dt>Used to recover the actual output shape in case there are more</dt><dd><p>than one possible shape.  Must be smaller than stride.</p>
</dd>
<dt>groups<span class="classifier">int</span></dt><dd><p>number of groups</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 3-D with shape [batch, out_channel, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.group_conv2d_nchw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">group_conv2d_nchw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.group_conv2d_nchw" title="Link to this definition"></a></dt>
<dd><p>Group convolution operator in NCHW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [num_filter, in_channel // groups, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>2</em><em> or </em><em>4 ints</em>) – padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of groups</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output type. This is used for mixed precision.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.group_conv2d_nhwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">group_conv2d_nhwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.group_conv2d_nhwc" title="Link to this definition"></a></dt>
<dd><p>Group convolution operator in NHWC layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_height, in_width, in_channel, …]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [filter_height, filter_width, in_channel // groups, num_filter]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>2</em><em> or </em><em>4 ints</em>) – padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of groups</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output type. This is used for mixed precision.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.group_conv2d_transpose_nchw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">group_conv2d_transpose_nchw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.group_conv2d_transpose_nchw" title="Link to this definition"></a></dt>
<dd><p>Group convolution operator in NCHW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [in_channel, out_channel // groups, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>2</em><em> or </em><em>4 ints</em>) – padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output data type. This is used for mixed precision.</p></li>
<li><p><strong>output_padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>ints</em>) – Used to get the right output shape for gradients</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of groups</p></li>
<li><p><strong>out_dtype</strong> – The output type. This is used for mixed precision.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.group_conv3d_transpose_ncdhw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">group_conv3d_transpose_ncdhw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.group_conv3d_transpose_ncdhw" title="Link to this definition"></a></dt>
<dd><p>Transposed group 3D convolution ncdhw forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 5-D with shape [batch, in_channel, in_depth, in_height, in_width]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 5-D with shape [in_channel, num_filter, filter_depth, filter_height, filter_width]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>three ints</em>) – The spatial stride along depth,height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output data type. This is used for mixed precision.</p></li>
<li><p><strong>output_padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>ints</em>) – Used to get the right output shape for gradients</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – number of groups</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 5-D with shape [batch, out_channel, out_depth, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.leaky_relu">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">leaky_relu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.leaky_relu" title="Link to this definition"></a></dt>
<dd><p>Take leaky relu of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – The slope for the small gradient when x &lt; 0</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.log_softmax">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">log_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.log_softmax" title="Link to this definition"></a></dt>
<dd><p>Perform log softmax activation on the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – N-D input data</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – N-D output with same shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.lrn">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">lrn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.75</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.lrn" title="Link to this definition"></a></dt>
<dd><p>Perform the across channels local response normalisation
on the input data.</p>
<p>sum_sqr_up^i{x, y} = (bias+((alpha/size)*                                 {sum_{j=max(0, i-size/2)}^{min(N-1,i+size/2)}                                      (data^j{x,y})^2}))^beta
output^i{x, y} = data^i{x, y}/sum_sqr_up^i{x, y}
N is the number for input channels</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, channel, height, width]</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – normalisation window size</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – input data layout channel axis
default value is 1 for NCHW format</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – offset to avoid dividing by 0</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – to be divided</p></li>
<li><p><strong>beta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – exponent</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D output with same shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.lstm">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">lstm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Wi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Wh</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Bi=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Bh=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_init=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_init=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_i=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_f=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_o=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f_act=&lt;function</span> <span class="pre">sigmoid&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">g_act=&lt;function</span> <span class="pre">tanh&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_act=&lt;function</span> <span class="pre">tanh&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_layout:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'IFGO'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.lstm" title="Link to this definition"></a></dt>
<dd><p>General LSTM implemented using TE scan.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a>) – Input sequence with shape <cite>(seq_len, batch_size, in_dim)</cite></p></li>
<li><p><strong>Wi</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a>) – Input weight matrix with shape <cite>(4 * hidden_dim, in_dim)</cite>. The weights are packed according
to <cite>weight_layout</cite>.</p></li>
<li><p><strong>Wh</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a>) – Hidden weight matrix with shape <cite>(4 * hidden_dim, hidden_dim or proj_dim)</cite>. Packed as <cite>Wh</cite>.</p></li>
<li><p><strong>Bi</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a><em>, </em><em>optional</em>) – Input bias with shape <cite>(4 * hidden_dim,)</cite>, by default None. Packed as <cite>Wh</cite>.</p></li>
<li><p><strong>Bh</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a><em>, </em><em>optional</em>) – Hidden bias with shape as <cite>Bi</cite>, by default None. Packed as <cite>Wh</cite>.</p></li>
<li><p><strong>h_init</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a><em>, </em><em>optional</em>) – Initial hidden state with shape <cite>(batch_size, hidden_dim or proj_dim)</cite>, zero if None</p></li>
<li><p><strong>c_init</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a><em>, </em><em>optional</em>) – Initial cell state with same shape as <cite>h_init</cite>, zero if None</p></li>
<li><p><strong>proj</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a><em>, </em><em>optional</em>) – Projection matrix with shape <cite>(proj_dim, hidden_dim)</cite>, by default None</p></li>
<li><p><strong>p_i</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a><em>, </em><em>optional</em>) – Peephole LSTM matrices with shape <cite>(batch_size, hidden_dim)</cite>, by default None</p></li>
<li><p><strong>p_f</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a><em>, </em><em>optional</em>) – Peephole LSTM matrices with shape <cite>(batch_size, hidden_dim)</cite>, by default None</p></li>
<li><p><strong>p_o</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>te.Tensor</em></a><em>, </em><em>optional</em>) – Peephole LSTM matrices with shape <cite>(batch_size, hidden_dim)</cite>, by default None</p></li>
<li><p><strong>f_act</strong> (<em>F</em><em>, </em><em>optional</em>) – Gate activation functions</p></li>
<li><p><strong>g_act</strong> (<em>F</em><em>, </em><em>optional</em>) – Gate activation functions</p></li>
<li><p><strong>h_act</strong> (<em>F</em><em>, </em><em>optional</em>) – Gate activation functions</p></li>
<li><p><strong>reverse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to process <cite>Xs</cite> in reverse, by default False</p></li>
<li><p><strong>weight_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The packed weight layout for gates, by default “IFGO”. Note: I = input, F = forget,
G = cell, O = output.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – Tuple of hidden states (with shape <cite>(seq_len, batch_size, hidden_dim or proj_dim)</cite>), and
cell states (with shape <cite>(seq_len, batch_size, hidden_dim)</cite>).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">te.Tensor</a>, <a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.matmul">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">matmul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor_a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transpose_a</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transpose_b</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_scheduler_rewritten_layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">meta_schedule_original_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.matmul" title="Link to this definition"></a></dt>
<dd><p>The default implementation of matmul in topi.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor_a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 2-D with shape [batch, in_dim]</p></li>
<li><p><strong>tensor_b</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 2-D with shape [out_dim, in_dim]</p></li>
<li><p><strong>bias</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>]</em>) – 1-D with shape [out_dim]</p></li>
<li><p><strong>out_dtype</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The output type. This is used for mixed precision.</p></li>
<li><p><strong>transpose_a</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>] </em><em>= False</em>) – Whether the tensor_a is in transposed format.</p></li>
<li><p><strong>transpose_b</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>] </em><em>= False</em>) – Whether the tensor_b is in transposed format.</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>] </em><em>= &quot;&quot;</em>) – The layout after auto-scheduler’s layout rewrite pass.</p></li>
<li><p><strong>meta_schedule_original_shape</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a><em>]</em><em>] </em><em>= None</em>) – The original shape of the input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 2-D with shape [batch, out_dim]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.mirror_pad">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">mirror_pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_before</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_after</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'SYMMETRIC'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'MirrorPadInput'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.mirror_pad" title="Link to this definition"></a></dt>
<dd><p>Pad Input with mirroring either symmetric or reflected.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – n-D input, can be any layout.</p></li>
<li><p><strong>pad_before</strong> (<em>list / tuple</em><em> of </em><em>n ints</em>) – Pad width on each dimension to pad the before the axis begin.</p></li>
<li><p><strong>pad_after</strong> (<em>list / tuple</em><em> of </em><em>n ints</em><em>, </em><em>optional</em>) – Pad width each dimension to pad the after the axis end.</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Type of mirror padding to apply. Must be SYMMETRIC or REFLECT</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The name prefix operators generated</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – n-D, the same layout as Input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.namedtuple">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">namedtuple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">typename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">field_names</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.namedtuple" title="Link to this definition"></a></dt>
<dd><p>Returns a new subclass of tuple with named fields.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Point</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Point&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Point</span><span class="o">.</span><span class="vm">__doc__</span>                   <span class="c1"># docstring for the new class</span>
<span class="go">&#39;Point(x, y)&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Point</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>             <span class="c1"># instantiate with positional args or keywords</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>                     <span class="c1"># indexable like a plain tuple</span>
<span class="go">33</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">p</span>                        <span class="c1"># unpack like a regular tuple</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span>
<span class="go">(11, 22)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">y</span>                       <span class="c1"># fields also accessible by name</span>
<span class="go">33</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">_asdict</span><span class="p">()</span>                 <span class="c1"># convert to a dictionary</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="go">11</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Point</span><span class="p">(</span><span class="o">**</span><span class="n">d</span><span class="p">)</span>                      <span class="c1"># convert from a dictionary</span>
<span class="go">Point(x=11, y=22)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">_replace</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>               <span class="c1"># _replace() is like str.replace() but targets named fields</span>
<span class="go">Point(x=100, y=22)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.nll_loss">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">nll_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.nll_loss" title="Link to this definition"></a></dt>
<dd><p>Negative log likelihood loss on the input data.</p>
<dl class="simple">
<dt>output{n, i_1, i_2, …, i_k} = -p * w</dt><dd><dl class="simple">
<dt>where t = target{n, i_1, i_2, …, i_k}</dt><dd><p>p = predictions{n, t, i_1, i_2, i_k}
w = weights{n, i_1, i_2, …, i_k} if t != ignore_index else 0</p>
</dd>
</dl>
</dd>
</dl>
<p>result = reduction(output)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>predictions</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – (k+2)-D with shape (N, C, d_1, d_2, …, d_k),
where C is the number of target classes</p></li>
<li><p><strong>targets</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – (k+1)-D with shape (N, d_1, d_2, …, d_k)
The target value of the input.</p></li>
<li><p><strong>weights</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 1-D with shape (C,)
The weight of each target value.</p></li>
<li><p><strong>reduction</strong> (<em>string</em>) – The reduction method to apply to output.
Can be “mean”, “sum” or “none”.</p></li>
<li><p><strong>ignore_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The target value to ignore.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – a scalar if the reduction type is “mean” or “sum”,
otherwise the same shape as <cite>target</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.pad">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_before</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_after</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PadInput'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attrs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.pad" title="Link to this definition"></a></dt>
<dd><p>Pad Input with zeros.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – n-D input, can be any layout.</p></li>
<li><p><strong>pad_before</strong> (<em>list / tuple</em><em> of </em><em>n ints</em>) – Pad width on each dimension to pad the before the axis begin.</p></li>
<li><p><strong>pad_after</strong> (<em>list / tuple</em><em> of </em><em>n ints</em><em>, </em><em>optional</em>) – Pad width each dimension to pad the after the axis end.</p></li>
<li><p><strong>pad_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – The value to be padded.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The name prefix operators generated</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – n-D, the same layout as Input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.pool1d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">pool1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ceil_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_include_pad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.pool1d" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Perform pooling on width dimension of data.</dt><dd><p>Width axis is determined according to the layout string.
in which ‘w’ means width.
Width dimension cannot be split.
For example, NCW, NCW16c, etc. are valid for pool,
while NCW16w is not.
See parameter <cite>layout</cite> for more information of the layout string convention.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – n-D with shape of layout</p></li>
<li><p><strong>kernel</strong> (<em>list/tuple</em><em> of </em><em>one int</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Kernel size, [kernel_width]</p></li>
<li><p><strong>stride</strong> (<em>list/tuple</em><em> of </em><em>one int</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Stride size, [stride_width]</p></li>
<li><p><strong>dilation</strong> (<em>list/tuple</em><em> of </em><em>two ints</em>) – Dilation size, [dilation_height, dilation_width]</p></li>
<li><p><strong>padding</strong> (<em>list/tuple</em><em> of </em><em>two ints</em>) – Pad size, [pad_left, pad_right]</p></li>
<li><p><strong>pool_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Pool type, ‘max’ or ‘avg’</p></li>
<li><p><strong>ceil_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether to use ceil when calculating output size.</p></li>
<li><p><strong>layout</strong> (<em>string</em>) – Layout of the input data.
The layout is supposed to be composed of upper cases, lower cases and numbers,
where upper case indicates a dimension and
the corresponding lower case with factor size indicates the split dimension.
For example, NCW16c can describe a 4-D tensor of
[batch_size, channel, width, channel_block],
in which channel_block=16 is a split of dimension channel.</p></li>
<li><p><strong>count_include_pad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether include padding in the calculation when pool_type is ‘avg’</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – n-D in the same layout</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.pool2d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">pool2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ceil_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCHW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_include_pad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.pool2d" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Perform pooling on height and width dimension of data.</dt><dd><p>It decides the height and width dimension according to the layout string,
in which ‘W’ and ‘H’ means width and height respectively.
Width and height dimension cannot be split.
For example, NCHW, NCHW16c, etc. are valid for pool,
while NCHW16w, NCHW16h are not.
See parameter <cite>layout</cite> for more information of the layout string convention.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – n-D with shape of layout</p></li>
<li><p><strong>kernel</strong> (<em>list/tuple</em><em> of </em><em>two ints</em>) – Kernel size, [kernel_height, kernel_width]</p></li>
<li><p><strong>stride</strong> (<em>list/tuple</em><em> of </em><em>two ints</em>) – Stride size, [stride_height, stride_width]</p></li>
<li><p><strong>dilation</strong> (<em>list/tuple</em><em> of </em><em>two ints</em>) – Dilation size, [dilation_height, dilation_width]</p></li>
<li><p><strong>padding</strong> (<em>list/tuple</em><em> of </em><em>four ints</em>) – Pad size, [pad_top, pad_left, pad_bottom, pad_right]]</p></li>
<li><p><strong>pool_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Pool type, ‘max’ or ‘avg’</p></li>
<li><p><strong>ceil_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether to use ceil when calculating output size.</p></li>
<li><p><strong>layout</strong> (<em>string</em>) – Layout of the input data.
The layout is supposed to be composed of upper cases, lower cases and numbers,
where upper case indicates a dimension and
the corresponding lower case with factor size indicates the split dimension.
For example, NCHW16c can describe a 5-D tensor of
[batch_size, channel, height, width, channel_block],
in which channel_block=16 is a split of dimension channel.</p></li>
<li><p><strong>count_include_pad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether include padding in the calculation when pool_type is ‘avg’</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – n-D in the same layout</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.pool3d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">pool3d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ceil_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCDHW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_include_pad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.pool3d" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Perform pooling on depth, height and width dimension of data.</dt><dd><p>It decides the depth, height and width dimension according to the layout string,
in which ‘D’, ‘W’ and ‘H’ means depth, width and height respectively.
Depth, width and height dimension cannot be split.
For example, NCDHW, NCDHW16c, etc. are valid for pool,
while NCDHW16d, NCDHW16w, NCDHW16h are not.
See parameter <cite>layout</cite> for more information of the layout string convention.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – n-D with shape of layout</p></li>
<li><p><strong>kernel</strong> (<em>list/tuple</em><em> of </em><em>three ints</em>) – Kernel size, [kernel_depth, kernel_height, kernel_width]</p></li>
<li><p><strong>stride</strong> (<em>list/tuple</em><em> of </em><em>three ints</em>) – Stride size, [stride_depth, stride_height, stride_width]</p></li>
<li><p><strong>dilation</strong> (<em>list/tuple</em><em> of </em><em>two ints</em>) – Dilation size, [dilation_height, dilation_width]</p></li>
<li><p><strong>padding</strong> (<em>list/tuple</em><em> of </em><em>six ints</em>) – Pad size, [pad_front, pad_top, pad_left, pad_back, pad_bottom, pad_right]</p></li>
<li><p><strong>pool_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Pool type, ‘max’ or ‘avg’</p></li>
<li><p><strong>ceil_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether to use ceil when calculating output size.</p></li>
<li><p><strong>layout</strong> (<em>string</em>) – Layout of the input data.
The layout is supposed to be composed of upper cases, lower cases and numbers,
where upper case indicates a dimension and
the corresponding lower case with factor size indicates the split dimension.
For example, NCDHW16c can describe a 6-D tensor of
[batch_size, channel, depth, height, width, channel_block],
in which channel_block=16 is a split of dimension channel.</p></li>
<li><p><strong>count_include_pad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether include padding in the calculation when pool_type is ‘avg’</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – n-D in the same layout</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.pool_grad">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">pool_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ceil_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_include_pad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCHW'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.pool_grad" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Gradient of pooling on height and width dimension of data.</dt><dd><p>It decides the height and width dimension according to the layout string,
in which ‘W’ and ‘H’ means width and height respectively.
Width and height dimension cannot be split.
For example, NCHW, NCHW16c, etc. are valid for pool,
while NCHW16w, NCHW16h are not.
See parameter <cite>layout</cite> for more information of the layout string convention.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>grads</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – n-D with shape of layout</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – n-D with shape of layout</p></li>
<li><p><strong>kernel</strong> (<em>list/tuple</em><em> of </em><em>two ints</em>) – Kernel size, [kernel_height, kernel_width]</p></li>
<li><p><strong>stride</strong> (<em>list/tuple</em><em> of </em><em>two ints</em>) – Stride size, [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<em>list/tuple</em><em> of </em><em>four ints</em>) – Pad size, [pad_top, pad_left, pad_bottom, pad_right]]</p></li>
<li><p><strong>pool_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Pool type, ‘max’ or ‘avg’</p></li>
<li><p><strong>ceil_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether to use ceil when calculating output size.</p></li>
<li><p><strong>count_include_pad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether include padding in the calculation when pool_type is ‘avg’</p></li>
<li><p><strong>layout</strong> (<em>string</em>) – Layout of the input data.
The layout is supposed to be composed of upper cases, lower cases and numbers,
where upper case indicates a dimension and
the corresponding lower case with factor size indicates the split dimension.
For example, NCHW16c can describe a 5-D tensor of
[batch_size, channel, height, width, channel_block],
in which channel_block=16 is a split of dimension channel.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – n-D in the same layout</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.prelu">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">prelu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slope</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.prelu" title="Link to this definition"></a></dt>
<dd><p>PReLU.
It accepts two arguments: an input <code class="docutils literal notranslate"><span class="pre">x</span></code> and a weight array <code class="docutils literal notranslate"><span class="pre">W</span></code>
and computes the output as <span class="math notranslate nohighlight">\(PReLU(x) y = x &gt; 0 ? x : W * x\)</span>,
where <span class="math notranslate nohighlight">\(*\)</span> is an elementwise multiplication for each sample in the
batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p></li>
<li><p><strong>slope</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Channelised slope tensor for prelu</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The axis where the channel data needs to be applied</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>y</strong> (<em>tvm.te.Tensor</em>) – The result.</p></li>
<li><p><em>Links</em></p></li>
<li><p><em>—–</em></p></li>
<li><p><strong>[http</strong> (<em>//arxiv.org/pdf/1502.01852v1.pdf]</em>)</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.reduce">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">reduce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequence</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">initial</span></span></em><span class="optional">]</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">value</span></span></span><a class="headerlink" href="#tvm.topi.nn.reduce" title="Link to this definition"></a></dt>
<dd><p>Apply a function of two arguments cumulatively to the items of a sequence,
from left to right, so as to reduce the sequence to a single value.
For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates
((((1+2)+3)+4)+5).  If initial is present, it is placed before the items
of the sequence in the calculation, and serves as a default when the
sequence is empty.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.relu">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">relu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.relu" title="Link to this definition"></a></dt>
<dd><p>Take relu of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Input argument.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.scale_shift_nchw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">scale_shift_nchw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Shift</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.scale_shift_nchw" title="Link to this definition"></a></dt>
<dd><p>Batch normalization operator in inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D input tensor, NCHW layout [batch, channel, height, width]</p></li>
<li><p><strong>Scale</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Scale tensor, 1-D of size channel number</p></li>
<li><p><strong>Shift</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Shift tensor, 1-D of size channel number</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – Output tensor, layout is NCHW</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.scale_shift_nchwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">scale_shift_nchwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Shift</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.scale_shift_nchwc" title="Link to this definition"></a></dt>
<dd><p>Batch normalization operator in inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 5-D input tensor, NCHWc layout [batch, channel_chunk, height, width, channel_block]</p></li>
<li><p><strong>Scale</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Scale tensor, 2-D of size [channel_chunk, channel_block]</p></li>
<li><p><strong>Shift</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Shift tensor, 2-D of size [channel_chunk, channel_block]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – Output tensor, layout is NHWC</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.scale_shift_nhwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">scale_shift_nhwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Shift</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.scale_shift_nhwc" title="Link to this definition"></a></dt>
<dd><p>Batch normalization operator in inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D input tensor, NHWC layout [batch, height, width, channel]</p></li>
<li><p><strong>Scale</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Scale tensor, 1-D of size channel number</p></li>
<li><p><strong>Shift</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Shift tensor, 1-D of size channel number</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – Output tensor, layout is NHWC</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.simplify">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">simplify</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expr</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.simplify" title="Link to this definition"></a></dt>
<dd><p>Simplify the expression if it is Expr, directly return if it is int.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>expr</strong> (<em>Expr</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>out</strong> – The simplified output</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expr or <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.simulated_dequantize">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">simulated_dequantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_zero_point</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.simulated_dequantize" title="Link to this definition"></a></dt>
<dd><p>Simulated QNN dequantize operator that mimics QNN outputs without changing datatype.
The benefit of this operator over true QNN dequantize is that this operator allows dynamic
datatype selection and can operate on both per-channel and scalar scales and zero points while
QNN dequantize requires both of these to be fixed at compile time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – An N-D input tensor to the operator.</p></li>
<li><p><strong>in_dtype</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – A scalar variable that indicates which datatype to simulate dequantization with. Use
SQNN_DTYPE_TO_CODE to convert a dtype string into the corresponding variable
value.</p></li>
<li><p><strong>input_scale</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) – A scalar tensor representing the scale to use when dequantizing from integer datatypes.
When it contains more than a single value, N must match the number of channels in data.</p></li>
<li><p><strong>input_zero_point</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) – A 1-D tensor representing the zero point to use when dequantizing from integer datatypes.
When it contains more than a single value, N must match the number of channels in data.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The channel axis for quantization. Default value is -1 which corresponds to the last axis.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.simulated_quantize">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">simulated_quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_zero_point</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.simulated_quantize" title="Link to this definition"></a></dt>
<dd><p>Simulated QNN quantize operator that mimics QNN outputs without changing datatype.
The benefit of this operator over true QNN quantize is that this operator allows dynamic
datatype selection and can operate on both per-channel and scalar scales and zero points while
QNN quantize requires both of these to be fixed at compile time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – An N-D input tensor to the operator.</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – A scalar variable that indicates which datatype to simulate quantization with. Use
SQNN_DTYPE_TO_CODE to convert a dtype string into the corresponding variable
value.</p></li>
<li><p><strong>output_scale</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) – A scalar tensor representing the scale to use when quantizing to integer datatypes.
When it contains more than a single value, N must match the number of channels in data.</p></li>
<li><p><strong>output_zero_point</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) – A 1-D tensor representing the zero point to use when quantizing to integer datatypes.
When it contains more than a single value, N must match the number of channels in data.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The channel axis for quantization. Default value is -1 which corresponds to the last axis.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.softmax">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.softmax" title="Link to this definition"></a></dt>
<dd><p>Perform softmax activation on the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – can be any dimension</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – channel axis</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – output shape is the same as input</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.softmax_common">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">softmax_common</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_fast_exp</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.softmax_common" title="Link to this definition"></a></dt>
<dd><p>The common part of softmax and fast_softmax</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.space_to_batch_nd">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">space_to_batch_nd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_before</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_after</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.space_to_batch_nd" title="Link to this definition"></a></dt>
<dd><p>Perform batch to space transformation on the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – N-D Tensor with shape [batch, spatial_shape, remaining_shapes],
where spatial_shape has M dimensions.</p></li>
<li><p><strong>block_shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>ints</em>) – list of size [M] where M is number of spatial dims, specifies block
size for each spatial dimension.</p></li>
<li><p><strong>pad_before</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>ints</em>) – list of shape [M] where M is number of spatial dims, specifies
zero-padding size before each spatial dimension.</p></li>
<li><p><strong>pad_after</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>ints</em>) – list of shape [M] where M is number of spatial dims, specifies
zero-padding size after each spatial dimension.</p></li>
<li><p><strong>pad_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – The value used for padding.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.space_to_depth">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">space_to_depth</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCHW'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.space_to_depth" title="Link to this definition"></a></dt>
<dd><p>Perform space to depth transformation on the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D tensor in either NCHW or NHWC layout.</p></li>
<li><p><strong>block_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size of blocks to decompose into channel dimension.</p></li>
<li><p><strong>layout</strong> (<em>string</em>) – Either NCHW or NHWC, indicating data layout.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – Output of shape [N, C * block_size**2, H / block_size, W / block_size]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.strided_slice">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">strided_slice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">begin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slice_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'end'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assume_inbound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.strided_slice" title="Link to this definition"></a></dt>
<dd><p>Slice of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The tensor to be sliced.</p></li>
<li><p><strong>begin</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The indices to begin with in the slicing.</p></li>
<li><p><strong>end</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Indices indicating end of the slice.</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Specifies the stride values, it can be negative
in that case, the input tensor will be reversed
in that particular axis.</p></li>
<li><p><strong>axes</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Axes along which slicing is applied. When it is specified, begin, end
strides, and axes need to a list of integers of the same length.</p></li>
<li><p><strong>slice_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The slice mode [end, size].
end - The ending indices for the slice [default].
size - The input strides will be ignored, input end in this mode indicates
the sizeof a slice starting at the location specified by begin. If end[i]
is -1, all remaining elements in that dimension are included in the slice.</p></li>
<li><p><strong>assume_inbound</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – A flag to indicate if all indices are assumed to be inbound</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.unpack_NCHWc_to_nchw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">unpack_NCHWc_to_nchw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">packed_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.unpack_NCHWc_to_nchw" title="Link to this definition"></a></dt>
<dd><p>Unpack conv2d_NCHWc output from layout NCHWc to NCHW</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>packed_out</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – The output tensor of conv2d_NCHWc.</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The output dtype.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>unpacked_out</strong> – The unpacked output tensor in NCHW layout.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.upsampling">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">upsampling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCHW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nearest_neighbor'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.upsampling" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Perform upsampling on the data.</dt><dd><p>Nearest neighbor and bilinear upsampling are supported.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – inputs is a 4-D tensor with shape
[batch, channel, in_height, in_width]
or  [batch, in_height, in_width, channel]</p></li>
<li><p><strong>scale_h</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Scaling factor for height</p></li>
<li><p><strong>scale_w</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Scaling factor for width</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) – either “NCHW” or “NHWC”</p></li>
<li><p><strong>method</strong> (<em>{&quot;bilinear&quot;</em><em>, </em><em>&quot;nearest_neighbor&quot;</em><em>, </em><em>&quot;bicubic&quot;}</em>) – Method to be used for upsampling.</p></li>
<li><p><strong>output_shape</strong> (<em>tvm.tir.container.Array</em><em>, </em><em>optional</em>) – Shape to return. If left None will be inferred
(If shape is determined dynamically, pass out_dtype.shape as output_shape)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, channel, in_height*scale_h, in_width*scale_w]
or [batch, in_height*scale, in_width*scale, channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.upsampling3d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">upsampling3d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCDHW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nearest_neighbor'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coordinate_transformation_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'half_pixel'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.upsampling3d" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Perform upsampling on the data.</dt><dd><p>Nearest neighbor and bilinear upsampling are supported.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – inputs is a 5-D tensor with shape
[batch, channel, in_depth, in_height, in_width]
or  [batch, in_depth, in_height, in_width, channel]</p></li>
<li><p><strong>scale_d</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Scaling factor for depth</p></li>
<li><p><strong>scale_h</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Scaling factor for height</p></li>
<li><p><strong>scale_w</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Scaling factor for width</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) – either “NCDHW” or “NDHWC”</p></li>
<li><p><strong>method</strong> (<em>{&quot;trilinear&quot;</em><em>, </em><em>&quot;nearest_neighbor&quot;}</em>) – Method to be used for upsampling.</p></li>
<li><p><strong>coordinate_transformation_mode</strong> (<em>string</em><em>, </em><em>optional</em>) – Describes how to transform the coordinate in the resized tensor
to the coordinate in the original tensor.
Refer to the ONNX Resize operator specification for details.
Available options are “half_pixel”, “align_corners” and “asymmetric”.</p></li>
<li><p><strong>output_shape</strong> (<em>tvm.tir.container.Array</em><em>, </em><em>optional</em>) – Shape to return. If left None will be inferred
(If shape is determined dynamically, pass out_dtype.shape as output_shape)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 5-D with shape [batch, channel, in_depth*scale, in_height*scale, in_width*scale]
or [batch, in_depth*scale, in_height*scale, in_width*scale, channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.winograd_transform_matrices">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">winograd_transform_matrices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tile_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.winograd_transform_matrices" title="Link to this definition"></a></dt>
<dd><p>Compute the A, B, and G transform matrices for <cite>tile_size</cite> as a <cite>tvm.Expr</cite>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.instance_norm">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">instance_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.instance_norm" title="Link to this definition"></a></dt>
<dd><p>Instance normalization operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – N-D with shape (d_0, d_1, …, d_{N-1})</p></li>
<li><p><strong>gamma</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – K-D with shape (r_0, r_1, …, r_{K-1}) where K == len(axis) and d_{axis_k} == r_k</p></li>
<li><p><strong>beta</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Optional, K-D with shape (r_0, r_1, …, r_{K-1}) where K == len(axis) and d_{axis_k} == r_k</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis over the normalization applied (the axis along which the mean and variance are
computed)</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – The epsilon value to avoid division by zero.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – N-D with shape (d_0, d_1, …, d_{N-1})</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.layer_norm">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">layer_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.layer_norm" title="Link to this definition"></a></dt>
<dd><p>Layer normalization operator.
It accepts fp16 and fp32 as input data type. It will cast the input to fp32
to perform the computation. The output will have the same data type as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – N-D with shape (d_0, d_1, …, d_{N-1})</p></li>
<li><p><strong>gamma</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – K-D with shape (r_0, r_1, …, r_{K-1}) where K == len(axis) and d_{axis_k} == r_k</p></li>
<li><p><strong>beta</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Optional, K-D with shape (r_0, r_1, …, r_{K-1}) where K == len(axis) and d_{axis_k} == r_k</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis over the normalization applied</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – The epsilon value to avoid division by zero.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – N-D with shape (d_0, d_1, …, d_{N-1})</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.group_norm">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">group_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.group_norm" title="Link to this definition"></a></dt>
<dd><p>Group normalization operator.
It accepts fp16 and fp32 as input data type. It will cast the input to fp32
to perform the computation. The output will have the same data type as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – N-D with shape (d_0, d_1, …, d_{N-1})</p></li>
<li><p><strong>gamma</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 1-D with shape (r_0) where r_0 == d_{channel_axis}</p></li>
<li><p><strong>beta</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – Optional, 1-D with shape (r_0) where r_0 == d_{channel_axis}</p></li>
<li><p><strong>num_groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The number of groups</p></li>
<li><p><strong>channel_axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The channel axis</p></li>
<li><p><strong>axes</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis over the normalization applied, excluding the channel axis</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – The epsilon value to avoid division by zero.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – N-D with shape (d_0, d_1, …, d_{N-1})</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.nn.rms_norm">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.nn.</span></span><span class="sig-name descname"><span class="pre">rms_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.rms_norm" title="Link to this definition"></a></dt>
<dd><p>Root mean square normalization operator. The output will have the same data type as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – N-D with shape (d_0, d_1, …, d_{N-1})</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – K-D with shape (r_0, r_1, …, r_{K-1}) where K == len(axis) and d_{axis_k} == r_k</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Axis over the normalization applied</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – The epsilon value to avoid division by zero.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>result</strong> – N-D with shape (d_0, d_1, …, d_{N-1})</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-tvm.topi.image">
<span id="tvm-topi-image"></span><h2>tvm.topi.image<a class="headerlink" href="#module-tvm.topi.image" title="Link to this heading"></a></h2>
<p>IMAGE network operators</p>
<p><strong>Functions:</strong></p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.image.affine_grid" title="tvm.topi.image.affine_grid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">affine_grid</span></code></a>(data, target_shape)</p></td>
<td><p>affine_grid operator that generates 2D sampling grid.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.image.can_convert_multiply_to_intdiv" title="tvm.topi.image.can_convert_multiply_to_intdiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">can_convert_multiply_to_intdiv</span></code></a>(origin_size, ...)</p></td>
<td><p>Check whether can convert multiplication to division</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.image.crop_and_resize" title="tvm.topi.image.crop_and_resize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">crop_and_resize</span></code></a>(data, boxes, box_indices, ...)</p></td>
<td><p>Perform crop and resize operation on the data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.image.dilation2d_nchw" title="tvm.topi.image.dilation2d_nchw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dilation2d_nchw</span></code></a>(input, filter, stride, ...)</p></td>
<td><p>Morphological dilation operator in NCHW layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.image.dilation2d_nhwc" title="tvm.topi.image.dilation2d_nhwc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dilation2d_nhwc</span></code></a>(input, filter, stride, ...)</p></td>
<td><p>Morphological 2d dilation NHWC layout.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.image.get_1d_indices" title="tvm.topi.image.get_1d_indices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_1d_indices</span></code></a>(indices[, layout])</p></td>
<td><p>Get 1d indices</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.image.get_1d_pixel" title="tvm.topi.image.get_1d_pixel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_1d_pixel</span></code></a>(data, layout, image_width, n, ...)</p></td>
<td><p>Get 1d pixel</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.image.get_2d_indices" title="tvm.topi.image.get_2d_indices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_2d_indices</span></code></a>(indices[, layout])</p></td>
<td><p>Get 2d indices</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.image.get_2d_pixel" title="tvm.topi.image.get_2d_pixel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_2d_pixel</span></code></a>(data, layout, image_height, ...)</p></td>
<td><p>Get 2d pixel</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.image.get_3d_indices" title="tvm.topi.image.get_3d_indices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_3d_indices</span></code></a>(indices[, layout])</p></td>
<td><p>Get 3d indices</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.image.get_3d_pixel" title="tvm.topi.image.get_3d_pixel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_3d_pixel</span></code></a>(data, layout, image_depth, ...)</p></td>
<td><p>Get 3d pixel</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.image.get_closest_index" title="tvm.topi.image.get_closest_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_closest_index</span></code></a>(in_x, rounding_method, boxes)</p></td>
<td><p>get the closest index to a value based on a certain rounding method</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.image.get_inx" title="tvm.topi.image.get_inx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_inx</span></code></a>(x, image_width, target_width, ...[, ...])</p></td>
<td><p>Infer input x from output x with various coordinate transformation methods</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.image.get_pad_tuple" title="tvm.topi.image.get_pad_tuple"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_pad_tuple</span></code></a>(padding, kernel)</p></td>
<td><p>Common code to get the pad option</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.image.grid_sample" title="tvm.topi.image.grid_sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">grid_sample</span></code></a>(data, grid[, method, layout, ...])</p></td>
<td><p>Applies grid sampling to input feature map.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.image.nchw_pack_layout" title="tvm.topi.image.nchw_pack_layout"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nchw_pack_layout</span></code></a>(layout_info)</p></td>
<td><p>Check whether the layout type is NCHWinic</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.image.nchw_xc_layout" title="tvm.topi.image.nchw_xc_layout"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nchw_xc_layout</span></code></a>(layout_info)</p></td>
<td><p>Check whether the layout type is NCHWxc</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.image.pad" title="tvm.topi.image.pad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pad</span></code></a>(data, pad_before[, pad_after, ...])</p></td>
<td><p>Pad Input with zeros.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.image.resize1d" title="tvm.topi.image.resize1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resize1d</span></code></a>(data, roi, size[, layout, method, ...])</p></td>
<td><p>Perform resize operation on the data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.image.resize2d" title="tvm.topi.image.resize2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resize2d</span></code></a>(data, roi, size[, layout, method, ...])</p></td>
<td><p>Perform resize operation on the data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.image.resize3d" title="tvm.topi.image.resize3d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resize3d</span></code></a>(data, roi, size[, layout, method, ...])</p></td>
<td><p>Perform resize operation on the data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.image.simplify" title="tvm.topi.image.simplify"><code class="xref py py-obj docutils literal notranslate"><span class="pre">simplify</span></code></a>(expr)</p></td>
<td><p>Simplify the expression if it is Expr, directly return if it is int.</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.affine_grid">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">affine_grid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.affine_grid" title="Link to this definition"></a></dt>
<dd><p>affine_grid operator that generates 2D sampling grid.</p>
<p>This operation is described in <a class="reference external" href="https://arxiv.org/pdf/1506.02025.pdf">https://arxiv.org/pdf/1506.02025.pdf</a>. It generates a uniform
sampling grid within the target shape and normalizes it to [-1, 1]. The provided affine
transformation is then applied on the sampling grid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>tvm.Tensor</em>) – 3-D with shape [batch, 2, 3]. The affine matrix.</p></li>
<li><p><strong>target_shape</strong> (<em>list/tuple</em><em> of </em><em>two int</em>) – Specifies the output shape (H, W).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, 2, target_height, target_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tvm.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.can_convert_multiply_to_intdiv">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">can_convert_multiply_to_intdiv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">origin_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaled_size</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.can_convert_multiply_to_intdiv" title="Link to this definition"></a></dt>
<dd><p>Check whether can convert multiplication to division</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.crop_and_resize">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">crop_and_resize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boxes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box_indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCHW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'bilinear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extrapolation_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.crop_and_resize" title="Link to this definition"></a></dt>
<dd><p>Perform crop and resize operation on the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – inputs is a 4-D tensor with shape
[batch, channel, in_height, in_width]
or  [batch, in_height, in_width, channel]</p></li>
<li><p><strong>boxes</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – A 2-D tensor of shape [num_boxes, 4]. Each row of the tensor specifies
the coordinates of a box.</p></li>
<li><p><strong>box_indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – A 1-D tensor of shape [num_boxes], box_indices[i] specifies the data that
the i-th box refers to.</p></li>
<li><p><strong>crop_size</strong> (<a class="reference internal" href="relax/relax.html#tvm.relax.Tuple" title="tvm.relax.Tuple"><em>Tuple</em></a>) – The target size of each box.</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) – “NCHW”, “NHWC”</p></li>
<li><p><strong>method</strong> (<em>{&quot;bilinear&quot;</em><em>, </em><em>&quot;nearest_neighbor&quot;}</em>) – Method to be used for resizing.</p></li>
<li><p><strong>extrapolation_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Value used for extrapolation, when applicable.</p></li>
<li><p><strong>out_dtype</strong> (<em>string</em><em>, </em><em>optional</em>) – Type to return. If left None will be same as input type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [num_boxes, channel, crop_height, crop_width]
or [num_boxes, crop_height, crop_width, channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.dilation2d_nchw">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">dilation2d_nchw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.dilation2d_nchw" title="Link to this definition"></a></dt>
<dd><p>Morphological dilation operator in NCHW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D with shape [ in_channel, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size</p></li>
<li><p><strong>dilations</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – Specifies the output data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, in_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.dilation2d_nhwc">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">dilation2d_nhwc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.dilation2d_nhwc" title="Link to this definition"></a></dt>
<dd><p>Morphological 2d dilation NHWC layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – 3-D with shape [filter_height, filter_width, in_channel]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Padding size</p></li>
<li><p><strong>dilations</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>a list/tuple</em><em> of </em><em>two ints</em>) – dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – Specifies the output data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, out_height, out_width, in_channel]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.get_1d_indices">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">get_1d_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCW'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.get_1d_indices" title="Link to this definition"></a></dt>
<dd><p>Get 1d indices</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.get_1d_pixel">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">get_1d_pixel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ib</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.get_1d_pixel" title="Link to this definition"></a></dt>
<dd><p>Get 1d pixel</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.get_2d_indices">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">get_2d_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCHW'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.get_2d_indices" title="Link to this definition"></a></dt>
<dd><p>Get 2d indices</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.get_2d_pixel">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">get_2d_pixel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_height</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ib</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.get_2d_pixel" title="Link to this definition"></a></dt>
<dd><p>Get 2d pixel</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.get_3d_indices">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">get_3d_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCDHW'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.get_3d_indices" title="Link to this definition"></a></dt>
<dd><p>Get 3d indices</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.get_3d_pixel">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">get_3d_pixel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_depth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_height</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cc</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.get_3d_pixel" title="Link to this definition"></a></dt>
<dd><p>Get 3d pixel</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.get_closest_index">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">get_closest_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rounding_method</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boxes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_int_div</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.get_closest_index" title="Link to this definition"></a></dt>
<dd><p>get the closest index to a value based on a certain rounding method</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.get_inx">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">get_inx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coordinate_transformation_mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_int_div</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.get_inx" title="Link to this definition"></a></dt>
<dd><p>Infer input x from output x with various coordinate transformation methods</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.get_pad_tuple">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">get_pad_tuple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.get_pad_tuple" title="Link to this definition"></a></dt>
<dd><p>Common code to get the pad option</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Padding size, or [‘VALID’, ‘SAME’]</p></li>
<li><p><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Conv kernel size</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pad_top</strong> (<em>int</em>) – Padding size on top</p></li>
<li><p><strong>pad_left</strong> (<em>int</em>) – Padding size on left</p></li>
<li><p><strong>pad_down</strong> (<em>int</em>) – Padding size on down.</p></li>
<li><p><strong>pad_right</strong> (<em>int</em>) – Padding size on right.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.grid_sample">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">grid_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'bilinear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCHW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'zeros'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.grid_sample" title="Link to this definition"></a></dt>
<dd><p>Applies grid sampling to input feature map.</p>
<p>Given <span class="math notranslate nohighlight">\(data\)</span> and <span class="math notranslate nohighlight">\(grid\)</span>, then for 4-D the output is computed by</p>
<div class="math notranslate nohighlight">
\[x_{src} = grid[batch, 0, y_{dst}, x_{dst}] \
y_{src} = grid[batch, 1, y_{dst}, x_{dst}] \
output[batch, channel, y_{dst}, x_{dst}] = G(data[batch, channel, y_{src}, x_{src}])\]</div>
<p><span class="math notranslate nohighlight">\(x_{dst}\)</span>, <span class="math notranslate nohighlight">\(y_{dst}\)</span> enumerate all spatial locations in <span class="math notranslate nohighlight">\(output\)</span>, and
<span class="math notranslate nohighlight">\(G()\)</span> denotes the interpolation function.</p>
<p>The out-boundary points will be padded with zeros if padding_mode is “zeros”, or
border pixel value if padding_mode is “border”, or
inner pixel value if padding_mode is “reflection”.</p>
<p>The left-top corner (-1, -1) and right-bottom corner (1, 1) in grid will be map to
(0, 0) and (h - 1, w - 1) of data if align_corners is “True”, or
(-0.5, -0.5) and (h - 0.5, w - 0.5) of data if align_corners is “False”.</p>
<p>The shape of the output will be
4-D (data.shape[0], data.shape[1], grid.shape[2], grid.shape[3]), or
5-D (data.shape[0], data.shape[1], grid.shape[2], grid.shape[3], grid.shape[4]).</p>
<p>The operator assumes that <span class="math notranslate nohighlight">\(grid\)</span> has been normalized to [-1, 1].</p>
<p>grid_sample often cooperates with affine_grid which generates sampling grids for grid_sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>tvm.Tensor</em>) – 4-D with shape [batch, in_channel, in_height, in_width], or
5-D with shape [batch, in_channel, in_depth, in_height, in_width]</p></li>
<li><p><strong>grid</strong> (<em>tvm.Tensor</em>) – 4-D with shape [batch, 2, out_height, out_width], or
5-D with shape [batch, 3, out_depth, out_height, out_width]</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The interpolation method, 4-D “nearest”, “bilinear”, “bicubic” and
5-D “nearest”, “bilinear”(“trilinear”) are supported.</p></li>
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The layout of input data and the output.</p></li>
<li><p><strong>padding_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The padding mode for outside grid values, “zeros”, “border”, “reflection” are supported.</p></li>
<li><p><strong>align_corners</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Geometrically, we consider the pixels of the input as squares rather than points.
If set to “True”, the extrema (“-1” and “1”) are considered as referring
to the center points of the input corner pixels. If set to “False”, they
are instead considered as referring to the corner points of the input corner
pixels, making the sampling more resolution agnostic.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – 4-D with shape [batch, in_channel, out_height, out_width], or
5-D with shape [batch, in_channel, out_depth, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tvm.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.nchw_pack_layout">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">nchw_pack_layout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layout_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.nchw_pack_layout" title="Link to this definition"></a></dt>
<dd><p>Check whether the layout type is NCHWinic</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.nchw_xc_layout">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">nchw_xc_layout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layout_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.nchw_xc_layout" title="Link to this definition"></a></dt>
<dd><p>Check whether the layout type is NCHWxc</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.pad">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_before</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_after</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PadInput'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attrs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.pad" title="Link to this definition"></a></dt>
<dd><p>Pad Input with zeros.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – n-D input, can be any layout.</p></li>
<li><p><strong>pad_before</strong> (<em>list / tuple</em><em> of </em><em>n ints</em>) – Pad width on each dimension to pad the before the axis begin.</p></li>
<li><p><strong>pad_after</strong> (<em>list / tuple</em><em> of </em><em>n ints</em><em>, </em><em>optional</em>) – Pad width each dimension to pad the after the axis end.</p></li>
<li><p><strong>pad_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – The value to be padded.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The name prefix operators generated</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Output</strong> – n-D, the same layout as Input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.resize1d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">resize1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">roi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coordinate_transformation_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'half_pixel'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rounding_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bicubic_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bicubic_exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extrapolation_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.resize1d" title="Link to this definition"></a></dt>
<dd><p>Perform resize operation on the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – inputs is a 3-D tensor with shape
[batch, channel in_width]
or  [batch in_width, channel]</p></li>
<li><p><strong>roi</strong> (<a class="reference internal" href="relax/relax.html#tvm.relax.Tuple" title="tvm.relax.Tuple"><em>Tuple</em></a><em> of </em><em>Float</em><em> or </em><em>Expr</em>) – The region of interest for cropping the input image. Expected to be of
size 2, and format [start_w, end_w].
Only used if coordinate_transformation_mode is tf_crop_and_resize.</p></li>
<li><p><strong>size</strong> (<a class="reference internal" href="relax/relax.html#tvm.relax.Tuple" title="tvm.relax.Tuple"><em>Tuple</em></a>) – Output resolution scale to</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) – “NCW”, “NWC”, or “NCWc”.</p></li>
<li><p><strong>coordinate_transformation_mode</strong> (<em>string</em><em>, </em><em>optional</em>) – Describes how to transform the coordinate in the resized tensor
to the coordinate in the original tensor.
Refer to the ONNX Resize operator specification for details.
Available options are “half_pixel”, “align_corners” and “asymmetric”.</p></li>
<li><p><strong>method</strong> (<em>string</em><em>, </em><em>optional</em>) – method of interpolation (“nearest”, “linear”, “bicubic”)</p></li>
<li><p><strong>coordinate_transformation_mode</strong> – Describes how to transform the coordinate in the resized tensor
to the coordinate in the original tensor.
[half_pixel, align_corners, asymmetric, pytorch_half_pixel,
tf_half_pixel_for_nn, and tf_crop_and_resize].</p></li>
<li><p><strong>rounding_method</strong> – Method for rounding coordinate locations</p></li>
<li><p><strong>bicubic_alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Bicubic spline coefficient</p></li>
<li><p><strong>bicubic_exclude</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional:</em>) – Exclude values outside the image fdor bicubic interpolation</p></li>
<li><p><strong>extrapolation_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Value used for extrapolation, when applicable.</p></li>
<li><p><strong>out_dtype</strong> (<em>string</em><em>, </em><em>optional</em>) – Type to return. If left None will be same as input type.</p></li>
<li><p><strong>output_shape</strong> (<em>tvm.tir.container.Array</em><em>, </em><em>optional</em>) – Shape to return. If left None will be inferred
(If shape is determined dynamically, pass out_dtype.shape as output_shape)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, chananel, in_width*scale]
or [batch, in_width*scale, channel]
or 5-D with shape [batch, channel-major, in_width*scale, channel-minor]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.resize2d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">resize2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">roi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCHW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coordinate_transformation_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'half_pixel'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rounding_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bicubic_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bicubic_exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extrapolation_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.resize2d" title="Link to this definition"></a></dt>
<dd><p>Perform resize operation on the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – inputs is a 4-D tensor with shape
[batch, channel, in_height, in_width]
or  [batch, in_height, in_width, channel]</p></li>
<li><p><strong>roi</strong> (<a class="reference internal" href="relax/relax.html#tvm.relax.Tuple" title="tvm.relax.Tuple"><em>Tuple</em></a><em> of </em><em>Float</em><em> or </em><em>Expr</em>) – The region of interest for cropping the input image. Expected to be of
size 4, and format [start_h, start_w, end_h, end_w].
Only used if coordinate_transformation_mode is tf_crop_and_resize.</p></li>
<li><p><strong>size</strong> (<a class="reference internal" href="relax/relax.html#tvm.relax.Tuple" title="tvm.relax.Tuple"><em>Tuple</em></a>) – Output resolution scale to</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) – “NCHW”, “NHWC”, or “NCHWc”.</p></li>
<li><p><strong>method</strong> (<em>string</em><em>, </em><em>optional</em>) – method of interpolation (“nearest”, “linear”, “bicubic”)</p></li>
<li><p><strong>coordinate_transformation_mode</strong> (<em>string</em><em>, </em><em>optional</em>) – Describes how to transform the coordinate in the resized tensor
to the coordinate in the original tensor.
[half_pixel, align_corners, asymmetric, pytorch_half_pixel,
tf_half_pixel_for_nn, and tf_crop_and_resize].</p></li>
<li><p><strong>rounding_method</strong> – Method for rounding coordinate locations</p></li>
<li><p><strong>bicubic_alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Bicubic spline coefficient</p></li>
<li><p><strong>bicubic_exclude</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional:</em>) – Exclude values outside the image fdor bicubic interpolation</p></li>
<li><p><strong>extrapolation_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Value used for extrapolation, when applicable.</p></li>
<li><p><strong>out_dtype</strong> (<em>string</em><em>, </em><em>optional</em>) – Type to return. If left None will be same as input type.</p></li>
<li><p><strong>output_shape</strong> (<em>tvm.tir.container.Array</em><em>, </em><em>optional</em>) – Shape to return. If left None will be inferred
(If shape is determined dynamically, pass out_dtype.shape as output_shape)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, channel, in_height*scale, in_width*scale]
or [batch, in_height*scale, in_width*scale, channel]
or 5-D with shape [batch, channel-major, in_height*scale, in_width*scale, channel-minor]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.resize3d">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">resize3d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">roi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCDHW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coordinate_transformation_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'half_pixel'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rounding_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bicubic_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bicubic_exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extrapolation_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.resize3d" title="Link to this definition"></a></dt>
<dd><p>Perform resize operation on the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) – inputs is a 5-D tensor with shape
[batch, channel, in_depth, in_height, in_width]
or  [batch, in_depth, in_height, in_width, channel]</p></li>
<li><p><strong>roi</strong> (<a class="reference internal" href="relax/relax.html#tvm.relax.Tuple" title="tvm.relax.Tuple"><em>Tuple</em></a><em> of </em><em>Float</em><em> or </em><em>Expr</em>) – The region of interest for cropping the input image. Expected to be of
size 6, and format [start_d, start_h, start_w, end_d, end_h, end_w].
Only used if coordinate_transformation_mode is tf_crop_and_resize.</p></li>
<li><p><strong>size</strong> (<a class="reference internal" href="relax/relax.html#tvm.relax.Tuple" title="tvm.relax.Tuple"><em>Tuple</em></a>) – Output resolution scale to</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) – “NCDHW”, “NDHWC”, or “NCDHWc”.</p></li>
<li><p><strong>method</strong> (<em>string</em><em>, </em><em>optional</em>) – method of interpolation (“nearest”, “linear”, “bicubic”)</p></li>
<li><p><strong>coordinate_transformation_mode</strong> (<em>string</em><em>, </em><em>optional</em>) – Describes how to transform the coordinate in the resized tensor
to the coordinate in the original tensor.
[half_pixel, align_corners, asymmetric, pytorch_half_pixel,
tf_half_pixel_for_nn, and tf_crop_and_resize].</p></li>
<li><p><strong>rounding_method</strong> – Method for rounding coordinate locations</p></li>
<li><p><strong>bicubic_alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Bicubic spline coefficient</p></li>
<li><p><strong>bicubic_exclude</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional:</em>) – Exclude values outside the image fdor bicubic interpolation</p></li>
<li><p><strong>extrapolation_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Value used for extrapolation, when applicable.</p></li>
<li><p><strong>out_dtype</strong> (<em>string</em><em>, </em><em>optional</em>) – Type to return. If left None will be same as input type.</p></li>
<li><p><strong>output_shape</strong> (<em>tvm.tir.container.Array</em><em>, </em><em>optional</em>) – Shape to return. If left None will be inferred
(If shape is determined dynamically, pass out_dtype.shape as output_shape)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>output</strong> – 4-D with shape [batch, channel, in_depth*scale, in_height*scale, in_width*scale]
or [batch, in_depth*scale, in_height*scale, in_width*scale, channel]
or 5-D with shape
[batch, channel-major, in_depth*scale, in_height*scale, in_width*scale, channel-minor]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tvm.topi.image.simplify">
<span class="sig-prename descclassname"><span class="pre">tvm.topi.image.</span></span><span class="sig-name descname"><span class="pre">simplify</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expr</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.simplify" title="Link to this definition"></a></dt>
<dd><p>Simplify the expression if it is Expr, directly return if it is int.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>expr</strong> (<em>Expr</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>out</strong> – The simplified output</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expr or <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a></p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="meta_schedule.html" class="btn btn-neutral float-right" title="tvm.meta_schedule" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="te.html" class="btn btn-neutral float-left" title="tvm.te" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2024 Apache Software Foundation | All rights reserved</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote">Copyright © 2024 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="../../../_static/downloads/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="../../../_static/downloads/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>