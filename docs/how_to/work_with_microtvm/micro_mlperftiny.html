





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>8. Creating Your MLPerfTiny Submission with microTVM &mdash; tvm 0.18.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tlcpack_theme.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="9. Bring microTVM to your own development environment" href="micro_custom_ide.html" />
    <link rel="prev" title="7. Running TVM on bare metal Arm(R) Cortex(R)-M55 CPU and Ethos(TM)-U55 NPU with CMSIS-NN" href="micro_ethosu.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://tvm.apache.org/docs/reference/security.html>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://tvm.apache.org/docs/reference/security.html>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <input type="checkbox" class="version-toggle-box" hidden id="version-toggle">
              <label for="version-toggle" class="version-toggle-label">
                  <div tabindex="0" class="version version-selector version-selector-show">
                    0.18.dev0 <span class="chevron versions-hidden"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m8 4 8 8-8 8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span><span class="chevron versions-shown"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m4 8 8 8 8-8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span>
                  </div>
                </label>
                <div class="version-details wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                  <p class="caption" role="heading"><span class="caption-text">Versions</span></p>
                  <ol style="text-align: left">
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="/">0.18.dev0 (main)</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.8.0/">v0.8.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.9.0/">v0.9.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.10.0/">v0.10.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.11.0/">v0.11.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.12.0/">v0.12.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.13.0/">v0.13.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.14.0/">v0.14.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.15.0/">v0.15.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.16.0/">v0.16.0</a></div></li>
                    
                  </ol>
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../get_started/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installing TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get_started/tutorials/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get_started/tutorials/ir_module.html">IRModule</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">How To</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/e2e_opt_model.html">End-to-End Optimize Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/customize_opt.html">Customize Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/optimize_llm.html">Optimize Large Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev/index.html">Development Guides</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Dive</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../arch/index.html">Design and Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deep_dive/tensor_ir/index.html">TensorIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deep_dive/relax/index.html">Relax</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/links.html">Other APIs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Legacy</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/index.html">User Tutorial</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../legacy_index.html">How To Guides</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../compile_models/index.html">Compile Deep Learning Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deploy/index.html">Deploy Models and Integrate TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_relay/index.html">Work With Relay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_schedules/index.html">Work With Tensor Expression and Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../optimize_operators/index.html">Optimize Tensor Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autotvm/index.html">Auto-Tune with Templates and AutoTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autoscheduler/index.html">Use AutoScheduler for Template-Free Scheduling</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Work With microTVM</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="micro_tvmc.html">1. microTVM CLI Tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_tflite.html">2. microTVM TFLite Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_aot.html">3. microTVM Ahead-of-Time (AOT) Compilation</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_pytorch.html">4. microTVM PyTorch Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_train.html">5. Training Vision Models for microTVM on Arduino</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_autotune.html">6. Model Tuning with microTVM</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_ethosu.html">7. Running TVM on bare metal Arm(R) Cortex(R)-M55 CPU and Ethos(TM)-U55 NPU with CMSIS-NN</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">8. Creating Your MLPerfTiny Submission with microTVM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#install-microtvm-python-dependencies">Install microTVM Python dependencies</a></li>
<li class="toctree-l4"><a class="reference internal" href="#install-zephyr">Install Zephyr</a></li>
<li class="toctree-l4"><a class="reference internal" href="#install-cmsis-nn">Install CMSIS-NN</a></li>
<li class="toctree-l4"><a class="reference internal" href="#import-python-dependencies">Import Python dependencies</a></li>
<li class="toctree-l4"><a class="reference internal" href="#import-visual-wake-word-model">Import Visual Wake Word Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#defining-target-runtime-and-executor">Defining Target, Runtime and Executor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#compile-the-model-and-export-model-library-format">Compile the model and export model library format</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generate-input-output-header-files">Generate input/output header files</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-the-project-build-and-prepare-the-project-tar-file">Create the project, build and prepare the project tar file</a></li>
<li class="toctree-l4"><a class="reference internal" href="#use-this-project-with-your-board">Use this project with your board</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="micro_custom_ide.html">9. Bring microTVM to your own development environment</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../extend_tvm/index.html">Extend TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../profile/index.html">Profile Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/tutorial/index.html">Developer Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to/how_to.html">Developer How-To Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../topic/microtvm/index.html">microTVM: TVM on bare-metal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../topic/vta/index.html">VTA: Versatile Tensor Accelerator</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contributor Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/security.html">Security Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Index</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="../legacy_index.html">How To Guides</a> <span class="br-arrow">></span></li>
        
          <li><a href="index.html">Work With microTVM</a> <span class="br-arrow">></span></li>
        
      <li>8. Creating Your MLPerfTiny Submission with microTVM</li>
    
    
      
      
        
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/tvm/edit/main/docs/how_to/work_with_microtvm/micro_mlperftiny.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial can be used interactively with Google Colab! You can also click
<a class="reference internal" href="#sphx-glr-download-how-to-work-with-microtvm-micro-mlperftiny-py"><span class="std std-ref">here</span></a> to run the Jupyter notebook locally.</p>
<a class="reference external image-reference" href="https://colab.research.google.com/github/apache/tvm-site/blob/asf-site/docs/_downloads/1fc1683d67bee4f26703504a58d42578/micro_mlperftiny.ipynb"><img alt="https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg" class="align-center" src="https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg" width="300px" /></a>
</div>
<div class="sphx-glr-example-title section" id="creating-your-mlperftiny-submission-with-microtvm">
<span id="tutorial-micro-mlperftiny"></span><span id="sphx-glr-how-to-work-with-microtvm-micro-mlperftiny-py"></span><h1>8. Creating Your MLPerfTiny Submission with microTVM<a class="headerlink" href="#creating-your-mlperftiny-submission-with-microtvm" title="Permalink to this headline">¶</a></h1>
<p><strong>Authors</strong>:
<a class="reference external" href="https://github.com/mehrdadh">Mehrdad Hessar</a></p>
<p>This tutorial is showcasing building an MLPerfTiny submission using microTVM. This
tutorial shows the steps to import a TFLite model from MLPerfTiny benchmark models,
compile it with TVM and generate a Zephyr project which can be flashed to a Zephyr
supported board to benchmark the model using EEMBC runner.</p>
<div class="section" id="install-microtvm-python-dependencies">
<h2>Install microTVM Python dependencies<a class="headerlink" href="#install-microtvm-python-dependencies" title="Permalink to this headline">¶</a></h2>
<p>TVM does not include a package for Python serial communication, so
we must install one before using microTVM. We will also need TFLite
to load models.</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%%shell
pip<span class="w"> </span>install<span class="w"> </span><span class="nv">pyserial</span><span class="o">==</span><span class="m">3</span>.5<span class="w"> </span><span class="nv">tflite</span><span class="o">==</span><span class="m">2</span>.1
</pre></div>
</div>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">tarfile</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">shutil</span>
</pre></div>
</div>
</div>
<div class="section" id="install-zephyr">
<h2>Install Zephyr<a class="headerlink" href="#install-zephyr" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%%shell
<span class="c1"># Install west and ninja</span>
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>west
apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>ninja-build

<span class="c1"># Install ZephyrProject</span>
<span class="nv">ZEPHYR_PROJECT_PATH</span><span class="o">=</span><span class="s2">&quot;/content/zephyrproject&quot;</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">ZEPHYR_BASE</span><span class="o">=</span><span class="si">${</span><span class="nv">ZEPHYR_PROJECT_PATH</span><span class="si">}</span>/zephyr
west<span class="w"> </span>init<span class="w"> </span><span class="si">${</span><span class="nv">ZEPHYR_PROJECT_PATH</span><span class="si">}</span>
<span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">ZEPHYR_BASE</span><span class="si">}</span>
git<span class="w"> </span>checkout<span class="w"> </span>v3.2-branch
<span class="nb">cd</span><span class="w"> </span>..
west<span class="w"> </span>update
west<span class="w"> </span>zephyr-export
chmod<span class="w"> </span>-R<span class="w"> </span>o+w<span class="w"> </span><span class="si">${</span><span class="nv">ZEPHYR_PROJECT_PATH</span><span class="si">}</span>

<span class="c1"># Install Zephyr SDK</span>
<span class="nb">cd</span><span class="w"> </span>/content
<span class="nv">ZEPHYR_SDK_VERSION</span><span class="o">=</span><span class="s2">&quot;0.15.2&quot;</span>
wget<span class="w"> </span><span class="s2">&quot;https://github.com/zephyrproject-rtos/sdk-ng/releases/download/v</span><span class="si">${</span><span class="nv">ZEPHYR_SDK_VERSION</span><span class="si">}</span><span class="s2">/zephyr-sdk-</span><span class="si">${</span><span class="nv">ZEPHYR_SDK_VERSION</span><span class="si">}</span><span class="s2">_linux-x86_64.tar.gz&quot;</span>
tar<span class="w"> </span>xvf<span class="w"> </span><span class="s2">&quot;zephyr-sdk-</span><span class="si">${</span><span class="nv">ZEPHYR_SDK_VERSION</span><span class="si">}</span><span class="s2">_linux-x86_64.tar.gz&quot;</span>
mv<span class="w"> </span><span class="s2">&quot;zephyr-sdk-</span><span class="si">${</span><span class="nv">ZEPHYR_SDK_VERSION</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span>zephyr-sdk
rm<span class="w"> </span><span class="s2">&quot;zephyr-sdk-</span><span class="si">${</span><span class="nv">ZEPHYR_SDK_VERSION</span><span class="si">}</span><span class="s2">_linux-x86_64.tar.gz&quot;</span>

<span class="c1"># Install python dependencies</span>
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">ZEPHYR_BASE</span><span class="si">}</span><span class="s2">/scripts/requirements.txt&quot;</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Note:</strong> Install CMSIS-NN only if you are interested to generate this submission
using CMSIS-NN code generator.</p>
</div>
<div class="section" id="install-cmsis-nn">
<h2>Install CMSIS-NN<a class="headerlink" href="#install-cmsis-nn" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%%shell
<span class="nv">CMSIS_SHA</span><span class="o">=</span><span class="s2">&quot;51263182d16c92649a48144ba56c0945f9fce60e&quot;</span>
<span class="nv">CMSIS_URL</span><span class="o">=</span><span class="s2">&quot;http://github.com/ARM-software/CMSIS_5/archive/</span><span class="si">${</span><span class="nv">CMSIS_SHA</span><span class="si">}</span><span class="s2">.tar.gz&quot;</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">CMSIS_PATH</span><span class="o">=</span>/content/cmsis
<span class="nv">DOWNLOAD_PATH</span><span class="o">=</span><span class="s2">&quot;/content/</span><span class="si">${</span><span class="nv">CMSIS_SHA</span><span class="si">}</span><span class="s2">.tar.gz&quot;</span>
mkdir<span class="w"> </span><span class="si">${</span><span class="nv">CMSIS_PATH</span><span class="si">}</span>
wget<span class="w"> </span><span class="si">${</span><span class="nv">CMSIS_URL</span><span class="si">}</span><span class="w"> </span>-O<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">DOWNLOAD_PATH</span><span class="si">}</span><span class="s2">&quot;</span>
tar<span class="w"> </span>-xf<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">DOWNLOAD_PATH</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span>-C<span class="w"> </span><span class="si">${</span><span class="nv">CMSIS_PATH</span><span class="si">}</span><span class="w"> </span>--strip-components<span class="o">=</span><span class="m">1</span>
rm<span class="w"> </span><span class="si">${</span><span class="nv">DOWNLOAD_PATH</span><span class="si">}</span>

<span class="nv">CMSIS_NN_TAG</span><span class="o">=</span><span class="s2">&quot;v4.0.0&quot;</span>
<span class="nv">CMSIS_NN_URL</span><span class="o">=</span><span class="s2">&quot;https://github.com/ARM-software/CMSIS-NN.git&quot;</span>
git<span class="w"> </span>clone<span class="w"> </span><span class="si">${</span><span class="nv">CMSIS_NN_URL</span><span class="si">}</span><span class="w"> </span>--branch<span class="w"> </span><span class="si">${</span><span class="nv">CMSIS_NN_TAG</span><span class="si">}</span><span class="w"> </span>--single-branch<span class="w"> </span><span class="si">${</span><span class="nv">CMSIS_PATH</span><span class="si">}</span>/CMSIS-NN
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="import-python-dependencies">
<h2>Import Python dependencies<a class="headerlink" href="#import-python-dependencies" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">relay</span>
<span class="kn">from</span> <span class="nn">tvm.relay.backend</span> <span class="kn">import</span> <span class="n">Executor</span><span class="p">,</span> <span class="n">Runtime</span>
<span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="kn">import</span> <span class="n">download_testdata</span>
<span class="kn">from</span> <span class="nn">tvm.micro</span> <span class="kn">import</span> <a href="../../reference/api/python/micro.html#tvm.micro.export_model_library_format" title="tvm.micro.export_model_library_format" class="sphx-glr-backref-module-tvm-micro sphx-glr-backref-type-py-function"><span class="n">export_model_library_format</span></a>
<span class="kn">import</span> <span class="nn">tvm.micro.testing</span>
<span class="kn">from</span> <span class="nn">tvm.micro.testing.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">create_header_file</span><span class="p">,</span>
    <span class="n">mlf_extract_workspace_size_bytes</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="import-visual-wake-word-model">
<h2>Import Visual Wake Word Model<a class="headerlink" href="#import-visual-wake-word-model" title="Permalink to this headline">¶</a></h2>
<p>To begin with, download and import the Visual Wake Word (VWW) TFLite model from MLPerfTiny.
This model is originally from <a class="reference external" href="https://github.com/mlcommons/tiny">MLPerf Tiny repository</a>.
We also capture metadata information from the TFLite model such as input/output name,
quantization parameters, etc. which will be used in following steps.</p>
<p>We use indexing for various models to build the submission. The indices are defined as follows:
To build another model, you need to update the model URL, the short name and index number.</p>
<blockquote>
<div><ul class="simple">
<li><p>Keyword Spotting(KWS) 1</p></li>
<li><p>Visual Wake Word(VWW) 2</p></li>
<li><p>Anomaly Detection(AD) 3</p></li>
<li><p>Image Classification(IC) 4</p></li>
</ul>
</div></blockquote>
<p>If you would like to build the submission with CMSIS-NN, modify USE_CMSIS environment variable.</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">USE_CMSIS</span><span class="o">=</span><span class="m">1</span>
</pre></div>
</div>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">MODEL_URL</span> <span class="o">=</span> <span class="s2">&quot;https://github.com/mlcommons/tiny/raw/bceb91c5ad2e2deb295547d81505721d3a87d578/benchmark/training/visual_wake_words/trained_models/vww_96_int8.tflite&quot;</span>
<span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">MODEL_URL</span><span class="p">,</span> <span class="s2">&quot;vww_96_int8.tflite&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">)</span>

<span class="n">MODEL_SHORT_NAME</span> <span class="o">=</span> <span class="s2">&quot;VWW&quot;</span>
<span class="n">MODEL_INDEX</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">USE_CMSIS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;TVM_USE_CMSIS&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

<span class="n">tflite_model_buf</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">MODEL_PATH</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">tflite</span>

    <span class="n">tflite_model</span> <span class="o">=</span> <span class="n">tflite</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">GetRootAsModel</span><span class="p">(</span><span class="n">tflite_model_buf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">tflite.Model</span>

    <span class="n">tflite_model</span> <span class="o">=</span> <span class="n">tflite</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">GetRootAsModel</span><span class="p">(</span><span class="n">tflite_model_buf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">interpreter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">Interpreter</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">MODEL_PATH</span><span class="p">))</span>
<span class="n">interpreter</span><span class="o">.</span><span class="n">allocate_tensors</span><span class="p">()</span>
<span class="n">input_details</span> <span class="o">=</span> <span class="n">interpreter</span><span class="o">.</span><span class="n">get_input_details</span><span class="p">()</span>
<span class="n">output_details</span> <span class="o">=</span> <span class="n">interpreter</span><span class="o">.</span><span class="n">get_output_details</span><span class="p">()</span>

<span class="n">input_name</span> <span class="o">=</span> <span class="n">input_details</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;name&quot;</span><span class="p">]</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">input_details</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;shape&quot;</span><span class="p">])</span>
<span class="n">input_dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">input_details</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;dtype&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">name</span>
<span class="n">output_name</span> <span class="o">=</span> <span class="n">output_details</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;name&quot;</span><span class="p">]</span>
<span class="n">output_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output_details</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;shape&quot;</span><span class="p">])</span>
<span class="n">output_dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">output_details</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;dtype&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">name</span>

<span class="c1"># We extract quantization information from TFLite model.</span>
<span class="c1"># This is required for all models except Anomaly Detection,</span>
<span class="c1"># because for other models we send quantized data to interpreter</span>
<span class="c1"># from host, however, for AD model we send floating data and quantization</span>
<span class="c1"># happens on the microcontroller.</span>
<span class="k">if</span> <span class="n">MODEL_SHORT_NAME</span> <span class="o">!=</span> <span class="s2">&quot;AD&quot;</span><span class="p">:</span>
    <span class="n">quant_output_scale</span> <span class="o">=</span> <span class="n">output_details</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;quantization_parameters&quot;</span><span class="p">][</span><span class="s2">&quot;scales&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">quant_output_zero_point</span> <span class="o">=</span> <span class="n">output_details</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;quantization_parameters&quot;</span><span class="p">][</span><span class="s2">&quot;zero_points&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">relay_mod</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <a href="../../reference/api/python/relay/frontend.html#tvm.relay.frontend.from_tflite" title="tvm.relay.frontend.from_tflite" class="sphx-glr-backref-module-tvm-relay-frontend sphx-glr-backref-type-py-function"><span class="n">relay</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">from_tflite</span></a><span class="p">(</span>
    <span class="n">tflite_model</span><span class="p">,</span> <span class="n">shape_dict</span><span class="o">=</span><span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">input_shape</span><span class="p">},</span> <span class="n">dtype_dict</span><span class="o">=</span><span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">input_dtype</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="defining-target-runtime-and-executor">
<h2>Defining Target, Runtime and Executor<a class="headerlink" href="#defining-target-runtime-and-executor" title="Permalink to this headline">¶</a></h2>
<p>Now we need to define the target, runtime and executor to compile this model. In this tutorial,
we use Ahead-of-Time (AoT) compilation and we build a standalone project. This is different
than using AoT with host-driven mode where the target would communicate with host using host-driven
AoT executor to run inference.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use the C runtime (crt)</span>
<span class="n">RUNTIME</span> <span class="o">=</span> <span class="n">Runtime</span><span class="p">(</span><span class="s2">&quot;crt&quot;</span><span class="p">)</span>

<span class="c1"># Use the AoT executor with `unpacked-api=True` and `interface-api=c`. `interface-api=c` forces</span>
<span class="c1"># the compiler to generate C type function APIs and `unpacked-api=True` forces the compiler</span>
<span class="c1"># to generate minimal unpacked format inputs which reduces the stack memory usage on calling</span>
<span class="c1"># inference layers of the model.</span>
<span class="n">EXECUTOR</span> <span class="o">=</span> <span class="n">Executor</span><span class="p">(</span>
    <span class="s2">&quot;aot&quot;</span><span class="p">,</span>
    <span class="p">{</span><span class="s2">&quot;unpacked-api&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;interface-api&quot;</span><span class="p">:</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;workspace-byte-alignment&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">},</span>
<span class="p">)</span>

<span class="c1"># Select a Zephyr board</span>
<span class="n">BOARD</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.html#os.getenv" title="os.getenv" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">getenv</span></a><span class="p">(</span><span class="s2">&quot;TVM_MICRO_BOARD&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;nucleo_l4r5zi&quot;</span><span class="p">)</span>

<span class="c1"># Get the full target description using the BOARD</span>
<span class="n">TARGET</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">micro</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">get_target</span><span class="p">(</span><span class="s2">&quot;zephyr&quot;</span><span class="p">,</span> <span class="n">BOARD</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="compile-the-model-and-export-model-library-format">
<h2>Compile the model and export model library format<a class="headerlink" href="#compile-the-model-and-export-model-library-format" title="Permalink to this headline">¶</a></h2>
<p>Now, we compile the model for the target. Then, we generate model
library format for the compiled model. We also need to calculate the
workspace size that is required for the compiled model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;tir.disable_vectorize&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>
<span class="k">if</span> <span class="n">USE_CMSIS</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tvm.relay.op.contrib</span> <span class="kn">import</span> <span class="n">cmsisnn</span>

    <span class="n">config</span><span class="p">[</span><span class="s2">&quot;relay.ext.cmsisnn.options&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mcpu&quot;</span><span class="p">:</span> <span class="n">TARGET</span><span class="o">.</span><span class="n">mcpu</span><span class="p">}</span>
    <span class="n">relay_mod</span> <span class="o">=</span> <span class="n">cmsisnn</span><span class="o">.</span><span class="n">partition_for_cmsisnn</span><span class="p">(</span><span class="n">relay_mod</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">mcpu</span><span class="o">=</span><span class="n">TARGET</span><span class="o">.</span><span class="n">mcpu</span><span class="p">)</span>

<span class="k">with</span> <a href="../../reference/api/python/transform.html#tvm.transform.PassContext" title="tvm.transform.PassContext" class="sphx-glr-backref-module-tvm-transform sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span></a><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">):</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">relay</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
        <span class="n">relay_mod</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">TARGET</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">runtime</span><span class="o">=</span><span class="n">RUNTIME</span><span class="p">,</span> <span class="n">executor</span><span class="o">=</span><span class="n">EXECUTOR</span>
    <span class="p">)</span>

<span class="n">temp_dir</span> <span class="o">=</span> <a href="../../reference/api/python/contrib.html#tvm.contrib.utils.tempdir" title="tvm.contrib.utils.tempdir" class="sphx-glr-backref-module-tvm-contrib-utils sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">tempdir</span></a><span class="p">()</span>
<span class="n">model_tar_path</span> <span class="o">=</span> <span class="n">temp_dir</span> <span class="o">/</span> <span class="s2">&quot;model.tar&quot;</span>
<a href="../../reference/api/python/micro.html#tvm.micro.export_model_library_format" title="tvm.micro.export_model_library_format" class="sphx-glr-backref-module-tvm-micro sphx-glr-backref-type-py-function"><span class="n">export_model_library_format</span></a><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">model_tar_path</span><span class="p">)</span>
<span class="n">workspace_size</span> <span class="o">=</span> <span class="n">mlf_extract_workspace_size_bytes</span><span class="p">(</span><span class="n">model_tar_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="generate-input-output-header-files">
<h2>Generate input/output header files<a class="headerlink" href="#generate-input-output-header-files" title="Permalink to this headline">¶</a></h2>
<p>To create a microTVM standalone project with AoT, we need to generate
input and output header files. These header files are used to connect
the input and output API from generated code to the rest of the
standalone project. For this specific submission, we only need to generate
output header file since the input API call is handled differently.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">extra_tar_dir</span> <span class="o">=</span> <a href="../../reference/api/python/contrib.html#tvm.contrib.utils.tempdir" title="tvm.contrib.utils.tempdir" class="sphx-glr-backref-module-tvm-contrib-utils sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">tempdir</span></a><span class="p">()</span>
<span class="n">extra_tar_file</span> <span class="o">=</span> <span class="n">extra_tar_dir</span> <span class="o">/</span> <span class="s2">&quot;extra.tar&quot;</span>

<span class="k">with</span> <a href="https://docs.python.org/3/library/tarfile.html#tarfile.open" title="tarfile.open" class="sphx-glr-backref-module-tarfile sphx-glr-backref-type-py-function"><span class="n">tarfile</span><span class="o">.</span><span class="n">open</span></a><span class="p">(</span><span class="n">extra_tar_file</span><span class="p">,</span> <span class="s2">&quot;w:gz&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tf</span><span class="p">:</span>
    <span class="n">create_header_file</span><span class="p">(</span>
        <span class="s2">&quot;output_data&quot;</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">output_shape</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">output_dtype</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="s2">&quot;include/tvm&quot;</span><span class="p">,</span>
        <span class="n">tf</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="create-the-project-build-and-prepare-the-project-tar-file">
<h2>Create the project, build and prepare the project tar file<a class="headerlink" href="#create-the-project-build-and-prepare-the-project-tar-file" title="Permalink to this headline">¶</a></h2>
<p>Now that we have the compiled model as a model library format,
we can generate the full project using Zephyr template project. First,
we prepare the project options, then build the project. Finally, we
cleanup the temporary files and move the submission project to the
current working directory which could be downloaded and used on
your development kit.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">input_total_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)):</span>
    <span class="n">input_total_size</span> <span class="o">*=</span> <span class="n">input_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="n">template_project_path</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span></a><span class="p">(</span><a href="../../reference/api/python/micro.html#tvm.micro.get_microtvm_template_projects" title="tvm.micro.get_microtvm_template_projects" class="sphx-glr-backref-module-tvm-micro sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">micro</span><span class="o">.</span><span class="n">get_microtvm_template_projects</span></a><span class="p">(</span><span class="s2">&quot;zephyr&quot;</span><span class="p">))</span>
<span class="n">project_options</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;extra_files_tar&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">extra_tar_file</span><span class="p">),</span>
    <span class="s2">&quot;project_type&quot;</span><span class="p">:</span> <span class="s2">&quot;mlperftiny&quot;</span><span class="p">,</span>
    <span class="s2">&quot;board&quot;</span><span class="p">:</span> <span class="n">BOARD</span><span class="p">,</span>
    <span class="s2">&quot;compile_definitions&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="sa">f</span><span class="s2">&quot;-DWORKSPACE_SIZE=</span><span class="si">{</span><span class="n">workspace_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">512</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>  <span class="c1"># Memory workspace size, 512 is a temporary offset</span>
        <span class="c1"># since the memory calculation is not accurate.</span>
        <span class="sa">f</span><span class="s2">&quot;-DTARGET_MODEL=</span><span class="si">{</span><span class="n">MODEL_INDEX</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>  <span class="c1"># Sets the model index for project compilation.</span>
        <span class="sa">f</span><span class="s2">&quot;-DTH_MODEL_VERSION=EE_MODEL_VERSION_</span><span class="si">{</span><span class="n">MODEL_SHORT_NAME</span><span class="si">}</span><span class="s2">01&quot;</span><span class="p">,</span>  <span class="c1"># Sets model version. This is required by MLPerfTiny API.</span>
        <span class="sa">f</span><span class="s2">&quot;-DMAX_DB_INPUT_SIZE=</span><span class="si">{</span><span class="n">input_total_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>  <span class="c1"># Max size of the input data array.</span>
    <span class="p">],</span>
<span class="p">}</span>

<span class="k">if</span> <span class="n">MODEL_SHORT_NAME</span> <span class="o">!=</span> <span class="s2">&quot;AD&quot;</span><span class="p">:</span>
    <span class="n">project_options</span><span class="p">[</span><span class="s2">&quot;compile_definitions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;-DOUT_QUANT_SCALE=</span><span class="si">{</span><span class="n">quant_output_scale</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">project_options</span><span class="p">[</span><span class="s2">&quot;compile_definitions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;-DOUT_QUANT_ZERO=</span><span class="si">{</span><span class="n">quant_output_zero_point</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">USE_CMSIS</span><span class="p">:</span>
    <span class="n">project_options</span><span class="p">[</span><span class="s2">&quot;compile_definitions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;-DCOMPILE_WITH_CMSISNN=1&quot;</span><span class="p">)</span>

<span class="c1"># Note: You might need to adjust this based on the board that you are using.</span>
<span class="n">project_options</span><span class="p">[</span><span class="s2">&quot;config_main_stack_size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4000</span>

<span class="k">if</span> <span class="n">USE_CMSIS</span><span class="p">:</span>
    <span class="n">project_options</span><span class="p">[</span><span class="s2">&quot;cmsis_path&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;CMSIS_PATH&quot;</span><span class="p">,</span> <span class="s2">&quot;/content/cmsis&quot;</span><span class="p">)</span>

<span class="n">generated_project_dir</span> <span class="o">=</span> <span class="n">temp_dir</span> <span class="o">/</span> <span class="s2">&quot;project&quot;</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">micro</span><span class="o">.</span><span class="n">project</span><span class="o">.</span><span class="n">generate_project_from_mlf</span><span class="p">(</span>
    <span class="n">template_project_path</span><span class="p">,</span> <span class="n">generated_project_dir</span><span class="p">,</span> <span class="n">model_tar_path</span><span class="p">,</span> <span class="n">project_options</span>
<span class="p">)</span>
<span class="n">project</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>

<span class="c1"># Cleanup the build directory and extra artifacts</span>
<a href="https://docs.python.org/3/library/shutil.html#shutil.rmtree" title="shutil.rmtree" class="sphx-glr-backref-module-shutil sphx-glr-backref-type-py-function"><span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span></a><span class="p">(</span><span class="n">generated_project_dir</span> <span class="o">/</span> <span class="s2">&quot;build&quot;</span><span class="p">)</span>
<span class="p">(</span><span class="n">generated_project_dir</span> <span class="o">/</span> <span class="s2">&quot;model.tar&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">unlink</span><span class="p">()</span>

<span class="n">project_tar_path</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/os.html#os.getcwd" title="os.getcwd" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span></a><span class="p">())</span> <span class="o">/</span> <span class="s2">&quot;project.tar&quot;</span>
<span class="k">with</span> <a href="https://docs.python.org/3/library/tarfile.html#tarfile.open" title="tarfile.open" class="sphx-glr-backref-module-tarfile sphx-glr-backref-type-py-function"><span class="n">tarfile</span><span class="o">.</span><span class="n">open</span></a><span class="p">(</span><span class="n">project_tar_path</span><span class="p">,</span> <span class="s2">&quot;w:tar&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
    <span class="n">tar</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">generated_project_dir</span><span class="p">,</span> <span class="n">arcname</span><span class="o">=</span><a href="https://docs.python.org/3/library/os.path.html#os.path.basename" title="os.path.basename" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span></a><span class="p">(</span><span class="s2">&quot;project&quot;</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The generated project is located here: </span><span class="si">{</span><span class="n">project_tar_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="use-this-project-with-your-board">
<h2>Use this project with your board<a class="headerlink" href="#use-this-project-with-your-board" title="Permalink to this headline">¶</a></h2>
<p>Now that we have the generated project, you can use this project locally
to flash your board and prepare it for EEMBC runner software.
To do this follow these steps:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tar<span class="w"> </span>-xf<span class="w"> </span>project.tar
<span class="nb">cd</span><span class="w"> </span>project
mkdir<span class="w"> </span>build
cmake<span class="w"> </span>..
make<span class="w"> </span>-j2
west<span class="w"> </span>flash
</pre></div>
</div>
</div></blockquote>
<p>Now you can connect your board to EEMBC runner using this
<a class="reference external" href="https://github.com/eembc/energyrunner">instructions</a>
and benchmark this model on your board.</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-how-to-work-with-microtvm-micro-mlperftiny-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/4577847d31fa9ec38d0a6dda3e1d178d/micro_mlperftiny.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">micro_mlperftiny.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/1fc1683d67bee4f26703504a58d42578/micro_mlperftiny.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">micro_mlperftiny.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="micro_custom_ide.html" class="btn btn-neutral float-right" title="9. Bring microTVM to your own development environment" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="micro_ethosu.html" class="btn btn-neutral float-left" title="7. Running TVM on bare metal Arm(R) Cortex(R)-M55 CPU and Ethos(TM)-U55 NPU with CMSIS-NN" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2024 Apache Software Foundation | All rights reserved</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote">Copyright © 2024 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>