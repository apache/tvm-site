





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>9. Bring microTVM to your own development environment &mdash; tvm 0.12.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tlcpack_theme.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Extend TVM" href="../extend_tvm/index.html" />
    <link rel="prev" title="8. Creating Your MLPerfTiny Submission with microTVM" href="micro_mlperftiny.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/vta>VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <input type="checkbox" class="version-toggle-box" hidden id="version-toggle">
              <label for="version-toggle" class="version-toggle-label">
                  <div tabindex="0" class="version version-selector version-selector-show">
                    0.12.dev0 <span class="chevron versions-hidden"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m8 4 8 8-8 8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span><span class="chevron versions-shown"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m4 8 8 8 8-8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span>
                  </div>
                </label>
                <div class="version-details wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                  <p class="caption" role="heading"><span class="caption-text">Versions</span></p>
                  <ol style="text-align: left">
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="/">0.12.dev0 (main)</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.8.0/">v0.8.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.9.0/">v0.9.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.10.0/">v0.10.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.11.0/">v0.11.0</a></div></li>
                    
                  </ol>
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installing TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contributor Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/index.html">User Tutorial</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">How To Guides</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../compile_models/index.html">Compile Deep Learning Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deploy/index.html">Deploy Models and Integrate TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_relay/index.html">Work With Relay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_schedules/index.html">Work With Tensor Expression and Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../optimize_operators/index.html">Optimize Tensor Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autotvm/index.html">Auto-Tune with Templates and AutoTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autoscheduler/index.html">Use AutoScheduler for Template-Free Scheduling</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Work With microTVM</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="micro_tvmc.html">1. microTVM CLI Tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_tflite.html">2. microTVM TFLite Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_aot.html">3. microTVM Ahead-of-Time (AOT) Compilation</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_pytorch.html">4. microTVM PyTorch Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_train.html">5. Training Vision Models for microTVM on Arduino</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_autotune.html">6. Model Tuning with microTVM</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_ethosu.html">7. Running TVM on bare metal Arm(R) Cortex(R)-M55 CPU and Ethos(TM)-U55 NPU with CMSIS-NN</a></li>
<li class="toctree-l3"><a class="reference internal" href="micro_mlperftiny.html">8. Creating Your MLPerfTiny Submission with microTVM</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">9. Bring microTVM to your own development environment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#install-microtvm-python-dependencies">Install microTVM Python dependencies</a></li>
<li class="toctree-l4"><a class="reference internal" href="#import-python-dependencies">Import Python dependencies</a></li>
<li class="toctree-l4"><a class="reference internal" href="#import-the-tflite-model">Import the TFLite model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generate-the-model-library-format-file">Generate the Model Library Format file</a></li>
<li class="toctree-l4"><a class="reference internal" href="#add-sample-images-to-the-mlf-files">Add sample images to the MLF files</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generate-the-project-in-your-ide">Generate the project in your IDE</a></li>
<li class="toctree-l4"><a class="reference internal" href="#import-the-model-to-the-generated-project">Import the model to the generated project</a></li>
<li class="toctree-l4"><a class="reference internal" href="#evaluate-the-model">Evaluate the model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../extend_tvm/index.html">Extend TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../profile/index.html">Profile Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../errors.html">Handle TVM Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/tutorial/index.html">Developer Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to/how_to.html">Developer How-To Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Architecture  Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../arch/index.html">Design and Architecture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Topic Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../topic/microtvm/index.html">microTVM: TVM on bare-metal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../topic/vta/index.html">VTA: Versatile Tensor Accelerator</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/links.html">Other APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="../index.html">How To Guides</a> <span class="br-arrow">></span></li>
        
          <li><a href="index.html">Work With microTVM</a> <span class="br-arrow">></span></li>
        
      <li>9. Bring microTVM to your own development environment</li>
    
    
      
      
        
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/tvm/edit/main/docs/how_to/work_with_microtvm/micro_custom_ide.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial can be used interactively with Google Colab! You can also click
<a class="reference internal" href="#sphx-glr-download-how-to-work-with-microtvm-micro-custom-ide-py"><span class="std std-ref">here</span></a> to run the Jupyter notebook locally.</p>
<a class="reference external image-reference" href="https://colab.research.google.com/github/apache/tvm-site/blob/asf-site/docs/_downloads/a74627f44186b95116fe0ed6f77e3b99/micro_custom_ide.ipynb"><img alt="https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg" class="align-center" src="https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg" width="300px" /></a>
</div>
<div class="sphx-glr-example-title section" id="bring-microtvm-to-your-own-development-environment">
<span id="tutorial-micro-ide"></span><span id="sphx-glr-how-to-work-with-microtvm-micro-custom-ide-py"></span><h1>9. Bring microTVM to your own development environment<a class="headerlink" href="#bring-microtvm-to-your-own-development-environment" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>:
<a class="reference external" href="https://github.com/mkatanbaf">Mohamad Katanbaf</a></p>
<p>This tutorial describes the steps required to integrate a model compiled with microTVM into a custom development environment.
We use <a class="reference external" href="https://www.st.com/en/development-tools/stm32cubeide.html">STM32CubeIDE</a>, as the target IDE in this tutorial, but we do not rely on any specific feature of this IDE and integrating microTVM in other IDEs would be similar.
We also use the Visual Wake Word (VWW) model from MLPerf Tiny and the nucleo_l4r5zi board here, but the same steps can be used for any other model or target MCU.
If you want to use another target MCU with the vww model, we recommend a cortex-M4 or cortex-M7 device with ~512 KB and ~256 KB of Flash and RAM respectively.</p>
<p>Here is a brief overview of the steps that we would take in this tutorial.</p>
<ol class="arabic simple">
<li><p>We start by importing the model, compiling it using TVM and generating the <a class="reference external" href="https://tvm.apache.org/docs/arch/model_library_format.html">Model Library Format</a> (MLF) tar-file that includes the generated code for the model as well as all the required TVM dependencies.</p></li>
<li><p>We also add two sample images in binary format (one person and one not-person sample) to the .tar file for evaluating the model.</p></li>
<li><p>Next we use the stmCubeMX to generate the initialization code for the project in stmCube IDE.</p></li>
<li><p>After that, we include our MLF file and the required CMSIS libraries in the project and build it.</p></li>
<li><p>Finally, we flash the device and evaluate the model performance on our sample images.</p></li>
</ol>
<p>Let’s Begin.</p>
<div class="section" id="install-microtvm-python-dependencies">
<h2>Install microTVM Python dependencies<a class="headerlink" href="#install-microtvm-python-dependencies" title="Permalink to this headline">¶</a></h2>
<p>TVM does not include a package for Python serial communication, so
we must install one before using microTVM. We will also need TFLite
to load models, and Pillow to prepare the sample images.</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="nv">pyserial</span><span class="o">==</span><span class="m">3</span>.5<span class="w"> </span><span class="nv">tflite</span><span class="o">==</span><span class="m">2</span>.1<span class="w"> </span><span class="nv">Pillow</span><span class="o">==</span><span class="m">9</span>.0<span class="w"> </span>typing_extensions
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="import-python-dependencies">
<h2>Import Python dependencies<a class="headerlink" href="#import-python-dependencies" title="Permalink to this headline">¶</a></h2>
<p>If you want to run this script locally, check out <a class="reference external" href="https://tvm.apache.org/docs/install/index.html">TVM Online Documentation</a> for instructions to install TVM.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">tarfile</span>

<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">relay</span>
<span class="kn">from</span> <span class="nn">tvm.relay.backend</span> <span class="kn">import</span> <span class="n">Executor</span><span class="p">,</span> <span class="n">Runtime</span>
<span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="kn">import</span> <span class="n">download_testdata</span>
<span class="kn">from</span> <span class="nn">tvm.micro</span> <span class="kn">import</span> <a href="../../reference/api/python/micro.html#tvm.micro.export_model_library_format" title="tvm.micro.export_model_library_format" class="sphx-glr-backref-module-tvm-micro sphx-glr-backref-type-py-function"><span class="n">export_model_library_format</span></a>
<span class="kn">from</span> <span class="nn">tvm.relay.op.contrib</span> <span class="kn">import</span> <span class="n">cmsisnn</span>
<span class="kn">from</span> <span class="nn">tvm.micro.testing.utils</span> <span class="kn">import</span> <span class="n">create_header_file</span>
</pre></div>
</div>
</div>
<div class="section" id="import-the-tflite-model">
<h2>Import the TFLite model<a class="headerlink" href="#import-the-tflite-model" title="Permalink to this headline">¶</a></h2>
<p>To begin with, download and import a Visual Wake Word TFLite model. This model takes in a 96x96x3 RGB image and determines whether a person is present in the image or not.
This model is originally from <a class="reference external" href="https://github.com/mlcommons/tiny">MLPerf Tiny repository</a>.
To test this model, we use two samples from <a class="reference external" href="https://cocodataset.org/">COCO 2014 Train images</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MODEL_URL</span></a> <span class="o">=</span> <span class="s2">&quot;https://github.com/mlcommons/tiny/raw/bceb91c5ad2e2deb295547d81505721d3a87d578/benchmark/training/visual_wake_words/trained_models/vww_96_int8.tflite&quot;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MODEL_NAME</span></a> <span class="o">=</span> <span class="s2">&quot;vww_96_int8.tflite&quot;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MODEL_PATH</span></a> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MODEL_URL</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MODEL_NAME</span></a><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">)</span>

<a href="https://docs.python.org/3/library/stdtypes.html#bytes" title="builtins.bytes" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tflite_model_buf</span></a> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MODEL_PATH</span></a><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">tflite</span>

    <span class="n">tflite_model</span> <span class="o">=</span> <span class="n">tflite</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">GetRootAsModel</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#bytes" title="builtins.bytes" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tflite_model_buf</span></a><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">tflite.Model</span>

    <span class="n">tflite_model</span> <span class="o">=</span> <span class="n">tflite</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">GetRootAsModel</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#bytes" title="builtins.bytes" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tflite_model_buf</span></a><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_shape</span></a> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">INPUT_NAME</span></a> <span class="o">=</span> <span class="s2">&quot;input_1_int8&quot;</span>
<span class="n">relay_mod</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a> <span class="o">=</span> <a href="../../reference/api/python/relay/frontend.html#tvm.relay.frontend.from_tflite" title="tvm.relay.frontend.from_tflite" class="sphx-glr-backref-module-tvm-relay-frontend sphx-glr-backref-type-py-function"><span class="n">relay</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">from_tflite</span></a><span class="p">(</span>
    <span class="n">tflite_model</span><span class="p">,</span> <span class="n">shape_dict</span><span class="o">=</span><span class="p">{</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">INPUT_NAME</span></a><span class="p">:</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_shape</span></a><span class="p">},</span> <span class="n">dtype_dict</span><span class="o">=</span><span class="p">{</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">INPUT_NAME</span></a><span class="p">:</span> <span class="s2">&quot;int8&quot;</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="generate-the-model-library-format-file">
<h2>Generate the Model Library Format file<a class="headerlink" href="#generate-the-model-library-format-file" title="Permalink to this headline">¶</a></h2>
<p>First we define the target, runtime and executor. Then we compile the model for the target device and
finally we export the generated code and all the required dependencies in a single file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># We can use TVM native schedules or rely on the CMSIS-NN kernels using TVM Bring-Your-Own-Code (BYOC) capability.</span>
<a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">USE_CMSIS_NN</span></a> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># USMP (Unified Static Memory Planning) performs memory planning of all tensors holistically to achieve best memory utilization</span>
<a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DISABLE_USMP</span></a> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Use the C runtime (crt)</span>
<span class="n">RUNTIME</span> <span class="o">=</span> <span class="n">Runtime</span><span class="p">(</span><span class="s2">&quot;crt&quot;</span><span class="p">)</span>

<span class="c1"># We define the target by passing the board name to `tvm.target.target.micro`.</span>
<span class="c1"># If your board is not included in the supported models, you can define the target such as:</span>
<span class="c1"># TARGET = tvm.target.Target(&quot;c -keys=arm_cpu,cpu -mcpu=cortex-m4&quot;)</span>
<a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TARGET</span></a> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">micro</span><span class="p">(</span><span class="s2">&quot;stm32l4r5zi&quot;</span><span class="p">)</span>

<span class="c1"># Use the AOT executor rather than graph or vm executors. Use unpacked API and C calling style.</span>
<span class="n">EXECUTOR</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">relay</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">Executor</span><span class="p">(</span>
    <span class="s2">&quot;aot&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;unpacked-api&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;interface-api&quot;</span><span class="p">:</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;workspace-byte-alignment&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Now, we set the compilation configurations and compile the model for the target:</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">config</span></a> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;tir.disable_vectorize&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>
<span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">USE_CMSIS_NN</span></a><span class="p">:</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">config</span></a><span class="p">[</span><span class="s2">&quot;relay.ext.cmsisnn.options&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mcpu&quot;</span><span class="p">:</span> <a href="../../reference/api/python/target.html#tvm.target.Target.mcpu" title="tvm.target.Target.mcpu" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-property"><span class="n">TARGET</span><span class="o">.</span><span class="n">mcpu</span></a><span class="p">}</span>
<span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DISABLE_USMP</span></a><span class="p">:</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">config</span></a><span class="p">[</span><span class="s2">&quot;tir.usmp.enable&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

<span class="k">with</span> <a href="../../reference/api/python/ir.html#tvm.transform.PassContext" title="tvm.transform.PassContext" class="sphx-glr-backref-module-tvm-transform sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span></a><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">config</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">config</span></a><span class="p">):</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">USE_CMSIS_NN</span></a><span class="p">:</span>
        <span class="c1"># When we are using CMSIS-NN, TVM searches for patterns in the</span>
        <span class="c1"># relay graph that it can offload to the CMSIS-NN kernels.</span>
        <span class="n">relay_mod</span> <span class="o">=</span> <span class="n">cmsisnn</span><span class="o">.</span><span class="n">partition_for_cmsisnn</span><span class="p">(</span><span class="n">relay_mod</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="p">,</span> <span class="n">mcpu</span><span class="o">=</span><a href="../../reference/api/python/target.html#tvm.target.Target.mcpu" title="tvm.target.Target.mcpu" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-property"><span class="n">TARGET</span><span class="o">.</span><span class="n">mcpu</span></a><span class="p">)</span>
    <span class="n">lowered</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">relay</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
        <span class="n">relay_mod</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TARGET</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="p">,</span> <span class="n">runtime</span><span class="o">=</span><span class="n">RUNTIME</span><span class="p">,</span> <span class="n">executor</span><span class="o">=</span><span class="n">EXECUTOR</span>
    <span class="p">)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameter_size</span></a> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><a href="../../reference/api/python/runtime.html#tvm.runtime.save_param_dict" title="tvm.runtime.save_param_dict" class="sphx-glr-backref-module-tvm-runtime sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">save_param_dict</span></a><span class="p">(</span><span class="n">lowered</span><span class="o">.</span><span class="n">get_params</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model parameter size: </span><span class="si">{</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameter_size</span></a><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># We need to pick a directory where our file will be saved.</span>
<span class="c1"># If running on Google Colab, we&#39;ll save everything in ``/root/tutorial`` (aka ``~/tutorial``)</span>
<span class="c1"># but you&#39;ll probably want to store it elsewhere if running locally.</span>

<a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BUILD_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class"><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span></a><span class="p">(</span><span class="s2">&quot;/root/tutorial&quot;</span><span class="p">)</span>

<a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir" title="pathlib.Path.mkdir" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-method"><span class="n">BUILD_DIR</span><span class="o">.</span><span class="n">mkdir</span></a><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Now, we export the model into a tar file:</span>
<a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TAR_PATH</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class"><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BUILD_DIR</span></a><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;model.tar&quot;</span>
<a href="../../reference/api/python/micro.html#tvm.micro.export_model_library_format" title="tvm.micro.export_model_library_format" class="sphx-glr-backref-module-tvm-micro sphx-glr-backref-type-py-function"><span class="n">export_model_library_format</span></a><span class="p">(</span><span class="n">lowered</span><span class="p">,</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TAR_PATH</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Model parameter size: 32

PosixPath(&#39;/workspace/gallery/how_to/work_with_microtvm/tutorial/model.tar&#39;)
</pre></div>
</div>
</div>
<div class="section" id="add-sample-images-to-the-mlf-files">
<h2>Add sample images to the MLF files<a class="headerlink" href="#add-sample-images-to-the-mlf-files" title="Permalink to this headline">¶</a></h2>
<p>Finally, we downlaod two sample images (one person and one not-person), convert them to binary format and store them in two header files.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <a href="https://docs.python.org/3/library/tarfile.html#tarfile.open" title="tarfile.open" class="sphx-glr-backref-module-tarfile sphx-glr-backref-type-py-function"><span class="n">tarfile</span><span class="o">.</span><span class="n">open</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TAR_PATH</span></a><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <a href="https://docs.python.org/3/library/tarfile.html#tarfile.TarFile" title="tarfile.TarFile" class="sphx-glr-backref-module-tarfile sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tar_file</span></a><span class="p">:</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLES_DIR</span></a> <span class="o">=</span> <span class="s2">&quot;samples&quot;</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLE_PERSON_URL</span></a> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&quot;https://github.com/tlc-pack/web-data/raw/main/testdata/microTVM/data/vww_sample_person.jpg&quot;</span>
    <span class="p">)</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLE_NOT_PERSON_URL</span></a> <span class="o">=</span> <span class="s2">&quot;https://github.com/tlc-pack/web-data/raw/main/testdata/microTVM/data/vww_sample_not_person.jpg&quot;</span>

    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLE_PERSON_PATH</span></a> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLE_PERSON_URL</span></a><span class="p">,</span> <span class="s2">&quot;person.jpg&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLES_DIR</span></a><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLE_PERSON_PATH</span></a><span class="p">)</span>
    <span class="n">create_header_file</span><span class="p">(</span><span class="s2">&quot;sample_person&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLES_DIR</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/tarfile.html#tarfile.TarFile" title="tarfile.TarFile" class="sphx-glr-backref-module-tarfile sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tar_file</span></a><span class="p">)</span>

    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLE_NOT_PERSON_PATH</span></a> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLE_NOT_PERSON_URL</span></a><span class="p">,</span> <span class="s2">&quot;not_person.jpg&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLES_DIR</span></a>
    <span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLE_NOT_PERSON_PATH</span></a><span class="p">)</span>
    <span class="n">create_header_file</span><span class="p">(</span><span class="s2">&quot;sample_not_person&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SAMPLES_DIR</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/tarfile.html#tarfile.TarFile" title="tarfile.TarFile" class="sphx-glr-backref-module-tarfile sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tar_file</span></a><span class="p">)</span>
</pre></div>
</div>
<p>At this point you have all you need to take the compiled model to your IDE and evaluate it. Inside the MLF file (model.tar), you should find the following file hierearchy:</p>
<blockquote>
<div><div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/root
├── codegen
├── parameters
├── runtime
├── samples
├── src
├── templates
├── metadata.json
</pre></div>
</div>
</div></blockquote>
<ul class="simple">
<li><p>The codegen folder includes the C code TVM generated for your model.</p></li>
<li><p>The runtime folder includes all the TVM dependencies that the target needs to compile the generated C code.</p></li>
<li><p>The samples folder includes the two generated sample files for evaluating the model.</p></li>
<li><p>The src folder includes the relay module describing the model.</p></li>
<li><p>The templates folder includes two template files that you might need to edit based on your platform.</p></li>
<li><p>The metadata.json file includes information about the model, its layers and memory requirement.</p></li>
</ul>
</div>
<div class="section" id="generate-the-project-in-your-ide">
<h2>Generate the project in your IDE<a class="headerlink" href="#generate-the-project-in-your-ide" title="Permalink to this headline">¶</a></h2>
<p>The next step is to create a project for our target device. We use STM32CubeIDE, you can download it <a class="reference external" href="https://www.st.com/en/development-tools/stm32cubeide.html">here</a>.
We are using version 1.11.0 in this tutorial. Once you install STM32CubeIDE follow these steps to create a project:</p>
<ol class="arabic">
<li><p>select File -&gt; New -&gt; STM32Project. The target selection Window appears.</p></li>
<li><p>Navigate to the “Board Selector” tab, type in the board name “nucleo-l4r5zi” in the “Commercial Part Number” text box. Select the board from the list of boards that appear on the right side of the screen and click “Next”.</p></li>
<li><p>Type in your project name (for example microtvm_vww_demo). We are using the default options. (Target Language: C, Binary Type: Executable, Project Type: STM32Cube). Click “Finish”.</p></li>
<li><p>A text box will appear asking if you want to “Initialize all the peripherals with their default mode?”. click “Yes”. This will generate the project and open the device configuration tool where you can use the GUI to setup the peripherals. By default the USB, USART3 and LPUART1 are enabled, as well as a few GPIOs.</p></li>
<li><p>We will use LPUART1 to send data to the host pc. From the connectivity section, select the LPUART1 and set the “Baud Rate” to 115200 and the “Word Length” to 8. Save the changes and click “Yes” to regenerate the initialization code. This should regenerate the code and open your main.c file. You can also find main.c from the Project Explorer panel on the left, under microtvm_vww_demo -&gt; Core -&gt; Src.</p></li>
<li><p>For sanity check, copy the code below and paste it in the “Infinite loop (aka. While (1) ) section of the main function.</p>
<ul>
<li><p>Note: Make sure to write your code inside the sections marked by USER CODE BEGIN &lt;…&gt; and USER CODE END &lt;…&gt;. The code outside these sections get erased if you regenerate the initialization code.</p>
<blockquote>
<div><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">HAL_GPIO_TogglePin</span><span class="p">(</span><span class="n">LD2_GPIO_Port</span><span class="p">,</span><span class="w"> </span><span class="n">LD2_Pin</span><span class="p">);</span>
<span class="n">HAL_UART_Transmit</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hlpuart1</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Hello World.</span><span class="se">\r\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">14</span><span class="p">,</span><span class="w"> </span><span class="mi">100</span><span class="p">);</span>
<span class="n">HAL_Delay</span><span class="p">(</span><span class="mi">1000</span><span class="p">);</span>
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
</li>
<li><p>From the menu bar, select Project -&gt; Build (or right click on project name and select Build). This should build the project and generate the .elf file. Select Run -&gt; Run to download the binary on your MCU. If the “Edit Configuration” window opens, just click “OK”.</p></li>
<li><p>Open the terminal console on your host machine. On Mac you can simply use the “screen &lt;usb_device&gt; 115200” command, e.g. “screen tty.usbmodemXXXX 115200”. An LED should blink on the board and the string “Hello World.” should print out on your terminal console every second. Press “Control-a k” to exit screen.</p></li>
</ol>
</div>
<div class="section" id="import-the-model-to-the-generated-project">
<h2>Import the model to the generated project<a class="headerlink" href="#import-the-model-to-the-generated-project" title="Permalink to this headline">¶</a></h2>
<p>To integrate the compiled model into the generated project, follow these steps:</p>
<ol class="arabic">
<li><p>Extract the tar file and include it in the project</p>
<ul class="simple">
<li><p>Open the project Properties. (by right clicking on the project name and selecting “Properties” or by selecting Project -&gt; Properties from the menu bar).</p></li>
<li><p>Select C/C++ General -&gt; Paths and Symbols. Select the Source Location tab.</p></li>
<li><p>If you extracted the model inside the project folder, click “Add Folder” and select the “model” folder. (You might need to right click on the project name and select “Refresh” before it appears.)</p></li>
<li><p>If you extracted the model file somewhere else, click on the “Link Folder” button, check the box for “Link to folder in the file system” in the window that appears, click “Browse” and select the model folder.</p></li>
</ul>
</li>
<li><p>If you used CMSIS-NN in compiling the model, you need to include the CMSIS-NN source files in your project too.</p>
<ul class="simple">
<li><p>Download or clone the files from the <a class="reference external" href="https://github.com/ARM-software/CMSIS-NN">CMSIS-NN repository</a>, and follow the above steps to include the CMSIS-NN folder in the project.</p></li>
</ul>
</li>
<li><p>Open the project properties. In C/C++ Build -&gt; Settings: add the following folders to the list of Include Paths for MCU GCC Compiler (and MCU G++ Compiler if you have a C++ project) by clicking on the “+” button, selecting “Workspace” and navigating to each of the following folders:</p>
<ul class="simple">
<li><p>model/runtime/include</p></li>
<li><p>model/codegen/host/include</p></li>
<li><p>model/samples</p></li>
<li><p>CMSIS-NN/Include</p></li>
</ul>
</li>
<li><p>Copy crt_config.h.template from model/templates to the Core/Inc folder, and rename it to crt_config.h.</p></li>
<li><p>Copy platform.c.template from model/templates to the Core/Src folder, and rename it to platform.c.
* This file includes functions for managing the memory that you might need to edit based on your platform.
* define “TVM_WORKSPACE_SIZE_BYTES” in platform.c. if you are using USMP, a small value (for example 1024 Bytes) is enough.
* if you are not using usmp, checkout “workspace_size_bytes” field in metadata.json for an estimate of the required memory.</p></li>
<li><p>Exclude the following folders from build (right click on the folder name, select Resource Configuration → Exclude from build). Check Debug and Release configurations.</p>
<ul class="simple">
<li><p>CMSIS_NN/Tests</p></li>
</ul>
</li>
<li><p>Download the CMSIS drivers from <a class="reference external" href="https://github.com/ARM-software/CMSIS_5">CMSIS Version 5 repository</a>.</p>
<ul class="simple">
<li><p>In your Project directory, delete the Drivers/CMSIS/Include folder (which is an older version of the CMSIS drivers) and copy the CMSIS/Core/Include from the one you downloaded in its place.</p></li>
</ul>
</li>
<li><p>Edit the main.c file:</p>
<ul>
<li><p>Include following header files:</p>
<blockquote>
<div><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;string.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdarg.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;tvmgen_default.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;sample_person.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;sample_not_person.h&quot;</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Copy the following code into the main function right before the infinite loop. It sets the input and output to the model.</p>
<blockquote>
<div><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">TVMPlatformInitialize</span><span class="p">();</span>
<span class="kt">signed</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="n">output</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">tvmgen_default_inputs</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="p">.</span><span class="n">input_1_int8</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">sample_person</span><span class="p">,</span>
<span class="p">};</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">tvmgen_default_outputs</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="p">.</span><span class="n">Identity_int8</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">output</span><span class="p">,</span>
<span class="p">};</span>
<span class="kt">char</span><span class="w"> </span><span class="n">msg</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Evaluating VWW model using microTVM:</span><span class="se">\r\n</span><span class="s">&quot;</span><span class="p">;</span>
<span class="n">HAL_UART_Transmit</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hlpuart1</span><span class="p">,</span><span class="w"> </span><span class="n">msg</span><span class="p">,</span><span class="w"> </span><span class="n">strlen</span><span class="p">(</span><span class="n">msg</span><span class="p">),</span><span class="w"> </span><span class="mi">100</span><span class="p">);</span>
<span class="kt">uint8_t</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="kt">uint32_t</span><span class="w"> </span><span class="n">timer_val</span><span class="p">;</span>
<span class="kt">char</span><span class="w"> </span><span class="n">buf</span><span class="p">[</span><span class="mi">50</span><span class="p">];</span>
<span class="kt">uint16_t</span><span class="w"> </span><span class="n">buf_len</span><span class="p">;</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Copy the following code inside the infinite loop to run inference on both images and print the result on the console:</p>
<blockquote>
<div><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">sample</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
<span class="w">    </span><span class="n">inputs</span><span class="p">.</span><span class="n">input_1_int8</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">sample_person</span><span class="p">;</span>
<span class="k">else</span>
<span class="w">    </span><span class="n">inputs</span><span class="p">.</span><span class="n">input_1_int8</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">sample_not_person</span><span class="p">;</span>

<span class="n">timer_val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">HAL_GetTick</span><span class="p">();</span>
<span class="n">tvmgen_default_run</span><span class="p">(</span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">);</span>
<span class="n">timer_val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">HAL_GetTick</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">timer_val</span><span class="p">;</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="w">    </span><span class="n">buf_len</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sprintf</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Person not detected, inference time = %lu ms</span><span class="se">\r\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">timer_val</span><span class="p">);</span>
<span class="k">else</span>
<span class="w">    </span><span class="n">buf_len</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sprintf</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Person detected, inference time = %lu ms</span><span class="se">\r\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">timer_val</span><span class="p">);</span>
<span class="n">HAL_UART_Transmit</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hlpuart1</span><span class="p">,</span><span class="w"> </span><span class="n">buf</span><span class="p">,</span><span class="w"> </span><span class="n">buf_len</span><span class="p">,</span><span class="w"> </span><span class="mi">100</span><span class="p">);</span>

<span class="n">sample</span><span class="o">++</span><span class="p">;</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">sample</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span>
<span class="w">    </span><span class="n">sample</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Define the TVMLogf function in main, to receive TVM runtime errors on serial console.</p>
<blockquote>
<div><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">TVMLogf</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">msg</span><span class="p">,</span><span class="w"> </span><span class="p">...)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">char</span><span class="w"> </span><span class="n">buffer</span><span class="p">[</span><span class="mi">128</span><span class="p">];</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">;</span>
<span class="w">  </span><span class="kt">va_list</span><span class="w"> </span><span class="n">args</span><span class="p">;</span>
<span class="w">  </span><span class="n">va_start</span><span class="p">(</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="n">msg</span><span class="p">);</span>
<span class="w">  </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">TVMPlatformFormatMessage</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="n">msg</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="p">);</span>
<span class="w">  </span><span class="n">va_end</span><span class="p">(</span><span class="n">args</span><span class="p">);</span>
<span class="w">  </span><span class="n">HAL_UART_Transmit</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hlpuart1</span><span class="p">,</span><span class="w"> </span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="mi">100</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
</li>
<li><p>In project properties, C/C++ Build -&gt; Settings, MCU GCC Compiler -&gt; Optimization, set the Optimization level to “Optimize more (-O2)”</p></li>
</ol>
</div>
<div class="section" id="evaluate-the-model">
<h2>Evaluate the model<a class="headerlink" href="#evaluate-the-model" title="Permalink to this headline">¶</a></h2>
<p>Now, select Run -&gt; Run from the menu bar to flash the MCU and run the project.
You should see the LED blinking and the inference result printing on the console.</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-how-to-work-with-microtvm-micro-custom-ide-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/9322c6c215567e9975d1df6b3a218ff1/micro_custom_ide.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">micro_custom_ide.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a74627f44186b95116fe0ed6f77e3b99/micro_custom_ide.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">micro_custom_ide.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../extend_tvm/index.html" class="btn btn-neutral float-right" title="Extend TVM" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="micro_mlperftiny.html" class="btn btn-neutral float-left" title="8. Creating Your MLPerfTiny Submission with microTVM" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2022 Apache Software Foundation | All rights reserved</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote">Copyright © 2022 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>