



<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>End-to-End Optimize Model &mdash; tvm 0.20.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/downloads/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tlcpack_theme.css" type="text/css" />

  
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=1b5e2a23"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Customize Optimization" href="customize_opt.html" />
    <link rel="prev" title="IRModule" href="../../get_started/tutorials/ir_module.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://tvm.apache.org/docs/reference/security.html>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://tvm.apache.org/docs/reference/security.html>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="sidetitle" alt="Documentation Home"> tvm
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../get_started/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installing TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get_started/tutorials/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get_started/tutorials/ir_module.html">IRModule</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">How To</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">End-to-End Optimize Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#preparation">Preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#review-overall-flow">Review Overall Flow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#convert-the-model-to-irmodule">Convert the model to IRModule</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#irmodule-optimization">IRModule Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#build-and-deploy">Build and Deploy</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="customize_opt.html">Customize Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimize_llm.html">Optimize Large Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev/index.html">Development Guides</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Dive</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../arch/index.html">Design and Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deep_dive/tensor_ir/index.html">TensorIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deep_dive/relax/index.html">Relax</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/links.html">Other APIs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contributor Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/security.html">Security Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Index</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
      <li>End-to-End Optimize Model</li>
    
    
      
      
        
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/tvm/edit/main/docs/how_to/tutorials/e2e_opt_model.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial can be used interactively with Google Colab! You can also click
<a class="reference internal" href="#sphx-glr-download-how-to-tutorials-e2e-opt-model-py"><span class="std std-ref">here</span></a> to run the Jupyter notebook locally.</p>
<a class="reference external image-reference" href="https://colab.research.google.com/github/apache/tvm-site/blob/asf-site/docs/_downloads/317a8cc53139718b9a36a16ba052e44b/e2e_opt_model.ipynb"><img alt="../../_static/downloads/colab_button.svg" class="align-center" src="../../_static/downloads/colab_button.svg" style="width: 300px;" />
</a>
</div>
<section class="sphx-glr-example-title" id="end-to-end-optimize-model">
<span id="optimize-model"></span><span id="sphx-glr-how-to-tutorials-e2e-opt-model-py"></span><h1>End-to-End Optimize Model<a class="headerlink" href="#end-to-end-optimize-model" title="Link to this heading"></a></h1>
<p>This tutorial demonstrates how to optimize a machine learning model using Apache TVM. We will
use a pre-trained ResNet-18 model from PyTorch and end-to-end optimize it using TVM’s Relax API.
Please note that default end-to-end optimization may not suit complex models.</p>
<section id="preparation">
<h2>Preparation<a class="headerlink" href="#preparation" title="Link to this heading"></a></h2>
<p>First, we prepare the model and input information. We use a pre-trained ResNet-18 model from
PyTorch.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.export</span><span class="w"> </span><span class="kn">import</span> <span class="n">export</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models.resnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">ResNet18_Weights</span><span class="p">,</span> <span class="n">resnet18</span>

<span class="n">torch_model</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">ResNet18_Weights</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://download.pytorch.org/models/resnet18-f37072fd.pth&quot; to /workspace/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth

  0%|          | 0.00/44.7M [00:00&lt;?, ?B/s]
  9%|▊         | 3.88M/44.7M [00:00&lt;00:01, 40.5MB/s]
 18%|█▊        | 8.00M/44.7M [00:00&lt;00:00, 39.7MB/s]
 30%|██▉       | 13.2M/44.7M [00:00&lt;00:00, 46.4MB/s]
 40%|███▉      | 17.8M/44.7M [00:00&lt;00:00, 44.5MB/s]
 51%|█████▏    | 23.0M/44.7M [00:00&lt;00:00, 47.7MB/s]
 64%|██████▍   | 28.8M/44.7M [00:00&lt;00:00, 51.3MB/s]
 76%|███████▌  | 33.9M/44.7M [00:00&lt;00:00, 52.0MB/s]
 87%|████████▋ | 38.9M/44.7M [00:00&lt;00:00, 44.4MB/s]
 97%|█████████▋| 43.5M/44.7M [00:00&lt;00:00, 45.2MB/s]
100%|██████████| 44.7M/44.7M [00:01&lt;00:00, 46.6MB/s]
</pre></div>
</div>
</section>
<section id="review-overall-flow">
<h2>Review Overall Flow<a class="headerlink" href="#review-overall-flow" title="Link to this heading"></a></h2>
<figure class="align-center">
<a class="reference internal image-reference" href="../../_static/downloads/tvm_overall_flow.svg"><img alt="../../_static/downloads/tvm_overall_flow.svg" src="../../_static/downloads/tvm_overall_flow.svg" style="width: 80%;" />
</a>
</figure>
<p>The overall flow consists of the following steps:</p>
<ul class="simple">
<li><p><strong>Construct or Import a Model</strong>: Construct a neural network model or import a pre-trained
model from other frameworks (e.g. PyTorch, ONNX), and create the TVM IRModule, which contains
all the information needed for compilation, including high-level Relax functions for
computational graph, and low-level TensorIR functions for tensor program.</p></li>
<li><p><strong>Perform Composable Optimizations</strong>: Perform a series of optimization transformations,
such as graph optimizations, tensor program optimizations, and library dispatching.</p></li>
<li><p><strong>Build and Universal Deployment</strong>: Build the optimized model to a deployable module to the
universal runtime, and execute it on different devices, such as CPU, GPU, or other accelerators.</p></li>
</ul>
<section id="convert-the-model-to-irmodule">
<h3>Convert the model to IRModule<a class="headerlink" href="#convert-the-model-to-irmodule" title="Link to this heading"></a></h3>
<p>Next step, we convert the model to an IRModule using the Relax frontend for PyTorch for further
optimization.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tvm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tvm</span><span class="w"> </span><span class="kn">import</span> <span class="n">relax</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tvm.relax.frontend.torch</span><span class="w"> </span><span class="kn">import</span> <a href="../../reference/api/python/relax/frontend.html#tvm.relax.frontend.torch.from_exported_program" title="tvm.relax.frontend.torch.from_exported_program" class="sphx-glr-backref-module-tvm-relax-frontend-torch sphx-glr-backref-type-py-function"><span class="n">from_exported_program</span></a>

<span class="c1"># Give an example argument to torch.export</span>
<a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">example_args</span></a> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),)</span>

<span class="c1"># Convert the model to IRModule</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">exported_program</span> <span class="o">=</span> <span class="n">export</span><span class="p">(</span><span class="n">torch_model</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">example_args</span></a><span class="p">)</span>
    <span class="n">mod</span> <span class="o">=</span> <a href="../../reference/api/python/relax/frontend.html#tvm.relax.frontend.torch.from_exported_program" title="tvm.relax.frontend.torch.from_exported_program" class="sphx-glr-backref-module-tvm-relax-frontend-torch sphx-glr-backref-type-py-function"><span class="n">from_exported_program</span></a><span class="p">(</span><span class="n">exported_program</span><span class="p">,</span> <span class="n">keep_params_as_input</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">mod</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a> <span class="o">=</span> <a href="../../reference/api/python/relax/frontend.html#tvm.relax.frontend.detach_params" title="tvm.relax.frontend.detach_params" class="sphx-glr-backref-module-tvm-relax-frontend sphx-glr-backref-type-py-function"><span class="n">relax</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">detach_params</span></a><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
<span class="n">mod</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span># from tvm.script import ir as I
# from tvm.script import relax as R

@I.ir_module
class Module:
    @R.function
    def main(x: R.Tensor((1, 3, 224, 224), dtype=&quot;float32&quot;), p_conv1_weight: R.Tensor((64, 3, 7, 7), dtype=&quot;float32&quot;), p_bn1_weight: R.Tensor((64,), dtype=&quot;float32&quot;), p_bn1_bias: R.Tensor((64,), dtype=&quot;float32&quot;), p_getattr_l__self___layer1___0___conv1_weight: R.Tensor((64, 64, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer1___0___bn1_weight: R.Tensor((64,), dtype=&quot;float32&quot;), p_getattr_l__self___layer1___0___bn1_bias: R.Tensor((64,), dtype=&quot;float32&quot;), p_getattr_l__self___layer1___0___conv2_weight: R.Tensor((64, 64, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer1___0___bn2_weight: R.Tensor((64,), dtype=&quot;float32&quot;), p_getattr_l__self___layer1___0___bn2_bias: R.Tensor((64,), dtype=&quot;float32&quot;), p_getattr_l__self___layer1___1___conv1_weight: R.Tensor((64, 64, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer1___1___bn1_weight: R.Tensor((64,), dtype=&quot;float32&quot;), p_getattr_l__self___layer1___1___bn1_bias: R.Tensor((64,), dtype=&quot;float32&quot;), p_getattr_l__self___layer1___1___conv2_weight: R.Tensor((64, 64, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer1___1___bn2_weight: R.Tensor((64,), dtype=&quot;float32&quot;), p_getattr_l__self___layer1___1___bn2_bias: R.Tensor((64,), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___0___conv1_weight: R.Tensor((128, 64, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___0___bn1_weight: R.Tensor((128,), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___0___bn1_bias: R.Tensor((128,), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___0___conv2_weight: R.Tensor((128, 128, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___0___bn2_weight: R.Tensor((128,), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___0___bn2_bias: R.Tensor((128,), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___0___downsample_0_weight: R.Tensor((128, 64, 1, 1), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___0___downsample_1_weight: R.Tensor((128,), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___0___downsample_1_bias: R.Tensor((128,), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___1___conv1_weight: R.Tensor((128, 128, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___1___bn1_weight: R.Tensor((128,), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___1___bn1_bias: R.Tensor((128,), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___1___conv2_weight: R.Tensor((128, 128, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___1___bn2_weight: R.Tensor((128,), dtype=&quot;float32&quot;), p_getattr_l__self___layer2___1___bn2_bias: R.Tensor((128,), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___0___conv1_weight: R.Tensor((256, 128, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___0___bn1_weight: R.Tensor((256,), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___0___bn1_bias: R.Tensor((256,), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___0___conv2_weight: R.Tensor((256, 256, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___0___bn2_weight: R.Tensor((256,), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___0___bn2_bias: R.Tensor((256,), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___0___downsample_0_weight: R.Tensor((256, 128, 1, 1), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___0___downsample_1_weight: R.Tensor((256,), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___0___downsample_1_bias: R.Tensor((256,), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___1___conv1_weight: R.Tensor((256, 256, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___1___bn1_weight: R.Tensor((256,), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___1___bn1_bias: R.Tensor((256,), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___1___conv2_weight: R.Tensor((256, 256, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___1___bn2_weight: R.Tensor((256,), dtype=&quot;float32&quot;), p_getattr_l__self___layer3___1___bn2_bias: R.Tensor((256,), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___0___conv1_weight: R.Tensor((512, 256, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___0___bn1_weight: R.Tensor((512,), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___0___bn1_bias: R.Tensor((512,), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___0___conv2_weight: R.Tensor((512, 512, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___0___bn2_weight: R.Tensor((512,), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___0___bn2_bias: R.Tensor((512,), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___0___downsample_0_weight: R.Tensor((512, 256, 1, 1), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___0___downsample_1_weight: R.Tensor((512,), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___0___downsample_1_bias: R.Tensor((512,), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___1___conv1_weight: R.Tensor((512, 512, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___1___bn1_weight: R.Tensor((512,), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___1___bn1_bias: R.Tensor((512,), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___1___conv2_weight: R.Tensor((512, 512, 3, 3), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___1___bn2_weight: R.Tensor((512,), dtype=&quot;float32&quot;), p_getattr_l__self___layer4___1___bn2_bias: R.Tensor((512,), dtype=&quot;float32&quot;), p_fc_weight: R.Tensor((1000, 512), dtype=&quot;float32&quot;), p_fc_bias: R.Tensor((1000,), dtype=&quot;float32&quot;)) -&gt; R.Tuple(R.Tensor((1, 1000), dtype=&quot;float32&quot;)):
        R.func_attr({&quot;num_input&quot;: 1})
        with R.dataflow():
            lv: R.Tensor((1, 64, 112, 112), dtype=&quot;float32&quot;) = R.nn.conv2d(x, p_conv1_weight, strides=[2, 2], padding=[3, 3, 3, 3], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv1: R.Tuple(R.Tensor((1, 64, 112, 112), dtype=&quot;float32&quot;), R.Tensor((64,), dtype=&quot;float32&quot;), R.Tensor((64,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv, p_bn1_weight, p_bn1_bias, metadata[&quot;relax.expr.Constant&quot;][0], metadata[&quot;relax.expr.Constant&quot;][1], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv2: R.Tensor((1, 64, 112, 112), dtype=&quot;float32&quot;) = lv1[0]
            lv3: R.Tensor((1, 64, 112, 112), dtype=&quot;float32&quot;) = R.nn.relu(lv2)
            lv4: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = R.nn.max_pool2d(lv3, pool_size=[3, 3], strides=[2, 2], dilation=[1, 1], padding=[1, 1, 1, 1], ceil_mode=False, count_include_pad=False, layout=&quot;NCHW&quot;, out_layout=&quot;NCHW&quot;)
            lv5: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = R.nn.conv2d(lv4, p_getattr_l__self___layer1___0___conv1_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv6: R.Tuple(R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;), R.Tensor((64,), dtype=&quot;float32&quot;), R.Tensor((64,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv5, p_getattr_l__self___layer1___0___bn1_weight, p_getattr_l__self___layer1___0___bn1_bias, metadata[&quot;relax.expr.Constant&quot;][2], metadata[&quot;relax.expr.Constant&quot;][3], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv7: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = lv6[0]
            lv8: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = R.nn.relu(lv7)
            lv9: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = R.nn.conv2d(lv8, p_getattr_l__self___layer1___0___conv2_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv10: R.Tuple(R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;), R.Tensor((64,), dtype=&quot;float32&quot;), R.Tensor((64,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv9, p_getattr_l__self___layer1___0___bn2_weight, p_getattr_l__self___layer1___0___bn2_bias, metadata[&quot;relax.expr.Constant&quot;][4], metadata[&quot;relax.expr.Constant&quot;][5], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv11: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = lv10[0]
            lv12: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = R.add(lv11, lv4)
            lv13: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = R.nn.relu(lv12)
            lv14: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = R.nn.conv2d(lv13, p_getattr_l__self___layer1___1___conv1_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv15: R.Tuple(R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;), R.Tensor((64,), dtype=&quot;float32&quot;), R.Tensor((64,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv14, p_getattr_l__self___layer1___1___bn1_weight, p_getattr_l__self___layer1___1___bn1_bias, metadata[&quot;relax.expr.Constant&quot;][6], metadata[&quot;relax.expr.Constant&quot;][7], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv16: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = lv15[0]
            lv17: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = R.nn.relu(lv16)
            lv18: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = R.nn.conv2d(lv17, p_getattr_l__self___layer1___1___conv2_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv19: R.Tuple(R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;), R.Tensor((64,), dtype=&quot;float32&quot;), R.Tensor((64,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv18, p_getattr_l__self___layer1___1___bn2_weight, p_getattr_l__self___layer1___1___bn2_bias, metadata[&quot;relax.expr.Constant&quot;][8], metadata[&quot;relax.expr.Constant&quot;][9], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv20: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = lv19[0]
            lv21: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = R.add(lv20, lv13)
            lv22: R.Tensor((1, 64, 56, 56), dtype=&quot;float32&quot;) = R.nn.relu(lv21)
            lv23: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = R.nn.conv2d(lv22, p_getattr_l__self___layer2___0___conv1_weight, strides=[2, 2], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv24: R.Tuple(R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;), R.Tensor((128,), dtype=&quot;float32&quot;), R.Tensor((128,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv23, p_getattr_l__self___layer2___0___bn1_weight, p_getattr_l__self___layer2___0___bn1_bias, metadata[&quot;relax.expr.Constant&quot;][10], metadata[&quot;relax.expr.Constant&quot;][11], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv25: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = lv24[0]
            lv26: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = R.nn.relu(lv25)
            lv27: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = R.nn.conv2d(lv26, p_getattr_l__self___layer2___0___conv2_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv28: R.Tuple(R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;), R.Tensor((128,), dtype=&quot;float32&quot;), R.Tensor((128,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv27, p_getattr_l__self___layer2___0___bn2_weight, p_getattr_l__self___layer2___0___bn2_bias, metadata[&quot;relax.expr.Constant&quot;][12], metadata[&quot;relax.expr.Constant&quot;][13], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv29: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = lv28[0]
            lv30: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = R.nn.conv2d(lv22, p_getattr_l__self___layer2___0___downsample_0_weight, strides=[2, 2], padding=[0, 0, 0, 0], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv31: R.Tuple(R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;), R.Tensor((128,), dtype=&quot;float32&quot;), R.Tensor((128,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv30, p_getattr_l__self___layer2___0___downsample_1_weight, p_getattr_l__self___layer2___0___downsample_1_bias, metadata[&quot;relax.expr.Constant&quot;][14], metadata[&quot;relax.expr.Constant&quot;][15], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv32: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = lv31[0]
            lv33: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = R.add(lv29, lv32)
            lv34: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = R.nn.relu(lv33)
            lv35: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = R.nn.conv2d(lv34, p_getattr_l__self___layer2___1___conv1_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv36: R.Tuple(R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;), R.Tensor((128,), dtype=&quot;float32&quot;), R.Tensor((128,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv35, p_getattr_l__self___layer2___1___bn1_weight, p_getattr_l__self___layer2___1___bn1_bias, metadata[&quot;relax.expr.Constant&quot;][16], metadata[&quot;relax.expr.Constant&quot;][17], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv37: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = lv36[0]
            lv38: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = R.nn.relu(lv37)
            lv39: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = R.nn.conv2d(lv38, p_getattr_l__self___layer2___1___conv2_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv40: R.Tuple(R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;), R.Tensor((128,), dtype=&quot;float32&quot;), R.Tensor((128,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv39, p_getattr_l__self___layer2___1___bn2_weight, p_getattr_l__self___layer2___1___bn2_bias, metadata[&quot;relax.expr.Constant&quot;][18], metadata[&quot;relax.expr.Constant&quot;][19], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv41: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = lv40[0]
            lv42: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = R.add(lv41, lv34)
            lv43: R.Tensor((1, 128, 28, 28), dtype=&quot;float32&quot;) = R.nn.relu(lv42)
            lv44: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = R.nn.conv2d(lv43, p_getattr_l__self___layer3___0___conv1_weight, strides=[2, 2], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv45: R.Tuple(R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;), R.Tensor((256,), dtype=&quot;float32&quot;), R.Tensor((256,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv44, p_getattr_l__self___layer3___0___bn1_weight, p_getattr_l__self___layer3___0___bn1_bias, metadata[&quot;relax.expr.Constant&quot;][20], metadata[&quot;relax.expr.Constant&quot;][21], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv46: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = lv45[0]
            lv47: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = R.nn.relu(lv46)
            lv48: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = R.nn.conv2d(lv47, p_getattr_l__self___layer3___0___conv2_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv49: R.Tuple(R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;), R.Tensor((256,), dtype=&quot;float32&quot;), R.Tensor((256,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv48, p_getattr_l__self___layer3___0___bn2_weight, p_getattr_l__self___layer3___0___bn2_bias, metadata[&quot;relax.expr.Constant&quot;][22], metadata[&quot;relax.expr.Constant&quot;][23], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv50: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = lv49[0]
            lv51: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = R.nn.conv2d(lv43, p_getattr_l__self___layer3___0___downsample_0_weight, strides=[2, 2], padding=[0, 0, 0, 0], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv52: R.Tuple(R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;), R.Tensor((256,), dtype=&quot;float32&quot;), R.Tensor((256,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv51, p_getattr_l__self___layer3___0___downsample_1_weight, p_getattr_l__self___layer3___0___downsample_1_bias, metadata[&quot;relax.expr.Constant&quot;][24], metadata[&quot;relax.expr.Constant&quot;][25], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv53: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = lv52[0]
            lv54: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = R.add(lv50, lv53)
            lv55: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = R.nn.relu(lv54)
            lv56: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = R.nn.conv2d(lv55, p_getattr_l__self___layer3___1___conv1_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv57: R.Tuple(R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;), R.Tensor((256,), dtype=&quot;float32&quot;), R.Tensor((256,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv56, p_getattr_l__self___layer3___1___bn1_weight, p_getattr_l__self___layer3___1___bn1_bias, metadata[&quot;relax.expr.Constant&quot;][26], metadata[&quot;relax.expr.Constant&quot;][27], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv58: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = lv57[0]
            lv59: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = R.nn.relu(lv58)
            lv60: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = R.nn.conv2d(lv59, p_getattr_l__self___layer3___1___conv2_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv61: R.Tuple(R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;), R.Tensor((256,), dtype=&quot;float32&quot;), R.Tensor((256,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv60, p_getattr_l__self___layer3___1___bn2_weight, p_getattr_l__self___layer3___1___bn2_bias, metadata[&quot;relax.expr.Constant&quot;][28], metadata[&quot;relax.expr.Constant&quot;][29], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv62: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = lv61[0]
            lv63: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = R.add(lv62, lv55)
            lv64: R.Tensor((1, 256, 14, 14), dtype=&quot;float32&quot;) = R.nn.relu(lv63)
            lv65: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = R.nn.conv2d(lv64, p_getattr_l__self___layer4___0___conv1_weight, strides=[2, 2], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv66: R.Tuple(R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;), R.Tensor((512,), dtype=&quot;float32&quot;), R.Tensor((512,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv65, p_getattr_l__self___layer4___0___bn1_weight, p_getattr_l__self___layer4___0___bn1_bias, metadata[&quot;relax.expr.Constant&quot;][30], metadata[&quot;relax.expr.Constant&quot;][31], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv67: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = lv66[0]
            lv68: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = R.nn.relu(lv67)
            lv69: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = R.nn.conv2d(lv68, p_getattr_l__self___layer4___0___conv2_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv70: R.Tuple(R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;), R.Tensor((512,), dtype=&quot;float32&quot;), R.Tensor((512,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv69, p_getattr_l__self___layer4___0___bn2_weight, p_getattr_l__self___layer4___0___bn2_bias, metadata[&quot;relax.expr.Constant&quot;][32], metadata[&quot;relax.expr.Constant&quot;][33], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv71: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = lv70[0]
            lv72: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = R.nn.conv2d(lv64, p_getattr_l__self___layer4___0___downsample_0_weight, strides=[2, 2], padding=[0, 0, 0, 0], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv73: R.Tuple(R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;), R.Tensor((512,), dtype=&quot;float32&quot;), R.Tensor((512,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv72, p_getattr_l__self___layer4___0___downsample_1_weight, p_getattr_l__self___layer4___0___downsample_1_bias, metadata[&quot;relax.expr.Constant&quot;][34], metadata[&quot;relax.expr.Constant&quot;][35], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv74: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = lv73[0]
            lv75: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = R.add(lv71, lv74)
            lv76: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = R.nn.relu(lv75)
            lv77: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = R.nn.conv2d(lv76, p_getattr_l__self___layer4___1___conv1_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv78: R.Tuple(R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;), R.Tensor((512,), dtype=&quot;float32&quot;), R.Tensor((512,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv77, p_getattr_l__self___layer4___1___bn1_weight, p_getattr_l__self___layer4___1___bn1_bias, metadata[&quot;relax.expr.Constant&quot;][36], metadata[&quot;relax.expr.Constant&quot;][37], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv79: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = lv78[0]
            lv80: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = R.nn.relu(lv79)
            lv81: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = R.nn.conv2d(lv80, p_getattr_l__self___layer4___1___conv2_weight, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, data_layout=&quot;NCHW&quot;, kernel_layout=&quot;OIHW&quot;, out_layout=&quot;NCHW&quot;, out_dtype=&quot;float32&quot;)
            lv82: R.Tuple(R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;), R.Tensor((512,), dtype=&quot;float32&quot;), R.Tensor((512,), dtype=&quot;float32&quot;)) = R.nn.batch_norm(lv81, p_getattr_l__self___layer4___1___bn2_weight, p_getattr_l__self___layer4___1___bn2_bias, metadata[&quot;relax.expr.Constant&quot;][38], metadata[&quot;relax.expr.Constant&quot;][39], axis=1, epsilon=1.0000000000000001e-05, center=True, scale=True, momentum=0.10000000000000001)
            lv83: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = lv82[0]
            lv84: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = R.add(lv83, lv76)
            lv85: R.Tensor((1, 512, 7, 7), dtype=&quot;float32&quot;) = R.nn.relu(lv84)
            lv86: R.Tensor((1, 512, 1, 1), dtype=&quot;float32&quot;) = R.nn.adaptive_avg_pool2d(lv85, output_size=[1, 1], layout=&quot;NCHW&quot;, out_layout=&quot;NCHW&quot;)
            lv87: R.Tensor((1, 512), dtype=&quot;float32&quot;) = R.reshape(lv86, R.shape([1, 512]))
            lv88: R.Tensor((512, 1000), dtype=&quot;float32&quot;) = R.permute_dims(p_fc_weight, axes=None)
            lv89: R.Tensor((1, 1000), dtype=&quot;float32&quot;) = R.matmul(lv87, lv88, out_dtype=&quot;float32&quot;)
            lv90: R.Tensor((1, 1000), dtype=&quot;float32&quot;) = R.add(lv89, p_fc_bias)
            gv: R.Tuple(R.Tensor((1, 1000), dtype=&quot;float32&quot;)) = (lv90,)
            R.output(gv)
        return gv

# Metadata omitted. Use show_meta=True in script() method to show it.
</pre></div>
</div>
</section>
</section>
<section id="irmodule-optimization">
<h2>IRModule Optimization<a class="headerlink" href="#irmodule-optimization" title="Link to this heading"></a></h2>
<p>Apache TVM Unity provides a flexible way to optimize the IRModule. Everything centered
around IRModule optimization can be composed with existing pipelines. Note that each
transformation can be combined as an optimization pipeline via <code class="docutils literal notranslate"><span class="pre">tvm.ir.transform.Sequential</span></code>.</p>
<p>In this tutorial, we focus on the end-to-end optimization of the model via auto-tuning. We
leverage MetaSchedule to tune the model and store the tuning logs to the database. We also
apply the database to the model to get the best performance.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TOTAL_TRIALS</span></a> <span class="o">=</span> <span class="mi">8000</span>  <span class="c1"># Change to 20000 for better performance if needed</span>
<a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a> <span class="o">=</span> <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class"><span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">Target</span></a><span class="p">(</span><span class="s2">&quot;nvidia/geforce-rtx-3090-ti&quot;</span><span class="p">)</span>  <span class="c1"># Change to your target device</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">work_dir</span></a> <span class="o">=</span> <span class="s2">&quot;tuning_logs&quot;</span>

<span class="c1"># Skip running in CI environment</span>
<a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">IS_IN_CI</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.html#os.getenv" title="os.getenv" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">getenv</span></a><span class="p">(</span><span class="s2">&quot;CI&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;true&quot;</span>
<span class="k">if</span> <span class="ow">not</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">IS_IN_CI</span></a><span class="p">:</span>
    <span class="n">mod</span> <span class="o">=</span> <a href="../../reference/api/python/relax/relax.html#tvm.relax.get_pipeline" title="tvm.relax.get_pipeline" class="sphx-glr-backref-module-tvm-relax sphx-glr-backref-type-py-function"><span class="n">relax</span><span class="o">.</span><span class="n">get_pipeline</span></a><span class="p">(</span><span class="s2">&quot;static_shape_tuning&quot;</span><span class="p">,</span> <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="o">=</span><a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">,</span> <span class="n">total_trials</span><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TOTAL_TRIALS</span></a><span class="p">)(</span><span class="n">mod</span><span class="p">)</span>

    <span class="c1"># Only show the main function</span>
    <span class="n">mod</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="build-and-deploy">
<h2>Build and Deploy<a class="headerlink" href="#build-and-deploy" title="Link to this heading"></a></h2>
<p>Finally, we build the optimized model and deploy it to the target device.
We skip this step in the CI environment.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">IS_IN_CI</span></a><span class="p">:</span>
    <span class="n">ex</span> <span class="o">=</span> <a href="../../reference/api/python/relax/relax.html#tvm.relax.build" title="tvm.relax.build" class="sphx-glr-backref-module-tvm-relax sphx-glr-backref-type-py-function"><span class="n">relax</span><span class="o">.</span><span class="n">build</span></a><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
    <span class="n">dev</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">vm</span> <span class="o">=</span> <a href="../../reference/api/python/runtime/relax_vm.html#tvm.runtime.relax_vm.VirtualMachine" title="tvm.runtime.relax_vm.VirtualMachine" class="sphx-glr-backref-module-tvm-runtime-relax_vm sphx-glr-backref-type-py-class"><span class="n">relax</span><span class="o">.</span><span class="n">VirtualMachine</span></a><span class="p">(</span><span class="n">ex</span><span class="p">,</span> <span class="n">dev</span><span class="p">)</span>
    <span class="c1"># Need to allocate data and params on GPU device</span>
    <span class="n">gpu_data</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">dev</span><span class="p">)</span>
    <span class="n">gpu_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">dev</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">]]</span>
    <span class="n">gpu_out</span> <span class="o">=</span> <span class="n">vm</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">](</span><span class="n">gpu_data</span><span class="p">,</span> <span class="o">*</span><span class="n">gpu_params</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">gpu_out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-how-to-tutorials-e2e-opt-model-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/317a8cc53139718b9a36a16ba052e44b/e2e_opt_model.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">e2e_opt_model.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a4f940a6740cf66055ca729bf25bfbaa/e2e_opt_model.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">e2e_opt_model.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a7dd7652b2ad50f82d7b739ce3645799/e2e_opt_model.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">e2e_opt_model.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="customize_opt.html" class="btn btn-neutral float-right" title="Customize Optimization" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../../get_started/tutorials/ir_module.html" class="btn btn-neutral float-left" title="IRModule" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2024 Apache Software Foundation | All rights reserved</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote">Copyright © 2024 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="../../_static/downloads/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="../../_static/downloads/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>